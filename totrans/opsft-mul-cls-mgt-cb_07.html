<html><head></head><body>
		<div id="_idContainer125">
			<h1 id="_idParaDest-125" class="chapter-number"><a id="_idTextAnchor133"/>7</h1>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor134"/>OpenShift Network</h1>
			<p>As we know, networking can be the cause of big trouble if it is not well designed. From a traditional perspective, the network is the dorsal spine of every infrastructure. Networking equipment such as routers, modems, switches, firewalls, <strong class="bold">Web Application Firewalls</strong> (<strong class="bold">WAFs</strong>), <strong class="bold">Intrusion Detection Systems/Intrusion Prevention Systems</strong> (<strong class="bold">IDSs/IPSs</strong>), proxies, and <strong class="bold">Virtual Private Networks</strong> (<strong class="bold">VPNs</strong>) needs to be totally integrated, deployed, and maintained using best practices to ensure high performance and reliable network infrastructure. In this chapter, we will discuss important concepts related to networking on OpenShift that you need to take into consideration to make the best decisions for your case.</p>
			<p>This chapter covers the following topics:</p>
			<ul>
				<li>OpenShift networking </li>
				<li>Network policies</li>
				<li>What is an Ingress controller?</li>
				<li>Types of routes</li>
			</ul>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor135"/>OpenShift networking</h1>
			<p>Throughout this book, we continue to reaffirm the importance of choosing the right architecture as it directly <a id="_idIndexMarker465"/>impacts the way the cluster will work. We expect that, at this time, all the required network decisions have been made and implemented already – there are a lot of network changes that are not possible after cluster deployment. </p>
			<p>Although we already discussed networks in <a href="B18015_02.xhtml#_idTextAnchor028"><em class="italic">Chapter 2</em></a>, <em class="italic">Architecture Overview and Definitions</em>, and deployed our cluster, we believe that it is important to expand on this topic a bit more and include more details about the differences when considering network usage.</p>
			<p>Red Hat OpenShift uses a default <strong class="bold">Software-Defined Network</strong> (<strong class="bold">SDN</strong>) based on Open vSwitch (<a href="https://github.com/openvswitch/ovs">https://github.com/openvswitch/ovs</a>) that creates a multilayer network solution. This additional layer works as a virtual switch <a id="_idIndexMarker466"/>on top of the network layer, and it is responsible for creating, maintaining, and isolating traffic on the virtual LAN.</p>
			<p>Because of its <a id="_idIndexMarker467"/>multiple-layer network capacity, Open vSwitch provides a way to control traffic coming in and out of the cluster. Refer to the following diagram to better understand network traffic between network layers:</p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B18015_07_01.jpg" alt="Figure 7.1 – Overview of the networking layers "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Overview of the networking layers</p>
			<p>During the OpenShift cluster installation, some namespaces related to network functions are created; basically, the most important network project is <strong class="source-inline">openshift-sdn</strong>, which contains some <a id="_idIndexMarker468"/>pods for each node that will be responsible for the traffic between the nodes. It is relevant to also state that the traffic is running inside a virtual LAN operated by Open vSwitch. There are other network projects involved as well, such as <strong class="source-inline">openshift-host-network</strong> and <strong class="source-inline">openshift-ingress</strong>.</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor136"/>How does traffic work on Open vSwitch?</h2>
			<p>To answer this question, we <a id="_idIndexMarker469"/>need to define where the traffic begins. Let’s start with the internal traffic, which means the communication between the application’s pods that are inside the OpenShift cluster.</p>
			<p>To facilitate your understanding, consider two applications running on OpenShift; the first one is named <strong class="source-inline">app-frontend</strong> and the second <strong class="source-inline">app-backend</strong>. As the name suggests, <strong class="source-inline">app-frontend</strong> makes API calls to <strong class="source-inline">app-backend</strong> to process user requests.</p>
			<p>Therefore, when a pod from the <strong class="source-inline">app-frontend</strong> application makes a request to the <strong class="source-inline">app-backend</strong> application, this request will be sent to the internal service, in this case the <strong class="source-inline">app-backend</strong> service. The <strong class="source-inline">app-backend</strong> service is responsible for delivering that package to one of the <strong class="source-inline">app-backend</strong> pods. In the same way, the application handles its request and sends the result package back to the service network, which, at this point, already has a connection established with <strong class="source-inline">app-frontend</strong>.</p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B18015_07_02.jpg" alt="Figure 7.2 – Service network layer "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Service network layer</p>
			<p>With that, we have briefly explained the traffic between applications inside the cluster. Now, let’s see how external-to-internal traffic is handled. When a request comes from outside the cluster, it <a id="_idIndexMarker470"/>goes initially to the external load balancer. As the load balancer receives a connection, it routes the request to one of the <em class="italic">OpenShift Ingress</em> pods, which sends it to the service of the destination application, which, in turn, routes it to the proper application’s pod.</p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> </p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B18015_07_03.jpg" alt="Figure 7.3 – Route SDN networking "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Route SDN networking</p>
			<p>Now that you understand how traffic works in an OpenShift cluster, it is important to reinforce that OpenShift basically works with three network layers: the node network, the service network, and the cluster network (aka the pods network).</p>
			<p>The <strong class="bold">node network</strong> is the physical <a id="_idIndexMarker471"/>network used to create and maintain machines. The <strong class="bold">service network</strong> is a virtual layer created by Open vSwitch that is responsible for routing traffic between <a id="_idIndexMarker472"/>pods and services. The <strong class="bold">cluster network</strong> is another Open <a id="_idIndexMarker473"/>vSwitch virtual layer responsible for creating subnets for the communication of pods – it allows isolating traffic between projects as needed.</p>
			<p>In the next sections, we will look deeper into the main available networking plugins for OpenShift. Keep in mind that <a id="_idIndexMarker474"/>there are subtle differences between the aforementioned plugins, so the decision between using one plugin and another must be taken into account according to the differences in functionality, which can somewhat affect the architecture of the cluster, and also the network functionality available to the applications. This is a decision that must be made together with the network and software architecture team, to understand the current use cases and planned future implementations, aiming for an efficient and functional cluster.</p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor137"/>Network type – OpenShift SDN or OVN-Kubernetes</h2>
			<p>OpenShift is a complete <a id="_idIndexMarker475"/>PaaS solution based on Kubernetes that provides several options other than its default components. For instance, OpenShift, by default, uses the Open vSwitch network <a id="_idIndexMarker476"/>plugin (OpenShift SDN), but you can use <strong class="bold">OVN-Kubernetes</strong> as an alternative. </p>
			<p>A network plugin is a feature that creates an overlay <a id="_idIndexMarker477"/>network using the Kubernetes <strong class="bold">Container Network Interface</strong> (<strong class="bold">CNI</strong>) that isolates the traffic between the virtual machines network and the OpenShift nodes.</p>
			<p>These two supported options offer a good and reliably performing network, but you can use other kinds of CNI depending on the scenario where OpenShift has been provisioned. Check the link for <em class="italic">OpenShift Tested Integrations</em> in the <em class="italic">Further reading</em> section of this chapter to see the options that are tested and supported by Red Hat.</p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor138"/>Network policies</h1>
			<p>As we already mentioned, OpenShift uses an SDN, and preferably, the network traffic control should be done <a id="_idIndexMarker478"/>using the features the cluster provides itself. In our experience, having implemented OpenShift in many organizations, we have often heard doubts regarding how to control network traffic within the cluster, as most customers are used to doing it by using regular firewall devices. In this section, we will walk you through how to control network traffic to be able to allow or deny network traffic as needed. Before giving you some options to do that, we first need to differentiate the different traffic directions that we have in a cluster.</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor139"/>North-south traffic</h2>
			<p>OpenShift has been designed to cover the <a id="_idIndexMarker479"/>most common scenarios, even regarding networking. When an incoming connection comes from outside the cluster to an application, it is possible to control network traffic into the cluster using an external firewall and/or the <strong class="bold">OpenShift Ingress</strong> solution.</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor140"/>East-west traffic</h2>
			<p>Initially, it may sound a little weird to say that there is also network traffic in east-west directions but east-west network <a id="_idIndexMarker480"/>traffic is nothing more than traffic between applications in different namespaces inside the same OpenShift cluster.</p>
			<p>The following diagram explains how these different types of traffic occur in a cluster:</p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> </p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B18015_07_04.jpg" alt="Figure 7.4 – North-south/east-west traffic flow "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – North-south/east-west traffic flow</p>
			<p>You have seen the <a id="_idIndexMarker481"/>possible directions in which the traffic on the network can be controlled. In the next section, you will see how to control the network traffic in the cluster.</p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor141"/>Controlling network traffic</h2>
			<p>There are different options for <a id="_idIndexMarker482"/>controlling traffic on OpenShift:</p>
			<ul>
				<li>For north-south traffic, you can either use an external firewall and load balancer to control the traffic before getting into the OpenShift cluster or use annotations in the OpenShift <strong class="bold">route</strong> object to control aspects such as the rate limit, timeout, and load balancing algorithm.</li>
				<li>Use a proper <strong class="bold">network policy</strong> to allow or deny a traffic flow, as needed.</li>
				<li>Use the <strong class="bold">ovs-multitenant</strong> network isolation<a id="_idIndexMarker483"/> mode. This mode was commonly used on OpenShift version 3 but is not encouraged on version 4, as the Network Policy plugin has become the standard.</li>
				<li>If you intend to use microservices with OpenShift, you may also choose to use a <strong class="bold">service mesh</strong> to control the <a id="_idIndexMarker484"/>east-west traffic, which uses the <strong class="bold">istio-proxy</strong> sidecar to give the lowest granularity of isolation mode. Service meshes are not the focus of this book, but if you want more information on them, check out the <em class="italic">Further reading</em> section of this chapter.</li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">If you used to use <strong class="bold">ovs-multitenant</strong> on OpenShift 3.x and want to have similar functionality on version 4.x, we recommend you customize the project template, adding network policies to block traffic between different projects by default. The process to do that is simple and described at this link: <a href="https://docs.openshift.com/container-platform/latest/networking/network_policy/default-network-policy.html">https://docs.openshift.com/container-platform/latest/networking/network_policy/default-network-policy.html</a>.</p>
			<p>In this chapter, we will focus on Network Policy, as this is the standard network plugin on OpenShift 4. See next how to create a network policy to control the network traffic.</p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor142"/>Creating a network policy</h2>
			<p>As we already mentioned, with<a id="_idIndexMarker485"/> network policies, you can define rules to allow or block ingress network traffic in a cluster. With a network policy, you can, for instance, allow traffic between pods inside the same namespace but deny it from other namespaces. You may also allow traffic only on a specific port, and so on. Therefore, for a better understanding of network policies and the directions in which traffic is and isn’t allowed to flow, we will provide several diagrams and scenarios to clarify the importance of namespace isolation.</p>
			<p>For learning purposes, we will use three namespaces, named <strong class="source-inline">bluepets</strong>, <strong class="source-inline">greenpets</strong>, and <strong class="source-inline">otherpets</strong>. In the following diagram, we are illustrating the default <strong class="bold">network policy</strong>, which allows traffic between namespaces and traffic from a cluster ingress by default:</p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B18015_07_05.jpg" alt="Figure 7.5 – Default network policy – allow all "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – Default network policy – allow all</p>
			<p>So, let’s go ahead and demonstrate <a id="_idIndexMarker486"/>connections allowed to these two namespaces: <strong class="source-inline">bluepets</strong> and <strong class="source-inline">greenpets</strong>. To facilitate your understanding, we are running tests in an external network with no direct route to the <strong class="bold">service network</strong>, which is the <a id="_idIndexMarker487"/>only routable network from our cluster. So, to simulate all scenarios, we access the pod using <strong class="source-inline">rsh</strong> on the <strong class="source-inline">greenpets</strong> namespace and try to reach the service IP of the <strong class="source-inline">bluepets</strong> namespace in our lab scenario discussed previously.</p>
			<p>Before going into that, we must get the service IPs from both the namespaces to use later in the pod terminal and check the results accordingly.</p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B18015_07_06.jpg" alt="Figure 7.6 – Service IPs – bluepets and greenpets namespaces "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.6 – Service IPs – bluepets and greenpets namespaces</p>
			<p>Take a look at the following <a id="_idIndexMarker488"/>screenshot. We <strong class="source-inline">rsh</strong> a pod under the <strong class="source-inline">greenpets</strong> namespace and run <strong class="source-inline">curl</strong> on the following endpoints:</p>
			<ul>
				<li>The service IP in <strong class="source-inline">greenpets</strong> (the same namespace): To check connectivity between a pod and service in the same namespace (highlighted with a green square in the following screenshot).</li>
				<li>The service IP in <strong class="source-inline">bluepets</strong> (a different namespace): We similarly call the service IP of the <strong class="source-inline">bluepets</strong> namespace and it also works fine (highlighted with a blue square in the following screenshot).</li>
			</ul>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B18015_07_07.jpg" alt="Figure 7.7 – Testing connectivity between two namespaces "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.7 – Testing connectivity between two namespaces</p>
			<p>In our next scenario, we will block all traffic on the <strong class="source-inline">greenpets</strong> namespace, for which the diagram looks like the<a id="_idIndexMarker489"/> following:</p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B18015_07_08.jpg" alt="Figure 7.8 – greenpets namespace – denying all traffic "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.8 – greenpets namespace – denying all traffic</p>
			<p>To accomplish this scenario, we apply a network policy manifest on the <strong class="source-inline">greenpets</strong> namespace:</p>
			<pre class="source-code">$ cat &lt;&lt; EOF &gt;&gt; block-everything-to-namespace.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-by-default
spec:
  podSelector:
  ingress: []
EOF
$ oc –n greenpets apply –f block-everything-to-namespace.yaml</pre>
			<p>Now, let’s perform the same tests <a id="_idIndexMarker490"/>again to demonstrate that all network traffic in <strong class="source-inline">greenpets</strong> (route and service) is denying connections:</p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B18015_07_09.jpg" alt="Figure 7.9 – Deny all traffic test "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.9 – Deny all traffic test</p>
			<p>Now, we will go deeper and apply a rule that only allows traffic from ingress to flow to pods under the <strong class="source-inline">greenpets</strong> namespace. To do so, we are going to apply the following YAML file:</p>
			<pre class="source-code">$ cat &lt;&lt; EOF &gt;&gt;allow-ingress-to-namespace.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-openshift-ingress
spec:
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          network.openshift.io/policy-group: ingress
  podSelector: {}
  policyTypes:
  - Ingress
EOF
$ oc –n greenpets  apply –f allow-ingress-to-namespace.yaml</pre>
			<p>What this NP does is to only<a id="_idIndexMarker491"/> allow pods in the ingress namespace to communicate with pods in the <strong class="source-inline">greenpets</strong> namespace, all other traffic will be blocked. Check out the following diagram and notice that <em class="italic">east-west</em> traffic between namespaces is denied, but <em class="italic">north-south</em> traffic is allowed:</p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B18015_07_10.jpg" alt="Figure 7.10 – greenpets namespace traffic only allowed for Ingress connections (external route) "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.10 – greenpets namespace traffic only allowed for Ingress connections (external route)</p>
			<p>Notice now that the network <a id="_idIndexMarker492"/>communication between the external route (ingress) and the service is working; however, traffic between <strong class="source-inline">bluepets</strong> and <strong class="source-inline">greenpets</strong> is denied.</p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B18015_07_11.jpg" alt="Figure 7.11 – Testing network traffic. 1) From bluepets namespace to greenpets namespace: Connection denied. 2) From external route (ingress) to greenpets namespace: Connection allowed. "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.11 – Testing network traffic. 1) From bluepets namespace to greenpets namespace: Connection denied. 2) From external route (ingress) to greenpets namespace: Connection allowed.</p>
			<p>Finally, we will take a look at <a id="_idIndexMarker493"/>the most common scenario: the least isolation configuration. This network policy scenario is based on a namespace label that we will apply in the <strong class="source-inline">greenpets</strong> namespace and will work as a key to configure the communication between namespaces.</p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B18015_07_12.jpg" alt="Figure 7.12 – Labeled namespaces allowing traffic "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.12 – Labeled namespaces allowing traffic</p>
			<p>Looking at the previous diagram, you can see three different namespaces, <strong class="source-inline">bluepets</strong>, <strong class="source-inline">greenpets</strong>, and <strong class="source-inline">otherpets</strong>. A network policy will be applied to the <strong class="source-inline">greenpets</strong> namespace, which will use a label with the <strong class="source-inline">join=greenpets</strong> value. In other words, it means that only elements<a id="_idIndexMarker494"/> in namespaces labeled with <strong class="source-inline">join=greenpets</strong> can communicate with the application in the <strong class="source-inline">greenpets</strong> namespace. To implement this, we will apply the following manifest and commands:</p>
			<pre class="source-code">$ cat &lt;&lt; EOF &gt;&gt; allow-namespace-by-label.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-namespace-label
spec:
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          join: greenpets
  podSelector: {}
EOF
$ oc –n greenpets apply –f allow-namespace-by-label.yaml
$ oc label namespace bluepets join=greenpets</pre>
			<p>Now, check the connectivity between the namespaces <strong class="source-inline">bluepets</strong> and <strong class="source-inline">greenpets</strong> by running the following test:</p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B18015_07_13.jpg" alt="Figure 7.13 – Testing labeled namespace. Connection to a namespace that contains the proper label – connection allowed "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.13 – Testing labeled namespace. Connection to a namespace that contains the proper label – connection allowed</p>
			<p>In <em class="italic">Figure 7.13,</em> you see that the <a id="_idIndexMarker495"/>connection was allowed as the namespace contains the label <strong class="source-inline">join=greenpets</strong>. However, in <em class="italic">Figure 7.14</em>, you can see the connection is denied, as the traffic flows from a namespace (<strong class="source-inline">otherpets</strong>) that doesn’t contain this label.</p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/B18015_07_14.jpg" alt="Figure 7.14 – Testing non-labeled namespace denying traffic "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.14 – Testing non-labeled namespace denying traffic</p>
			<p>Network policy is an important tool to isolate network traffic. It is important you consider the challenges that certain types of rules may bring, though. If not properly designed, standardized, and adopted, they may cause you headaches by allowing what should be blocked and blocking what shouldn’t be.</p>
			<p>Also, you have to consider which<a id="_idIndexMarker496"/> types of workload will run in your cluster. For microservice-oriented applications, for instance, we recommend you look at the <strong class="bold">Istio service mesh</strong>, which<a id="_idIndexMarker497"/> in general is more appropriate and will bring more granular network access control.</p>
			<p>So far, you have learned the definitions and important concepts of SDNs, such as controlling traffic in horizontal and vertical directions by applying policies using labels. Continue, next, to see more about routes and ingress controllers and learn how to use them for your applications.</p>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor143"/>What is an ingress controller?</h1>
			<p>An <strong class="bold">Ingress controller</strong> is a lightweight, self-healing<a id="_idIndexMarker498"/> load balancer that distributes network traffic from outside the cluster to a network service. Using an Ingress controller is a standard approach for providing and managing ingress traffic to containerized applications. The default ingress controllers on OpenShift use the mature and stable <strong class="bold">HAProxy</strong> under the hood. In OpenShift, when you deploy a cluster, the ingress controller is automatically created and hosted in two worker nodes by default.</p>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor144"/>How does an ingress operator work?</h2>
			<p>An Ingress operator acts<a id="_idIndexMarker499"/> similarly to almost all cluster operators in OpenShift: protecting the important settings of the operation of a cluster. The operator monitors the ingress pods running in the <strong class="source-inline">openshift-ingress</strong> namespace and protects the <strong class="source-inline">IngressController</strong> objects from wrong and non-compatible settings that can lead to problems with the cluster network.</p>
			<p>Otherwise, you can create others <strong class="source-inline">IngressController</strong> objects in addition to the default one to isolate the traffic of <a id="_idIndexMarker500"/>certain groups of applications, using what is named <strong class="bold">router sharding</strong>.</p>
			<p>Different from traditional networking configuration, in which you need complex routing tables and firewall configuration, OpenShift abstracts this complex networking layer configuration, making it a much easier task. </p>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor145"/>Creating a new ingress controller</h2>
			<p>To create a new ingress <a id="_idIndexMarker501"/>controller, you must take the following steps:</p>
			<ol>
				<li>Define at least two nodes to host the new ingress controller.</li>
				<li>Apply a new label to nodes.</li>
				<li>Export the default <strong class="source-inline">IngressController</strong> object.</li>
				<li>Change the name and desired settings of the newly created YAML manifest file.</li>
				<li>Deploy the new <strong class="source-inline">IngressController</strong> object by applying the YAML created previously.</li>
			</ol>
			<p>You can see in the following lines an example of the process mentioned previously:</p>
			<pre class="source-code"># Apply labels to nodes
$ oc label node &lt;node1&gt; &lt;node2&gt; .. &lt;nodeN&gt; new-ingress=true
$ oc get ingresscontroller default -n openshift-ingress-operator -o yaml &gt; new-ingress.yaml
$ vi new-ingress.yaml
# Remove unnecessary fields to make the yaml looks like 
# the following one
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  name: new-ingress <strong class="bold">[1]</strong>
  namespace: openshift-ingress-operator
spec:
  domain: apps.env.hybridmycloud.com <strong class="bold">[2]</strong>
  replicas: 2
  nodePlacement:
    nodeSelector:
      matchLabels:
        new-ingress: "true" <strong class="bold">[3]</strong>
  routeSelector: <strong class="bold">[4]</strong>
    matchLabels:
      type: sharded <strong class="bold">[5]</strong></pre>
			<p>In the previous code, we<a id="_idIndexMarker502"/> have highlighted some parts with numbers. Let’s take a look:</p>
			<p><em class="italic">[1]: New IngressController name.</em></p>
			<p><em class="italic">[2]: DNS domain for the new ingress.</em></p>
			<p><em class="italic">[3]: A label that defines where the IngressController pods will run.</em></p>
			<p><em class="italic">[4]: To implement shards. It can be namespaceSelector or routeSelector.</em></p>
			<p><em class="italic">[5]: Used to filter the set of routes that are served by this IngressController.</em></p>
			<p class="callout-heading">Namespace or Route Selector?</p>
			<p class="callout">The example you have seen uses the <strong class="source-inline">routeSelector</strong>. There is an alternative way to configure the IngressController, which is using <strong class="source-inline">namespaceSelector</strong>. It may seem confusing to define the right selector for your case, but it is not – <strong class="source-inline">routeSelector</strong> is a more granular option, allowing you to publish routes to different IngressControllers in the same namespace. The main decision factor is if, in your case, you need to be able to publish routes of a single namespace in different IngressControllers, you have to use <strong class="source-inline">routeSelectors</strong>. Otherwise, you will most likely use <strong class="source-inline">namespaceSelectors</strong>. </p>
			<p class="callout">For example, consider a namespace called <strong class="source-inline">APP</strong> that contains two different routes: </p>
			<p class="callout">Route A published in router 1 with the URL <strong class="source-inline">app1.prod.hybridmycloud.com</strong></p>
			<p class="callout">Route B published in router 2 with the URL <strong class="source-inline">app1.qa.hybridmycloud.com</strong></p>
			<p class="callout">This scenario is only possible if you use <strong class="source-inline">routeSelector</strong>. However, this is an unusual scenario; usually, routes in a single namespace are always published in the same IngressController, so for that reason, it is also very common to use <strong class="source-inline">namespaceSelector</strong>.</p>
			<p>As previously <a id="_idIndexMarker503"/>mentioned, router sharding is a technique that allows creating an ingress for the purpose of segregating traffic, whether due to the need for isolation between environments or even for the traffic of a given application to be fully directed from this new ingress.</p>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor146"/>Testing the new ingress</h2>
			<p>After the ingress pods<a id="_idIndexMarker504"/> are created on the nodes, you can test the newly created ingress. We will create a route using the sample application named <strong class="source-inline">hello-openshift</strong> and apply the proper route selector label. Follow these steps to accomplish this task:</p>
			<pre class="source-code">$ oc new-project hello-openshift
$ oc create -f https://raw.githubusercontent.com/openshift/origin/master/examples/hello-openshift/hello-pod.json
$ oc expose pod/hello-openshift
$ oc expose svc hello-openshift
$ oc label route hello-openshift type=sharded</pre>
			<p>The last line of the previous block of commands explicitly sets the <strong class="source-inline">type=sharded</strong> label, which we used in our example for <strong class="source-inline">routeSelector</strong>. When OpenShift sees this label, it will automatically publish this route in the new ingress.</p>
			<p>Continue on to the<a id="_idIndexMarker505"/> following section to get a full understanding of how to use the recently created ingress with what is called a <strong class="bold">route</strong> in OpenShift.</p>
			<h1 id="_idParaDest-139"><a id="_idTextAnchor147"/>Types of routes</h1>
			<p>Routes are the representation of a <a id="_idIndexMarker506"/>configuration on an ingress internal load balancer for a specific application to expose a Kubernetes service to a DNS name, such as <strong class="source-inline">example.apps.env.hybridmycloud.com</strong>. When a route is created, OpenShift automatically configures a frontend and backend in the Ingress’ HAProxy pod to publish the URL and make the traffic available from the outside world.</p>
			<p>Routes can be published using either the HTTP or HTTPS protocol. For HTTPS, three different types of routes define how the TLS termination works in the SSL stream between the user and the pod. In the following subsections, we will walk you through each of them.</p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor148"/>Passthrough routes</h2>
			<p>A <strong class="bold">passthrough route</strong>, as the name <a id="_idIndexMarker507"/>suggests, is a configuration in which the packages are forwarded straight to the network service without doing a TLS termination, acting <a id="_idIndexMarker508"/>as a Layer 4 load balancer. Passthrough is often used with applications that provide their own TLS termination inside the application’s pod, either by implementing it in the source code or using a middleware layer (such as JBoss or WebSphere).</p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/B18015_07_15.jpg" alt="Figure 7.15 – Passthrough route  "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.15 – Passthrough route </p>
			<p>Next, you'll see the<a id="_idIndexMarker509"/> second option you<a id="_idIndexMarker510"/> have: edge route.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor149"/>Edge routes</h2>
			<p>In this route, the TLS termination is<a id="_idIndexMarker511"/> handled by OpenShift ingress and forwarded to the <a id="_idIndexMarker512"/>service as clear text. This kind of route is used very often as it is easy to use: a self-signed certificate automatically generated by OpenShift is applied to the ingress and it signs all the routes that use the default wildcard domain – this is performed by OpenShift automatically; no additional configuration is needed. However, you can replace the self-signed certificate with a custom digital certificate, if you don’t want to use the default self-signed certificate. </p>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="image/B18015_07_16.jpg" alt="Figure 7.16 – Edge route "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.16 – Edge route</p>
			<p>An edge route is the most common and easy-to-implement model since the certificate chain terminates at the<a id="_idIndexMarker513"/> edge of the OpenShift network, which is the ingress. It is important to<a id="_idIndexMarker514"/> highlight that the traffic between the ingress and the application pods is not encrypted but occurs inside the OpenShift SDN, which means that the network packages are encapsulated using OVS. The last method available is reencrypted routes. You'll see how it works next.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor150"/>Reencrypted routes</h2>
			<p>Reencrypted routes offer two<a id="_idIndexMarker515"/> layers of TLS termination: traffic is decrypted using the certificate for the external FQDN (for example, <strong class="source-inline">example.apps.env.hybridmycloud.com</strong>) at the cluster edge (OpenShift Ingress), and then the traffic is re-encrypted again, but now using a different certificate. While this is a secure route, it has also a<a id="_idIndexMarker516"/> performance penalty due to the termination and re-encryption operation performed by the ingress.</p>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/B18015_07_17.jpg" alt="Figure 7.17 – Reencrypted route "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.17 – Reencrypted route</p>
			<p>A reencrypted route takes a similar approach as an edge route but it goes through two layers of CAs. The first is<a id="_idIndexMarker517"/> related to the external public domain, for example, <em class="italic">hybridcloud.com</em>, and then the<a id="_idIndexMarker518"/> second layer of encryption is internal, known by OpenShift Ingress and the application.</p>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor151"/>Summary</h1>
			<p>We have seen in this chapter some of the important aspects related to the OpenShift network. Now you are familiar with the two types of network plugins supported with OpenShift, OpenShift SDN and OVN-Kubernetes, and the different kinds of traffic you need to care about when managing the platform’s network. You have also seen how the ingress controller works, how to create a new one, and the three different types of secure routes you may use with your applications: passthrough, edge, and reencrypted.</p>
			<p>You navigated through network policies to learn a bit more about how to control traffic and provide network isolation.</p>
			<p>As you know, security is a real concern in today's digital world. In the next chapter, we will cover important aspects you need to consider about security on OpenShift. So, go ahead and check it out!</p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor152"/>Further reading</h1>
			<p>If you want more information related to the concepts we covered in this chapter, check out the following references:</p>
			<ul>
				<li><em class="italic">Kubernetes Ingress controller</em>: <a href="https://www.nginx.com/resources/glossary/kubernetes-ingress-controller">https://www.nginx.com/resources/glossary/kubernetes-ingress-controller</a></li>
				<li><em class="italic">HAProxy documentation</em>: <a href="https://www.haproxy.com/documentation/hapee/latest/onepage/">https://www.haproxy.com/documentation/hapee/latest/onepage/</a></li>
				<li><em class="italic">Annotations used to override a route’s default configuration</em>: <a href="https://docs.openshift.com/container-platform/4.10/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration">https://docs.openshift.com/container-platform/4.10/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration</a></li>
				<li><em class="italic">Configuring ingress cluster traffic using an Ingress controller</em>: <a href="https://docs.openshift.com/container-platform/4.10/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html">https://docs.openshift.com/container-platform/4.10/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html</a></li>
				<li><em class="italic">Creating secured routes</em>: <a href="https://docs.openshift.com/container-platform/4.10/networking/routes/secured-routes.html">https://docs.openshift.com/container-platform/4.10/networking/routes/secured-routes.html</a></li>
				<li><em class="italic">OpenShift Tested Integrations</em>: <a href="https://access.redhat.com/articles/4128421">https://access.redhat.com/articles/4128421 </a></li>
				<li><em class="italic">Service mesh</em>: <a href="https://docs.openshift.com/container-platform/4.10/service_mesh/v2x/servicemesh-release-notes.html">https://docs.openshift.com/container-platform/4.10/service_mesh/v2x/servicemesh-release-notes.html</a></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer126">
			</div>
		</div>
</body></html>