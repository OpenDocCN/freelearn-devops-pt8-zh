- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing CI/CD for AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to build an end-to-end solution, similar to the
    previous chapter, but it will target the **Amazon Web Services** (**AWS**) cloud
    platform, deploy the same applications, and promote them from a test environment
    to a production environment. This chapter showcases the flexibility of Azure Pipelines
    to adapt to your environment needs, no matter the destination, allowing for similar
    CI/CD capabilities with a different cloud provider and the ability to still be
    able to control the process all the way through.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the solution architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and packaging applications and IaC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a Python catalog service to **Elastic Kubernetes** **Service** (**EKS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a Node.js cart service to **Fargate**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a .NET checkout service to **Elastic Container** **Service** (**ECS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an Angular frontend app to **Lightsail**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we jump right in, let’s take care of some technical requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code for this chapter at [https://github.com/PacktPublishing/Implementing-CI-CD-Using-Azure-Pipelines/tree/main/ch10](https://github.com/PacktPublishing/Implementing-CI-CD-Using-Azure-Pipelines/tree/main/ch10).
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete the tasks described in this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Access to an AWS account and service connection**: It is assumed that you
    completed the *Access to an AWS account* and *Creating a service connection to
    AWS* sections in [*Chapter 8*](B18875_08.xhtml#_idTextAnchor103). If you skipped
    these, please go back and complete those steps to be able to complete this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The sample repository imported**: It is also assumed that you have already
    imported the sample repository from GitHub. If you haven’t done so, check out
    [*Chapter 9*](B18875_09.xhtml#_idTextAnchor135) to learn how to complete this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If at any moment you get stuck while working on the pipelines, review the complete
    code available in the **complete** branch.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the technical requirements covered, let’s review the solution
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining the solution architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For our solution, we will use the same fictitious Packt Store from [*Chapter
    9*](B18875_09.xhtml#_idTextAnchor135). However, in this chapter, this has been
    adapted to host the applications in different AWS services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Solution diagram](img/B18875_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Solution diagram
  prefs: []
  type: TYPE_NORMAL
- en: 'We will implement Azure Pipelines by performing the following steps for each
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: Build and package the application and corresponding IaC.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy to a test environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy to a production environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automate environment deployment checks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following diagram depicts the CI/CD process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – The CI/CD process](img/B18875_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – The CI/CD process
  prefs: []
  type: TYPE_NORMAL
- en: During this chapter, we will not cover any details about the code in the applications
    as that is not relevant to CI/CD. Instead, we will focus on the Azure Pipelines
    details that are needed to make this work.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement the CI/CD process, we will be taking advantage of multi-stage
    pipelines with environments and templates, as we did in the previous chapter.
    Let’s get started with the following pipeline definition in `ch10/aws/aws-pipeline.yml`.
    This can be found inside the `Implementing-CI-CD-Using-Azure-Pipeline` repository
    we imported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this pipeline definition is the same as what we used in the
    previous chapter, so it will work in the same way as the previous chapter. However,
    `build-apps.yml`, `build-iac.yml`, and `deploy.yml` will be different. Once the
    file is in the repository, add it as a new pipeline and rename it `E2E-AWS`. We
    will have to add some security configuration for everything to work at the end,
    such as approving the deployment to different environments, similar to what we
    did in [*Chapter 9*](B18875_09.xhtml#_idTextAnchor135).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to the build stage.
  prefs: []
  type: TYPE_NORMAL
- en: Building and packaging applications and IaC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The applications in this solution are all container-enabled, as we saw in the
    previous chapter. So, in this chapter, we will go through the steps of building
    and pushing the container images to Amazon `docker-compose.yml` file.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the `docker-compose.yml` file remains the same, which means that
    building the applications with containers allows for flexibility and ease of deployment
    into numerous destinations.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s create the repositories that are needed in ECR.
  prefs: []
  type: TYPE_NORMAL
- en: Creating ECR repositories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, an ECR registry is available when you create an account in AWS,
    but you are responsible for creating the repositories for each of your images
    in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do this easily with the following AWS CLI commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: With this in place, let’s move on and build the applications in the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the build apps job
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s create the `e2e/pipelines/aws/build-apps.yml` file with the content described
    in this section. We have broken it into two sections for easier reading.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first section simply defines the parameters, job header, and the only step
    needed. This uses the `AWSShellScript@1` task for a custom script that needs to
    be running in the context of the AWS CLI. This must be authenticated with AWS
    via the service connection we created previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'With this in place, let’s describe the custom script that’s needed to log into
    ECR, build the containers, and tag and push each of them to ECR. The content of
    the script must be aligned properly with the preceding YAML within the `inlineScript`
    property for it to work correctly. This means that all lines must be exactly two
    spaces after the column where this property starts. It is only presented in this
    way in this chapter for ease of reading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s break this code block down:'
  prefs: []
  type: TYPE_NORMAL
- en: The `L` and `ID` variables represent the AWS region and AWS account ID, both
    of which are needed to build the commands to log into ECR, tag images, and push
    them to ECR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Logging into ECR is a two-step operation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieve a login token from the ECR service.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `docker login` command, which allows you to use the `docker` and `docker-compose`
    utilities in the next steps.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The build of the images uses the `docker-compose build` command, which in this
    context will use the existing `docker-compose.yaml` file in the repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last step is a loop over two arrays, defining the names of services and
    tags to use to apply the `docker tag` and `docker` `push` commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might be wondering why we didn’t use the `DockerCompose@0` task like we
    did in [*Chapter 9*](B18875_09.xhtml#_idTextAnchor135). The reason for this is
    the types of container registries supported by this task and the authentication
    mechanism supported by ECR in AWS. The `DockerCompose@0` task supports Azure Container
    Registry and the generic Docker Registry. For the latter, you could use a Docker
    Registry service connection, but the authorization tokens provided by ECR are
    short-lived, lasting only 12 hours. This would force you to update the service
    connection periodically.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, this approach, which uses the `AWSShellScript@1` task and a custom
    script, takes advantage of the existing AWS service connection and negotiates
    a new password every time it runs, storing it locally during the build phase and
    making it possible to have a maintenance-free setup.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our container images available, let’s work to verify and package
    the infrastructure as code.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying and packaging IaC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We learned how to work with AWS CloudFormation templates in the previous chapter,
    Now, we need to validate the templates and publish them as artifacts to the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we will create a `build-iac.yml` file in the repository and add
    the following six segments to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '`aws-pipeline.yaml` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Jobs**: Here, we just add the header for the following segments, all of which
    are a series of steps to validate and publish the IaC artifacts that are required
    for the deployment of each application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Catalog service IaC**: Add the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s break it down:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The script task with `displayName` `'Lint Catalog Helm Chart'` validates the
    Helm chart
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `HelmInstaller@1` task installs the Helm tool
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `HelmDeploy@0` task is used to package the Helm chart
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `PublishPipelineArtifact@1` task is then used to publish the Helm chart
    artifact to be used for deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cart service IaC**: The following code is added:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s break it down:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `AWSCLI@1` task is used to validate the AWS CloudFormation stack template
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `PublishPipelineArtifact@1` task is then used to publish the AWS CloudFormation
    stack template artifact to be used for deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Checkout service IaC**: Add the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s break it down:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `AWSCLI@1` task is used to validate the AWS CloudFormation stack template
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `PublishPipelineArtifact@1` task is then used to publish the AWS CloudFormation
    stack template artifact to be used for deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frontend application IaC**: The code to be added is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s break it down:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `AWSCLI@1` task is used to validate the AWS CloudFormation stack template
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `PublishPipelineArtifact@1` task is then used to publish the AWS CloudFormation
    stack template artifact to be used for deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: With our IaC artifacts build phase complete, we can move on to environment deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Managing environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn about how to create environments and deploy IaC
    and applications to them. First, let’s configure our environment.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we did in [*Chapter 9*](B18875_09.xhtml#_idTextAnchor135), you will need
    to create two environments named `awstest` and `awsproduction` to complete this
    chapter. Once you have created these two environments, we can proceed with the
    deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will deploy these two environments by creating a `deploy.yml` file and start
    by adding the steps needed for each application. This file will start with the
    following content; we will be adding to it in every section hereafter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `parameters` section defines all the values that can be reused within the
    pipeline definition, with `envName` being the only one used from the main pipeline,
    but this gives you the flexibility to change them when needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `jobs` collection includes the `deployment` job type, which allows us to
    implement different rollout strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: For simplicity, here, we use the `runOnce` strategy, but you can also use `canary`
    and `rolling` where appropriate. With this in place, let’s move on to the applications.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Python catalog service to EKS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deploying to EKS has become increasingly complex recently. To make things easier,
    AWS recommends using **eksctl**, an open source CLI tool created by **WeaveWorks**.
    This is a simple CLI tool for creating clusters on EKS that’s written in the **Go**
    language and uses CloudFormation templates while following best practices. It
    handles creating or updating clusters, adding node groups, and other intermediary
    tasks to wait for cluster readiness that you would otherwise have to script yourself.
    To learn more about eksctl, go to [https://eksctl.io](https://eksctl.io).
  prefs: []
  type: TYPE_NORMAL
- en: Every section from here on is displayed aligned to the left. However, in the
    `deploy.yml` file, they must be aligned so that they start in the same position
    as the last `steps:` instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `download` task retrieves the catalog Helm chart pipeline artifact:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `HelmInstaller@1` task installs Helm in the agent:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `AWSShellScript@1` task is used to coordinate a series of steps in a custom
    script while using the existing AWS service connection:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The script does the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Installs the `eksctl` tool
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates a simple EKS cluster
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Installs the catalog Helm chart
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieves the hostname of the AWS Elastic Load Balancer that was created for
    the catalog service
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sets an environment variable, `CatalogUrl`, with the properly formed URL of
    the catalog service to be used in the frontend deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, you could store the custom script in a shell script file in the
    repository, use the `filePath` option for the `scriptType` property, and provide
    the path to the file in the `filePath` property. Refer to [https://docs.aws.amazon.com/vsts/latest/userguide/awsshell.xhtml](https://docs.aws.amazon.com/vsts/latest/userguide/awsshell.xhtml)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are done with the catalog service, it is time to move on to the
    cart service.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Node.js cart service to Lightsail
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cart service will be deployed to the Lightsail service, which is a compute
    resource that’s managed by AWS for running containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will allow you to complete the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `download` task retrieves the catalog Helm chart pipeline artifact:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `CloudFormationCreateOrUpdateStack@1` task creates the infrastructure required
    to run the service. The URL of the cart service will be automatically parsed and
    made available as an environment variable, in this case in the `CartUrl` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `AWSShellScript@1` task performs the application deployment by doing the
    following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connecting the service to the `packt-store-cart` private registry
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a deployment with the corresponding container version
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Waiting for the deployment to complete by checking its state
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s take a look at the code that’s used to do this. You will notice that
    it has been broken into sections for easier understanding:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following lines simply echo the parameters to the console to confirm their
    values while the pipeline is running:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Adding private registry access requires executing a CLI command and waiting
    for a property to be updated to confirm that the principal ARN has been assigned.
    This requires executing another CLI command to check this every 5 seconds:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Applying the **Elastic Container Policy** (**ECR**) requires deleting any existing
    one and then setting the new one:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: The preceding section will execute a CLI command every 5 seconds to wait for
    the Lightsail service to complete updates before we can proceed further. This
    is required because the CLI command we executed previously to assign access to
    the private registry takes a while to complete. This will ensure that we don’t
    try to create a deployment while the service is still updating.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, while using a CLI command to create the deployment and waiting for
    it to complete in the pipeline, ensure any further steps that require the service
    to be running do not fail:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Now that we are done with the cart service, let’s move on to the checkout service.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the .NET checkout service to ECS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For this, we must create a task execution IAM role. First, let’s create an
    `ecs-tasks-trust-policy.json` file with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following commands will create an IAM role and attach a policy that’s needed
    to run the container image in the private registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'With this complete, we can move on to the content for the `deploy.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `download` task retrieves the checkout IaC pipeline artifact:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `CloudFormationCreateOrUpdateStack@1` task creates the infrastructure required
    to run the service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The URL of the checkout service will become available via the outputs of this
    deployment, which are automatically parsed and made available as an environment
    variable, in this case in the `CheckoutUrl` variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now that we are done with the checkout service, it is time to move on to the
    frontend application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Angular frontend to Fargate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Angular frontend application will be deployed into an ECS with a Fargate
    backend, a serverless offering from AWS. This deployment is much simpler because
    it only requires creating the CloudFormation stack, which incorporates the definition
    of the container to deploy within the template.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add the following to the `deploy.yml` file and walk through the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `download` task retrieves the frontend IaC pipeline artifact:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `CloudFormationCreateOrUpdateStack@1` task creates the infrastructure required
    to run the service and deploy the application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice the different notation when providing parameters to the template in the
    `templateParameters` property. This is due to the way these values become available
    in the context of pipeline execution. When injecting values into a task, there
    is a distinction between pipeline parameters and variables and how they are evaluated.
    The `${{ parameters.name }}` notation is only processed at compile time, before
    runtime starts. This would be your typical usage for parameters as they should
    not change during runtime.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `$(variable)` notation is processed during runtime before a task runs, which
    means it will be evaluated before each task is executed; any changes that are
    made to it through its execution will be reflected in its value. This would be
    your typical usage for variables. To learn more about this, read
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Understand variable syntax*, which is available in the official documentation
    at [https://learn.microsoft.com/en-us/azure/devops/pipelines/process/variables](https://learn.microsoft.com/en-us/azure/devops/pipelines/process/variables).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With all of this in place, it’s finally time to make it all work by adding the
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have all the YAML files completed, it is time to put everything
    to work by adding a new pipeline. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the **Pipelines** section of your project, click on the **New pipeline**
    button, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Adding the pipeline](img/B18875_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Adding the pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the **Azure Repos Git** **YAML** option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Adding a pipeline from Azure Repos Git YAML](img/B18875_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Adding a pipeline from Azure Repos Git YAML
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the repository where you created the pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Selecting the repository to add the YAML pipeline from](img/B18875_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Selecting the repository to add the YAML pipeline from
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, select the **Existing Azure Pipelines YAML** **file** option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Selecting the Existing Azure Pipelines YAML file option](img/B18875_10_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – Selecting the Existing Azure Pipelines YAML file option
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, enter the `/e2e/pipelines/aws/aws-pipeline.yml`, and click **Continue**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Select an existing YAML file](img/B18875_10_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Select an existing YAML file
  prefs: []
  type: TYPE_NORMAL
- en: With the pipeline in place, you can trigger it manually or by making changes
    to the repository. Now that we’ve got this ready, let’s wrap up.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you completed all these steps, then you’ve deployed test and production
    environments, so it is time to clean up! You have deployed many resources into
    AWS throughout the chapter, so make sure you delete them if you do not want to
    keep paying for them. You can do this via the AWS console or the following AWS
    CLI commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If you missed anything or got stuck and are having trouble putting the entire
    solution together, the pipeline definitions can be found in the GitHub repository
    mentioned in the *Technical requirements* section, in the `e2e/pipelines/aws`
    directory in the **complete** branch.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s recap what we have learned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to deploy containerized applications to different
    services in the AWS cloud. At the same time, we learned how containers allow for
    portability across cloud providers and the ability to take advantage of multiple
    services within the same ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we learned how to use AWS ECR and private repositories to manage all our
    container images and how the process to build and push those containers, although
    based on the same `docker-compose` tool, must be implemented differently depending
    on the target platform.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned about the eksctl CLI tool, which makes it easier to provision
    and configure EKS clusters in AWS with best practices, as well as how to use Helm
    charts to deploy a containerized application to a Kubernetes-based service regardless
    of the underlying infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we learned how to deploy to ECS with both Fargate (serverless) and
    EC2 (virtual machines) infrastructure, both with a very similar and simple application
    deployment model.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about CI/CD for **cross-mobile applications**.
  prefs: []
  type: TYPE_NORMAL
