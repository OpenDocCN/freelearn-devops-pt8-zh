- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing the Application Life Cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this book, we’ve reviewed some modern architectures and the microservices
    concept, understanding how containers fit into this new application development
    logic and covering how to create applications using different containers to provide
    their differing functionalities. This concept really is a game changer: we can
    implement an application’s components using different deployment strategies and
    scale processes up or down as needed. We used container registries for storing
    and managing the new artifacts and container images, which in turn are used for
    creating containers. Container runtimes allow us to run such components. We then
    introduced orchestration, which allows us to manage application availability and
    updates easily. Container orchestration requires new resources to solve different
    issues that arise from these new architectures. In this chapter, we will cover
    how all these pieces fit together in the management of your application life cycle.
    Then, we will learn how the automation of such actions allows us to provide a
    complete application **supply chain**, running **continuous integration/continuous
    delivery** (**CI/CD**) on Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the main topics covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the application life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shifting our application’s security left
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding CI patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating continuous application deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating CI/CD with Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the labs for this chapter at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13),
    where you will find some extended explanations, omitted in the chapter’s content
    to make it easier to follow. The *Code In Action* video for this chapter can be
    found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the application life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we talk about how applications are created and evolve, we have to consider
    all the creative and maintenance processes involved. The application life cycle
    includes the following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Planning** of a software solution'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Development** of the application’s components'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Different **testing** phases, including component integration and performance
    tests
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Deployment** of the solution'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Maintenance**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As we can see, a lot of people, processes, and tools are involved across the
    whole life cycle of an application. In this book, however, we will only cover
    those that can be resolved technically with the use of software containers. We
    can use the following schema to situate the aforementioned processes within a
    broader context:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – Basic application life cycle schema](img/B19845_13_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – Basic application life cycle schema
  prefs: []
  type: TYPE_NORMAL
- en: Let’s think now about which of these phases can be implemented using software
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: Planning a software solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This phase covers the early stages of a software solution when an idea becomes
    a project. It includes the collection and analysis of the **requirements** of
    the users, customers, and other project stakeholders. These requirements will
    always need validation to ensure the final characteristics of the developed solution.
    Depending on the size of the project, an exploration of alternatives currently
    available on the market and the viability of the solution may call a stop to the
    process. The success of the project is usually directly related to the effectiveness
    of the planning phase, in which different teams propose the architecture, infrastructure,
    software frameworks, and other resources that may be key for the resulting solution.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In this book, all the content presented is intended for working on either cloud
    environments or an on-premises data center infrastructure. You will be able to
    use your desktop computer for developing your application code and can use a variety
    of workflows to interact with different infrastructure platforms through the different
    project phases, as we will learn in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a good **timeline** for the project is always critical, and working
    with containers helps you improve delivery times, as they don’t require dedicated
    or overly specific infrastructure. You can even start your project on one platform
    and then move to a new completely different one. Containers mitigate any friction
    and remove infrastructure vendor lock-in.
  prefs: []
  type: TYPE_NORMAL
- en: In this phase, you will also decide on the **architecture** for your application.
    Dividing your application into small, code-independent but cooperative services
    allows different groups of developers to work in parallel, which will always speed
    up project delivery. Working with microservices lets you as a developer focus
    on specific functionality and deliver your component following defined guidelines
    to ensure proper integrations. It is important to prepare the logic for scaling
    up or down any application’s process if needed and to ensure components’ **high
    availability** (**HA**) and resilience. This will add flexibility to your solution
    and increase overall availability for your users.
  prefs: []
  type: TYPE_NORMAL
- en: Developing the application’s components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This stage involves writing the code for your application. When you are developing
    microservices applications, you can choose the most appropriate language for your
    code, but you must be aware of any issues in the dependencies you use and understand
    the risks that come with using certain components instead of others. Using open
    source libraries or frameworks always requires a good knowledge of the maintainer’s
    activity and the maturity of their code.
  prefs: []
  type: TYPE_NORMAL
- en: In the microservices model, your applications serve their APIs, and resources
    and other components use them. If you plan to enable multiple instances, you must
    ensure that your application’s logic allows this situation. To avoid infrastructure
    friction and provide maximum availability, ensure your application runs in different
    circumstances, manage its dependencies, and enable some circuit breakers. You
    will need to figure out how your processes behave when some components are down,
    how to reconnect in case some connection is lost and recovered, what will happen
    if you decide to execute your application’s components in a cloud platform or
    on a different cluster, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Testing your application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once your development is finished, a selection of test stages will be triggered.
    As this is an iterative process, you can deliver certain components of the application
    (or even the full solution), but it won’t truly be finished until all the tests
    return positive results. We must always consider the following principles when
    preparing and running our tests:'
  prefs: []
  type: TYPE_NORMAL
- en: Tests must meet the expected requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They should be executed by third-party groups, not involved in the design or
    development of the application to keep these tests independent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automation helps to reproduce tests under the same circumstances in different
    iterations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tests must be executed on either small components or a set of components running
    together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s see some of the testing types and how containers can integrate them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit testing**: This type tests the *individual* components of an application.
    It is usually generated and executed in the *development phase* because developers
    need to know whether their code is working as expected. Depending on the complexity
    of the component’s code and the returned objects of the requests, they may be
    included in the container probes. Components will not be considered healthy if
    the returned status isn’t valid, although further pattern matching can be included
    in the validation of the returned data. If you are developing a component that
    works via an API, you should consider having a test request that always returns
    a valid value, or alternatively, you could use mock data. Unit tests will help
    you validate your code whenever changes have to be made to fix an issue, and they
    also make your code modular (microservices). Each component should include its
    own unit tests, and we can also include some code quality verification against
    defined standards.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration testing**: These tests validate how *different* components of
    your software solution work together. They help us to identify issues between
    components and fix the delivery and interaction of all the components. So, this
    type of test needs to be arranged between the developers of the different components
    and planned consistently. If our application’s components run within containers,
    it would be very easy to prepare Docker Compose or some Kubernetes manifests to
    run all the required components together in our development environment – although
    these tests can also be automated on a remote CI/CD platform, as we will see later
    in this chapter in the *Orchestrating CI/CD within Kubernetes* section. If some
    components are key for your application’s health, their endpoints or probes can
    be integrated into the monitoring platform to ensure everything works as expected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression testing**: These tests validate that new changes made don’t introduce
    new issues or break the overall project. Working with containers in these tests
    can significantly improve the overall process. We can go forward with new container
    image builds or roll backward using a previous image. If your code has changed
    significantly between releases, maybe having a completely different development
    platform as a result of moving to a new version of Python or Java, this can be
    tricky, but using containers makes it smooth and simple. Regression tests help
    us solve any issues related to advancements or changes in our code (evolution
    of the solution) that can break the current application’s behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`depends_on` key, but it’s recommended to solve any dependency order issues
    in your code because commonly used container orchestrators don’t include such
    keys, requiring other mechanisms to manage dependencies. You can include additional
    `init` containers or sidecar containers that will check for the required components
    before other containers actually start.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stress testing**: These tests validate your application’s component under
    stress or heavy load. We learned in [*Chapter 12*](B19845_12.xhtml#_idTextAnchor267)
    how to make tests using third-party tools. These tools can be deployed within
    containers and automated to create thousands of requests for our application’s
    components. If we’ve already dealt with the monitoring of the application’s components,
    we can get a good overview of the hardware requirements of our processes and use
    this to minimize resource usage within our container orchestrator clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance testing**: Once you have integrated all your components and tested
    the requirements for each one, you can go further and verify different contexts
    for your application. You can test, for example, how your application behaves
    with multiple frontend components or work out how to distribute load between multiple
    databases. You can prepare both the application and the tests within containers,
    scale certain components up or down, and analyze the performance outcomes. This
    lets you distribute load automatically and add dynamism to your software solutions
    – but you do have to ensure that your code allows multiple instances at once of
    certain components. For example, you can have multiple instances of a distributed
    NoSQL database or multiple static frontends, but you can’t run multiple database
    instances at once and write to the same data file. This also applies to your application’s
    code. You can’t simultaneously execute multiple instances of a process that write
    to a file if you don’t block the file, so just one gets complete access to it.
    Another example is to allow requests from users on different instances without
    managing the response in a central database. You have to atomize the requests
    or integrate mechanisms to distribute them across the different instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Acceptance testing**: You should always define **user acceptance tests**
    (**UATs**) before delivering your solution because these will ensure that your
    code fits the requirements exposed at the beginning of the project. Multiple tests
    can be included in this stage (alpha, beta tests) depending on the complexity
    of your solution. New issues may arise in these tests, hence multiple iterations
    will probably be required. The automation of delivery and the simplicity inherited
    from working with software containers both help you to provide different testing
    environments to your users in a short period of time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The testing phase is very important for a project because it helps you improve
    the quality and reliability of your software delivery, identify and fix problems
    before going to production, and increase the visibility of the project, improving
    stakeholders’ confidence and user satisfaction. We can also reduce the maintenance
    costs of the solution because it was designed and tested with all the requirements
    in mind and validated multiple times, so errors that arise should have been ironed
    out before they impact production. On the other hand, testing is always time-consuming,
    but making different tests using containers will reduce both costs (as fewer environments
    are required for tests) and the time spent on each test (as we can deploy multiple
    releases at the time and test in parallel).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this phase, we actually deploy our software solution in production. The
    solution often goes through multiple environments before this step is complete.
    For example, we can have a preproduction environment for validating certain releases
    and **Quality Assurance** (**QA**) environments where other more specific tests
    can be run. Using containers makes deployments in these testing stages simple
    – we just change our configuration; all the container images will be the same.
    Using containers as new **deployment artifacts** makes things easier. Let’s quickly
    introduce some packaging solutions for containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Helm charts**: This package solution only works with Kubernetes. A Helm chart
    is just a packaged set of manifests that includes variables for modifying the
    deployment of an application and its components. Version-3-compatible Helm charts
    are the go-to now. A previous version of Helm that was deprecated some time ago
    used the Tiller privileged component for deploying manifests, which may affect
    cluster integrity and security. Newer releases simplify how applications are deployed
    without having to create any Helm-specific resources in your Kubernetes cluster.
    Helm charts are very popular, and software vendors provide their own supported
    chart repositories for installing their applications directly from the internet
    into your own Kubernetes clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubectl` command line includes Kustomize functionality, which makes it very
    usable out of the box without having to include new binaries in our environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud-Native Application Bundle** (**CNAB**): CNAB goes a step further than
    Helm and Kustomize. It is designed to include the infrastructure and services
    required by our application to work. Multiple tools work together to provide both
    the infrastructure (with the Porter component providing integration of Helm, HashiCorp
    Terraform, and the cloud provider’s API) and the application (managed by Duffle
    and Docker). This solution is not really in use today and many of its components
    have been deprecated, but it is worth mentioning as it can give you some ideas
    for fully packaging your software solutions (that is, the infrastructure and the
    application together).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kubernetes operators**: Kubernetes operators are controllers that deploy
    and manage specific application deployments and have become very popular these
    days. An operator deploys its own specific controllers inside a Kubernetes cluster
    to manage application instances. Kubernetes operators are intended to self-manage
    all the tricky parts of your application’s management and upgrades. You as a user
    just need to define certain required values for your instance, and the operator
    will handle installing the required components and dependencies and manage any
    upgrade during its lifetime. If you are planning to develop your application using
    a Kubernetes operator, make sure to include all the manifests of your application,
    dependencies, and the automation required for the application to come up. Third-party
    Kubernetes operators run as black boxes in your Kubernetes cluster and may not
    include all the functionality you expect for your applications to work; therefore,
    it may be worth reading the documentation before deploying a third-party Kubernetes
    operator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying your application using a microservices architecture allows you to
    integrate different components’ releases. Depending on your software solution,
    you might use one full deployment or multiple small ones for each component of
    your application. Either way, the solution must provide all the functionality
    called for by your users and stakeholders in the project planning stage.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining the application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We might think that the deployment of the solution is the last phase, but it
    isn’t. Once the application is in production, new functionalities may be required,
    new improvements to current functionality may be called for, and inevitably, new
    errors will appear. If your application is monitored, you can obtain feedback
    on the status of different components before actual errors appear. **Logging**
    also helps to identify problems, and tracing allows you to improve your code.
  prefs: []
  type: TYPE_NORMAL
- en: But in any case, the application’s life cycle continues, and a new project may
    start adding new functionalities while issues are repaired for the current release.
    Monolithic architectures require multiple environments for such processes. Working
    on two releases at the same time will double the efforts for maintaining environments.
    Microservices architecture allows us to distribute the work according to the different
    components, and thus mitigate the need for having dedicated environments for building
    each component. And, more importantly, we can change one component at a time and
    focus on solving a specific issue, or have each application component managed
    by a different team with different release times. These teams develop their code
    using the programming language that best fits the functionality of their requirements,
    taking into account release times and proper integration within the application.
    However, note that each team also has to keep track of vulnerabilities and security
    issues in their implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this book, we have learned some security practices that will make
    our applications safer when we work within containers ([*Chapter 2*](B19845_02.xhtml#_idTextAnchor036)
    and [*Chapter 3*](B19845_03.xhtml#_idTextAnchor082)) and with container orchestrators
    ([*Chapter 6*](B19845_06.xhtml#_idTextAnchor134), [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147),
    and [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170)). **Shift-left security**
    goes beyond these recommendations and includes security from the very beginning
    of the project. We can consider shift-left security as a practice where we don’t
    wait to address software security vulnerabilities until it’s too late: when the
    application is already developed, built, and packaged. In the next section, we
    will learn how taking care of security from the very first phases of the application
    life cycle can significantly improve the overall security of the solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Shifting our application’s security left
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Shift-left security** refers to the practice of starting security checks
    as early as possible in the development of our application. This doesn’t mean
    we don’t apply any security measures at other stages but that it will start improving
    security from the very beginning of the application life cycle. Shifting security
    left allows us to identify any vulnerabilities and other problems before it’s
    too late and the application is already running in production. The benefits of
    shifting our security left include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It improves the delivery of software solutions because bugs are detected and
    fixed in early development stages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It distributes application security into different stages, allowing different
    actions at each stage, starting from the code and ending in the infrastructure
    where the application will finally be deployed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different groups can implement different security policies and mechanisms, furthering
    the creation of a security culture in your organization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It reduces overall development time and the costs of pushing back applications
    because of poor security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s understand some different methodologies for tackling the software
    development life cycle and how they impact security.
  prefs: []
  type: TYPE_NORMAL
- en: Software life cycle methodologies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s introduce some software life cycle methodologies here that will help
    us understand the importance of security when things begin to move faster in the
    stages of development:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Waterfall model**: In this model, stages must run *linearly*, hence a new
    stage begins when the previous one finishes. This model works very well when we
    don’t expect to have many modifications from the planned requirements and our
    project tasks are well defined. However, this model lacks flexibility, which makes
    changes harder to implement, and issues usually remain hidden until the end of
    the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agile model**: In this model, we *iterate* over stages to improve the final
    software solution. Flexibility and quick response times are key in this model.
    Iterations allow the introduction of new changes and the resolution of any issue
    found in the previous review. The main problem of this model is that it requires
    lots of collaboration between the groups or people involved in each stage, hence
    it may not work in big projects, but microservices architectures fit very well
    into this development model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spiral model**: This model can be considered a *mixture* of both the Waterfall
    and Agile models. The final software solution will be the result of different
    iterations that can be considered a complete software development cycle. In each
    iteration, we start from the very beginning, taking user requirements, designing
    a solution, developing the code, and testing, implementing, and maintaining the
    solution as is, before moving on to the next iteration. The Agile and spiral development
    models allow us to review and solve issues before the next iteration, which both
    accelerates the development process and makes the solution more secure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of these methods, Agile methodologies in particular have really changed how
    software is developed and delivered. Their adoption allows teams to go faster
    and swiftly adapt software solutions when users require new features. However,
    in such scenarios, the security team can be a bottleneck. These teams receive
    a software solution just before it goes into production, seeking to identify and
    resolve any vulnerabilities and security issues before malicious users find them
    in production. If we decouple our application into small pieces (that is, microservices),
    then the work required in the security review task is multiplied by the number
    of pieces, even if they are small. It gets even worse when we realize that most
    of the legacy tools used for reviewing security on monolith applications don’t
    work on highly distributed and dynamic environments such as Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: It is also the case that software containers and open source solutions have
    become so widely used in data centers and cloud platforms that we can find ourselves
    deploying third-party software solutions while barely even knowing their contents.
    Even software vendors provide open source products inside their own complex software
    solutions. Therefore, we cannot just keep using the same old security methodologies
    at the infrastructure and application levels.
  prefs: []
  type: TYPE_NORMAL
- en: Security at the application level
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed earlier, shifting the security of our applications left implies
    integrating security mechanisms and best practices as early as possible in our
    software development model. But this doesn’t mean we leave security to the developers.
    We will prepare automated security validations in the testing phase and implement
    security policies in both the development environments and production clusters.
    This will ensure that everyone knows the security measures applied and how to
    implement them. The DevSecOps team prepares infrastructure and application rules
    and shares them with all the developer teams. Infrastructure rules include all
    policy enforcements in your execution environment, which is usually your Kubernetes
    cloud or on-premises platform. These policies may include, for example, the denial
    of any privileged container, the denial of Pods without limited resources, and
    the denial of access to hosts’ filesystems. However, note that these rules are
    not part of the code, although they do affect the execution of your applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we consider security from the application perspective, there are several
    techniques we can apply:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software composition analysis** (**SCA**): When we add open source libraries
    or other components to our code, we unconsciously add risk to our application.
    SCA tools help us identify these risks and in some cases mitigate them with patches
    and updates. While **static application security testing** (**SAST**) tools (which
    we will discuss next) are used to find vulnerabilities in the development cycle,
    within your code, SCA tools provide continuous vulnerability monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SAST**: These tests are used to find vulnerabilities in our code before it
    is actually compiled, hence they are run in the early stages of our development
    phase. The tools running these tests will search for well-known insecure patterns
    in our code and report them to us. Any hardcoded secret data and misconfigurations
    will be reported as issues in the analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic application security testing** (**DAST**): These tests are executed
    when the application is running, in the testing phase. They involve the execution
    of simulated attacks against our application’s components. These tests can include
    code injection or malformed requests that may break your application at some point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These three types of tests are very valuable in identifying vulnerabilities
    in our application before moving it to production, but SAST and SCA are the ones
    to focus on when talking about shifting security left. When automation is put
    in place, we can execute these tests continuously and use **integrated development
    environment** (**IDE**) plugins to help figure out problems before they are actually
    stored in our code. To start, we can use any good linter for our specific programming
    language. Let’s discuss these next.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing linters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **linter** is a tool used to analyze our code looking for problems. Depending
    on the quality of the given linter, it can identify things from simple code improvements
    to more advanced issues. It is usual to use specific linters for different programming
    languages. You can check the extensions available in your favorite IDE.
  prefs: []
  type: TYPE_NORMAL
- en: Linters help us reduce the amount of code errors in the development stage, and
    improve our code style, construction consistency, and performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple code linter will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Check for syntax errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verify code standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review *code smells* (well-known signs that something will go wrong in your
    code)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verify security checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make your code look as if it were written by a single person
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You should include linters in your code environment, but your specific choice
    will depend on the language you use. Good linters can be categorized based on
    the aspects they focus on, as outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Standardized coding**: Examples include SonarLint, Prettier, StandardJS,
    Brakeman, and StyleCop. Some languages such as .NET even include their own linter
    (Format).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: GoSec, ESLint, or Bandit (Python module).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What’s more, some linters can be used for both of these aspects when the appropriate
    configurations are used. You can check for additional code analysis tools at [https://owasp.org/www-community/Source_Code_Analysis_Tools](https://owasp.org/www-community/Source_Code_Analysis_Tools).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see a quick example using a Dockerfile linter, **Hadolint** ([https://github.com/hadolint/hadolint](https://github.com/hadolint/hadolint)).
    We will simply check a valid Dockerfile that does not include the best practices
    we learned in [*Chapter 1*](B19845_01.xhtml#_idTextAnchor015), *Modern Infrastructure
    and Applications with Docker*. Let’s see this in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Local Hadolint installation reviewing a simple Dockerfile](img/B19845_13_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – Local Hadolint installation reviewing a simple Dockerfile
  prefs: []
  type: TYPE_NORMAL
- en: 'But the good thing here is that we can include this linter, or any other, inside
    container images and have a collection of linters ready to use for any language
    we might encounter. Let’s see how this works within a container using `docker
    run –i hadolint/hadolint` `hadolint -`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Docker-based Hadolint execution reviewing a simple Dockerfile](img/B19845_13_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Docker-based Hadolint execution reviewing a simple Dockerfile
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: There are tools such as **Conftest** ([https://www.conftest.dev/](https://www.conftest.dev/))
    that can be integrated with different **Infrastructure as Code** (**IaC**) solutions
    and used to validate infrastructure scripts before they are deployed in our platform.
  prefs: []
  type: TYPE_NORMAL
- en: Linting tools can be executed automatically within our development processes
    to improve security. We will see this in action when we talk about CI/CD workflows.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will introduce simple methodologies and practices to
    learn how CI can help us manage the life cycle of our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding CI patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CI refers to the practice of automating the integration of code changes from
    multiple contributors (or even multiple projects) into a single project. These
    automated processes may happen once a day or several times per hour. We can consider
    CI as the part of the software supply chain where we build our application (or
    its components) and launch different tests before moving to production. The second
    part of this process is deploying the application or its components into production,
    although some intermediate environments can also be employed to test the quality
    of the solution or certification in special circumstances (for example, integrating
    our solution with a third-party solution release from a vendor).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to review some of the most common patterns used
    for CI in the most intuitive logical order. Developers should always get the last
    version of their code to start developing a new feature or start over the creation
    of a new component, or new release with fixes. Therefore, we will start our development
    process by pulling the code from a **version control** **system** (**VCS**).
  prefs: []
  type: TYPE_NORMAL
- en: Versioning the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A VCS is a tool that stores file and directory changes over time, allowing us
    to recover a specific version later. This tool is crucial from the developer’s
    perspective as it allows multiple developers to work together and track the changes
    made to application code over time. Versioning the code and the artifacts created
    allows us to run specific integration tests and deploy a specific release of our
    code.
  prefs: []
  type: TYPE_NORMAL
- en: These tools usually run in *client-server* mode. Users interact using the relevant
    commands to push and pull the changes. The VCS stores and manages these changes.
    Once all the changes are synced (committed), you can proceed to build your applications’
    artifacts. This step may not be necessary if you are using an interpreted scripting
    language, although some bytecode artifacts may be created to speed up the application’s
    execution. We can automate this process and trigger a compilation of our code
    in certain circumstances – for example, when we do a commit (synchronization of
    the code). As a result, we get a **binary artifact** with all its dependencies
    every time we simply commit our code. But we can go further and create different
    branches on our code repository to allow different users to interact with the
    code at the same time or solve different code functionalities. Once all required
    changes are made, we can consolidate these branches into a common one and build
    the artifact again. Depending on the final product, the issues found, and the
    functionalities required, this process can be complicated, but automation can
    be used to create a common workflow that is much easier to follow and reproduce.
  prefs: []
  type: TYPE_NORMAL
- en: When a project is developed by multiple developers or teams, certain types of
    management are required to avoid collisions between changes. VCSs offer mechanisms
    to resolve incompatibilities between different pulls when multiple developers
    change the same files at the same time. `MAJOR.MINOR.PATCH` versioning syntax,
    where `MAJOR` indicates changes that may break compatibilities with previous releases,
    `MINOR` indicates that some functionality was added without breaking compatibility,
    and `PATCH` is used when some issues were solved without actually modifying any
    of the previous functionality. On the other hand, branch names can be used to
    reference any issues found and their solutions in the code.
  prefs: []
  type: TYPE_NORMAL
- en: At this early stage, we can add some **validation tests** using linters to ensure
    proper code syntax, code quality, and the presence of security features (such
    as valid external dependencies) and exclude any sensitive information that may
    have made its way into the code.
  prefs: []
  type: TYPE_NORMAL
- en: If we work with containers, our code should include at least one **Dockerfile**
    to allow us to create our container image artifact. Versioning of this file is
    also required, and thus it will be stored in our code repository (which is a VCS).
    Validation tests can be automated and executed to verify certain patterns such
    as the user executing the container’s main process or exposed ports.
  prefs: []
  type: TYPE_NORMAL
- en: A CI pipeline, therefore, is a group of workflow processes intended to automate
    software application code validation, construction, and integration. Accordingly,
    let’s quickly introduce the concept of DevOps here.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing DevOps methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**DevOps** is a methodology that improves software engineering by integrating
    and automating some of the stages of software development, the operational tasks
    related to the operation and maintenance of the systems where the applications
    run, and the applications themselves. We should think of DevOps as a culture that
    goes *beyond* groups or teams in your organization; it applies to your entire
    organization with the goal of minimizing time and friction between the development,
    deployment, and maintenance stages.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following list shows some of the key features of the DevOps methodology:'
  prefs: []
  type: TYPE_NORMAL
- en: Automate as many tasks as possible in the software life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaboration between different teams as part of this culture makes things work
    more effectively
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous revision and feedback from tasks, automation, and code quality, all
    of which are key to improving the software development processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and logging are part of the application life cycle, and they are
    important for improving its performance and finding code issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since DevOps covers a lot of tasks and disciplines, there are many tools available
    to help you with different tasks and stages. For example, for VCSs and code repositories,
    you can use very popular **cloud services** such as GitHub (acquired by Microsoft
    in 2018), Atlassian’s Bitbucket, or GitLab, among others. If you are looking for
    **on-premise solutions**, you can use open source offerings such as Gitea, GitLab,
    or Azure DevOps Server. Choosing the right tool for your organization can be complicated
    because many tools offer multiple features. The following schema represents some
    of the more popular DevOps tools related to the application development stage,
    showing where they fit in best:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Most popular DevOps tools](img/B19845_13_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Most popular DevOps tools
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A new methodology was recently introduced that focuses heavily on the security
    of development, deployment, and maintenance processes, called **DevSecOps**. This
    methodology emphasizes an extension of security as part of the culture of the
    different teams involved in the process. This is why we reviewed shift-left security
    practices, which are an aspect of DevSecOps that lies closer to the development
    teams. A DevSecOps culture breaks the old mindset in which a singular team is
    given the security role and participates in the development process only at the
    end, validating the code just before the software is moved into production.
  prefs: []
  type: TYPE_NORMAL
- en: Once the code is synced and validated, we are able to build our software solution.
    Let’s discuss this process next.
  prefs: []
  type: TYPE_NORMAL
- en: Building artifacts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on the programming language and its dependencies, it may be tricky
    to prepare environments for different releases. For example, moving from one previous
    Node.js release to a newer one may require separate build environments, even if
    the language is interpreted and not compiled.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a situation where different code developers need to compile their software
    at the same time in the same environment. It would be complete chaos, and errors
    from different releases would appear. Automation allows us to package environments
    and build our software using the appropriate environment. But we can go further
    by using software containers because these environments need only to exist at
    runtime, specifically when required, and we can use software containers to build
    our software using the required builder environment. The resulting container images
    of the complete build process are stored in a container image registry right after
    the successful building and validation of the new artifact.
  prefs: []
  type: TYPE_NORMAL
- en: What is even more important is that we can prepare a full workflow in which
    all code is validated using our rules (code syntax, code quality, non-privileged
    execution, and so on), then the workflow triggers the build of the code, and finally,
    different tests (unity, integration, stress, performance, and so on) are triggered
    using the container images generated. We can forbid the execution of any application
    in production if it doesn’t come from this standardized construction workflow.
    You as a developer are able to code on your laptop and test your application,
    but you must pass all the corporate validation checks on a shared environment
    or platform before actually deploying in production (or sometimes even earlier,
    in the quality or certification stages).
  prefs: []
  type: TYPE_NORMAL
- en: Testing your application’s components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned before, automating different tests allows us to break the workflow
    whenever any test fails before moving on to the next step. To achieve this with
    containers, we can prepare some integrated processes using Docker Compose (for
    example) and validate how they work together. This can be done on your own desktop
    environment or using shared services, triggering the execution of the components
    by using defined tasks. These tasks also can be defined in Docker Compose format
    and be stored with your code. There are tools such as Jenkins that help us define
    these automated jobs and execute them on different systems. This tool is a very
    popular CI/CD orchestration tool created for managing build tasks on different
    systems that can be evolved to integrate the use of containers to simplify the
    overall workflow. Instead of having different nodes with separate releases for
    different languages or compilers, we can use software containers executed on a
    unique container runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring the build processes and tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand how changes can improve or have a negative impact on our applications,
    we need to continuously measure the performance and output of the different tests.
    We must always ensure we monitor the workflow processes because this will help
    us to improve the overall development process thanks to the iteration of the different
    tests. Popular CI orchestration tools always measure the build time, and we can
    retrieve the time spent during the execution of chained jobs, hence we will be
    able to trace how a certain change in our code (for example, the addition of new
    dependencies) impacts the build and modify the tests accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing information about the development process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DevOps culture is all about communicating changes, exchanging feedback, and
    sharing information about any issues that arise to align all the teams involved
    in the process. Automation will avoid many misunderstandings; everything should
    be reproducible, hence the same results will be expected if we don’t change anything.
    All changes must be traceable to allow us to quickly identify issues related to
    any given change and apply the appropriate patches. As we saw in *Figure 13**.4*,
    there are many tools available to assist us in keeping our teams informed. One
    good practice is to implement automatic notifications sent by the different tools
    whenever a development task is executed (code changes, validated tests, and so
    on).
  prefs: []
  type: TYPE_NORMAL
- en: Excluding configurations from code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although it might be obvious, we should keep any configuration or sensitive
    information for the application out of the code. It would be nice to include a
    set of default values and some documentation covering how to change them, but
    keep in mind that your application will pass through several phases and maybe
    different environments. In this book, we have looked at multiple mechanisms used
    to include sensitive information and configurations within containers ([*Chapter
    2*](B19845_02.xhtml#_idTextAnchor036), [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096),
    and [*Chapter 5*](B19845_05.xhtml#_idTextAnchor118)). Never include certificates,
    even if they are just required for a simple step in which you download some artifact
    from a self-signed or corporate server. It is important to understand that sometimes,
    it is even necessary to use versioning for configurations. If you change the way
    you use a variable in your code, it may break a rollback to a previous release.
    In such cases, you may also need to store configurations in the versioning system.
    But keep in mind that the audience of this repository is probably different from
    the repository that stores your code. Automation helps us to keep track of the
    different code releases with the appropriate configurations and ensure that every
    task runs smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have reviewed the first part of the development process, where the
    application is coded, compiled, and validated, we can move on to the delivery
    stage.
  prefs: []
  type: TYPE_NORMAL
- en: Automating continuous application deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to examine the second part of the software development
    process – the delivery of the product. Many organizations invest all their efforts
    into CI, leaving the determination of whether or not software should be executed
    in production to a manual decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'A CD pipeline gets changes from the artifacts and code repositories, including
    required configurations, and deploys them into production in a fluent and continuous
    way. To achieve this, we need to somehow package all these artifacts and configurations
    in a reproducible and deployable state, aiming to keep the maximum stability and
    reliability in our systems. The following list shows some of the most notable
    benefits of using CD:'
  prefs: []
  type: TYPE_NORMAL
- en: We mitigate the risks of deploying new releases because automation ensures a
    quick rollback in case something goes wrong
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automation may use blue–green and canary deployments, enabling new application
    releases while older processes are still serving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lower **time to market** (**TTM**) and reduced costs can be reliably expected
    due to the level of confidence generated by the application’s life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While CI automates the build and testing stages, CD on the other hand continues
    the process and goes a step further, automating the packaging, deployment, and
    testing throughout the rest of the life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: While the benefits of CI are for developers, we might think that CD is more
    targeted at operations teams. However, in the DevOps culture, many stages are
    shared between the two groups. The major benefits of using CD extend even to the
    end users because applications are always kept updated and don’t suffer outages
    between changes. Additionally, new functionalities can be added with less friction.
    Users can provide feedback using the defined channels (see the tools presented
    in *Figure 13**.4*), and monitoring, logging, and tracing the software allows
    us to enrich this feedback, and then the cycle starts again to keep improving
    the application’s code.
  prefs: []
  type: TYPE_NORMAL
- en: If we give some thought to how can we implement the different stages of CD automation,
    containers fit perfectly as we can package container images and the application’s
    configurations for different environments and deploy the software solution. In
    case of errors, container runtimes provide **resilience**, and container orchestrators
    allow us to roll back to the previous release in seconds, informing us of the
    issues encountered during deployment. As mentioned before, blue–green and canary
    deployments allow us to progressively deploy a new release or test it with just
    a few users to avoid a massive outage if anything goes wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Modern application life cycle models, such as **GitOps**, manage the deployment
    of software releases by defining a repository as the **source of truth** (**SOT**).
    Any change within our applications or even the Kubernetes clusters themselves
    are managed as out-of-sync situations, requiring either manual intervention or
    automatic triggers to apply the appropriate changes and synchronize the situation
    with the required configuration (SOT). In such scenarios, we will just customize
    how the deployment packages will be executed on each environment by setting a
    required state for the application. Resource upgrades or rollbacks will be executed
    to synchronize the current status with the required one.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring the actual performance of the new deployment is key in situations
    where you are limiting access to a new release while most users are still using
    the old one. Should we go further with our new release, we must have a reliable
    **performance baseline** to fully understand how the changes are impacting our
    application’s services. Although we may have passed all our performance tests
    successfully, deploying a new release may show different behaviors when accessed
    by real users. The better the tests in the testing stages, the lower the gap between
    the real user experience and the automated test, which lowers the risks of releasing
    a new version.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logging** is also important. We use logs to search for well-designed error
    patterns. The log standardization in your corporation can be used to easily implement
    common patterns for all your application’s components and provide a single logging
    control plane for all processes at once, which will make it easy to find errors
    across multiple logs and verify how some requests affect different components
    at specific time frames.'
  prefs: []
  type: TYPE_NORMAL
- en: Tracing in production is *not* recommended unless you have some dedicated instances
    of your project for that purpose or you are reviewing a critical error.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving **user feedback** is the final step of the complete application’s
    life cycle. User feedback, alongside monitoring and logging (and eventually tracing)
    of the application components, feeds into the next iteration of the application’s
    life cycle process to improve its overall performance and behavior, and the process
    starts over.
  prefs: []
  type: TYPE_NORMAL
- en: We examined some open source monitoring, logging, and tracing tools back in
    [*Chapter 12*](B19845_12.xhtml#_idTextAnchor267), *Gaining Application Insights*.
    To get users’ feedback, any ticketing software will be fine, but the smoother
    it integrates into the full DevOps paradigm, the better. In *Figure 13**.4*, we
    showed some of the most common and popular DevOps tools. All serious code repositories
    include an **issue tracking system** with which you can align users’ comments
    and issues with actual code commits, solving these issues or adding requested
    functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, some of these tools can be deployed on and integrated into
    Kubernetes. The next section presents a sample DevOps environment in which we
    will use some of the tools presented in *Figure 13**.4* to provide a full application
    life cycle management platform.
  prefs: []
  type: TYPE_NORMAL
- en: Orchestrating CI/CD with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will help us understand the full life cycle of an application prepared
    and managed within a Kubernetes cluster. Let’s start by reviewing the CI part.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the CI component of the workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The CI part of our workflow is where we code, build, and test our solution.
  prefs: []
  type: TYPE_NORMAL
- en: At the beginning of the project, user requirements are collected. Subsequently,
    during the development stage, you can use your favorite code editor. Depending
    on the programming language you use, compilation may be necessary, which requires
    you to have installed compilers. Instead of that, you can use software containers
    to run the actual compilation steps. You will be able to use different releases
    of code compilers, with different environments and sets of tools at the same time
    without actually having to install any of them. Indeed, managing multiple releases
    of certain code environments on a single computer can be tricky. Building your
    application’s code using containers will help you decide which container images
    would best fit your needs for each stage (building the application’s artifacts,
    and running them for either testing or production).
  prefs: []
  type: TYPE_NORMAL
- en: Next, in the CI workflow, you build your binaries and prepare the Dockerfiles
    for your application’s components. Multiple Dockerfiles can be created for a single
    component, specifying things such as the inclusion or omission of some debugging
    tools or flags that could be very useful during the testing stages.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you build your container images. Production images must be clean and only
    include the binaries and libraries required for running your application’s processes.
    You can build your code artifacts and container images for testing the application
    in your coding environment, although you may already have a shared environment
    for such tasks.
  prefs: []
  type: TYPE_NORMAL
- en: With containers, it becomes possible to locally test each application component
    (unit tests) or even the full application stack (integration tests) using Docker
    Compose. In such a case, you will need access to the other application components’
    container images and some mock configurations that will help you run a sample
    environment more easily. It’s usual to include some mocked-up default values and
    perhaps some test connection strings, authentications, and tokens (which will
    be overwritten during execution with real values). Having *sample values* is key
    when you work in a team, and other developers may need to execute your artifacts
    and adjust their parameters to meet their needs.
  prefs: []
  type: TYPE_NORMAL
- en: You are likely to work on a specific branch of the code depending on the development
    stage you are in. Code branches are usually used to either fix issues or develop
    new functionalities and allow multiple developers to code in parallel on different
    resources at the same time. Once a given issue is solved and tested successfully,
    the code can be committed, pushed, and finally merged into the main code.
  prefs: []
  type: TYPE_NORMAL
- en: You may have your own code routine, but chances are it is quite similar to the
    one described here (the order of steps may vary, but ultimately the main code
    should contain your changes), and you probably apply similar steps for adding
    some new functionality or fixing an issue.
  prefs: []
  type: TYPE_NORMAL
- en: Pushing the new code to the code repository will trigger automation mechanisms
    that create appropriate artifacts (binaries, libraries, and container images)
    using tags and labels to help you track the changes associated and the issues
    or functionalities included. This allows you to either use your own built artifacts
    or those created by the automation system using your build rules and the Dockerfiles
    included in your code. It is recommended to use the artifacts created by the automated
    build environment because your DevOps team has most likely created a full supply
    chain, and this step is just the beginning of a longer process in which they will
    use these automatically created artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Code repositories will probably run on top of Kubernetes in your on-premise
    infrastructure, although you could use SaaS services instead. Depending on the
    integrations required for the different steps, it may be difficult to fully integrate
    cloud solutions with on-premises tools without taking on risks such as having
    certain data center credentials stored on your cloud platform (integration from
    cloud repositories to your on-premises Kubernetes clusters, for example). You
    should always ensure minimal required privileges for all your platform integrations,
    no matter whether they run on the cloud or your own data center.
  prefs: []
  type: TYPE_NORMAL
- en: Once your code is pushed to the code repository, different triggers can be configured
    to first validate the quality of your code, the maturity and security of the dependencies
    included in your project, and the security itself of your code and built binaries.
    For these tasks, the different tools presented in *Figure 13**.4* can be used.
    For example, we can configure some container images with programming language
    linters and rules, and execute containers injecting our code for its validation.
    The process can be stopped whenever any test isn’t passed or just inform us at
    the end of the check about some minor or major improvements we can make to our
    code. These tasks can be configured as jobs in our favorite CI/CD orchestration
    environment, probably also running on Kubernetes to leverage the availability
    of the cluster container runtimes. Some of the most popular CI/CD orchestrators
    are presented in *Figure 13**.4*, but many advanced code repositories include
    task management functionality of their own, which simplifies the number of tools
    required for running our complete CI/CD workflows. For example, we can use GitLab
    for storing and versioning our code, storing and managing our artifacts (built
    artifacts and container images), and executing different CI/CD tasks. We will
    see platforms such as this in action in the *Labs* section with a full example.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned before, consecutive validation tasks (tests) can be triggered,
    and as a final step, we can build a container image ready for production. At this
    time, new tests can be executed for testing the integration of the new component
    release with other application components and validate the performance of the
    solution. Depending on the required integrations, this pipeline (that is, the
    definition of the different concatenated tasks to be executed) can be complex.
    It is usually recommended to group tasks and prepare the output of the different
    processes involved to provide easy-to-read reports. Most of the tools mentioned
    in the validation group of *Figure 13**.4* provide summary reports that can be
    parsed to find any errors that should stop the workflow. The tasks associated
    with the pipeline can be executed within containers (isolated Pods on Kubernetes),
    and their logs should be available in the CI/CD orchestrators as these containers
    will be volatile.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the complexity of the application, it might be worthwhile to package
    the required components before the tests. You probably wouldn’t execute simple
    manifests in your Kubernetes environments, and you would use Helm charts or Kustomize
    to create packages for either your full application or each component.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Some tools such as **Argo CD** can use Helm charts as templates for application
    deployments. Although we do not really deploy our application using a Helm chart,
    it will be used by the process to manage and manipulate the Kubernetes resources
    associated with your application. That’s why it is always worthwhile preparing
    your applications as packages: it allows someone else to easily deploy your full
    application or some components therein without really knowing the contents back
    to front.'
  prefs: []
  type: TYPE_NORMAL
- en: Before we continue, let’s see some of the most important features of Helm and
    how to create a simple manifests package.
  prefs: []
  type: TYPE_NORMAL
- en: Using Helm to package our application’s resource manifests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Helm** is a tool that packages Kubernetes resource manifests using templated
    YAML files and automation scripts that allow us to completely configure and deploy
    applications using a simple command line and a configuration file.'
  prefs: []
  type: TYPE_NORMAL
- en: Using Helm charts, we can replace all application resource manifests at once
    or only those that were changed, with a simple path to roll them back to a previous
    release at any time. Helm keeps track of all the changes made to a Helm instance
    and is capable of reverting those changes by applying a previously stored release
    version.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we execute `helm create <NAME_OF_THE_CHART>`, Helm creates a directory
    structure that contains some example manifests and other files used to create
    a new Helm chart package:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – Helm chart file structure](img/B19845_13_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Helm chart file structure
  prefs: []
  type: TYPE_NORMAL
- en: 'In this code snippet, we used `helm create` to create a Helm chart tree structure.
    You may have noticed the existence of the `charts` directory. A Helm chart can
    contain other Helm charts as dependencies. This way, we can create an `Chart.yaml`
    file describes the dependencies of your package and its version. You will find
    two versioning properties in your `Chart.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: The `version` key, which indicates the package release number
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `appVersion` key, which is used to identify your application release
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Helm charts can be uploaded to repositories for storage and to share with other
    users. This way, your applications can be deployed by anyone authorized to pull
    and execute the Helm chart containing the manifests. Many vendors and open source
    projects offer their Helm charts as a way to deploy their applications, and some
    community-driven repositories host thousands of charts ready to use in your projects.
    Two of the most popular repositories are *ArtifactHub* ([https://artifacthub.io](https://artifacthub.io))
    and *Bitnami Application* *Stacks* ([https://bitnami.com/stacks/helm](https://bitnami.com/stacks/helm)).
  prefs: []
  type: TYPE_NORMAL
- en: The magic behind the management and composition of some key variables, such
    as the instance name, is included in the `_helpers.tpl` file, and the composed
    variables will be used in all the YAML manifest files included within the `templates`
    directory. We will include all the manifests required for our application or its
    components to work. All the PersistentVolumeClaims, Deployments, StatefulSets,
    DaemonSets, Secrets, and ConfigMaps should be included. Indeed, if our application
    requires specific permissions, we must also include ServiceAccounts and the appropriate
    Role and RoleBinding manifests. The `values.yaml` file included by default is
    used to validate the manifests that will be created with the `helm` command with
    a set of default values. This is another validation test that can be included
    in our pipeline just before the creation of the Helm chart package. If this `values.yaml`
    file implements all the required values (a mocked version), the pipeline process
    can continue and create the Helm chart package. The Helm chart’s files should
    also be managed using a versioning system; hence, we will store them in our code
    repository. Whether or not to use a different repository depends on you as a developer,
    but it would be nice to manage different releases for the application’s components
    and the Helm charts that deploy them, and it will be easier if we use different
    repositories.
  prefs: []
  type: TYPE_NORMAL
- en: In the *Labs* section, you will work through a full example using the `simplestlab`
    application. We prepared a Helm chart for each application’s component and an
    umbrella chart that deploys the full application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s summarize the steps described so far before continuing with the rest
    of the pipeline chain that describes the application’s life cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: Write your code and push it to the code repository. Our code should include
    at least one Dockerfile for building the container image or images for the application’s
    component. Although it is not required, it is recommended to maintain a separate
    code repository for storing your Helm chart files. This way, you can follow the
    same code workflow for both the application’s code and the Helm chart’s code,
    but isolating each repository allows us to manage a different release for the
    code and the Helm chart’s package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code will be validated using the relevant linters to verify its quality, its
    compliance with your organization’s coding rules, its dependencies, and its inner
    security (do not include sensitive information unless it is mocked).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Different artifacts will be created and stored in your repositories. When your
    code is built, the resulting artifacts (binaries and libraries) will be stored
    (in our example, in GitLab). Storing artifacts is important if they are shared
    between components, such as binaries and client libraries, for example. Container
    images are also stored in GitLab as it additionally provides image registry capabilities.
    You can use a different repository for each type of artifact, but GitLab is a
    good catch-all solution because it offers storage for code, artifacts, and container
    images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When all the artifacts (the build and container images) are created, we can
    either automate the execution of the unit tests or pull the resulting release
    images (with fixes or new functionalities) and test them on our development computer,
    or even do both.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integration tests may require packaging the application’s components. If this
    is the case, validation of the Helm chart code will be triggered, and then the
    package will be created. Sometimes, we just change the application’s container
    image (that is, we change some code, which triggers a new artifact build and a
    new image is created) without actually changing the application’s Helm charts.
    That’s why it is always useful to keep track of Helm chart package template changes
    in a different repository from the application’s code. You may need to upgrade
    your application’s code without changing the templated deployment manifests. Here,
    we would just need the customized values for deploying a new container image and
    the `appVersion` key on your `Chart.yaml` file. This is a good practice because
    you will be able to track your package and application release at the same time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the container images are created and stored correctly in the images registry,
    and the Helm chart packages are created, the application is ready to be deployed.
    Additional vulnerability tests can be triggered using the container images. Some
    tools such as AquaSec’s Trivy use a **bill of materials** (**BOM**), which is
    a list of all the files included in all the container image layers, and search
    for known issues using both their own and internet-based vulnerability databases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s continue now with the second part of the pipeline. As you can see, we
    usually refer to the complete CI/CD workflow because CI and CD are often concatenated
    automatically one after the other.
  prefs: []
  type: TYPE_NORMAL
- en: Adding CD to the workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Different integration and performance tests can be executed by using the container
    images directly using Docker Compose or Kubernetes manifests, or via the Helm
    chart packages, which provide a more customizable solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CI/CD workflow continues with the tests, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Deployments for the different tests are triggered using the custom value files
    stored in the code repository. It is important to understand that we should never
    store sensitive data in clear text in our code repositories. Instead, use solutions
    such as HashiCorp’s Vault or Bitnami’s SealedSecrets to store sensitive data under
    encryption. Both solutions enable data decryption during the deployment stages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application’s performance and workflow task metrics can be integrated into
    your favorite dashboard environment. Most of the tests in this stage provide helpful
    summaries of the validation tasks executed, with which we can get a good overview
    of the impact of newly added changes. Logs will highlight any errors from either
    the tasks or the application’s processes. We should separate these into different
    dashboards because they will probably have different end users.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once all the tests are passed, we are ready to deploy the new release in production.
    Whether or not to automatically trigger this process depends on how your organization
    manages the changes in production. If your applications are governed using a GitOps
    model, use your configurations repository as the SOT, and the CI/CD orchestrator
    will push the changes into the Kubernetes platform. The current state of the application’s
    components may necessitate an upgrade to a new release or a rollback to a previous
    version to synchronize the desired state of the application. This model allows
    you to manage all your applications by changing their deployment configurations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The **GitOps** model extends the use of repositories to improve the tracking
    of infrastructure and application changes by using custom values repositories
    as a **single SOT** (**SSOT**) to trigger the delivery process. We can include
    automation for requiring specific security configurations, solving application
    or infrastructure dependencies before they are deployed, or any other requirement
    for the applications to work. All changes made to code and the values used for
    deploying the applications are tracked, making updates and rollbacks easier than
    ever.
  prefs: []
  type: TYPE_NORMAL
- en: Automating the deployment of our applications requires access and authorization
    to our Kubernetes environment. We include the required credentials for a deployment
    user in our CI/CD platform. We can use Argo CD to implement a simple GitOps working
    model. This way, a simple change in the custom package parameters will trigger
    the deployment of a new release using updated manifests. As a result, the new
    application release will be delivered with the given fixes or new requested features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The new release deployed will be kept in the maintenance stage until a new
    one is released to replace it. Monitoring the application and retrieving and analyzing
    feedback from the users will end this iteration. The process will start over,
    with the team planning the implementation of newly requested features and fixes
    to issues not yet solved in the latest release. The following schema represents
    the workflow presented in the preceding bullet points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.6 – Schema of the workflow followed to deliver a new application
    release](img/B19845_13_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – Schema of the workflow followed to deliver a new application release
  prefs: []
  type: TYPE_NORMAL
- en: We will now review some of the aforementioned stages in the following *Labs*
    section, using a GitLab platform deployed on a Minikube desktop environment.
  prefs: []
  type: TYPE_NORMAL
- en: Labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this lab, we will reproduce a very simplified supply chain using automation
    and the GitOps deployment model by installing and configuring GitLab and Argo
    CD in a test environment for building, testing, and deploying the `simplestlab`
    application. You can use a fully working Kubernetes platform (on the cloud or
    on-premises) or a simplified Kubernetes desktop environment. The fully detailed
    steps of the process are explained in the GitHub repository of this book, in the
    `Chapter13` folder, but here is the summary of the processes and some notable
    configurations you will find there:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we will prepare our environment with the tools required for the lab (Helm,
    `kubectl`, and the Argo CD CLI), and we will also use some environment variables
    for easier configuration of the Ingress resources and CA certificates for each
    application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will find complete Helm charts for the `simplestlab` application, alongside
    some value configurations for deploying the application. The specific values used
    in this file will depend on your environment, and we have provided an explanation
    to help. You can test and deploy the Helm charts using local configurations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will deploy and use GitLab to store all the application code, Helm charts,
    container images, and application configurations. Steps to create groups, subgroups,
    repositories, and required users are included.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The code and Helm charts folders included in the `Chapter13` repository come
    with a `.gitlab-ci.yml` file that describes and prepares CI automation to validate
    our Dockerfile using **Hadolint** (a Docker linter) and finally build our image
    using **Kaniko** (a tool to build container images from a Dockerfile inside a
    container or Kubernetes cluster). This tool doesn’t depend on the Docker container
    runtime and executes each command within a Dockerfile completely in user space,
    which is great for security. This way, we can build images inside any standard
    Kubernetes cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use `git` commands, different branches, and tags to trigger the different
    automations included in the example pipeline for the code and the Helm charts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The automation creates `dev` and `release` images using different container
    image tags. Development images will be added to the code repositories, but the
    release images will be considered ready for production and will be stored in a
    separate container images repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Helm charts are created using an umbrella structure; hence, the `simplestlab`
    chart deploys all the components at once. This chart includes dependencies for
    different applications’ components, and these dependencies should be solved before
    it is deployed. We will see how this works with a local example and then automate
    the Helm chart creation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Argo CD provides the CD part. While GitLab can be used to deploy directly on
    your Kubernetes cluster, Argo CD works by following the GitOps model. We will
    configure Argo CD to review any change in the `values` repository, and it will
    deploy the application using the resources stored in GitLab (container images,
    Helm charts, and the file with the values required for deploying the application).
    We will give you a brief discussion of the steps included in this lab and recommend
    you follow the full description written in the `Chapter13/Readme.md` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have prepared for you three main directories:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ArgoCD`: Contains the installation of the Argo CD component and the Application
    resource we will use to deploy our `simplestlab` application'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GitLab`: Contains the installation of GitLab components'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab`: This directory contains all the code, Helm charts, and values
    used for deploying a `simplestlab` application instance'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will need the following tools in our environment:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`base64` strings in case you don’t have `Base64`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubectl`: To connect to our Kubernetes cluster'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Base64`: For decoding some strings'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed steps for installing these tools are included in the code repository.
    We will start the lab by setting up a Minikube environment. We will use Linux
    and Docker for running this environment to be able to set up a fixed IP address.
    This will help you in case you decide to take your time for the lab and start
    and stop the Minikube environment without changing the setup. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start `minikube` using the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: .git folders in the Simplestlab_WORKSPACE folder and subfolders (if any) every
    time you start with the lab. We will use these folders to push some code changes
    inside Code/simplestapp, push Helm charts included in the HelmCharts directory,
    and push deployment values included inside the Values folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Install GitLab following the instructions included in the code repository. We
    have prepared a setup script to help you customize the values file for deploying
    GitLab using Helm. The chart is included under the `chapter13/GitLab` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once it is installed, we will review the secret created with the credentials
    and log in to the GitLab web UI, published at [https://gitlab.172.31.255.254.nip.io](https://gitlab.172.31.255.254.nip.io).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We used the [nip.io](http://nip.io) domain to simplify all the qualified domain
    names for your environment. You can read more about this simplified domain at
    [https://nip.io/](https://nip.io/).
  prefs: []
  type: TYPE_NORMAL
- en: We include our GitLab environment inside the Minikube setup to allow Kubernetes
    to download images. Complete steps are described in the GitLab repository.
  prefs: []
  type: TYPE_NORMAL
- en: We will then install Argo CD using a setup script and Helm. The script will
    customize a values file for your environment, and we will use it to deploy Argo
    CD using the Helm chart included in the `Chapter13/ArgoCD` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Detailed steps are provided in the code repository. Once installed, you will
    be able to access Argo CD at [https://argocd.172.31.255.254.nip.io](https://argocd.172.31.255.254.nip.io).
    You will use the admin user with the password obtained from the deployment secret,
    following the procedure described in the code repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will then upload the code included in `SimplestLab/Code` directory to GitLab.
    But first, we will create a user (`coder` user) with developer privileges in GitLab.
    This user will be used to pull and push code only, without privileged access.
    Steps for creating this user and the different projects for managing the code,
    Helm charts, images, and the values for deploying the application are described
    in the code repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Different permissions will be declared for different projects in GitLab. We
    have simplified the environment, setting up some projects as `Public`. Follow
    the instructions detailed in the `Chapter13` repository.
  prefs: []
  type: TYPE_NORMAL
- en: Using this `coder` user, we will push the code for the `simplestapp` component,
    included in the `Chapter13/Simplestlab/Code/simplestapp` directory, to our GitLab
    instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Automation of a Docker image build is triggered thanks to the existence of
    the `.gitlab-ci.yml` file in our code repository. This file describes the automated
    process and steps for verifying and building a custom image using our code. We
    included three stages in the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`test` (which basically validates our Dockerfile syntax)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`security` (which reviews the content of the files to be included in the image
    before it is built)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`build` (using Kaniko instead of Docker to improve security, avoiding the need
    to use the Kubernetes host’s Docker or `containerd` engine)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The process is described in detail in the `Readme.md` file included in the code
    repository.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To avoid the need to add the GitLab environment SSL certificate to our client
    environment, we will configure Git to skip SSL verification (steps are included
    in the code repository).
  prefs: []
  type: TYPE_NORMAL
- en: 'This automation will use the following variables for executing the tasks defined
    in the `.``gitlab-ci.yaml` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`PROJECTGROUP_USERNAME`: `coder`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PROJECTGROUP_PASSWORD`: `C0der000`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LABS_LOCAL_GITLAB_CERTIFICATE`: Complete GitLab TLS certificate chain `Base64`-decoded
    value, obtained using the following command:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`Images` project repository'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We will create `dev` and `main` code branches, change some code, push it to
    GitLab, and switch between branches to see whether changes will trigger the build
    process or not. Once we are ready to build a release image, we will tag the commit
    with a release name, push it to GitLab, and verify how the automated pipeline
    will create the appropriate release image inside the image project in GitLab.
    Described steps for these tasks are included in the `Chapter13/Readme.md` file.
    Please follow them carefully, and review the pipeline results and files generated
    during the process in the different GitLab projects (`Code` and `Images`). Get
    familiar with the processes before continuing with the next step, in which we
    will push and build the Helm charts for deploying the different applications’
    components.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will now manage the Helm charts’ code files and their associated projects’
    repositories. We set up for you three Helm charts, one for each component (`simplestlab-db`,
    `simplestlab-app`, and `simplestlab-lb`), and one umbrella chart that will include
    the others as dependencies. Therefore, four project repositories must be created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`simplestlab`: This chart defines the umbrella Helm chart used to deploy all
    components at once and its Ingress resource. We didn’t add any Ingress resource
    on any other component.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-app`: Describes the application backend component Deployment resource
    deployment.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-db`: Describes the database component StatefulSet deployment.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-lb`: This describes the load balancer DaemonSet deployment.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This project should be `Public` in this demo because we will not declare any
    credentials in Argo CD. You will use credentials and `Private` repositories in
    your production and development platforms, but this will definitely require more
    configurations for this demo environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The `simplestlab` umbrella chart depends on `simplestlab-app`, `simplestlab-db`,
    and `simplestlab-lb` charts. Whatever change you make to any of these projects
    requires a Helm chart dependencies update on the `simplestlab` umbrella chart.
    While you use the prepared CI/CD environment, you will need to run the `simplestlab`
    umbrella chart project pipeline again to rebuild these dependencies. If you want
    to manually update them, you will use a Helm dependencies update in the `HelmCharts/simplestlab`
    directory. We prepared various scenarios in the `Chart.yaml` file in case you
    want to test it locally (review the `Chapter13/Simplestlab/Values/simplestlab/values.yaml`
    file comments).
  prefs: []
  type: TYPE_NORMAL
- en: Once the Helm charts’ project repositories are created, we can push the Helm
    charts’ code into their GitLab-associated repositories. The code for the charts
    is located in `Chapter13/Simplestlab/HelmCharts`. Push each component’s code to
    the appropriate repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have included in the charts’ code the `.gitlab-ci.yaml` file for GitLab
    automation. This file describes three stages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`test` (which validates the Helm chart using its own linter)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dependencies` (which validates the chart dependencies if any are declared)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`build` (which packages the code into a Helm chart `.``tgz` file)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We need to include two new variables, `DOCKERHUB_USERNAME` (with your Docker
    Hub username) and `DOCKERHUB_PASSWORD` (with your Docker Hub password). These
    variables should be defined in the `HelmChart/SimplestLab` umbrella chart only.
    This repository is `Public`, and anyone will be able to read your password, but
    you are using your own demo environment. You can secure this password by making
    it `Private`, but you will need to prepare some username authentication (new user
    or even coder user here) and include it in the Argo CD OCI repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GitLab automation file will trigger two types of package construction processes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`HelmChart` project repository.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab` chart.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We will create `dev` and `main` code branches and verify the build process when
    we push code to GitLab. Steps for making some changes and pushing them to GitLab
    are described in the `Chapter13/Readme.md` file. The `simplestlab` umbrella chart
    will be pushed to Docker Hub, and we will be ready to use it, but first, we will
    need to add the `values.yaml` file to the `Values` project repository.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will create a `Simplestlab/values/simplestlab` repository to manage a simple
    values file that will be used to deploy the `simplestlab` application using the
    `simplestlab` umbrella Helm chart. The file contains different sections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`simplestlab-lb`: Defines the values to overwrite when deploying the `simplestlab-lb`
    Helm chart, added as a dependency in the umbrella chart.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-app`: Defines the values to overwrite when deploying the `simplestlab-app`
    Helm chart, added as a dependency in the umbrella chart.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-db`: Defines the values to overwrite when deploying the `simplestlab-db`
    Helm chart, added as a dependency in the umbrella chart.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`App` component (`__dbhost: db__`). The correct data is commented: `__dbhost:
    simplestlab-simplestlab-db__`. Thus, when you create the Argo CD application for
    the first time, the application component and the load balancer components will
    fail. Until you change the correct mentioned value in the `values` YAML file,
    this will not fix the problem in the load balancer component.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The second test will deploy a new configuration that will fix the load balancer
    component by deploying a completely new `nginx.conf` ConfigMap. To make this happen,
    uncomment the `nginxConfig` key in `simplestlab-lb`. Indentation is key; uncomment
    all the lines (you can leave the `###################################` line).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When an Application resource is created in Argo CD, the synchronization with
    the different reports starts, and every time you change either the Helm chart
    package or the values file, the misconfigurations will be reflected in the Argo
    CD environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a `simplestlab` values repository (`Project`) inside the `Values` project,
    and push the file from `Chapter13/Simplestlab/values/simplestlab` into this new
    repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will now integrate our application into Argo CD. We will use the Argo CD
    CLI to manage the integration of our Kubernetes cluster with Argo CD. To connect
    Kubernetes with Argo CD, create a ServiceAccount resource with cluster privileges
    to manage applications cluster-wide. Detailed instructions for integrating our
    Minikube Kubernetes cluster are included in the `Chapter13` repository. Follow
    these instructions, and then log in to Argo CD to create the following repositories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`coder` as the username and `c0der000` as the password.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-chart` package.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simplestlab-chart` package uploaded at Docker Hub as a workaround for an issue
    in Argo CD with self-signed certificates ([https://github.com/argoproj/argo-cd/issues/12371](https://github.com/argoproj/argo-cd/issues/12371)).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Screenshots are provided in the instructions to guide you through the setup
    process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the repositories are created in Argo CD, we can create an Argo CD Application
    resource. The Argo CD GUI does not allow us to use multiple repositories, hence
    we will not be able to use a code repository for the values file and another one
    for the Helm chart package artifact. In these circumstances, we need to prepare
    the Application resource using a YAML file. We included a YAML file for you in
    `Chapter13/ArgoCD/Applications`. The `minikube-simplestlab.yaml` file includes
    both the values file repository ([https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git](https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git))
    and the Helm chart repository ([docker.io/frjaraur](http://docker.io/frjaraur)).
    If you have followed all the steps, you can use your own Helm chart repository.
    Mine is public, and you will be able to use it at any time. The `Applications`
    manifest includes the sources for deploying an application and the destination
    environment – the Minikube lab environment in our case.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will create this new resource using `kubectl`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We have included in the Argo CD Application resource the `simplestlab` namespace.
    This namespace should be created before the application is actually deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we change the database host lab. The first thing you will notice is that
    the application’s `App` component does not work. This is due to the fact that
    the connection string is wrong (check the comments included in the `Chapter13/Simplestlab/Values/simplestlab/values.yaml`
    file). Change the `dbhost` key to `simplestlab-simplestlab-db` and verify the
    changes in Argo CD.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Verify the new name, automatically created by the Helm chart template (these
    names could have been fixed, but this is a common error and we can see how to
    solve it in this example):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'envVariables:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'dbhost: simplestlab-simplestlab-db'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Commit the new changes and push the file to our repository in GitLab using Git.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The changes will be shown on Argo CD in a few seconds. We haven’t configured
    auto-sync, hence we will see a misconfiguration of the values (out of sync). Current
    values in the cluster are different from those expected by the configuration.
    We will just proceed to sync the application (screenshots are included in the
    repository). This will create a new Secret resource. We will delete the `App`
    component Pods, and the new changes will be applied to this component.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the first problem is solved, you will find a new error because the `Loadbalancer`
    component isn’t able to reach the `App` component. So, next, we need to fix the
    `Loadbalancer` component. In this case, we will change the `__nginx.conf__` file
    required by `Nginx ___Lb___`. It is included as a ConfigMap resource and managed
    by the `___nginxConfig___` key in the values file. We need to change the name
    of the application backend service (`___App___` component). By default, it uses
    `___app___`, as you can see in the default values file included in the `___simplest-lb___`
    Helm chart (`SimplestLab/HelmCharts/simplestlab/values.yaml`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We first verify the name of the `App` component service:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '# Second Test Update -- Uncomment this section'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'nginxConfig: |'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: user  nginx;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: worker_processes  auto;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: error_log  /tmp/nginx/error.log warn;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: pid        /tmp/nginx/nginx.pid;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: events {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: worker_connections  1024;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: http {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: server {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: listen 8080;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: location /healthz {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: add_header Content-Type text/plain;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return 200 'OK';
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: location / {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: proxy_pass http://simplestlab-simplestlab-app:3000;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We commit and push the new changes. Argo CD will show the changes in a few seconds,
    and we will sync the resources and delete the `Lb` Pod, associated with the DaemonSet,
    to fix the NGINX configuration issue. After the synchronization and removal of
    the Pod, the new Pod works fine, and Argo CD will show the application as healthy
    and synced.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ve now reached the end of this long and complex lab, but we divided it into
    different stages to make it easier to follow. You can make changes to either your
    configurations, code, or Helm charts and trigger pipelines or GitOps integration
    to manage your application status and behavior. We can’t explain in a single lab
    all the configurations we have done to make all the workflow work; we gave you
    some tips that will help, and you can deep dive by yourself, exploring the already
    prepared configuration and script steps.
  prefs: []
  type: TYPE_NORMAL
- en: It would be useful to follow the lab by including the NetworkPolicy resources
    created in [*Chapter 11*](B19845_11.xhtml#_idTextAnchor244) and the NGINX and
    Postgres Prometheus exporters prepared in [*Chapter 12*](B19845_12.xhtml#_idTextAnchor267).
    After the completion of this lab, you will understand how the different automations
    work and will be ready to create your own using any other popular DevOps tool
    because the basic concepts are the same, no matter whether you use a cloud solution
    or deploy your DevOps tools in your own data center.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described the life cycle of an application using software
    containers. We used most of the content learned in this book so far to prepare
    a CI/CD workflow, while we quickly reviewed the different stages involved in the
    creation of an application based on containers. We also presented some of the
    most popular applications used by DevOps teams to implement and automate the complete
    supply chain of an application and learned how to use them in the *Labs* section.
    This final lab showed you the different stages involved in the life cycle of an
    application. We coded our application, prepared our container images to use as
    our application’s artifacts, and prepared Helm charts, which we used to deploy
    the application in Kubernetes. Finally, we triggered the execution of the application
    in the Kubernetes cluster using Argo CD to deliver the application after its configuration
    was done. All changes will be tracked, and the automation and orchestration functionalities
    help us to deliver changes quickly and reliably. You are now ready to employ the
    content of this book to create your own supply chain or use one already created
    using other common DevOps tools. Best of luck preparing and delivering your applications
    using software containers!
  prefs: []
  type: TYPE_NORMAL
