<html><head></head><body>
<div id="_idContainer060">
<h1 class="chapter-number" id="_idParaDest-136"><a id="_idTextAnchor330"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-137"><a id="_idTextAnchor331"/><span class="koboSpan" id="kobo.2.1">Connecting It All Together – GitFlow, GitOps, and CI/CD</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.3.1">GitOps</span></strong><span class="koboSpan" id="kobo.4.1"> is a</span><a id="_idIndexMarker445"/><span class="koboSpan" id="kobo.5.1"> contemporary approach to software development and operations that strives to make the management of infrastructure and applications easier and more efficient. </span><span class="koboSpan" id="kobo.5.2">It achieves this by using </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">Git</span></strong><span class="koboSpan" id="kobo.7.1"> as the primary source of truth and adopting a declarative approach wherever possible. </span><span class="koboSpan" id="kobo.7.2">This methodology integrates the principles of version control and continuous delivery to optimize the software development life cycle and facilitate better teamwork between development and operations teams—and sometimes a fusion of the two disciplines into a true </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.8.1">DevOps</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.9.1"> team.</span></span></p>
<p><span class="koboSpan" id="kobo.10.1">The chapter covers the </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.12.1">Understanding key concepts </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">of GitOps</span></span></li>
<li><span class="koboSpan" id="kobo.14.1">Leveraging GitHub for source </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">control management</span></span></li>
<li><span class="koboSpan" id="kobo.16.1">Leveraging GitHub Actions for </span><strong class="bold"><span class="koboSpan" id="kobo.17.1">continuous integration/continuous deployment</span></strong><span class="koboSpan" id="kobo.18.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.19.1">CI/CD</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">) pipelines</span></span><a id="_idTextAnchor332"/></li>
</ul>
<h1 id="_idParaDest-138"><a id="_idTextAnchor333"/><span class="koboSpan" id="kobo.21.1">Understanding key concepts of GitOps</span></h1>
<p><span class="koboSpan" id="kobo.22.1">There are</span><a id="_idIndexMarker446"/><span class="koboSpan" id="kobo.23.1"> many ways of implementing GitOps, and we’ll look at several in this chapter, but at its core, GitOps is about applying the software development life</span><a id="_idIndexMarker447"/><span class="koboSpan" id="kobo.24.1"> cycle to both application source code and infrastructure configuration—or </span><strong class="bold"><span class="koboSpan" id="kobo.25.1">infrastructure as code</span></strong><span class="koboSpan" id="kobo.26.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.27.1">IaC</span></strong><span class="koboSpan" id="kobo.28.1">). </span><span class="koboSpan" id="kobo.28.2">The Git repository becomes the source of truth for what is in production, what </span><em class="italic"><span class="koboSpan" id="kobo.29.1">was</span></em><span class="koboSpan" id="kobo.30.1"> in production, and what </span><em class="italic"><span class="koboSpan" id="kobo.31.1">will</span></em><span class="koboSpan" id="kobo.32.1"> be in production soon. </span><span class="koboSpan" id="kobo.32.2">In order to do so, the Git repository will have to include configuration files, application code, infrastructure definitions, and deployment manifests—everything needed to reproduce a fully working version of </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">the application.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">Declarative representations are preferred over compiled artifacts, but when source code is compiled into artifacts, they need to be versioned and tied back to a commit within the Git repository itself. </span><span class="koboSpan" id="kobo.34.2">Tools such as Terraform, Docker, and Kubernetes interpret these declarative files and automatically apply changes to the system to conform to the </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">desired state.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">Any changes to</span><a id="_idIndexMarker448"/><span class="koboSpan" id="kobo.37.1"> the Git repository are automatically and continuously applied to the target environment, no matter where the environment sits in the life cycle—a development, staging, or production environment. </span><span class="koboSpan" id="kobo.37.2">This automated process ensures consistency and reduces the risk of </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">manual errors.</span></span></p>
<p><span class="koboSpan" id="kobo.39.1">This can be achieved</span><a id="_idIndexMarker449"/><span class="koboSpan" id="kobo.40.1"> through a </span><strong class="bold"><span class="koboSpan" id="kobo.41.1">push</span></strong><span class="koboSpan" id="kobo.42.1"> or a </span><strong class="bold"><span class="koboSpan" id="kobo.43.1">pull</span></strong><span class="koboSpan" id="kobo.44.1"> model, which we first saw in the previous chapter when looking at different CI/CD pipeline approaches for Kubernetes-based solutions. </span><span class="koboSpan" id="kobo.44.2">Due to Kubernetes’s influence within the GitOps space, it is</span><a id="_idIndexMarker450"/><span class="koboSpan" id="kobo.45.1"> often a foregone conclusion that the goal is to establish a pull model. </span><span class="koboSpan" id="kobo.45.2">However, a pull model is not required to implement GitOps. </span><span class="koboSpan" id="kobo.45.3">There are many ways to implement GitOps, and each approach has distinct trade-offs that should be evaluated in your </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">specific context.</span></span></p>
<p><span class="koboSpan" id="kobo.47.1">Whether you use the push model or the pull model, one of the big advantages of using GitOps is that it provides transparency and visibility into the changes made to the system by keeping a log of all deployments and updates through the normal source control management process. </span><span class="koboSpan" id="kobo.47.2">The Git commit history is transformed into an audit trail that makes it easier to understand what changes were made when they occurred, and by whom. </span><span class="koboSpan" id="kobo.47.3">The combination of the complete configuration and code to produce an end-to-end working system and a versioned copy makes it relatively easy to roll back to a previous state in the event of issues. </span><span class="koboSpan" id="kobo.47.4">Of course, stateful portions of your systems will likely need additional engineering to ensure both new deployments and rollbacks </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">are uneventful.</span></span></p>
<p><span class="koboSpan" id="kobo.49.1">Using this approach can improve software delivery processes, resulting in greater efficiency, reliability, and scalability while simultaneously encouraging collaboration between development, operations, and other teams. </span><span class="koboSpan" id="kobo.49.2">This is the key reason why adopting this approach is critical to enabling a DevOps culture within </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">an organization.</span></span></p>
<p><span class="koboSpan" id="kobo.51.1">Due to the heavy reliance on Git—traditionally a software development tool—team members without an application development background can tend to struggle. </span><span class="koboSpan" id="kobo.51.2">Therefore, if you come from a non-developer background such as a system administrator, network or security engineer, or other infrastructure discipline, it’s very important that you take the time to learn basic Git commands and a </span><strong class="bold"><span class="koboSpan" id="kobo.52.1">Gitflow</span></strong><span class="koboSpan" id="kobo.53.1"> process, as this knowledge will be critical for you to be effective on </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">the team.</span></span></p>
<p><span class="koboSpan" id="kobo.55.1">Terraform—and tools like it—are a critical component to a GitOps toolchain as the use of IaC is an important pillar of this approach, but it’s important to remember that Terraform is often</span><a id="_idIndexMarker451"/><span class="koboSpan" id="kobo.56.1"> just one ingredient in the grand recipe with the source control and pipelining tool playing the key role in facilitating the process. </span><span class="koboSpan" id="kobo.56.2">That’s why, in this book, we’ll be setting up sophisticated architectures using Terraform and CI/CD pipelines to provision them. </span><span class="koboSpan" id="kobo.56.3">Before we can get to that, we need to firmly understand what a CI/CD pipeline is and how to build one, which is what we will look at in the </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">next se</span><a id="_idTextAnchor334"/><span class="koboSpan" id="kobo.58.1">ction.</span></span></p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor335"/><span class="koboSpan" id="kobo.59.1">Understanding CI/CD</span></h2>
<p><span class="koboSpan" id="kobo.60.1">A CI/CD pipeline is </span><a id="_idIndexMarker452"/><span class="koboSpan" id="kobo.61.1">an automated set of steps and processes that help software development teams build, test, and deploy their applications quickly and reliably. </span><span class="koboSpan" id="kobo.61.2">It is a fundamental component when implementing a GitOps process as it takes on the critical role of facilitating the continuous flow of changes from development to production, ensuring that new code is automatically integrated, tested, and delivered to end users as a </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">working system:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer050">
<span class="koboSpan" id="kobo.63.1"><img alt="Figure 6.1 – Overview of the anatomy of a CI/CD pipeline" src="image/B21183_06_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.64.1">Figure 6.1 – Overview of the anatomy of a CI/CD pipeline</span></p>
<p><span class="koboSpan" id="kobo.65.1">As its very name might suggest, a CI/CD pipeline actually consists of two processes that are stitched together. </span><span class="koboSpan" id="kobo.65.2">First, the </span><strong class="bold"><span class="koboSpan" id="kobo.66.1">continuous integration</span></strong><span class="koboSpan" id="kobo.67.1"> pipeline, which </span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.68.1">is responsible for building and ensuring the built-in quality of the application code of the system, and second, the </span><strong class="bold"><span class="koboSpan" id="kobo.69.1">continuous deployment</span></strong><span class="koboSpan" id="kobo.70.1"> pipeline, which</span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.71.1"> is responsible for deploying that application code into </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">its environment.</span></span></p>
<p><span class="koboSpan" id="kobo.73.1">The CI/CD pipeline </span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.74.1">aggregates these two historically distinct processes: </span><strong class="bold"><span class="koboSpan" id="kobo.75.1">integration testing</span></strong><span class="koboSpan" id="kobo.76.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.77.1">deployment</span></strong><span class="koboSpan" id="kobo.78.1">. </span><span class="koboSpan" id="kobo.78.2">However, by combining them, it provides a systematic and automated approach to continuously delivering new features and bug fixes to users, reducing the time and risk associated with manual deployments. </span><span class="koboSpan" id="kobo.78.3">This, in turn, fosters a culture of collaboration, frequent feedback, and rapid innovation within </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">development teams.</span></span></p>
<p><span class="koboSpan" id="kobo.80.1">A CI/CD pipeline that uses Terraform to provision infrastructure and deploys the latest code version to that infrastructure typically has two objectives. </span><span class="koboSpan" id="kobo.80.2">First, produce a version of the software that has been tested and verified to have satisfactory levels of built-in quality. </span><span class="koboSpan" id="kobo.80.3">Second, provision an environment—whatever that looks like—to host the application that is compatible and meets the software’s requirements to function correctly and efficiently. </span><span class="koboSpan" id="kobo.80.4">The third and final step is to deploy the application to </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">that environment.</span></span></p>
<p><span class="koboSpan" id="kobo.82.1">The pipeline</span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.83.1"> makes no judgments about how robust your cloud architecture might be. </span><span class="koboSpan" id="kobo.83.2">Depending on your needs, you may opt to sacrifice certain qualities of your solution architecture for expediency or cost. </span><span class="koboSpan" id="kobo.83.3">The pipeline’s job is to provision whatever environment you tell it you need and to deploy the software to that environment, so once the pipeline has completed, your application is ready to accept incoming traffic </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">from users.</span></span></p>
<p><span class="koboSpan" id="kobo.85.1">In the next section, we’ll dig deeper into the internal structure of a CI/CD pipeline and discuss the mechanics of what is going on alon</span><a id="_idTextAnchor336"/><span class="koboSpan" id="kobo.86.1">g </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">the way.</span></span></p>
<h2 id="_idParaDest-140"><a id="_idTextAnchor337"/><span class="koboSpan" id="kobo.88.1">Anatomy of pipeline</span></h2>
<p><span class="koboSpan" id="kobo.89.1">In the </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.90.1">previous sections, we learned about the fundamental principles of GitOps and that the CI/CD pipeline is grounded on a version control system such as Git, where developers commit their code changes. </span><span class="koboSpan" id="kobo.90.2">We can configure a CI/CD pipeline to trigger when certain key events take place within the code base, such as changes being pushed to a </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">specific branch.</span></span></p>
<p><span class="koboSpan" id="kobo.92.1">Once certain key events take place within the version control system, such as a developer pushing changes to a particular branch or path, the CI/CD pipeline is triggered. </span><span class="koboSpan" id="kobo.92.2">It will pull the latest code, build the application, and run a series of automated tests to verify the functionality and integrity of the </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">application code:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer051">
<span class="koboSpan" id="kobo.94.1"><img alt="Figure 6.2 – Anatomy of a CI/CD pipeline" src="image/B21183_06_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.95.1">Figure 6.2 – Anatomy of a CI/CD pipeline</span></p>
<p><span class="koboSpan" id="kobo.96.1">Various tests, including </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.97.1">unit tests, integration tests, and sometimes even acceptance tests, can be conducted to ensure that the code meets quality standards and does not </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">introduce regressions.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.99.1">Unit tests</span></strong><span class="koboSpan" id="kobo.100.1"> operate </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.101.1">on individual components and use mocks to isolate the tests’ outcomes around a single component by injecting placeholders for the component’s </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">downstream dependencies:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<span class="koboSpan" id="kobo.103.1"><img alt="Figure 6.3 – Unit tests are isolated on a single component" src="image/B21183_06_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.104.1">Figure 6.3 – Unit tests are isolated on a single component</span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.105.1">Integration tests</span></strong><span class="koboSpan" id="kobo.106.1"> operate </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.107.1">across two or more components. </span><span class="koboSpan" id="kobo.107.2">They </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.108.1">can use mocks or not, and their focus is on the reliability of interactions between components. </span><span class="koboSpan" id="kobo.108.2">Sometimes, for very intricate or complex components, you might want integration tests that focus on the various use cases surrounding them while keeping other components’ outputs predictable </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">using mocks:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer053">
<span class="koboSpan" id="kobo.110.1"><img alt="Figure 6.4 – Integration tests are focused on two or more components and how they interact" src="image/B21183_06_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.111.1">Figure 6.4 – Integration tests are focused on two or more components and how they interact</span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.112.1">System tests</span></strong><span class="koboSpan" id="kobo.113.1"> introduce </span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.114.1">real-world dependencies, such as databases</span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.115.1"> or messaging subsystems, into the mix and allow you to achieve much more realistic coverage across a system without fully </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">deploying it:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer054">
<span class="koboSpan" id="kobo.117.1"><img alt="Figure 6.5 – System tests" src="image/B21183_06_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.118.1">Figure 6.5 – System tests</span></p>
<p><span class="koboSpan" id="kobo.119.1">System tests </span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.120.1">have a broader</span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.121.1"> focus, often introducing real-world dependencies such as databases and </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">external systems</span></span></p>
<p><span class="koboSpan" id="kobo.123.1">An </span><strong class="bold"><span class="koboSpan" id="kobo.124.1">end-to-end test</span></strong><span class="koboSpan" id="kobo.125.1"> is </span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.126.1">one where you provide the entire host environment for the application—as it would be in production—and execute tests that mimic an actual client application or end user as closely </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">as possible:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<span class="koboSpan" id="kobo.128.1"><img alt="Figure 6.6 – End-to-end tests" src="image/B21183_06_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.129.1">Figure 6.6 – End-to-end tests</span></p>
<p><span class="koboSpan" id="kobo.130.1">End-to-end tests</span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.131.1"> attempt to mimic, as closely as possible, actual</span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.132.1"> end-user activity with the system fully operational, end </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">to end.</span></span></p>
<p><span class="koboSpan" id="kobo.134.1">It depends on the requirements of the particular application and organization, what kind of testing, and how much needs to be done on an application. </span><span class="koboSpan" id="kobo.134.2">Terraform can also play a crucial role in the continuous integration process by provisioning </span><strong class="bold"><span class="koboSpan" id="kobo.135.1">just-in-time</span></strong><span class="koboSpan" id="kobo.136.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.137.1">JIT</span></strong><span class="koboSpan" id="kobo.138.1">) environments for</span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.139.1"> system or end-to-end testing environments. </span><span class="koboSpan" id="kobo.139.2">Terraform allows you to dynamically create an environment fit for purpose, execute your tests, and then shut </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">everything down.</span></span></p>
<p><span class="koboSpan" id="kobo.141.1">Depending on the level of reliability that you want in your release process, you could opt for a deeper and more robust level of testing before the continuous deployment process </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">is initiated.</span></span></p>
<p><span class="koboSpan" id="kobo.143.1">After the continuous integration process is successfully completed, the application is packaged into a deployment package (e.g., a Docker container or a JAR file) that contains all the necessary dependencies and configurations and is ready to </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">be deployed.</span></span></p>
<p><span class="koboSpan" id="kobo.145.1">During the </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.146.1">continuous deployment process, both the Git source code and this deployment package are used to provide the environment and deploy the package to the target environment. </span><span class="koboSpan" id="kobo.146.2">Terraform is crucial in provisioning or updating the required infrastructure, such as virtual machines, containers, or serverless resources. </span><span class="koboSpan" id="kobo.146.3">As we looked at in the previous chapters, Terraform can also optionally perform the application deployment through a pre-built virtual machine image or a Kubernetes deployment with pre-built </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">container images.</span></span></p>
<p><span class="koboSpan" id="kobo.148.1">After deployment, the CD pipeline can run additional verification tests to ensure that the application runs correctly in the target environment by utilizing health checks built into the application </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">and infrastructure.</span></span></p>
<p><span class="koboSpan" id="kobo.150.1">Regardless of the architecture, the outcome of the CD pipeline is that it applies environment-specific configurations—usually derived from Terraform outputs, which contain vital configuration details—to the artifact, thus, customizing it for the target environment. </span><span class="koboSpan" id="kobo.150.2">These configurations might include database connection strings, API endpoints, or other settings that differ </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">between environments.</span></span></p>
<p><span class="koboSpan" id="kobo.152.1">As you can see, Terraform plays an essential role in this process but is not the only player on the field. </span><span class="koboSpan" id="kobo.152.2">Each step in this process is equally important and plays a critical role in consistently releasing software with built-in quality. </span><span class="koboSpan" id="kobo.152.3">In this book, we will review three architectures and three corresponding techniques for deployment for each of the three paradigms of cloud hosting: virtual machines, containers, and serverless. </span><span class="koboSpan" id="kobo.152.4">These solutions will be built using GitHub as the source control repository and GitHub Actions as the tool we use to implement our CI/CD pipelines. </span><span class="koboSpan" id="kobo.152.5">Depending on the architecture of the software and how it is hosted within the environment, the deployment </span><a id="_idTextAnchor338"/><span class="koboSpan" id="kobo.153.1">technique </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">may vary.</span></span></p>
<p><span class="koboSpan" id="kobo.155.1">In the next section, we’ll look at the source control management aspects of GitOps, which include the developer workflows that add structure to our DevOps teams that are executing in </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">this manner.</span></span></p>
<h1 id="_idParaDest-141"><a id="_idTextAnchor339"/><span class="koboSpan" id="kobo.157.1">Leveraging GitHub for source control management</span></h1>
<p><span class="koboSpan" id="kobo.158.1">GitHub is </span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.159.1">just one option for source control management software. </span><span class="koboSpan" id="kobo.159.2">We’ll be using it in this book, but it’s important for you to understand that the concepts and patterns implemented using GitHub are consistent no matter what source control provider you end up using for your projects. </span><span class="koboSpan" id="kobo.159.3">There may be small differences between the syntax and mechanisms that implement and execute pipelines, but the source control management system is just </span><strong class="source-inline"><span class="koboSpan" id="kobo.160.1">git</span></strong><span class="koboSpan" id="kobo.161.1"> under </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">the hood.</span></span></p>
<p><span class="koboSpan" id="kobo.163.1">An important part of source control management is how to use it in a structured way on a team—large or small. </span><span class="koboSpan" id="kobo.163.2">These are conventions that your team can use so that you have consistent expectations across the team about how new features are shepherded through your development process and </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">into production.</span></span></p>
<p><span class="koboSpan" id="kobo.165.1">Gitflow is a common model that uses a combination of well-known, long-lived, and consistent naming conventions for short-lived branches. </span><span class="koboSpan" id="kobo.165.2">As we will see in the next subsection, it is highly customizable and a bit of a </span><em class="italic"><span class="koboSpan" id="kobo.166.1">Choose Your Own Adventure</span></em><span class="koboSpan" id="kobo.167.1">, which is why it has become one of the most common operating models for development teams, no matter </span><span class="No-Break"><span class="koboSpan" id="kobo.168.1">the size.</span></span></p>
<p><span class="koboSpan" id="kobo.169.1">We’ll also look at a miniature variant called GitHub flow, which is an example of trunk-based development. </span><span class="koboSpan" id="kobo.169.2">This model advocates for keeping the </span><strong class="source-inline"><span class="koboSpan" id="kobo.170.1">main</span></strong><span class="koboSpan" id="kobo.171.1"> branch always deployable and minimizing the use of long-lived branches. </span><span class="koboSpan" id="kobo.171.2">Instead of creating long-lived stable branches for various purposes and designs, developers work directly on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.172.1">main</span></strong><span class="koboSpan" id="kobo.173.1"> branch using only short-lived </span><strong class="source-inline"><span class="koboSpan" id="kobo.174.1">feature</span></strong><span class="koboSpan" id="kobo.175.1"> branches that are quickly merged back </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">into </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.177.1">main</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">In the next section, we’ll take a closer look at Gitflow to see what the developer experience would look like and how it would integrate with the automation systems that we bu</span><a id="_idTextAnchor340"/><span class="koboSpan" id="kobo.180.1">ild </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">using Terraform.</span></span></p>
<h2 id="_idParaDest-142"><a id="_idTextAnchor341"/><span class="koboSpan" id="kobo.182.1">Gitflow</span></h2>
<p><span class="koboSpan" id="kobo.183.1">Gitflow is </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.184.1">one of the most popular branching models and workflows used by development teams around the world. </span><span class="koboSpan" id="kobo.184.2">Its prolific nature has led to the development of different variations and adaptations to suit different development environments and teams’ preferences. </span><span class="koboSpan" id="kobo.184.3">At its core, Gitflow leverages a </span><strong class="source-inline"><span class="koboSpan" id="kobo.185.1">main</span></strong><span class="koboSpan" id="kobo.186.1"> branch to indicate production quality code and a </span><strong class="source-inline"><span class="koboSpan" id="kobo.187.1">develop</span></strong><span class="koboSpan" id="kobo.188.1"> branch that grants development teams a safe place to merge and perform </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">integration testing:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<span class="koboSpan" id="kobo.190.1"><img alt="Figure 6.7 – Gitflow at its simplest" src="image/B21183_06_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.191.1">Figure 6.7 – Gitflow at its simplest</span></p>
<p><span class="koboSpan" id="kobo.192.1">In Gitflow, </span><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">main</span></strong><span class="koboSpan" id="kobo.194.1"> is the main </span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.195.1">branch representing the production-ready code. </span><span class="koboSpan" id="kobo.195.2">Only code that is ready for production should live in this branch. </span><span class="koboSpan" id="kobo.195.3">Features that are under development are created by individual developers on their own </span><strong class="source-inline"><span class="koboSpan" id="kobo.196.1">feature/*</span></strong><span class="koboSpan" id="kobo.197.1"> branch and then merged into a shared </span><strong class="source-inline"><span class="koboSpan" id="kobo.198.1">develop</span></strong><span class="koboSpan" id="kobo.199.1"> branch that acts a bit like a staging environment before being merged </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">into </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.201.1">main</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.203.1">However, as mentioned before, Gitflow is highly customizable and there have been several extensions to this core model developed over the years with varying levels </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">of adoption.</span></span></p>
<p><span class="koboSpan" id="kobo.205.1">Sometimes, </span><strong class="source-inline"><span class="koboSpan" id="kobo.206.1">release</span></strong><span class="koboSpan" id="kobo.207.1"> branches are used for preparing and testing releases, starting from </span><strong class="source-inline"><span class="koboSpan" id="kobo.208.1">develop</span></strong><span class="koboSpan" id="kobo.209.1"> and merging back into both </span><strong class="source-inline"><span class="koboSpan" id="kobo.210.1">develop</span></strong><span class="koboSpan" id="kobo.211.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.212.1">main</span></strong><span class="koboSpan" id="kobo.213.1">. </span><span class="koboSpan" id="kobo.213.2">This can give a team greater control over when and how they release a set of features </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">into production.</span></span></p>
<p><span class="koboSpan" id="kobo.215.1">The real world happens fast. </span><span class="koboSpan" id="kobo.215.2">As a result, sometimes critical changes need to be made rapidly to production to fix a specific issue. </span><span class="koboSpan" id="kobo.215.3">That’s when </span><strong class="source-inline"><span class="koboSpan" id="kobo.216.1">hotfix</span></strong><span class="koboSpan" id="kobo.217.1"> branches are used by starting from </span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">main</span></strong><span class="koboSpan" id="kobo.219.1"> and merging back into both </span><strong class="source-inline"><span class="koboSpan" id="kobo.220.1">develop</span></strong><span class="koboSpan" id="kobo.221.1"> and then </span><strong class="source-inline"><span class="koboSpan" id="kobo.222.1">main</span></strong><span class="koboSpan" id="kobo.223.1"> once a hotfix has been </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1">fully tested:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<span class="koboSpan" id="kobo.225.1"><img alt="Figure 6.8 – Gitflow extended" src="image/B21183_06_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.226.1">Figure 6.8 – Gitflow extended</span></p>
<p><span class="koboSpan" id="kobo.227.1">Gitflow is </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">highly </span></span><span class="No-Break"><a id="_idIndexMarker474"/></span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">customizable:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.230.1">main</span></strong><span class="koboSpan" id="kobo.231.1">: Production only </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">code (1)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.233.1">release</span></strong><span class="koboSpan" id="kobo.234.1">: Release </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">staging (2)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.236.1">develop</span></strong><span class="koboSpan" id="kobo.237.1">: Integrating </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">testing (3)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.239.1">feature/*</span></strong><span class="koboSpan" id="kobo.240.1">: Feature </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">development (4)</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.242.1">hotfix/*</span></strong><span class="koboSpan" id="kobo.243.1">: Critical patches to </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">production (5)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.245.1">Gitflow does not dictate a specific versioning scheme, but it is common to use semantic versioning (e.g., </span><strong class="source-inline"><span class="koboSpan" id="kobo.246.1">{MAJOR}.{MINOR}.{PATCH}</span></strong><span class="koboSpan" id="kobo.247.1">) to indicate the significance of changes made in each release. </span><span class="koboSpan" id="kobo.247.2">Gitflow does provide a clear separation of tasks, making it suitable for larger teams and projects that require strict control over the development and release process. </span><span class="koboSpan" id="kobo.247.3">However, this structure can be overwhelming for smaller teams or </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">experimental projects:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<span class="koboSpan" id="kobo.249.1"><img alt="Figure 6.9 – Gitflow integration with CI/CD pipelines" src="image/B21183_06_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.250.1">Figure 6.9 – Gitflow integration with CI/CD pipelines</span></p>
<p><span class="koboSpan" id="kobo.251.1">The Gitflow process has</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.252.1"> several key events where automation might </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">be triggered:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.254.1">Feature integration</span></strong><span class="koboSpan" id="kobo.255.1">: The developer submits a pull request from their </span><strong class="source-inline"><span class="koboSpan" id="kobo.256.1">feature/*</span></strong><span class="koboSpan" id="kobo.257.1"> branch into </span><strong class="source-inline"><span class="koboSpan" id="kobo.258.1">develop</span></strong><span class="koboSpan" id="kobo.259.1">. </span><span class="koboSpan" id="kobo.259.2">This often triggers a CI/CD pipeline that includes application code with built-in quality, unit, and integration tests. </span><span class="koboSpan" id="kobo.259.3">The merge of this pull request initiates a release pipeline that is deployed to the </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">development environment.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.261.1">Feature releases</span></strong><span class="koboSpan" id="kobo.262.1">: The team lead submits a pull request from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.263.1">develop</span></strong><span class="koboSpan" id="kobo.264.1"> branch into </span><strong class="source-inline"><span class="koboSpan" id="kobo.265.1">release</span></strong><span class="koboSpan" id="kobo.266.1">. </span><span class="koboSpan" id="kobo.266.2">This usually includes additional testing, such as system and even end-to-end tests. </span><span class="koboSpan" id="kobo.266.3">The merge of this pull request initiates a release pipeline that deploys to the staging or </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">release environment.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.268.1">Production releases</span></strong><span class="koboSpan" id="kobo.269.1">: The release manager submits a pull request from </span><strong class="source-inline"><span class="koboSpan" id="kobo.270.1">release</span></strong><span class="koboSpan" id="kobo.271.1"> into </span><strong class="source-inline"><span class="koboSpan" id="kobo.272.1">main</span></strong><span class="koboSpan" id="kobo.273.1">. </span><span class="koboSpan" id="kobo.273.2">This usually includes additional variations of end-to-end tests that check performance or load and may include upgrade or version testing. </span><span class="koboSpan" id="kobo.273.3">The merge of this pull request initiates a release pipeline that deploys to the </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">production environment.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.275.1">Critical patch</span></strong><span class="koboSpan" id="kobo.276.1">: The developer submits a pull request from a </span><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">hotfix/*</span></strong><span class="koboSpan" id="kobo.278.1"> branch into </span><strong class="source-inline"><span class="koboSpan" id="kobo.279.1">main</span></strong><span class="koboSpan" id="kobo.280.1">. </span><span class="koboSpan" id="kobo.280.2">This would likely execute a smaller catalog of test suites but would likely include version or upgrade testing. </span><span class="koboSpan" id="kobo.280.3">The merge of this pull request initiates a release pipeline that deploys to the </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">production environment.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.282.1">It’s important to </span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.283.1">point out that this is probably the most extensive configuration of Gitflow, but humans being humans, I’m sure somebody out there has come up with an even more complex incarnation of Gitflow. </span><span class="koboSpan" id="kobo.283.2">In the next section, let’s look at something a little more simple and lightweight by going back and taking a look at Trunk-Based Developm</span><a id="_idTextAnchor342"/><span class="koboSpan" id="kobo.284.1">ent using </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">GitHub flow.</span></span></p>
<h2 id="_idParaDest-143"><a id="_idTextAnchor343"/><span class="koboSpan" id="kobo.286.1">GitHub flow</span></h2>
<p><span class="koboSpan" id="kobo.287.1">As we’ve</span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.288.1"> discussed, GitHub flow is the little brother of Gitflow. </span><span class="koboSpan" id="kobo.288.2">It’s much more simple and lightweight and perfect for small teams or experimentation. </span><span class="koboSpan" id="kobo.288.3">It focuses on only one branch—</span><strong class="source-inline"><span class="koboSpan" id="kobo.289.1">main</span></strong><span class="koboSpan" id="kobo.290.1">—with new features being introduced for individual </span><strong class="source-inline"><span class="koboSpan" id="kobo.291.1">feature/*</span></strong><span class="koboSpan" id="kobo.292.1"> branches. </span><span class="koboSpan" id="kobo.292.2">Developers create </span><strong class="source-inline"><span class="koboSpan" id="kobo.293.1">feature</span></strong><span class="koboSpan" id="kobo.294.1"> branches from </span><strong class="source-inline"><span class="koboSpan" id="kobo.295.1">main</span></strong><span class="koboSpan" id="kobo.296.1">, work on their changes, and then submit pull requests to merge them back into the </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">main</span></strong><span class="koboSpan" id="kobo.298.1"> branch. </span><span class="koboSpan" id="kobo.298.2">Releases are often tagged from </span><strong class="source-inline"><span class="koboSpan" id="kobo.299.1">main</span></strong><span class="koboSpan" id="kobo.300.1"> after </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">thorough testing:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<span class="koboSpan" id="kobo.302.1"><img alt="Figure 6.10 – GitHub flow for small teams or experiments" src="image/B21183_06_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.303.1">Figure 6.10 – GitHub flow for small teams or experiments</span></p>
<p><span class="koboSpan" id="kobo.304.1">The main difference is that there is no official process around creating staging branches such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.305.1">develop</span></strong><span class="koboSpan" id="kobo.306.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.307.1">release</span></strong><span class="koboSpan" id="kobo.308.1"> branches where integration testing is performed. </span><span class="koboSpan" id="kobo.308.2">The responsibility for integration testing resides on the individual developer of the feature within their own </span><strong class="source-inline"><span class="koboSpan" id="kobo.309.1">feature</span></strong><span class="koboSpan" id="kobo.310.1"> branch—in essence, taking individual responsibility for their changes working </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">in production.</span></span></p>
<p><span class="koboSpan" id="kobo.312.1">This also means that we have fewer key events which a CI/CD pipeline will trigger from. </span><span class="koboSpan" id="kobo.312.2">We only have a pull request from </span><strong class="source-inline"><span class="koboSpan" id="kobo.313.1">feature/*</span></strong><span class="koboSpan" id="kobo.314.1"> into </span><strong class="source-inline"><span class="koboSpan" id="kobo.315.1">main</span></strong><span class="koboSpan" id="kobo.316.1"> and then merge into </span><strong class="source-inline"><span class="koboSpan" id="kobo.317.1">main</span></strong><span class="koboSpan" id="kobo.318.1"> to trigger events. </span><span class="koboSpan" id="kobo.318.2">Additional testing can be performed on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.319.1">feature/*</span></strong><span class="koboSpan" id="kobo.320.1"> branches themselves or teams can optionally introduce a manual trigger for a production release, which allows for more time to perform testing </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">on </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">main</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.324.1">As mentioned previously, GitHub flow is great for smaller teams that don’t have dedicated teams focused on </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">integration testing!</span></span></p>
<p><span class="koboSpan" id="kobo.326.1">Each variation</span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.327.1"> of Gitflow has its strengths and weaknesses, and the choice of workflow depends on the project’s specific needs, team size, development process, and the tools or platforms used for version control. </span><span class="koboSpan" id="kobo.327.2">It’s essential to evaluate the requirements and preferences of the team and project to select the most suitable branching model. </span><span class="koboSpan" id="kobo.327.3">I’ll go over a few of these options in this book in more detail, but for the most part, I will use GitHub Flow to keep things simple in </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">my examples.</span></span></p>
<h1 id="_idParaDest-144"><a id="_idTextAnchor344"/><span class="koboSpan" id="kobo.329.1">Using GitHub Actions for CI/CD pipelines</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.330.1">GitHub Actions</span></strong><span class="koboSpan" id="kobo.331.1"> is a CI/CD </span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.332.1">service offered by GitHub that provides a</span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.333.1"> platform for you to implement automation around your source control management process no matter what workflow </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">you choose.</span></span></p>
<p><span class="koboSpan" id="kobo.335.1">In order to hook into GitHub Actions, you need to define YAML files that specify the tasks that you want to be automated. </span><span class="koboSpan" id="kobo.335.2">These files </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.336.1">are called </span><strong class="bold"><span class="koboSpan" id="kobo.337.1">workflows</span></strong><span class="koboSpan" id="kobo.338.1"> and they are stored in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.339.1">.github/workflows</span></strong><span class="koboSpan" id="kobo.340.1"> directory of your source code repository. </span><span class="koboSpan" id="kobo.340.2">The basic anatomy of a workflow consists of jobs. </span><span class="koboSpan" id="kobo.340.3">Jobs have steps. </span><span class="koboSpan" id="kobo.340.4">Steps can be a simple script that you execute or something more complex packaged together called </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">an action:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.342.1">
jobs:
  build:
    runs-on: ubuntu-latest # The type of runner (virtual machine) that the job will run on
    steps:
    - name: Checkout code # Name of the step
      uses: actions/checkout@v2 # Use a pre-built action to checkout the current repo
    - name: Run a command
      run: echo "Hello, World!" </span><span class="koboSpan" id="kobo.342.2"># Commands to run
  test:
    needs: build # Specifies that this job depends on the 'build' job
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Run tests
      run: |
        npm install
        npm test**</span></pre> <p><span class="koboSpan" id="kobo.343.1">The preceding</span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.344.1"> code has two jobs: </span><strong class="source-inline"><span class="koboSpan" id="kobo.345.1">build</span></strong><span class="koboSpan" id="kobo.346.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">test</span></strong><span class="koboSpan" id="kobo.348.1">. </span><span class="koboSpan" id="kobo.348.2">The jobs are grouped under the </span><strong class="source-inline"><span class="koboSpan" id="kobo.349.1">jobs:</span></strong><span class="koboSpan" id="kobo.350.1"> section and each job has steps grouped under the </span><strong class="source-inline"><span class="koboSpan" id="kobo.351.1">steps:</span></strong><span class="koboSpan" id="kobo.352.1"> section. </span><span class="koboSpan" id="kobo.352.2">You can customize the image that your job runs on using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.353.1">runs-on</span></strong><span class="koboSpan" id="kobo.354.1"> attribute. </span><span class="koboSpan" id="kobo.354.2">This allows you to specify a container image that is customized to your needs with the correct Linux distribution or </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">software configuration.</span></span></p>
<p><span class="koboSpan" id="kobo.356.1">By default, a step simply executes a bash script using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.357.1">run</span></strong><span class="koboSpan" id="kobo.358.1"> attribute, but you can utilize an action by specifying the action type with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.359.1">uses</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.360.1"> attribute.</span></span></p>
<p><span class="koboSpan" id="kobo.361.1">To execute Terraform, you simply need it installed on your agent. </span><span class="koboSpan" id="kobo.361.2">This can be done easily using an action provided by HashiCorp called </span><strong class="source-inline"><span class="koboSpan" id="kobo.362.1">hashicorp\setup-terraform@v2</span></strong><span class="koboSpan" id="kobo.363.1">. </span><span class="koboSpan" id="kobo.363.2">The following code snippet demonstrates how to do this while specifying the specific version of Terraform that you want </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">to use:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.365.1">
steps:
- uses: hashicorp/setup-terraform@v2
  with:
    terraform_version: 1.5.5</span></pre> <p><span class="koboSpan" id="kobo.366.1">There are</span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.367.1"> additional attributes, but they are more for edge cases and are beyond the scope of this book. </span><span class="koboSpan" id="kobo.367.2">I recommend you check out the documentation for the action to check out all the different options </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">available: </span></span><a href="https://github.com/hashicorp/setup-terraform"><span class="No-Break"><span class="koboSpan" id="kobo.369.1">https://github.com/hashicorp/setup-terraform</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.370.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.371.1">You must always store sensitive data as secrets to ensure that the data is not exposed in the logs. </span><span class="koboSpan" id="kobo.371.2">This can easily be accomplished by leveraging GitHub environments or other</span><a id="_idTextAnchor345"/><span class="koboSpan" id="kobo.372.1"> secret </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">management services.</span></span></p>
<h2 id="_idParaDest-145"><a id="_idTextAnchor346"/><span class="koboSpan" id="kobo.374.1">Virtual machine workloads</span></h2>
<p><span class="koboSpan" id="kobo.375.1">When</span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.376.1"> building automation pipelines that provision</span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.377.1"> virtual-machine-hosted workloads, your toolchain should consist of something that can be used to set up the initial configuration of the virtual machine, provision the virtual machine, and make updates to the virtual machine’s configuration over time. </span><span class="koboSpan" id="kobo.377.2">The tools that we will cover in this book for these purposes are Packer, Terrafo</span><a id="_idTextAnchor347"/><span class="koboSpan" id="kobo.378.1">rm, and </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">Ansible, respectively.</span></span></p>
<h3><span class="koboSpan" id="kobo.380.1">Packer build pipeline</span></h3>
<p><span class="koboSpan" id="kobo.381.1">As we discussed</span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.382.1"> when we looked at developing Packer templates, developers write and commit Packer configuration files </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.383.1">using </span><strong class="bold"><span class="koboSpan" id="kobo.384.1">HashiCorp Configuration Language</span></strong><span class="koboSpan" id="kobo.385.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.386.1">HCL</span></strong><span class="koboSpan" id="kobo.387.1">) to their </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">Git repository.</span></span></p>
<p><span class="koboSpan" id="kobo.389.1">An independent pipeline is triggered when changes are pushed to the version control system affecting the folder where the Packer configuration files are stored. </span><span class="koboSpan" id="kobo.389.2">Within that pipeline, Packer is utilized to build virtual machine images for each server role (e.g., frontend, backend, and database). </span><span class="koboSpan" id="kobo.389.3">Packer is configured with the latest configurations for each role within the application, including the necessary software and settings unique to each layer. </span><span class="koboSpan" id="kobo.389.4">After successfully building each image, Packer creates machine images optimized for the cloud provider of choice (e.g., </span><strong class="bold"><span class="koboSpan" id="kobo.390.1">Amazon Machine Images</span></strong><span class="koboSpan" id="kobo.391.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.392.1">AMIs</span></strong><span class="koboSpan" id="kobo.393.1">) for </span><strong class="bold"><span class="koboSpan" id="kobo.394.1">Amazon Web Services</span></strong><span class="koboSpan" id="kobo.395.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.396.1">AWS</span></strong><span class="koboSpan" id="kobo.397.1">) or Azure Managed Images </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">for Azure).</span></span></p>
<p><span class="koboSpan" id="kobo.399.1">Sometimes, Packer can fail due to transient issues with the virtual machine itself or just bugs within your script. </span><span class="koboSpan" id="kobo.399.2">You can use a </span><strong class="bold"><span class="koboSpan" id="kobo.400.1">debug mode</span></strong><span class="koboSpan" id="kobo.401.1"> within Packer that will allow you to pause the build process on the temporary virtual machine. </span><span class="koboSpan" id="kobo.401.2">This will allow you to connect to the </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.402.1">machine, execute the command that failed manually, and troubleshoot the issues within the </span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">environment itself.</span></span></p>
<p><span class="koboSpan" id="kobo.404.1">Depending on the target cloud platform, the generated machine images are stored in an artifact repository or directly in the cloud provider’s image repos</span><a id="_idTextAnchor348"/><span class="koboSpan" id="kobo.405.1">itory for later use </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">by Terraform.</span></span></p>
<h3><span class="koboSpan" id="kobo.407.1">Terraform apply pipeline</span></h3>
<p><span class="koboSpan" id="kobo.408.1">Now </span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.409.1">that the virtual machine images are published to an image repository, Terraform simply needs to reference the correct image in order to provision a virtual machine with the right one. </span><span class="koboSpan" id="kobo.409.2">Similar to the Packer Build Pipeline, developers commit Terraform configuration files to their Git repository, and a separate pipeline is triggered whenever changes are pushed to the folder where the Terraform configuration </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1">is stored.</span></span></p>
<p><span class="koboSpan" id="kobo.411.1">The Terraform configuration defines the network infrastructure, including subnets, security groups, and load balancers, needed for all the virtual machines within the solution. </span><span class="koboSpan" id="kobo.411.2">Terraform pulls the Packer-built machine images from the artifact repository or cloud provider’s image repository and provisions the required number of virtual machines for each role, setting up any load balancers necessary to distribute the load across multiple servers to ensure high availability and </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">fault tolerance.</span></span></p>
<p><span class="koboSpan" id="kobo.413.1">Terraform can sometimes fail either for transient issues but also potential race conditions between resources that you are trying to provision that are implicitly dependent upon each other. </span><span class="koboSpan" id="kobo.413.2">We’ll go into more advanced troubleshooting scenarios in </span><a href="B21183_17.xhtml#_idTextAnchor700"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.414.1">Chapter 17</span></em></span></a><span class="koboSpan" id="kobo.415.1">, but for now, it’s important to recognize that Terraform is idempotent, which means you can run it over and over again to reach a desired state—so, sometimes, just re-running the job can get you</span><a id="_idTextAnchor349"/><span class="koboSpan" id="kobo.416.1"> past the initial issue </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">you faced.</span></span></p>
<h3><span class="koboSpan" id="kobo.418.1">Ansible apply pipeline</span></h3>
<p><span class="koboSpan" id="kobo.419.1">Finally, after</span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.420.1"> Terraform applies the infrastructure changes and the virtual machines are set up using the Packer images, the environment is primed and ready. </span><span class="koboSpan" id="kobo.420.2">However, the environment is not yet fully operational as there will likely be certain configuration changes that need to be made specific to the environment that were not available during the Packer image build phase. </span><span class="koboSpan" id="kobo.420.3">This is what I call </span><em class="italic"><span class="koboSpan" id="kobo.421.1">last mile</span></em><span class="koboSpan" id="kobo.422.1"> configuration—where we put the last touches on the environment by</span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.423.1"> applying any configuration settings only known after Terraform </span><strong class="source-inline"><span class="koboSpan" id="kobo.424.1">apply</span></strong><span class="koboSpan" id="kobo.425.1"> executes. </span><span class="koboSpan" id="kobo.425.2">There are different options for performing these last-mile configuration changes. </span><span class="koboSpan" id="kobo.425.3">You can use Terraform to dynamically configure user data to pass directly to the virtual machine, or you can use another tool to do </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">the job.</span></span></p>
<p><span class="koboSpan" id="kobo.427.1">Since most virtual machines also need some routine maintenance performed, it’s good to consider a configuration management tool that can make updates to your environment without having to shut down or reboot virtual machines by changing the version of the Packer image used. </span><span class="koboSpan" id="kobo.427.2">That’s where tools such as Ansible </span><span class="No-Break"><span class="koboSpan" id="kobo.428.1">come in.</span></span></p>
<p><span class="koboSpan" id="kobo.429.1">Ansible can be used as a configuration management tool to perform the last mile configuration on the virtual machines in addition to performing ongoing maintenance on the machines. </span><span class="koboSpan" id="kobo.429.2">Ansible scripts are applied to the deployed virtual machines to set environment-specific values, configure services, and perform other necessary tasks. </span><span class="koboSpan" id="kobo.429.3">In doing so, the environment is now ready for operators to perform routine maintenance using the already established </span><span class="No-Break"><span class="koboSpan" id="kobo.430.1">Ansible configuration.</span></span></p>
<p><span class="koboSpan" id="kobo.431.1">Like Terraform, Ansible is idempotent and can fall prey to similar transient errors. </span><span class="koboSpan" id="kobo.431.2">However, like Packer, Ansible is invoking change within the operating system itself. </span><span class="koboSpan" id="kobo.431.3">As a result, you just need to connect to one of these virtual machines and troubleshoot the commands that failed when Ansible executed </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">its scripts.</span></span></p>
<p><span class="koboSpan" id="kobo.433.1">By employing this approach, a virtual-machine-based solution can efficiently be provisioned and operated over the lifespan of the application. </span><span class="koboSpan" id="kobo.433.2">This allows for reproducible, scalable, and automated deployments and provides the necessary flexibility for different environments while ensuring consistent and reliable setup</span><a id="_idTextAnchor350"/><span class="koboSpan" id="kobo.434.1">s for each role within </span><span class="No-Break"><span class="koboSpan" id="kobo.435.1">the solution.</span></span></p>
<h2 id="_idParaDest-146"><a id="_idTextAnchor351"/><span class="koboSpan" id="kobo.436.1">Container workloads</span></h2>
<p><span class="koboSpan" id="kobo.437.1">When building </span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.438.1">automation pipelines that provision</span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.439.1"> container-based workloads, your toolchain should consist of something that can be used to set the initial configuration of the various containers that need to be deployed, provision the Kubernetes cluster to host the containers and the underlying infrastructure that supports the Kubernetes cluster’s operations, and then finally provision Kubernetes resources to the Kubernetes control pane using Kubernetes’ REST API through a variety of </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">different options.</span></span></p>
<p><span class="koboSpan" id="kobo.441.1">Due to the immutability</span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.442.1"> of the container images and their lightweight and speedy nature, it’s easy to implement sophisticated rolling updates to roll out new versions of the container image across existing deployments. </span><span class="koboSpan" id="kobo.442.2">Therefore, the mechanics around provisioning and maintaining container-based workloads are really about building new container images and referencing the desired image within your Kubernetes configuration</span><a id="_idTextAnchor352"/><span class="koboSpan" id="kobo.443.1"> to invoke an update to </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">the deployment.</span></span></p>
<h3><span class="koboSpan" id="kobo.445.1">Docker build pipeline</span></h3>
<p><span class="koboSpan" id="kobo.446.1">As we </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.447.1">discussed when we looked at the principles around Docker and how it works, developers write and commit Docker files using their </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">Git repository.</span></span></p>
<p><span class="koboSpan" id="kobo.449.1">An independent pipeline is triggered when changes are pushed to the version control system, affecting the folder where the Docker configuration files are stored. </span><span class="koboSpan" id="kobo.449.2">Within that pipeline, Docker is utilized to build container images for each server role (e.g., frontend, backend, and database) within the application. </span><span class="koboSpan" id="kobo.449.3">Docker is configured with the latest configurations for each role within the application, including the necessary software and settings unique to each layer. </span><span class="koboSpan" id="kobo.449.4">The Docker image that is produced acts as our deployment package. </span><span class="koboSpan" id="kobo.449.5">As a result, it is versioned and stored in a Package repository called a container registry (which we discussed in </span><a href="B21183_05.xhtml#_idTextAnchor278"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.450.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.451.1">). </span><span class="koboSpan" id="kobo.451.2">Once the new Docker image is there, we can reference it from the Kubernetes configuration and trigger a deplo</span><a id="_idTextAnchor353"/><span class="koboSpan" id="kobo.452.1">yment in Kubernetes in a myriad </span><span class="No-Break"><span class="koboSpan" id="kobo.453.1">of ways.</span></span></p>
<h3><span class="koboSpan" id="kobo.454.1">Kubernetes manifest update pipeline</span></h3>
<p><span class="koboSpan" id="kobo.455.1">In this </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.456.1">pipeline, developers modify the manifests to reference the new version of the Docker image that was built and published in the previous step and submit a pull request to update the change. </span><span class="koboSpan" id="kobo.456.2">The trigger we use can be either a push model or a pull model. </span><span class="koboSpan" id="kobo.456.3">If you recall, in </span><a href="B21183_05.xhtml#_idTextAnchor278"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.457.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.458.1">, </span><em class="italic"><span class="koboSpan" id="kobo.459.1">Container-Based Architectures</span></em><span class="koboSpan" id="kobo.460.1">, we discussed several different methods for implementing a push model in this manner. </span><span class="koboSpan" id="kobo.460.2">Some options use </span><strong class="source-inline"><span class="koboSpan" id="kobo.461.1">kubectl</span></strong><span class="koboSpan" id="kobo.462.1"> and Kubernetes YAML manifests, and others use a Helm Chart with a set of YAML manifests that have been turned into a more dynamic template by </span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">using Helm.</span></span></p>
<p><span class="koboSpan" id="kobo.464.1">Alternatively, using the pull model, we could use a continuous deployment agent hosted on the Kubernetes cluster itself, such as ArgoCD, that would pick up on changes within the Git repository and apply them to the cluster. </span><span class="koboSpan" id="kobo.464.2">Because ArgoCD is continuously monitoring the </span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.465.1">Git repository containing the Kubernetes manifests (or Helm Charts), whenever a new commit is made to the repository, it will automatically trigger a deployment process. </span><span class="koboSpan" id="kobo.465.2">ArgoCD isn’t doing any magic; it is simply using </span><strong class="source-inline"><span class="koboSpan" id="kobo.466.1">kubectl apply</span></strong><span class="koboSpan" id="kobo.467.1"> to apply the latest version of the manifests to the </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">Kubernetes cluster.</span></span></p>
<h3><span class="koboSpan" id="kobo.469.1">Terraform apply pipeline</span></h3>
<p><span class="koboSpan" id="kobo.470.1">As we </span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.471.1">have discussed in </span><a href="B21183_05.xhtml#_idTextAnchor278"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.472.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.473.1">, due to Kubernetes architecture, the Kubernetes cluster is often a shared resource where multiple teams will deploy their own workloads by targeting their own namespace within the cluster. </span><span class="koboSpan" id="kobo.473.2">That’s why it’s often the case that this pipeline may be managed by a different team than the ones that own the Docker Build and Kubernetes Manifest pipelines. </span><span class="koboSpan" id="kobo.473.3">This pipeline is owned by the team responsible for provisioning and maintaining the Kubernetes cluster. </span><span class="koboSpan" id="kobo.473.4">Their responsibility is to ensure that the cluster is up and running and ready to accept deployments </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">from ArgoCD.</span></span></p>
<p><span class="koboSpan" id="kobo.475.1">Terraform could optionally be used to manage Kubernetes resources on the cluster, but as we addressed in </span><a href="B21183_05.xhtml#_idTextAnchor278"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.476.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.477.1">, this may not be ideal in all situations due to team and organizational dynamics. </span><span class="koboSpan" id="kobo.477.2">It’s best to consider your specific context and make the right decision for your team </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">and organization.</span></span></p>
<p><span class="koboSpan" id="kobo.479.1">In most cases, Terraform is simply used to provision the Kubernetes cluster and surrounding infrastructure on the cloud platform of choice. </span><span class="koboSpan" id="kobo.479.2">Developers will commit Terraform configuration files to their Git repository, and the pipeline is triggered whenever changes are pushed to the folder where the Terraform configuration </span><span class="No-Break"><span class="koboSpan" id="kobo.480.1">is stored.</span></span></p>
<p><span class="koboSpan" id="kobo.481.1">This approach allows developers to focus on code development and testing without worrying about the underlying infrastructure and deployment process. </span><span class="koboSpan" id="kobo.481.2">The development teams can rely on an isolated environment within the Kubernetes cluster that they deploy to and really only need to maintain their code base and the Docke</span><a id="_idTextAnchor354"/><span class="koboSpan" id="kobo.482.1">r file used to configure </span><span class="No-Break"><span class="koboSpan" id="kobo.483.1">their application.</span></span></p>
<h2 id="_idParaDest-147"><a id="_idTextAnchor355"/><span class="koboSpan" id="kobo.484.1">Serverless workloads</span></h2>
<p><span class="koboSpan" id="kobo.485.1">In serverless</span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.486.1"> architecture, the deployment process</span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.487.1"> can be greatly simplified. </span><span class="koboSpan" id="kobo.487.2">You typically have two main pipelines to manage the serverless framework and surrounding services and the actual function </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1">code themselves.</span></span></p>
<h3><span class="koboSpan" id="kobo.489.1">Terraform apply pipeline</span></h3>
<p><span class="koboSpan" id="kobo.490.1">This</span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.491.1"> pipeline is responsible for provisioning the underlying infrastructure required to support the serverless workloads. </span><span class="koboSpan" id="kobo.491.2">It uses Terraform to define and manage the infrastructure components. </span><span class="koboSpan" id="kobo.491.3">The pipeline may create resources such as load balancers, API gateways, event triggers, and other logical components that serve as the foundation for serverless functions. </span><span class="koboSpan" id="kobo.491.4">These are often lightweight cloud s</span><a id="_idTextAnchor356"/><span class="koboSpan" id="kobo.492.1">ervices that are extremely quick </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">to provision.</span></span></p>
<h3><span class="koboSpan" id="kobo.494.1">Serverless deployment pipeline</span></h3>
<p><span class="koboSpan" id="kobo.495.1">This </span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.496.1">pipeline is responsible for deploying individual serverless functions to the target platform (e.g., AWS Lambda or Azure Functions). </span><span class="koboSpan" id="kobo.496.2">Each serverless function typically has its own pipeline to handle its deployment, testing, and versioning. </span><span class="koboSpan" id="kobo.496.3">This maintains autonomy between the different components and allows teams to organize ownership that aligns with how they manage their code base. </span><span class="koboSpan" id="kobo.496.4">The pipeline really only involves packaging the function code, defining the configuration, and deploying it to the cloud platform </span><span class="No-Break"><span class="koboSpan" id="kobo.497.1">of choice.</span></span></p>
<p><span class="koboSpan" id="kobo.498.1">The serverless approach simplifies the deployment and management of code, and developers can focus more on writing the application logic while relying on automated deployment pipelines to handle infrastructure pr</span><a id="_idTextAnchor357"/><span class="koboSpan" id="kobo.499.1">ovisioning and serverless </span><span class="No-Break"><span class="koboSpan" id="kobo.500.1">function deployments.</span></span></p>
<h2 id="_idParaDest-148"><a id="_idTextAnchor358"/><span class="koboSpan" id="kobo.501.1">Terraform tools</span></h2>
<p><span class="koboSpan" id="kobo.502.1">There are </span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.503.1">a ton </span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.504.1">of tools out there to help improve Terraform code in terms of beauty, functionality, and maintainability. </span><span class="koboSpan" id="kobo.504.2">I won’t boil the ocean here but I will mention some critical tools that are absolutely required </span><a id="_idTextAnchor359"/><span class="koboSpan" id="kobo.505.1">for any Terraform continuous </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1">integration process.</span></span></p>
<h3><span class="koboSpan" id="kobo.507.1">Formatting</span></h3>
<p><span class="koboSpan" id="kobo.508.1">During </span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.509.1">development, you should install the HashiCorp Terraform plugin for Visual Studio Code. </span><span class="koboSpan" id="kobo.509.2">This will enable a ton of helpful productivity features within your editor but it will also automatically execute Terraform’s built-in formatting function, </span><strong class="source-inline"><span class="koboSpan" id="kobo.510.1">terraform fmt</span></strong><span class="koboSpan" id="kobo.511.1">, on saving each file. </span><span class="koboSpan" id="kobo.511.2">This will drastically help promote consistent formatting within your code base. </span><span class="koboSpan" id="kobo.511.3">This is a proactive approach that is dependent on the developer to take steps to configure their development </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">environment properly.</span></span></p>
<p><span class="koboSpan" id="kobo.513.1">In order to verify each developer is employing this technique to keep your project’s Terraform code neat and tidy, you need to use a linter as part of your pull request process. </span><span class="koboSpan" id="kobo.513.2">Adding </span><strong class="source-inline"><span class="koboSpan" id="kobo.514.1">tflint</span></strong><span class="koboSpan" id="kobo.515.1"> to your pull request process will help prevent poorly formatt</span><a id="_idTextAnchor360"/><span class="koboSpan" id="kobo.516.1">ed code from ever making it into your </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.517.1">main</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.518.1"> branch!</span></span></p>
<h3><span class="koboSpan" id="kobo.519.1">Documentation</span></h3>
<p><span class="koboSpan" id="kobo.520.1">Now that</span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.521.1"> the code is formatted properly, we should generate some documentation for our modules. </span><span class="koboSpan" id="kobo.521.2">This is useful whether you are writing root modules or reusable modules. </span><span class="koboSpan" id="kobo.521.3">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1">terraform-docs</span></strong><span class="koboSpan" id="kobo.523.1"> tool, when pointed at a Terraform module director, will generate a markdown </span><strong class="source-inline"><span class="koboSpan" id="kobo.524.1">README</span></strong><span class="koboSpan" id="kobo.525.1"> file that documents the key aspects of your Terraform module, including version requirements for both Terraform and the providers you employ, as well as details on the input and output variables. </span><span class="koboSpan" id="kobo.525.2">This tool is ideal to set up as a pre-commit operation to ensure that your documentation is automatically generated every time the code is merged. </span><span class="koboSpan" id="kobo.525.3">It reads annotations that are built-in to HCL, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.526.1">description</span></strong><span class="koboSpan" id="kobo.527.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.528.1">type</span></strong><span class="koboSpan" id="kobo.529.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.530.1">required</span></strong><span class="koboSpan" id="kobo.531.1">, and any </span><span class="No-Break"><span class="koboSpan" id="kobo.532.1">default values.</span></span></p>
<p><span class="koboSpan" id="kobo.533.1">You can read more </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">at </span><a id="_idTextAnchor361"/></span><a href="https://terraform-docs.io/user-guide/introduction/"><span class="No-Break"><span class="koboSpan" id="kobo.535.1">https://terraform-docs.io/user-guide/introduction/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.536.1">.</span></span></p>
<h3><span class="koboSpan" id="kobo.537.1">Security scanning</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.538.1">Checkov</span></strong><span class="koboSpan" id="kobo.539.1"> is a </span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.540.1">static </span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.541.1">code analyzer that can scan your Terraform plan files to detect security and compliance violations. </span><span class="koboSpan" id="kobo.541.2">It has thousands of built-in policies spanning many platforms but most importantly including the cloud platforms that we explore in this book: AWS, Azure, and Google Cloud. </span><span class="koboSpan" id="kobo.541.3">However, at the time of writing, the policy coverage is most comprehensive for AWS, with both Azure and Google Cloud with significantly </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">less coverage.</span></span></p>
<p><span class="koboSpan" id="kobo.543.1">You can </span><a id="_idTextAnchor362"/><span class="koboSpan" id="kobo.544.1">read more </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">at </span></span><a href="https://github.com/bridgecrewio/checkov"><span class="No-Break"><span class="koboSpan" id="kobo.546.1">https://github.com/bridgecrewio/checkov</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.547.1">.</span></span></p>
<h1 id="_idParaDest-149"><a id="_idTextAnchor363"/><span class="koboSpan" id="kobo.548.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.549.1">In this chapter, we learned the basic concepts of source control management, including detailed breakdowns of different branching and workflow strategies that are used by teams large and small. </span><span class="koboSpan" id="kobo.549.2">We looked at how our automation systems, namely our CI/CD pipelines, would integrate with these processes at </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">key events.</span></span></p>
<p><span class="koboSpan" id="kobo.551.1">In the next chapter, we will move conceptual knowledge and start working on our first solution, which is to leverage virtual machines on the first public </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">cloud, AWS.</span></span></p>
</div>


<div class="Content" id="_idContainer061">
<h1 id="_idParaDest-150" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor364"/><span class="koboSpan" id="kobo.1.1">Part 3: Building Solutions on AWS</span></h1>
<p><span class="koboSpan" id="kobo.2.1">Armed with the conceptual knowledge of Terraform and architectural concepts that transcend the implementation details of the major public cloud platforms, we’ll explore building solutions on </span><strong class="bold"><span class="koboSpan" id="kobo.3.1">Amazon Web Services</span></strong><span class="koboSpan" id="kobo.4.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.5.1">AWS</span></strong><span class="koboSpan" id="kobo.6.1">) with three cloud computing paradigms: virtual machines, containers with Kubernetes, and serverless with </span><span class="No-Break"><span class="koboSpan" id="kobo.7.1">AWS Lambda.</span></span></p>
<p><span class="koboSpan" id="kobo.8.1">This part has the </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">following chapters:</span></span></p>
<ul>
<li><a href="B21183_07.xhtml#_idTextAnchor365"><em class="italic"><span class="koboSpan" id="kobo.10.1">Chapter 7</span></em></a><span class="koboSpan" id="kobo.11.1">, </span><em class="italic"><span class="koboSpan" id="kobo.12.1">Getting Started on AWS – Building Solutions with AWS EC2</span></em></li>
<li><a href="B21183_08.xhtml#_idTextAnchor402"><em class="italic"><span class="koboSpan" id="kobo.13.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.14.1">, </span><em class="italic"><span class="koboSpan" id="kobo.15.1">Containerize with AWS – Building Solutions with AWS EKS</span></em></li>
<li><a href="B21183_09.xhtml#_idTextAnchor446"><em class="italic"><span class="koboSpan" id="kobo.16.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.17.1">, </span><em class="italic"><span class="koboSpan" id="kobo.18.1">Go Serverless with AWS – Building Solutions with AWS Lambda</span></em></li>
</ul>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer062">
</div>
</div>
</body></html>