["```\n$ oc project openshift-etcd\n$ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd\netcd-ocp-master-0 3/3 Pending 0 14m\netcd-ocp-master-1 3/3 CrashLoopBackOff 6 17m\netcd-ocp-master-3 2/3 Running 0 9m11s\n```", "```\noc rsh etcd-ocp-master-3\nDefaulting container name to etcdctl.\nUse 'oc describe pod/etcd-ocp-master-3 -n openshift-etcd' to see all of the containers in this pod.\nsh-4.4# etcdctl member list -w table\n+------+------+------+------+------+------+\n| ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER +------+------+------+------+------+------+\n| 5bdacda4e0f48d91 | failed | ocp-master-1 | https://192.168.200.235:2380 | https://192.168.200.235:2379 | false |\n| b50b656cba1b0122 | started | ocp-master-3 | https://192.168.200.14:2380 | https://192.168.200.14:2379 | false |\n| cdc9d2f71033600a | failed | ocp-master-0 | https://192.168.200.234:2380 | https://192.168.200.234:2379 | false |\n+------+------+------+------+------+------+\nsh-4.4# etcdctl endpoint status -w table\n+------+------+------+------+------+------+\n| ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+------+------+------+------+------+------+\n| https://192.168.200.14:2379 | b50b656cba1b0122 | 3.4.9 | 136 MB | true | false | 281 | 133213554 | 133213554 | |\n| https://192.168.200.234:2379 | cdc9d2f71033600a | 3.4.9 | 137 MB | false | false | 281 | 133213554 | 133213554 | |\n| https://192.168.200.235:2379 | 5bdacda4e0f48d91 | 3.4.9 | 136 MB | false | false | 281 | 133213554 | 133213554 | |\n+------+------+------+------+------+------+\n```", "```\n/usr/local/bin/cluster-backup.sh /home/core/assets/backup\n```", "```\n    oc get machine <master-node> \\\n        -n openshift-machine-api \\\n        -o yaml \\\n        > new-master-machine.yaml\n    ```", "```\n    new-master-machine.yaml\n    apiVersion: machine.openshift.io/v1beta1\n    kind: Machine\n    metadata:\n      finalizers:\n      - machine.machine.openshift.io\n      labels:\n        machine.openshift.io/cluster-api-cluster: ocp-sgw5f\n    (.. omitted ..)\n      name: ocp-master-4\n      namespace: openshift-machine-api\n      selfLink: /apis/machine.openshift.io/v1beta1/namespaces/openshift-machine-api/machines/ocp-master-4\n    spec:\n      metadata: {}\n      providerSpec:\n        value:\n          apiVersion: vsphereprovider.openshift.io/v1beta1\n          credentialsSecret:\n            name: vsphere-cloud-credentials\n          diskGiB: 120\n          kind: VSphereMachineProviderSpec\n    (.. omitted ..)\n    ```", "```\n    $ oc delete machine <problematic-master-node-name> -n openshift-machine-api\n    ```", "```\n    $ oc get machines -n openshift-machine-api -o wide\n    ```", "```\n    oc apply –f new-master-machine.yaml\n    ```", "```\n    $ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd\n    ```", "```\n    $ oc patch etcd cluster -p='{\"spec\": {\"forceRedeploymentReason\": \"recovery-'\"$( date --rfc-3339=ns )\"'\"}}' --type=merge\n    ```", "```\n    # Get the name of one etcd pod\n    $ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd\n    $ oc rsh <etcd-pod-name> -n openshift-etcd\n    ```", "```\n    etcdctl member list -w table\n    ```", "```\n    $ etcdctl remove <member-id>\n    ```", "```\n    $ ssh -i ~/.ssh/id_rsa core@ocp-master-3\n    ```", "```\n    $ sudo crictl | grep –i etcd\n    ```", "```\n    $ crictl exec bd077a3f1b211 etcdctl member list -w table\n    +---+---+---+---+---+---+\n    | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER |\n    +---+---+---+---+---+---+\n    | 9e715067705c0f7c | unknown | ocp-master-4 | https://192.168.200.15:2380 | https://192.168.200.15:2379 | false |\n    | b50b656cba1b0122 | started | ocp-master-3 | https://192.168.200.14:2380 | https://192.168.200.14:2379 | false |\n    | cdc9d2f71033600a | failed  | ocp-master-0 | https://192.168.200.234:2380 | https://192.168.200.234:2379 | false |\n    +---+---+---+---+---+---+\n    ```", "```\n    sudo /usr/local/bin/cluster-backup.sh /home/core/assets/backup\n    ```", "```\n    $ crictl exec bd077a3f1b211 etcdctl endpoint status -w table\n    +-------+-------+-------+-------+-------+-------+\n    | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n    +-------+-------+-------+-------+-------+-------+\n    | https://192.168.200.14:2379 | b50b656cba1b0122 | 3.4.9 | 136 MB | true | false | 491 | 133275501 | 133275501 | |\n    | https://192.168.200.15:2379 | 9e715067705c0f7c | 3.4.9 | 137 MB | false| false | 491 | 133275501 | 133275501 | |\n    +-------+-------+-------+-------+-------+-------+\n    ```", "```\n$ oc debug node/master1.ocp.hybridcloud.com\n```", "```\nStarting pod/ocp-master1hybridcloud-debug ...\n To use host binaries, run `chroot /host`\n chroot /host\nPod IP: 172.19.10.4\n If you don't see a command prompt, try pressing enter.\n sh-4.4# chroot /host\n sh-4.4#\n```", "```\nsh-4.4# podman run --volume /var/lib/etcd:/var/lib/etcd:Z quay.io/openshift-scale/etcd-perf Trying to pull quay.io/openshift-scale/etcd-perf:latest...\nGetting image source signatures\n(.. omitted ..)\n------- Running fio ------{\n\"fio version\" : \"fio-3.7\",\n\"timestamp\" : 1631814461,\n\"timestamp_ms\" : 1631814461780,\n\"time\" : \"Thu Sep 16 17:47:41 2021\",\n\"global options\" : {\n\"rw\" : \"write\",\n \"ioengine\" : \"sync\",\n\"fdatasync\" : \"1\",\n \"directory\" : \"/var/lib/etcd\",\n\"size\" : \"22m\", [1]\n\"bs\" : \"2300\" }, [2]\n(.. omitted ..)\n\"write\" : {\n\"io_bytes\" : 23066700,\n\"io_kbytes\" : 22526,\n\"bw_bytes\" : 1319077,\n\"bw\" : 1288, [3]\n\"iops\" : 573.511752, [4]\n(.. omitted ..)\n\"read_ticks\" : 3309,\n\"write_ticks\" : 29285,\n\"in_queue\" : 32594,\n\"util\" : 98.318751\n} ]\n}\n---------\n99th percentile of fsync is 5406720 ns\n99th percentile of the fsync is within the recommended threshold - 10 ms, the disk can be used to host etcd [5]\n```", "```\n    $ oc adm policy add-role-to-user <role> <user> -n <project>\n    ```", "```\n    $ oc adm policy add-cluster-role-to-user <role> <user>\n    ```", "```\n$ oc adm policy remove-role-from-user <role> <user> -n <project>\n$ oc adm policy remove-role-from-group <role> <group> -n <project>\n$ oc adm policy remove-cluster-role-from-user <role> <user>\n$ oc adm policy remove-cluster-role-from-group <role> <group>\n```", "```\n$ oc create role <role-name> --verb=<verbs-list> --resource=<resources-list>\n```", "```\n$ oc create role sample --verb=get,list,watch --resource=pods,pods/status\n```", "```\n$ oc describe pod sso-10-qm2hc\n```", "```\nEvents:\n  Type     Reason          Age                From               Message\n  ----     ------          ----               ----               -------\n  Normal   Scheduled       90s                default-scheduler  Successfully assigned rhsso/sso-10-qm2hc to ocp-hml4.hybridcloud.com\n  Normal   AddedInterface  89s                multus             Add eth0 [10.242.22.12/23] from openshift-sdn\n  Normal   Pulling         39s (x3 over 89s)  kubelet            Pulling image \"image-registry.openshift-image-registry.svc:5000/rhsso/sso74-custom\"\n  Warning  Failed          33s (x3 over 83s)  kubelet            Failed to pull image \"image-registry.openshift-image-registry.svc:5000/rhsso/sso74-custom\": rpc error: code = Unknown desc = pinging container registry image-registry.openshift-image-registry.svc:5000: Get \"https://image-registry.openshift-image-registry.svc:5000/v2/\": dial tcp 10.244.109.169:5000: connect: no route to host\n  Warning  Failed          33s (x3 over 83s)  kubelet            Error: ErrImagePull\n  Normal   BackOff         8s (x4 over 83s)   kubelet            Back-off pulling image \"image-registry.openshift-image-registry.svc:5000/rhsso/sso74-custom\"\n  Warning  Failed          8s (x4 over 83s)   kubelet            Error: ImagePullBackOff\n```", "```\n$ oc get events -n openshift-image-registry\nLAST SEEN   TYPE      REASON              OBJECT                                                  MESSAGE\n35m         Normal    Scheduled           pod/cluster-image-registry-operator-7456697c64-88hxc    Successfully assigned openshift-image-registry/cluster-image-registry-operator-7456697c64-88hxc to ocp-master2.hybridcloud.com\n35m         Normal    AddedInterface      pod/cluster-image-registry-operator-7456697c64-88hxc    Add eth0 [10.242.0.37/23] from openshift-sdn\n35m         Normal    Pulled              pod/cluster-image-registry-operator-7456697c64-88hxc    Container image \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6a78c524aab5bc95c671811b2c76d59a6c2d394c8f9ba3f2a92bc05a780c783a\" already present on machine\n(...omitted...)\n```", "```\n    $ oc project mynamespace\n    $ oc logs mypod\n    ```", "```\n    $ oc –n mynamespace logs mypod\n    ```", "```\n    $ oc -n mynamespace logs mypod -c kube_proxy\n    ```", "```\n$ oc –n mynamespace logs deployment/mydeploypods\n```", "```\n$ oc –n  mynamespace logs dc/mydeploypods\n```", "```\n$ oc debug deployment/<deployment-name>\n```", "```\n    $ oc get co\n    ```", "```\n    $ oc describe co <clusteroperatorName>\n    ```", "```\n$ oc describe co storage\n```", "```\n    (...omitted...)\n    Status:\n      Conditions:\n        Last Transition Time:  2021-08-26T14:51:59Z\n        Message:               All is well\n        Reason:                AsExpected\n        Status:                False\n        Type:                  Degraded\n        Last Transition Time:  2021-08-26T14:51:59Z\n        Message:               All is well\n        Reason:                AsExpected\n        Status:                False\n        Type:                  Progressing\n        Last Transition Time:  2021-08-26T14:51:59Z\n        Message:               DefaultStorageClassControllerAvailable: No default StorageClass for this platform\n        Reason:                AsExpected\n        Status:                True\n        Type:                  Available\n        Last Transition Time:  2021-08-26T14:52:00Z\n        Message:               All is well\n        Reason:                AsExpected\n        Status:                True\n        Type:                  Upgradeable\n    (...ommitted...)\n    ```", "```\n    $ oc –n <namespaceName> logs <podName> -v 8\n    ```", "```\n    $ oc get events\n    ```", "```\n    $ oc –n <namespaceName> get events\n    ```", "```\n    $ oc exec mypod -- date\n    ```", "```\n    $ oc exec mypod -c httpd-container -- date\n    ```", "```\n    $ oc exec mypod -i -t -- ls -t /usr\n    ```", "```\n    $ oc -n <namespaceName> rsh  <podName>\n    ```", "```\n$ oc debug node/<nodeName>\n```", "```\n$ chroot /host /bin/bash\n```", "```\n$ oc adm must-gather --dest-dir=/local/directory\n```", "```\nNAMESPACE   NAME READY STATUS RESTARTS AGE\nnamespace1  backend-tfmqm 0/1 ImagePullBackOff 0 17h\n```", "```\n$ oc -n namespace1 logs backend-tfmqm\nError from server (BadRequest): container \" backend\" in pod \" backend-tfmqm\" is waiting to start: trying and failing to pull image\n```", "```\nNAMESPACE NAME READY STATUS RESTARTS AGE\n3scale backend-redis-1-9qs2q 0/1 CrashLoopBackOff 211 17h\n```", "```\n$ oc logs backend-redis-1-9qs2q\n1:M 11 Jan 13:02:19.042 # Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix <filename>\n```", "```\nNAMESPACE NAME READY STATUS RESTARTS AGE\n3scale backend-cron-1-zmnpj 0/1 Init:0/1 0 17h\n```", "```\n$ oc logs backend-cron-1-zmnpj\nError from server (BadRequest): container \"backend-cron\" in pod \"backend-cron-1-zmnpj\" is waiting to start: PodInitializing\n```"]