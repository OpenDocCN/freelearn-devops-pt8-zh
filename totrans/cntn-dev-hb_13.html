<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer177">
<h1 class="chapter-number" id="_idParaDest-269"><a id="_idTextAnchor287"/>13</h1>
<h1 id="_idParaDest-270"><a id="_idTextAnchor288"/>Managing the Application Life Cycle</h1>
<p>In this book, we’ve reviewed some modern architectures and the microservices concept, understanding how containers fit into this new application development logic and covering how to create applications using different containers to provide their differing functionalities. This concept really is a game changer: we can implement an application’s components using different deployment strategies and scale processes up or down as needed. We used container registries for storing and managing the new artifacts and container images, which in turn are used for creating containers. Container runtimes allow us to run such components. We then introduced orchestration, which allows us to manage application availability and updates easily. Container orchestration requires new resources to solve different issues that arise from these new architectures. In this chapter, we will cover how all these pieces fit together in the management of your application life cycle. Then, we will learn how the automation of such actions allows us to provide a complete application <strong class="bold">supply chain</strong>, running <strong class="bold">continuous integration/continuous delivery</strong> (<strong class="bold">CI/CD</strong>) <span class="No-Break">on Kubernetes.</span></p>
<p>The following are the main topics covered in <span class="No-Break">this chapter:</span></p>
<ul>
<li>Reviewing the application <span class="No-Break">life cycle</span></li>
<li>Shifting our application’s <span class="No-Break">security left</span></li>
<li>Understanding <span class="No-Break">CI patterns</span></li>
<li>Automating continuous <span class="No-Break">application deployment</span></li>
<li>Orchestrating CI/CD <span class="No-Break">with Kubernetes</span></li>
</ul>
<h1 id="_idParaDest-271"><a id="_idTextAnchor289"/>Technical requirements</h1>
<p>You can find the labs for this chapter at <a href="https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13">https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13</a>, where you will find some extended explanations, omitted in the chapter’s content to make it easier to follow. The <em class="italic">Code In Action</em> video for this chapter can be found <span class="No-Break">at </span><a href="https://packt.link/JdOIY"><span class="No-Break">https://packt.link/JdOIY</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-272"><a id="_idTextAnchor290"/>Reviewing the application life cycle</h1>
<p>When<a id="_idIndexMarker1460"/> we talk about how applications are created and evolve, we have to consider all the creative and maintenance processes involved. The application life cycle includes the <span class="No-Break">following stages:</span></p>
<ol>
<li><strong class="bold">Planning</strong> of a <span class="No-Break">software solution</span></li>
<li><strong class="bold">Development</strong> of the <span class="No-Break">application’s components</span></li>
<li>Different <strong class="bold">testing</strong> phases, including component integration and <span class="No-Break">performance tests</span></li>
<li><strong class="bold">Deployment</strong> of <span class="No-Break">the solution</span></li>
<li><span class="No-Break"><strong class="bold">Maintenance</strong></span></li>
</ol>
<p>As we can see, a lot of people, processes, and tools are involved across the whole life cycle of an application. In this book, however, we will only cover those that can be resolved technically with the use of software containers. We can use the following schema to situate the aforementioned processes within a <span class="No-Break">broader context:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer171">
<img alt="Figure 13.1 – Basic application life cycle schema" height="664" src="image/B19845_13_01.jpg" width="1249"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.1 – Basic application life cycle schema</p>
<p>Let’s think now about which of these phases can be implemented using <span class="No-Break">software containers.</span></p>
<h2 id="_idParaDest-273"><a id="_idTextAnchor291"/>Planning a software solution</h2>
<p>This <a id="_idIndexMarker1461"/>phase covers the early stages of a software solution when an idea becomes a project. It includes the collection and analysis of the <strong class="bold">requirements</strong> of the users, customers, and other project stakeholders. These requirements will always need validation to ensure the final characteristics of the developed solution. Depending on the size of the project, an exploration of alternatives currently available on the market and the viability of the solution may call a stop to the process. The success of the project is usually directly related to the effectiveness of the planning phase, in which different teams propose the architecture, infrastructure, software frameworks, and other resources that may be key for the <span class="No-Break">resulting solution.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">In this book, all the content presented is intended for working on either cloud environments or an on-premises data center infrastructure. You will be able to use your desktop computer for developing your application code and can use a variety of workflows to interact with different infrastructure platforms through the different project phases, as we will learn in <span class="No-Break">this chapter.</span></p>
<p>Developing a good <strong class="bold">timeline</strong> for the project is always critical, and working with containers helps you improve delivery times, as they don’t require dedicated or overly specific infrastructure. You can even start your project on one platform and then move to a new completely different one. Containers mitigate any friction and remove infrastructure <span class="No-Break">vendor lock-in.</span></p>
<p>In this phase, you will also decide on the <strong class="bold">architecture</strong> for your application. Dividing your application into small, code-independent but cooperative services allows different groups of developers to work in parallel, which will always speed up project delivery. Working with microservices lets you as a developer focus on specific functionality and deliver your component following defined guidelines to ensure proper integrations. It is important to prepare the logic for scaling up or down any application’s process if needed and to ensure<a id="_idIndexMarker1462"/> components’ <strong class="bold">high availability</strong> (<strong class="bold">HA</strong>) and resilience. This will add flexibility to your solution and increase overall availability for <span class="No-Break">your users.</span></p>
<h2 id="_idParaDest-274"><a id="_idTextAnchor292"/>Developing the application’s components</h2>
<p>This stage <a id="_idIndexMarker1463"/>involves writing the code for your application. When you are developing microservices applications, you can choose the most appropriate language for your code, but you must be aware of any issues in the dependencies you use and understand the risks that come with using certain components instead of others. Using open source libraries or frameworks always requires a good knowledge of the maintainer’s activity and the maturity of <span class="No-Break">their code.</span></p>
<p>In the microservices model, your applications serve their APIs, and resources and other components use them. If you plan to enable multiple instances, you must ensure that your application’s logic allows this situation. To avoid infrastructure friction and provide maximum availability, ensure your application runs in different circumstances, manage its dependencies, and enable some circuit breakers. You will need to figure out how your processes behave when some components are down, how to reconnect in case some connection is lost and recovered, what will happen if you decide to execute your application’s components in a cloud platform or on a different cluster, and <span class="No-Break">so on.</span></p>
<h2 id="_idParaDest-275"><a id="_idTextAnchor293"/>Testing your application</h2>
<p>Once your development is <a id="_idIndexMarker1464"/>finished, a selection of test stages will be triggered. As this is an iterative process, you can deliver certain components of the application (or even the full solution), but it won’t truly be finished until all the tests return positive results. We must always consider the following principles when preparing and running <span class="No-Break">our tests:</span></p>
<ul>
<li>Tests must meet the <span class="No-Break">expected requirements</span></li>
<li>They should be executed by third-party groups, not involved in the design or development of the application to keep these <span class="No-Break">tests independent</span></li>
<li>Automation helps to reproduce tests under the same circumstances in <span class="No-Break">different iterations</span></li>
<li>Tests must be executed on either small components or a set of components <span class="No-Break">running together</span></li>
</ul>
<p>Let’s see some of the testing types and how containers can <span class="No-Break">integrate them:</span></p>
<ul>
<li><strong class="bold">Unit testing</strong>: This <a id="_idIndexMarker1465"/>type tests the <em class="italic">individual</em> components of an application. It is usually <a id="_idIndexMarker1466"/>generated and executed in the <em class="italic">development phase</em> because developers need to know whether their code is <a id="_idIndexMarker1467"/>working as expected. Depending on the complexity of the component’s code and the returned objects of the requests, they may be included in the container probes. Components will not be considered healthy if the returned status isn’t valid, although further pattern matching can be included in the validation of the returned data. If you are developing a component that works via an API, you should consider having a test request that always returns a valid value, or alternatively, you could use mock data. Unit tests will help you validate your code whenever changes have to be made to fix an issue, and they also make your code modular (microservices). Each component should include its own unit tests, and we can also include some code quality verification against <span class="No-Break">defined standards.</span></li>
<li><strong class="bold">Integration testing</strong>: These <a id="_idIndexMarker1468"/>tests validate how <em class="italic">different</em> components of your <a id="_idIndexMarker1469"/>software solution work together. They help us to identify issues between components and fix the delivery and interaction of all the components. So, this type of test needs to be arranged between the developers of the different components and planned consistently. If our application’s components run within containers, it would be very easy to prepare Docker Compose or some Kubernetes manifests to run all the required components together in our development environment – although these tests can also be automated on a remote CI/CD platform, as we will see later in this chapter in the <em class="italic">Orchestrating CI/CD within Kubernetes</em> section. If some components are key for your application’s health, their endpoints or probes can be integrated into the monitoring platform to ensure everything works <span class="No-Break">as expected.</span></li>
<li><strong class="bold">Regression testing</strong>: These<a id="_idIndexMarker1470"/> tests validate that new <a id="_idIndexMarker1471"/>changes <a id="_idIndexMarker1472"/>made don’t introduce new issues or break the overall project. Working with containers in these tests can significantly improve the overall process. We can go forward with new container image builds or roll backward using a previous image. If your code has changed significantly between releases, maybe having a completely different development platform as a result of moving to a new version of Python or Java, this can be tricky, but using containers makes it smooth and simple. Regression tests help us solve any issues related to advancements or changes in our code (evolution of the solution) that can break<a id="_idIndexMarker1473"/> the current<a id="_idIndexMarker1474"/> <span class="No-Break">application’s behavior.</span></li>
<li><strong class="bold">Smoke testing</strong>: This<a id="_idIndexMarker1475"/> stage is usually prepared in the early phases of integration<a id="_idIndexMarker1476"/> testing to ensure nothing will <em class="italic">crash and burn</em> when an application’s components start. These tests are used to solve dependency order. Running containers with Docker Compose allows us to change the order by changing the <strong class="source-inline">depends_on</strong> key, but it’s recommended to solve any dependency order issues in your code because commonly used container orchestrators don’t include such keys, requiring other mechanisms to manage dependencies. You can include additional <strong class="source-inline">init</strong> containers or sidecar containers that will check for the required components before other containers <span class="No-Break">actually start.</span></li>
<li><strong class="bold">Stress testing</strong>: These<a id="_idIndexMarker1477"/> tests validate your application’s component under stress or heavy load. We learned in <a href="B19845_12.xhtml#_idTextAnchor267"><span class="No-Break"><em class="italic">Chapter 12</em></span></a> how to make tests using third-party tools. These tools can be <a id="_idIndexMarker1478"/>deployed within containers and automated to create thousands of requests for our application’s components. If we’ve already dealt with the monitoring of the application’s components, we can get a good overview of the hardware requirements of our processes and use this to minimize resource usage within our container <span class="No-Break">orchestrator clusters.</span></li>
<li><strong class="bold">Performance testing</strong>: Once<a id="_idIndexMarker1479"/> you have integrated all<a id="_idIndexMarker1480"/> your <a id="_idIndexMarker1481"/>components and tested the requirements for each one, you can go further and verify different contexts for your application. You can test, for example, how your application behaves with multiple frontend components or work out how to distribute load between multiple databases. You can prepare both the application and the tests within containers, scale certain components up or down, and analyze the performance outcomes. This lets you distribute load automatically and add dynamism to your software solutions – but you do have to ensure that your code allows multiple instances at once of certain components. For example, you can have multiple instances of a distributed NoSQL database or multiple static frontends, but you can’t run multiple database instances at once and write to the same data file. This also applies to your application’s code. You can’t simultaneously execute multiple instances of a process that write to a file if you don’t block the file, so just one gets complete access to it. Another example is to allow requests from users on different instances<a id="_idIndexMarker1482"/> without managing the response in a central database. You <a id="_idIndexMarker1483"/>have to atomize the requests or integrate mechanisms to distribute them across the <span class="No-Break">different instances.</span></li>
<li><strong class="bold">Acceptance testing</strong>: You<a id="_idIndexMarker1484"/> should always define <strong class="bold">user acceptance tests</strong> (<strong class="bold">UATs</strong>) before <a id="_idIndexMarker1485"/>delivering your solution because these will <a id="_idIndexMarker1486"/>ensure that your code fits the requirements exposed at the beginning of the project. Multiple tests can be included in this stage (alpha, beta tests) depending on the complexity of your solution. New issues may arise in these tests, hence multiple iterations will probably be required. The automation of delivery and the simplicity inherited<a id="_idIndexMarker1487"/> from working with software containers both help you to provide different testing environments to your users in a short period <span class="No-Break">of time.</span></li>
</ul>
<p>The testing phase is very important for a project because it helps you improve the quality and reliability of your software delivery, identify and fix problems before going to production, and increase the visibility of the project, improving stakeholders’ confidence and user satisfaction. We can also reduce the maintenance costs of the solution because it was designed and tested with all the requirements in mind and validated multiple times, so errors that arise should have been ironed out before they impact production. On the other hand, testing is always time-consuming, but making different tests using containers will reduce both costs (as fewer environments are required for tests) and the time<a id="_idIndexMarker1488"/> spent on each test (as we can deploy multiple releases at the time and test <span class="No-Break">in parallel).</span></p>
<h2 id="_idParaDest-276"><a id="_idTextAnchor294"/>Deploying the solution</h2>
<p>In this phase, we actually deploy our <a id="_idIndexMarker1489"/>software solution in production. The solution often goes through multiple environments before this step is complete. For example, we can have a preproduction environment for <a id="_idIndexMarker1490"/>validating certain releases and <strong class="bold">Quality Assurance</strong> (<strong class="bold">QA</strong>) environments where other more specific tests can be run. Using containers makes deployments in these testing stages simple – we just change our configuration; all the container images will be the same. Using containers as <a id="_idIndexMarker1491"/>new <strong class="bold">deployment artifacts</strong> makes things easier. Let’s quickly introduce some packaging solutions <span class="No-Break">for containers:</span></p>
<ul>
<li><strong class="bold">Helm charts</strong>: This package <a id="_idIndexMarker1492"/>solution only works with Kubernetes. A Helm chart<a id="_idIndexMarker1493"/> is just a packaged set of manifests that includes variables for modifying the deployment of an application and its components. Version-3-compatible Helm charts are the go-to now. A previous version of Helm that was deprecated some time ago used the Tiller privileged component for deploying manifests, which may affect cluster integrity and security. Newer releases simplify how applications are deployed without having to create any Helm-specific resources in your Kubernetes cluster. Helm charts are very popular, and software vendors provide their own supported chart repositories for installing their applications directly from the internet into your own <span class="No-Break">Kubernetes clusters.</span></li>
<li><strong class="bold">Kustomize</strong>: This tool is<a id="_idIndexMarker1494"/> growing in popularity and is now part of the Kubernetes ecosystem. Kustomize<a id="_idIndexMarker1495"/> only works with Kubernetes and is also based on manifest templates that are refactored by users before being applied in a Kubernetes cluster. The <strong class="source-inline">kubectl</strong> command line<a id="_idIndexMarker1496"/> includes Kustomize functionality, which makes it very usable out of the box without having to include new binaries in <span class="No-Break">our environment.</span></li>
<li><strong class="bold">Cloud-Native Application Bundle</strong> (<strong class="bold">CNAB</strong>): CNAB goes a step further than Helm and Kustomize. It is designed to <a id="_idIndexMarker1497"/>include the infrastructure and services required by our application to work. Multiple tools work together <a id="_idIndexMarker1498"/>to provide both the infrastructure (with the Porter component providing integration of Helm, HashiCorp Terraform, and the cloud provider’s API) and the application (managed by Duffle and Docker). This solution is not really in use today and many of its components have been deprecated, but it is worth mentioning as it can give you some ideas for fully packaging your software solutions (that is, the infrastructure and the <span class="No-Break">application together).</span></li>
<li><strong class="bold">Kubernetes operators</strong>: Kubernetes <a id="_idIndexMarker1499"/>operators are controllers that deploy and manage specific application <a id="_idIndexMarker1500"/>deployments and have become very popular these days. An operator deploys its own specific controllers inside a Kubernetes cluster to manage application instances. Kubernetes operators are intended to self-manage all the tricky parts of your application’s management and upgrades. You as a user just need to define certain required values for your instance, and the operator will handle installing the required components and dependencies and manage any upgrade during its lifetime. If you are planning to develop your application using a Kubernetes operator, make sure to include all the manifests of your application, dependencies, and the automation required for the application to come up. Third-party Kubernetes operators run as black boxes in your Kubernetes cluster and may not include all the functionality you expect for your applications to work; therefore, it may be worth reading the documentation before deploying a third-party <span class="No-Break">Kubernetes operator.</span></li>
</ul>
<p>Deploying your <a id="_idIndexMarker1501"/>application using a microservices architecture allows you to integrate different components’ releases. Depending on your software solution, you might use one full deployment or multiple small ones for each component of your application. Either way, the solution must provide all the functionality<a id="_idIndexMarker1502"/> called for by your users and stakeholders in the project <span class="No-Break">planning stage.</span></p>
<h2 id="_idParaDest-277"><a id="_idTextAnchor295"/>Maintaining the application</h2>
<p>We might think that the deployment<a id="_idIndexMarker1503"/> of the solution is the last phase, but it isn’t. Once the application is in production, new functionalities may be required, new improvements to current functionality may be called for, and inevitably, new errors will appear. If your application is monitored, you can obtain feedback on the status of different components before actual errors appear. <strong class="bold">Logging</strong> also helps to<a id="_idIndexMarker1504"/> identify problems, and tracing allows you to improve <span class="No-Break">your code.</span></p>
<p>But in any case, the application’s life cycle continues, and a new project may start adding new functionalities while issues are repaired for the current release. Monolithic architectures require multiple environments for such processes. Working on two releases at the same time will double the efforts for maintaining environments. Microservices architecture allows us to distribute the work according to the different components, and thus mitigate the need for having dedicated environments for building each component. And, more importantly, we can change one component at a time and focus on solving a specific issue, or have each application component managed by a different team with different release times. These teams develop their code using the programming language that best fits the functionality of their requirements, taking into account release times and proper integration within the application. However, note that each team also has to keep track of vulnerabilities and security issues in <span class="No-Break">their implementation.</span></p>
<p>Throughout this book, we have learned some security practices that will make our applications safer when we work within containers (<a href="B19845_02.xhtml#_idTextAnchor036"><span class="No-Break"><em class="italic">Chapter 2</em></span></a> and <a href="B19845_03.xhtml#_idTextAnchor082"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>) and with container orchestrators (<a href="B19845_06.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <a href="B19845_07.xhtml#_idTextAnchor147"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, and <a href="B19845_08.xhtml#_idTextAnchor170"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>). <strong class="bold">Shift-left security</strong> goes <a id="_idIndexMarker1505"/>beyond these recommendations and includes security from the very beginning of the project. We can consider shift-left security as a practice where we don’t wait to address software security vulnerabilities until it’s too late: when the application is already <a id="_idIndexMarker1506"/>developed, built, and packaged. In the next section, we will learn how taking care of security from the very first<a id="_idIndexMarker1507"/> phases of the application life cycle can significantly improve the overall security of <span class="No-Break">the solution.</span></p>
<h1 id="_idParaDest-278"><a id="_idTextAnchor296"/>Shifting our application’s security left</h1>
<p><strong class="bold">Shift-left security</strong> refers<a id="_idIndexMarker1508"/> to the practice of starting security checks as early as possible in the development of our application. This doesn’t mean we don’t apply any security measures at other stages but that it will start improving security from the very beginning of the application life cycle. Shifting security left allows us to identify any vulnerabilities and other problems before it’s too late and the application is already running in production. The<a id="_idIndexMarker1509"/> benefits of shifting our security left include <span class="No-Break">the following:</span></p>
<ul>
<li>It improves the delivery of software solutions because bugs are detected and fixed in early <span class="No-Break">development stages</span></li>
<li>It distributes application security into different stages, allowing different actions at each stage, starting from the code and ending in the infrastructure where the application will finally <span class="No-Break">be deployed</span></li>
<li>Different groups can implement different security policies and mechanisms, furthering the creation of a security culture in <span class="No-Break">your organization</span></li>
<li>It reduces overall development time and the costs of pushing back applications because of <span class="No-Break">poor </span><span class="No-Break"><a id="_idIndexMarker1510"/></span><span class="No-Break">security</span></li>
</ul>
<p>Now, let’s understand some different methodologies for tackling the software development life cycle and how they <span class="No-Break">impact security.</span></p>
<h2 id="_idParaDest-279"><a id="_idTextAnchor297"/>Software life cycle methodologies</h2>
<p>Let’s introduce some software life cycle methodologies<a id="_idIndexMarker1511"/> here that will help us understand the importance of security when things begin to move faster in the stages <span class="No-Break">of development:</span></p>
<ul>
<li><strong class="bold">Waterfall model</strong>: In this <a id="_idIndexMarker1512"/>model, stages must run <em class="italic">linearly</em>, hence a new <a id="_idIndexMarker1513"/>stage begins when the previous one finishes. This model works very well when we don’t expect to have many modifications from the planned requirements and our project tasks are well defined. However, this model lacks flexibility, which makes changes<a id="_idIndexMarker1514"/> harder to implement, and issues usually remain hidden until the<a id="_idIndexMarker1515"/> end of <span class="No-Break">the project.</span></li>
<li><strong class="bold">Agile model</strong>: In this <a id="_idIndexMarker1516"/>model, we <em class="italic">iterate</em> over stages to improve the final software <a id="_idIndexMarker1517"/>solution. Flexibility and quick response times are key in this model. Iterations allow the introduction of new changes and the resolution of any issue found in the previous review. The main problem of this model is that it requires lots of collaboration between the groups or people involved in each stage, hence it may not work in big projects, but microservices architectures fit very well into this <span class="No-Break">development model.</span></li>
<li><strong class="bold">Spiral model</strong>: This<a id="_idIndexMarker1518"/> model can be considered a <em class="italic">mixture</em> of both the Waterfall and <a id="_idIndexMarker1519"/>Agile models. The final software solution will be the result of different iterations that can be considered a complete software development cycle. In each iteration, we start from the very beginning, taking user requirements, designing a solution, developing the code, and testing, implementing, and maintaining the solution as is, before moving on to the next iteration. The Agile and spiral development models allow us to review and solve issues before the next iteration, which both accelerates the development process and makes the solution <span class="No-Break">more secure.</span></li>
</ul>
<p>Of these methods, Agile methodologies in particular have really changed how software is developed and delivered. Their adoption allows teams to go faster and swiftly adapt software solutions when users require new features. However, in such scenarios, the security team can be a bottleneck. These teams receive a software solution just before it goes into production, seeking to identify and resolve any vulnerabilities and security issues before malicious users find them in production. If we decouple our application into small pieces (that is, microservices), then the work required in the security review task is multiplied by the number of pieces, even if they are small. It gets even worse when we realize that most of the legacy tools used for reviewing security on monolith applications don’t work on highly distributed and dynamic environments such <span class="No-Break">as Kubernetes.</span></p>
<p>It is also the case that software containers and open source solutions have become so widely used in data centers and cloud platforms that we can find ourselves deploying third-party software solutions while barely even knowing their contents. Even software vendors provide open source products inside their own complex software solutions. Therefore, we cannot just keep using the same old security methodologies at the infrastructure and <span class="No-Break">application levels.</span></p>
<h2 id="_idParaDest-280"><a id="_idTextAnchor298"/>Security at the application level</h2>
<p>As discussed earlier, shifting<a id="_idIndexMarker1520"/> the security of our applications left implies integrating security mechanisms and best practices as early as possible in our software development model. But this doesn’t mean we leave security to the developers. We will prepare automated security validations in the testing phase and implement security policies in both the development environments and production clusters. This will ensure that everyone knows the security measures applied and how to implement them. The DevSecOps team prepares infrastructure and application rules and shares them with all the developer teams. Infrastructure rules include all policy enforcements in your execution environment, which is usually your Kubernetes cloud or on-premises platform. These policies may include, for example, the denial of any privileged container, the denial of Pods without limited resources, and the denial of access to hosts’ filesystems. However, note that these rules are not part of the code, although they do affect the execution of <span class="No-Break">your applications.</span></p>
<p>If we consider security from the application perspective, there are several techniques we <span class="No-Break">can apply:</span></p>
<ul>
<li><strong class="bold">Software composition analysis</strong> (<strong class="bold">SCA</strong>): When we add open source libraries or other components to our code, we <a id="_idIndexMarker1521"/>unconsciously add risk to our application. SCA tools help us identify these risks and in some cases mitigate them with patches and updates. While <strong class="bold">static application security testing</strong> (<strong class="bold">SAST</strong>) tools (which we will<a id="_idIndexMarker1522"/> discuss next) are used to find vulnerabilities in the development cycle, within your code, SCA tools provide continuous <span class="No-Break">vulnerability monitoring.</span></li>
<li><strong class="bold">SAST</strong>: These<a id="_idIndexMarker1523"/> tests are used to find vulnerabilities in our code before it is actually compiled, hence they are run in the early stages of our development phase. The tools running these tests will search for well-known insecure patterns in our code and report them to us. Any hardcoded secret data and misconfigurations will be reported as issues in <span class="No-Break">the analysis.</span></li>
<li><strong class="bold">Dynamic application security testing</strong> (<strong class="bold">DAST</strong>): These tests are executed when the application is running, in the testing <a id="_idIndexMarker1524"/>phase. They involve the execution of simulated attacks against our application’s components. These tests can include code injection or malformed requests that may break your application at <span class="No-Break">some point.</span></li>
</ul>
<p>These three types of tests are<a id="_idIndexMarker1525"/> very valuable in identifying vulnerabilities in our application before moving it to production, but SAST and SCA are the ones to focus on when talking about shifting security left. When automation is put in place, we can execute these tests continuously and use <strong class="bold">integrated development environment</strong> (<strong class="bold">IDE</strong>) plugins<a id="_idIndexMarker1526"/> to help figure out problems before they are actually stored in our code. To start, we can use any good linter for our specific programming language. Let’s discuss <span class="No-Break">these next.</span></p>
<h2 id="_idParaDest-281"><a id="_idTextAnchor299"/>Introducing linters</h2>
<p>A <strong class="bold">linter</strong> is a tool used to analyze <a id="_idIndexMarker1527"/>our code looking for problems. Depending on the quality of the given linter, it can identify things from simple code improvements to more advanced issues. It is usual to use specific linters for different programming languages. You can check the extensions available in your <span class="No-Break">favorite IDE.</span></p>
<p>Linters help us reduce the amount of code errors in the development stage, and improve our code style, construction consistency, <span class="No-Break">and performance.</span></p>
<p>A simple code linter<a id="_idIndexMarker1528"/> will do <span class="No-Break">the following:</span></p>
<ul>
<li>Check for <span class="No-Break">syntax errors</span></li>
<li>Verify <span class="No-Break">code standards</span></li>
<li>Review <em class="italic">code smells</em> (well-known signs that something will go wrong in <span class="No-Break">your code)</span></li>
<li>Verify <span class="No-Break">security checks</span></li>
<li>Make your code<a id="_idIndexMarker1529"/> look as if it were written by a <span class="No-Break">single person</span></li>
</ul>
<p>You should include <a id="_idIndexMarker1530"/>linters in your code environment, but your specific choice will depend on the language you use. Good linters can be categorized based on the aspects they focus on, as <span class="No-Break">outlined here:</span></p>
<ul>
<li><strong class="bold">Standardized coding</strong>: Examples include SonarLint, Prettier, StandardJS, Brakeman, and StyleCop. Some languages such as .NET even include their own <span class="No-Break">linter (Format).</span></li>
<li><strong class="bold">Security</strong>: GoSec, ESLint, or Bandit (<span class="No-Break">Python module).</span></li>
</ul>
<p>What’s more, some linters can be used for both of these aspects when the appropriate configurations are used. You can check for additional code analysis tools <span class="No-Break">at </span><a href="https://owasp.org/www-community/Source_Code_Analysis_Tools"><span class="No-Break">https://owasp.org/www-community/Source_Code_Analysis_Tools</span></a><span class="No-Break">.</span></p>
<p>Let’s see a quick example using a <a id="_idIndexMarker1531"/>Dockerfile linter, <strong class="bold">Hadolint</strong> (<a href="https://github.com/hadolint/hadolint">https://github.com/hadolint/hadolint</a>). We will simply check a valid Dockerfile that does not include the best practices we learned in <a href="B19845_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Modern Infrastructure and Applications with Docker</em>. Let’s see this in the <span class="No-Break">following screenshot:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer172">
<img alt="Figure 13.2 – Local Hadolint installation reviewing a simple Dockerfile" height="650" src="image/B19845_13_02.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.2 – Local Hadolint installation reviewing a simple Dockerfile</p>
<p>But the good thing here is that we can include this<a id="_idIndexMarker1532"/> linter, or any other, inside container images and have a collection of linters ready to use for any language we might encounter. Let’s see how this works within a container using <strong class="source-inline">docker run –i hadolint/hadolint </strong><span class="No-Break"><strong class="source-inline">hadolint -</strong></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer173">
<img alt="Figure 13.3 – Docker-based Hadolint execution reviewing a simple Dockerfile" height="343" src="image/B19845_13_03.jpg" width="1045"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.3 – Docker-based Hadolint execution reviewing a simple Dockerfile</p>
<p class="callout-heading">Important note</p>
<p class="callout">There are tools such<a id="_idIndexMarker1533"/> as <strong class="bold">Conftest</strong> (<a href="https://www.conftest.dev/">https://www.conftest.dev/</a>) that can be integrated with different <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>) solutions<a id="_idIndexMarker1534"/> and used to validate infrastructure scripts before they are deployed in <span class="No-Break">our platform.</span></p>
<p>Linting tools can be executed automatically within our development processes to improve security. We will see this in action when we talk about <span class="No-Break">CI/CD workflows.</span></p>
<p>In the next section, we will introduce simple methodologies and practices to learn how CI can help us manage the life cycle of <span class="No-Break">our applications.</span></p>
<h1 id="_idParaDest-282"><a id="_idTextAnchor300"/>Understanding CI patterns</h1>
<p>CI refers to the practice <a id="_idIndexMarker1535"/>of automating the integration of code changes from multiple contributors (or even multiple projects) into a single project. These automated processes may happen once a day or several times per hour. We can consider CI as the part of the software supply chain where we build our application (or its components) and launch different tests before moving to production. The second part of this process is deploying the application or its components into production, although some intermediate environments can also be employed to test the quality of the solution or certification in special circumstances (for example, integrating our solution with a third-party solution release from <span class="No-Break">a vendor).</span></p>
<p>In this section, we are going to review some of the most common patterns used for CI in the most intuitive logical order. Developers should always get the last version of their code to start developing a new feature or start over the creation of a new component, or new release with fixes. Therefore, we<a id="_idIndexMarker1536"/> will start our development process by pulling the code from a <strong class="bold">version control </strong><span class="No-Break"><strong class="bold">system</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">VCS</strong></span><span class="No-Break">).</span></p>
<h2 id="_idParaDest-283"><a id="_idTextAnchor301"/>Versioning the code</h2>
<p>A VCS is a<a id="_idIndexMarker1537"/> tool that stores file and directory changes over time, allowing us<a id="_idIndexMarker1538"/> to recover a specific version later. This tool is crucial from the developer’s perspective as it allows multiple developers to work together and track the changes made to application code over time. Versioning the code and the artifacts created allows us to run specific integration tests and deploy a specific release of <span class="No-Break">our code.</span></p>
<p>These tools usually run in <em class="italic">client-server</em> mode. Users interact using the relevant commands to push and pull the changes. The VCS stores and manages these changes. Once all the changes are synced (committed), you can proceed to build your applications’ artifacts. This step may not be necessary if you are using an interpreted scripting language, although some bytecode artifacts may be created to speed up the application’s execution. We can automate this process and trigger a compilation of our code in certain circumstances – for example, when we do a commit (synchronization of the code). As a result, we get <a id="_idIndexMarker1539"/>a <strong class="bold">binary artifact</strong> with all its dependencies every time we simply commit our code. But we can go further and create different branches on our code repository to allow different users to interact with the code at the same time or solve different code functionalities. Once all required changes are made, we can consolidate these branches into a common one and build the artifact again. Depending on the final product, the issues found, and the functionalities required, this process can be complicated, but automation can be used to create a common workflow that is much easier to follow <span class="No-Break">and reproduce.</span></p>
<p>When a project is developed by multiple developers or teams, certain types of management are required to avoid collisions between changes. VCSs offer mechanisms to resolve incompatibilities between different pulls when multiple developers change the same files at the same time. <strong class="bold">Change management</strong> is <a id="_idIndexMarker1540"/>required to validate and merge the changes made by different users to the same parts of the application’s code. These validation procedures significantly speed up the code workflow without us losing control of the code itself. Version control also allows us to go back and forward through the application’s changes, and as such, is very useful even if you are the <a id="_idIndexMarker1541"/>only developer of a project. But none of these mechanisms work if we don’t define <strong class="bold">standardized methodologies</strong> and <strong class="bold">code conventions</strong> to<a id="_idIndexMarker1542"/> minimize code integration tasks. It is common practice to ask developers to write down useful descriptions for their commits and follow the branch and release naming conventions standardized in your organization. For example, for releases, it is common to follow the <strong class="source-inline">MAJOR.MINOR.PATCH</strong> versioning syntax, where <strong class="source-inline">MAJOR</strong> indicates changes that may break compatibilities with previous releases, <strong class="source-inline">MINOR</strong> indicates that some functionality was added without breaking compatibility, and <strong class="source-inline">PATCH</strong> is used when some issues were solved without actually modifying any of the previous functionality. On the other hand, branch names can be used to reference any issues found and their solutions in <span class="No-Break">the code.</span></p>
<p>At this early stage, we can add some <strong class="bold">validation tests</strong> using <a id="_idIndexMarker1543"/>linters to ensure proper code syntax, code quality, and the presence of security features (such as valid external dependencies) and exclude any sensitive information that may have made its way into <span class="No-Break">the code.</span></p>
<p>If we work with containers, our code should include at least one <strong class="bold">Dockerfile</strong> to allow us to create our container image artifact. Versioning of this file is also <a id="_idIndexMarker1544"/>required, and thus it will be stored in our code repository (which is a VCS). Validation tests can be automated and executed to verify certain patterns such as the user executing the container’s main process or <span class="No-Break">exposed ports.</span></p>
<p>A CI pipeline, therefore, is a <a id="_idIndexMarker1545"/>group of workflow processes intended to automate software application <a id="_idIndexMarker1546"/>code validation, construction, and integration. Accordingly, let’s quickly introduce the concept of <span class="No-Break">DevOps here.</span></p>
<h2 id="_idParaDest-284"><a id="_idTextAnchor302"/>Introducing DevOps methodology</h2>
<p><strong class="bold">DevOps</strong> is a <a id="_idIndexMarker1547"/>methodology that improves software engineering by integrating and automating some of the stages of software development, the operational tasks related to the operation and maintenance of the systems where the applications run, and the applications themselves. We should think of DevOps as a culture that goes <em class="italic">beyond</em> groups or teams in your organization; it applies to your entire organization with the goal of minimizing time and friction between the development, deployment, and <span class="No-Break">maintenance stages.</span></p>
<p>The following list shows some of the key features<a id="_idIndexMarker1548"/> of the <span class="No-Break">DevOps methodology:</span></p>
<ul>
<li>Automate as many tasks as possible in the software <span class="No-Break">life cycle</span></li>
<li>Collaboration between different teams as part of this culture makes things work <span class="No-Break">more effectively</span></li>
<li>Continuous revision and feedback from tasks, automation, and code quality, all of which are key to improving the software <span class="No-Break">development processes</span></li>
<li>Monitoring and logging are part of the application life cycle, and they are important for improving its performance and finding <span class="No-Break">code issues</span></li>
</ul>
<p>Since DevOps covers a lot of tasks and disciplines, there are many tools available to help you with different tasks and stages. For example, for VCSs and code repositories, you can use very popular <strong class="bold">cloud services</strong> such as<a id="_idIndexMarker1549"/> GitHub (acquired by Microsoft in 2018), Atlassian’s Bitbucket, or GitLab, among others. If you are looking for <strong class="bold">on-premise solutions</strong>, you can <a id="_idIndexMarker1550"/>use open source offerings such as Gitea, GitLab, or Azure DevOps Server. Choosing the right tool for your organization can be complicated because many tools offer multiple features. The following schema represents some of the more popular DevOps tools related to the application development stage, showing where they fit <span class="No-Break">in best:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer174">
<img alt="Figure 13.4 – Most popular DevOps tools" height="691" src="image/B19845_13_04.jpg" width="1224"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.4 – Most popular DevOps tools</p>
<p class="callout-heading">Important note</p>
<p class="callout">A new methodology was recently introduced that focuses heavily on the security of development, deployment, and maintenance processes, called <strong class="bold">DevSecOps</strong>. This methodology emphasizes an extension of security as part of the <a id="_idIndexMarker1551"/>culture of the different teams involved in the process. This is why we reviewed shift-left security practices, which are an aspect of DevSecOps that lies closer to the development teams. A DevSecOps culture breaks the old mindset in which a singular team is given the security role and participates in the development process only at the end, validating the code just before the software is moved <span class="No-Break">into production.</span></p>
<p>Once the code is synced and validated, we are able to build our software solution. Let’s discuss this <span class="No-Break">process next.</span></p>
<h2 id="_idParaDest-285"><a id="_idTextAnchor303"/>Building artifacts</h2>
<p>Depending<a id="_idIndexMarker1552"/> on the programming language and its dependencies, it may be tricky to prepare environments for different releases. For example, moving from one previous Node.js release to a newer one may require separate build environments, even if the language is interpreted and <span class="No-Break">not compiled.</span></p>
<p>Imagine a situation where different code developers need to compile their software at the same time in the same environment. It would be complete chaos, and errors from different releases would appear. Automation allows us to package environments and build our software using the appropriate environment. But we can go further by using software containers because these environments need only to exist at runtime, specifically when required, and we can use software containers to build our software using the required builder environment. The resulting container images of the complete build process are stored in a container image registry right after the successful building and validation of the <span class="No-Break">new artifact.</span></p>
<p>What is even more important is that we can prepare a full workflow in which all code is validated using our rules (code syntax, code quality, non-privileged execution, and so on), then the workflow triggers the build of the code, and finally, different tests (unity, integration, stress, performance, and so on) are triggered using the container images generated. We can forbid the execution of any application in production if it doesn’t come from this standardized construction workflow. You as a developer are able to code on your laptop and test your application, but you must pass all the corporate validation checks on a shared environment or platform before actually deploying in production (or sometimes even <a id="_idIndexMarker1553"/>earlier, in the quality or <span class="No-Break">certification stages).</span></p>
<h2 id="_idParaDest-286"><a id="_idTextAnchor304"/>Testing your application’s components</h2>
<p>As mentioned <a id="_idIndexMarker1554"/>before, automating different tests allows us to break the workflow whenever any test fails before moving on to the next step. To achieve this with containers, we can prepare some integrated processes using Docker Compose (for example) and validate how they work together. This can be done on your own desktop environment or using shared services, triggering the execution of the components by using defined tasks. These tasks also can be defined in Docker Compose format and be stored with your code. There are tools such as Jenkins that help us define these automated jobs and execute them on different systems. This tool is a very popular CI/CD orchestration tool created for managing build tasks on different systems that can be evolved to integrate the use of containers to simplify the overall workflow. Instead of having different nodes with separate releases for different languages or compilers, we can use software containers executed on a unique <span class="No-Break">container runtime.</span></p>
<h2 id="_idParaDest-287"><a id="_idTextAnchor305"/>Monitoring the build processes and tests</h2>
<p>To understand<a id="_idIndexMarker1555"/> how changes can improve or have a negative impact on our applications, we need to continuously measure the performance and output of the different tests. We must always ensure we monitor the workflow processes because this will help us to improve the overall development process thanks to the iteration of the different tests. Popular CI orchestration tools always measure the build time, and we can retrieve the time spent during the execution of chained jobs, hence we will be able to trace how a certain change in our code (for example, the addition of new dependencies) impacts the build and modify the <span class="No-Break">tests accordingly.</span></p>
<h2 id="_idParaDest-288"><a id="_idTextAnchor306"/>Sharing information about the development process</h2>
<p>DevOps<a id="_idIndexMarker1556"/> culture is all about communicating changes, exchanging feedback, and sharing information about any issues that arise to align all the teams involved in the process. Automation will avoid many misunderstandings; everything should be reproducible, hence the same results will be expected if we don’t change anything. All changes must be traceable to allow us to quickly identify issues related to any given change and apply the appropriate patches. As we saw in <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em>, there are many tools available to assist us in keeping our teams informed. One good practice is to implement automatic notifications sent by the different tools whenever a development task is executed (code changes, validated tests, and <span class="No-Break">so on).</span></p>
<h2 id="_idParaDest-289"><a id="_idTextAnchor307"/>Excluding configurations from code</h2>
<p>Although it<a id="_idIndexMarker1557"/> might be obvious, we should keep any configuration or sensitive information for the application out of the code. It would be nice to include a set of default values and some documentation covering how to change them, but keep in mind that your application will pass through several phases and maybe different environments. In this book, we have looked at multiple mechanisms used to include sensitive information and configurations within containers (<a href="B19845_02.xhtml#_idTextAnchor036"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, and <a href="B19845_05.xhtml#_idTextAnchor118"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>). Never include certificates, even if they are just required for a simple step in which you download some artifact from a self-signed or corporate server. It is important to understand that sometimes, it is even necessary to use versioning for configurations. If you change the way you use a variable in your code, it may break a rollback to a previous release. In such cases, you may also need to store configurations in the versioning system. But keep in mind that the audience of this repository is probably different from the repository that stores your code. Automation helps us to keep track of the different code releases with the appropriate <a id="_idIndexMarker1558"/>configurations and ensure that every task <span class="No-Break">runs smoothly.</span></p>
<p>Now that we have reviewed the first part of the development process, where the application is coded, compiled, and validated, we can move on to the <span class="No-Break">delivery stage.</span></p>
<h1 id="_idParaDest-290"><a id="_idTextAnchor308"/>Automating continuous application deployment</h1>
<p>In this section, we are going <a id="_idIndexMarker1559"/>to examine the second part of the software development process – the delivery of the product. Many organizations invest all their efforts into CI, leaving the determination of whether or not software should be executed in production to a <span class="No-Break">manual decision.</span></p>
<p>A CD pipeline gets changes from the artifacts and code repositories, including required configurations, and deploys them into production in a fluent and continuous way. To achieve this, we need to somehow package all these artifacts and configurations in a reproducible and deployable state, aiming to keep the maximum stability and reliability in our systems. The following list shows some of the most notable benefits of <span class="No-Break">using CD:</span></p>
<ul>
<li>We mitigate the risks of deploying new releases because automation ensures a quick rollback in case something <span class="No-Break">goes wrong</span></li>
<li>Automation may use blue–green and canary deployments, enabling new application releases while older processes are <span class="No-Break">still serving</span></li>
<li>Lower <strong class="bold">time to market</strong> (<strong class="bold">TTM</strong>) and<a id="_idIndexMarker1560"/> reduced costs can be reliably expected due to the level of confidence generated by the application’s <span class="No-Break">life cycle</span></li>
</ul>
<p>While CI automates the build and testing stages, CD on the other hand continues the process and goes a step further, automating the packaging, deployment, and testing throughout the rest of the <span class="No-Break">life cycle.</span></p>
<p>While the benefits of CI are for developers, we might think that CD is more targeted at operations teams. However, in the DevOps culture, many stages are shared between the two groups. The major benefits of using CD extend even to the end users because applications are always kept updated and don’t suffer outages between changes. Additionally, new functionalities can be added with less friction. Users can provide feedback using the defined channels (see the tools presented in <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em>), and monitoring, logging, and tracing the software allows us to enrich this feedback, and then the cycle starts again to keep improving the <span class="No-Break">application’s code.</span></p>
<p>If we give some thought to how can we implement the different stages of CD automation, containers fit perfectly as we can package container images and the application’s configurations for different environments and deploy the software solution. In case of errors, container runtimes<a id="_idIndexMarker1561"/> provide <strong class="bold">resilience</strong>, and container orchestrators allow us to roll back to the previous release in seconds, informing us of the issues encountered during deployment. As mentioned before, blue–green and canary deployments allow us to progressively deploy a new release or test it with just a few<a id="_idIndexMarker1562"/> users to avoid a massive outage if anything <span class="No-Break">goes wrong.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">Modern application life cycle models, such <a id="_idIndexMarker1563"/>as <strong class="bold">GitOps</strong>, manage the deployment of software releases by defining a repository as the <strong class="bold">source of truth</strong> (<strong class="bold">SOT</strong>). Any <a id="_idIndexMarker1564"/>change within our applications or even the Kubernetes clusters themselves are managed as out-of-sync situations, requiring either manual intervention or automatic triggers to apply the appropriate changes and synchronize the situation with the required configuration (SOT). In such scenarios, we will just customize how the deployment packages will be executed on each environment by setting a required state for the application. Resource upgrades or rollbacks will be executed to synchronize the current status with the <span class="No-Break">required one.</span></p>
<p>Monitoring the actual performance of the new deployment is key in situations where you are limiting access to a new release while most users are still using the old one. Should we go further with our new release, we must have a reliable <strong class="bold">performance baseline</strong> to fully<a id="_idIndexMarker1565"/> understand how the changes are impacting our application’s services. Although we may have passed all our performance tests successfully, deploying a new release may show different behaviors when accessed by real users. The better the tests in the testing stages, the lower the gap between the real user experience and the automated test, which lowers the risks of releasing a <span class="No-Break">new version.</span></p>
<p><strong class="bold">Logging</strong> is also <a id="_idIndexMarker1566"/>important. We use logs to search for well-designed error patterns. The log standardization in your corporation can be used to easily implement common patterns for all your application’s components and provide a single logging control plane for all processes at once, which will make it easy to find errors across multiple logs and verify how some requests affect different components at specific <span class="No-Break">time frames.</span></p>
<p>Tracing in production is <em class="italic">not</em> recommended unless you have some dedicated instances of your project for that purpose or you are reviewing a <span class="No-Break">critical error.</span></p>
<p>Retrieving <strong class="bold">user feedback</strong> is the<a id="_idIndexMarker1567"/> final step of the complete application’s life cycle. User feedback, alongside monitoring and logging (and eventually tracing) of the application components, feeds into the next iteration of the application’s life cycle process to improve its overall performance and behavior, and the process <span class="No-Break">starts over.</span></p>
<p>We examined some open source monitoring, logging, and tracing tools back in <a href="B19845_12.xhtml#_idTextAnchor267"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, <em class="italic">Gaining Application Insights</em>. To get users’ feedback, any ticketing software will be fine, but the smoother it integrates into the full DevOps paradigm, the better. In <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em>, we showed some of the most common and popular DevOps tools. All serious code repositories include an <strong class="bold">issue tracking system</strong> with which you can align users’ comments and issues with actual <a id="_idIndexMarker1568"/>code commits, solving these issues or adding <span class="No-Break">requested functionalities.</span></p>
<p>As you can imagine, some of<a id="_idIndexMarker1569"/> these tools can be deployed on and integrated into Kubernetes. The next section presents a sample DevOps environment in which we will use some of the tools presented in <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em> to provide a full application life cycle <span class="No-Break">management platform.</span></p>
<h1 id="_idParaDest-291"><a id="_idTextAnchor309"/>Orchestrating CI/CD with Kubernetes</h1>
<p>This section will help us understand the full life cycle of an application prepared and managed within a Kubernetes cluster. Let’s start by reviewing the <span class="No-Break">CI part.</span></p>
<h2 id="_idParaDest-292"><a id="_idTextAnchor310"/>Understanding the CI component of the workflow</h2>
<p>The <a id="_idIndexMarker1570"/>CI part of our workflow is where we code, build, and test <span class="No-Break">our solution.</span></p>
<p>At the beginning of the project, user requirements are collected. Subsequently, during the development stage, you can use your favorite code editor. Depending on the programming language you use, compilation may be necessary, which requires you to have installed compilers. Instead of that, you can use software containers to run the actual compilation steps. You will be able to use different releases of code compilers, with different environments and sets of tools at the same time without actually having to install any of them. Indeed, managing multiple releases of certain code environments on a single computer can be tricky. Building your application’s code using containers will help you decide which container images would best fit your needs for each stage (building the application’s artifacts, and running them for either testing <span class="No-Break">or production).</span></p>
<p>Next, in the CI workflow, you build your binaries and prepare the Dockerfiles for your application’s components. Multiple Dockerfiles can be created for a single component, specifying things such as the inclusion or omission of some debugging tools or flags that could be very useful during the <span class="No-Break">testing stages.</span></p>
<p>Then, you build your container images. Production images must be clean and only include the binaries and libraries required for running your application’s processes. You can build your code artifacts and container images for testing the application in your coding environment, although you may already have a shared environment for <span class="No-Break">such tasks.</span></p>
<p>With containers, it becomes possible to locally test each application component (unit tests) or even the full application stack (integration tests) using Docker Compose. In such a case, you will need access to the other application components’ container images and some mock configurations that will help you run a sample environment more easily. It’s usual to include some mocked-up default values and perhaps some test connection strings, authentications, and tokens (which will be overwritten during execution with real values). Having <em class="italic">sample values</em> is key when you work in a team, and other developers may need to execute your artifacts and adjust their parameters to meet <span class="No-Break">their needs.</span></p>
<p>You are likely to work on a specific branch of the code depending on the development stage you are in. Code branches are usually used to either fix issues or develop new functionalities and allow multiple developers to code in parallel on different resources at the same time. Once a given issue is solved and tested successfully, the code can be committed, pushed, and finally merged into the <span class="No-Break">main code.</span></p>
<p>You may have your own code routine, but chances are it is quite similar to the one described here (the order of steps may vary, but ultimately the main code should contain your changes), and you probably apply similar steps for adding some new functionality or fixing <span class="No-Break">an issue.</span></p>
<p>Pushing the new code to the code repository will trigger automation mechanisms that create appropriate artifacts (binaries, libraries, and container images) using tags and labels to help you track the changes associated and the issues or functionalities included. This allows you to either use your own built artifacts or those created by the automation system using your build rules and the Dockerfiles included in your code. It is recommended to use the artifacts created by the automated build environment because your DevOps team has most likely created a full supply chain, and this step is just the beginning of a longer process in which they will use these automatically <span class="No-Break">created artifacts.</span></p>
<p>Code repositories will <a id="_idIndexMarker1571"/>probably run on top of Kubernetes in your on-premise infrastructure, although you could use SaaS services instead. Depending on the integrations required for the different steps, it may be difficult to fully integrate cloud solutions with on-premises tools without taking on risks such as having certain data center credentials stored on your cloud platform (integration from cloud repositories to your on-premises Kubernetes clusters, for example). You should always ensure minimal required privileges for all your platform integrations, no matter whether they run on the cloud or your own <span class="No-Break">data center.</span></p>
<p>Once your code is pushed to the code repository, different triggers can be configured to first validate the quality of your code, the maturity and security of the dependencies included in your project, and the security itself of your code and built binaries. For these tasks, the different tools presented in <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em> can be used. For example, we can configure some container images with programming language linters and rules, and execute containers injecting our code for its validation. The process can be stopped whenever any test isn’t passed or just inform us at the end of the check about some minor or major improvements we can make to our code. These tasks can be configured as jobs in our favorite CI/CD orchestration environment, probably also running on Kubernetes to leverage the availability of the cluster container runtimes. Some of the most popular CI/CD orchestrators are presented in <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em>, but many advanced code repositories include task management functionality of their own, which simplifies the number of tools required for running our complete CI/CD workflows. For example, we can use GitLab for storing and versioning our code, storing and managing our artifacts (built artifacts and container images), and executing different CI/CD tasks. We will see platforms such as this in action in the <em class="italic">Labs</em> section with a <span class="No-Break">full example.</span></p>
<p>As mentioned before, consecutive validation tasks (tests) can be triggered, and as a final step, we can build a container image ready for production. At this time, new tests can be executed for testing the integration of the new component release with other application components and validate the performance of the solution. Depending on the required integrations, this pipeline (that is, the definition of the different concatenated tasks to be executed) can be complex. It is usually recommended to group tasks and prepare the output of the different processes involved to provide easy-to-read reports. Most of the tools mentioned in the validation group of <span class="No-Break"><em class="italic">Figure 13</em></span><em class="italic">.4</em> provide summary reports that can be parsed to find any errors that should stop the workflow. The tasks associated with the pipeline can be executed within containers (isolated Pods on Kubernetes), and their logs should be available in the CI/CD orchestrators as these containers will <span class="No-Break">be volatile.</span></p>
<p>Depending on the<a id="_idIndexMarker1572"/> complexity of the application, it might be worthwhile to package the required components before the tests. You probably wouldn’t execute simple manifests in your Kubernetes environments, and you would use Helm charts or Kustomize to create packages for either your full application or <span class="No-Break">each component.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">Some tools such as <strong class="bold">Argo CD</strong> can use Helm charts as templates for application deployments. Although we <a id="_idIndexMarker1573"/>do not really deploy our application using a Helm chart, it will be used by the process to manage and manipulate the Kubernetes resources associated with your application. That’s why it is always worthwhile preparing your applications as packages: it allows someone else to easily deploy your full application or some components therein without really knowing the contents back <span class="No-Break">to front.</span></p>
<p>Before we continue, let’s see some of the most important features of Helm and how to create a simple <span class="No-Break">manifests package.</span></p>
<h2 id="_idParaDest-293"><a id="_idTextAnchor311"/>Using Helm to package our application’s resource manifests</h2>
<p><strong class="bold">Helm</strong> is a<a id="_idIndexMarker1574"/> tool that packages Kubernetes resource manifests using templated YAML files and automation scripts that allow us to completely configure and deploy applications using a simple command line and a <span class="No-Break">configuration file.</span></p>
<p>Using Helm charts, we<a id="_idIndexMarker1575"/> can replace all application resource manifests at once or only those that were changed, with a simple path to roll them back to a previous release at any time. Helm keeps track of all the changes made to a Helm instance and is capable of reverting those changes by applying a previously stored <span class="No-Break">release version.</span></p>
<p>When we execute <strong class="source-inline">helm create &lt;NAME_OF_THE_CHART&gt;</strong>, Helm creates a directory structure that contains some example manifests and other files used to create a new Helm <span class="No-Break">chart package:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer175">
<img alt="Figure 13.5 – Helm chart file structure" height="762" src="image/B19845_13_05.jpg" width="1302"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.5 – Helm chart file structure</p>
<p>In this code snippet, we used <strong class="source-inline">helm create</strong> to create a Helm chart tree structure. You may have noticed the existence of the <strong class="source-inline">charts</strong> directory. A Helm chart can contain other Helm charts as dependencies. This way, we can create<a id="_idIndexMarker1576"/> an <strong class="bold">umbrella chart</strong> that includes all the Helm charts required to fully deploy an application with all its components. We could, for example, create a chart for the database component and other charts for the backend and frontend components. All these charts can be included inside an umbrella chart that defines the values required for deploying the full application. Each chart should contain a mocked values file, with example or real values that can be used to deploy it. We will write down and use a customized values file for deploying the application by overwriting the default values included on each chart. The <strong class="source-inline">Chart.yaml</strong> file describes the dependencies of your package and its version. You will find two versioning properties in your <span class="No-Break"><strong class="source-inline">Chart.yaml</strong></span><span class="No-Break"> file:</span></p>
<ul>
<li>The <strong class="source-inline">version</strong> key, which indicates the package <span class="No-Break">release number</span></li>
<li>The <strong class="source-inline">appVersion</strong> key, which is used to identify your <span class="No-Break">application release</span></li>
</ul>
<p class="callout-heading">Important note</p>
<p class="callout">Helm charts can be uploaded to repositories for storage and to share with other users. This way, your applications can be deployed by anyone authorized to pull and execute the Helm chart containing the manifests. Many vendors and open source projects offer their Helm charts as a way to deploy their applications, and some community-driven repositories host thousands of charts ready to use in your projects. Two of the most popular <a id="_idIndexMarker1577"/>repositories<a id="_idIndexMarker1578"/> are <em class="italic">ArtifactHub</em> (<a href="https://artifacthub.io">https://artifacthub.io</a>) and <em class="italic">Bitnami Application </em><span class="No-Break"><em class="italic">Stacks</em></span><span class="No-Break"> (</span><a href="https://bitnami.com/stacks/helm"><span class="No-Break">https://bitnami.com/stacks/helm</span></a><span class="No-Break">).</span></p>
<p>The magic <a id="_idIndexMarker1579"/>behind the management and composition of some key variables, such as the instance name, is included in the <strong class="source-inline">_helpers.tpl</strong> file, and the composed variables will be used in all the YAML manifest files included within the <strong class="source-inline">templates</strong> directory. We will include all the manifests required for our application or its components to work. All the PersistentVolumeClaims, Deployments, StatefulSets, DaemonSets, Secrets, and ConfigMaps should be included. Indeed, if our application requires specific permissions, we must also include ServiceAccounts and the appropriate Role and RoleBinding manifests. The <strong class="source-inline">values.yaml</strong> file included by default is used to validate the manifests that will be created with the <strong class="source-inline">helm</strong> command with a set of default values. This is another validation test that can be included in our pipeline just before the creation of the Helm chart package. If this <strong class="source-inline">values.yaml</strong> file implements all the required values (a mocked version), the pipeline process can continue and create the Helm chart package. The Helm chart’s files should also be managed using a versioning system; hence, we will store them in our code repository. Whether or not to use a different repository depends on you as a developer, but it would be nice to manage different releases for the application’s components and the Helm charts that deploy them, and it will be easier if we use <span class="No-Break">different repositories.</span></p>
<p>In the <em class="italic">Labs</em> section, you will work through a full example using the <strong class="source-inline">simplestlab</strong> application. We prepared a Helm chart for each application’s component and an umbrella chart that deploys the <span class="No-Break">full application.</span></p>
<p>Let’s summarize the steps described so far before continuing with the rest of the pipeline chain that<a id="_idIndexMarker1580"/> describes the application’s <span class="No-Break">life cycle:</span></p>
<ol>
<li>Write your code and push it to the code repository. Our code should include at least one Dockerfile for building the container image or images for the application’s component. Although it is not required, it is recommended to maintain a separate code repository for storing your Helm chart files. This way, you can follow the same code workflow for both the application’s code and the Helm chart’s code, but isolating each repository allows us to manage a different release for the code and the Helm <span class="No-Break">chart’s package.</span></li>
<li>Code will be validated using the relevant linters to verify its quality, its compliance with your organization’s coding rules, its dependencies, and its inner security (do not include sensitive information unless it <span class="No-Break">is mocked).</span></li>
<li>Different artifacts will be created and stored in your repositories. When your code is built, the resulting artifacts (binaries and libraries) will be stored (in our example, in GitLab). Storing artifacts is important if they are shared between components, such as binaries and client libraries, for example. Container images are also stored in GitLab as it additionally provides image registry capabilities. You can use a different repository for each type of artifact, but GitLab is a good catch-all solution because it offers storage for code, artifacts, and <span class="No-Break">container images.</span></li>
<li>When all the artifacts (the build and container images) are created, we can either automate the execution of the unit tests or pull the resulting release images (with fixes or new functionalities) and test them on our development computer, or even <span class="No-Break">do both.</span></li>
<li>Integration tests may require packaging the application’s components. If this is the case, validation of the Helm chart code will be triggered, and then the package will be created. Sometimes, we just change the application’s container image (that is, we change some code, which triggers a new artifact build and a new image is created) without actually changing the application’s Helm charts. That’s why it is always useful to keep track of Helm chart package template changes in a different repository from the application’s code. You may need to upgrade your application’s code without changing the templated deployment manifests. Here, we would just need the customized values for deploying a new container image and the <strong class="source-inline">appVersion</strong> key on your <strong class="source-inline">Chart.yaml</strong> file. This is a good practice because you will be able to track your package and application release at the <span class="No-Break">same time.</span></li>
<li>Once the <a id="_idIndexMarker1581"/>container images are created and stored correctly in the images registry, and the Helm chart packages are created, the application is ready to be deployed. Additional vulnerability tests can be triggered using the container images. Some tools such as AquaSec’s Trivy use <a id="_idIndexMarker1582"/>a <strong class="bold">bill of materials</strong> (<strong class="bold">BOM</strong>), which is a list of all the files included in all the container image layers, and search for known issues using both their own and internet-based <span class="No-Break">vulnerability databases.</span></li>
</ol>
<p>Let’s continue now with the second part of the pipeline. As you can see, we usually refer to the complete CI/CD workflow because CI and CD are often concatenated automatically one after <span class="No-Break">the other.</span></p>
<h2 id="_idParaDest-294"><a id="_idTextAnchor312"/>Adding CD to the workflow</h2>
<p>Different<a id="_idIndexMarker1583"/> integration and performance tests can be executed by using the container images directly using Docker Compose or Kubernetes manifests, or via the Helm chart packages, which provide a more <span class="No-Break">customizable solution.</span></p>
<p>The CI/CD workflow<a id="_idIndexMarker1584"/> continues with the tests, <span class="No-Break">as follows:</span></p>
<ol>
<li>Deployments for the different tests are triggered using the custom value files stored in the code repository. It is important to understand that we should never store sensitive data in clear text in our code repositories. Instead, use solutions such as HashiCorp’s Vault or Bitnami’s SealedSecrets to store sensitive data under encryption. Both solutions enable data decryption during the <span class="No-Break">deployment stages.</span></li>
<li>The application’s performance and workflow task metrics can be integrated into your favorite dashboard environment. Most of the tests in this stage provide helpful summaries of the validation tasks executed, with which we can get a good overview of the impact of newly added changes. Logs will highlight any errors from either the tasks or the application’s processes. We should separate these into different dashboards because they will probably have different <span class="No-Break">end users.</span></li>
<li>Once all the tests are<a id="_idIndexMarker1585"/> passed, we are ready to deploy the new release in production. Whether or not to automatically trigger this process depends on how your organization manages the changes in production. If your applications are governed using a GitOps model, use your configurations repository as the SOT, and the CI/CD orchestrator will push the changes into the Kubernetes platform. The current state of the application’s components may necessitate an upgrade to a new release or a rollback to a previous version to synchronize the desired state of the application. This model allows you to manage all your applications by changing their <span class="No-Break">deployment configurations.</span></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">The <strong class="bold">GitOps</strong> model<a id="_idIndexMarker1586"/> extends the use of repositories to improve the tracking of infrastructure and application changes by using custom values repositories as a <strong class="bold">single SOT</strong> (<strong class="bold">SSOT</strong>) to<a id="_idIndexMarker1587"/> trigger the delivery process. We can include automation for requiring specific security configurations, solving application or infrastructure dependencies before they are deployed, or any other requirement for the applications to work. All changes made to code and the values used for deploying the applications are tracked, making updates and rollbacks easier <span class="No-Break">than ever.</span></p>
<ol>
<li value="4">Automating the deployment of our applications requires access and authorization to our Kubernetes environment. We include the required credentials for a deployment user in our CI/CD platform. We can use Argo CD to implement a simple GitOps working model. This way, a simple change in the custom package parameters will trigger the deployment of a new release using updated manifests. As a result, the new application release will be delivered with the given fixes or new <span class="No-Break">requested features.</span></li>
<li>The new release deployed will be kept in the maintenance stage until a new one is released to replace it. Monitoring the application and retrieving and analyzing feedback from the users will end this iteration. The process will start over, with the team planning the implementation of newly requested features and fixes to issues not yet solved in the latest release. The following schema represents the workflow presented in the<a id="_idIndexMarker1588"/> preceding <span class="No-Break">bullet points:</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer176">
<img alt="Figure 13.6 – Schema of the workflow followed to deliver a new application release" height="707" src="image/B19845_13_06.jpg" width="1242"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.6 – Schema of the workflow followed to deliver a new application release</p>
<p>We will now review some of the aforementioned stages in the following <em class="italic">Labs</em> section, using a GitLab platform deployed on a Minikube <span class="No-Break">desktop environment.</span></p>
<h1 id="_idParaDest-295"><a id="_idTextAnchor313"/>Labs</h1>
<p>In this lab, we will reproduce a very simplified supply chain<a id="_idIndexMarker1589"/> using automation and the GitOps deployment model by installing and configuring GitLab and Argo CD in a test environment for building, testing, and deploying the <strong class="source-inline">simplestlab</strong> application. You can use a fully working Kubernetes platform (on the cloud or on-premises) or a simplified Kubernetes desktop environment. The fully detailed steps of the process are explained in the GitHub repository of this book, in the <strong class="source-inline">Chapter13</strong> folder, but here is the summary of the processes and some notable configurations you will <span class="No-Break">find there:</span></p>
<ol>
<li>First, we will prepare our environment with the tools required for the lab (Helm, <strong class="source-inline">kubectl</strong>, and the Argo CD CLI), and we will also use some environment variables for easier configuration of the Ingress resources and CA certificates for <span class="No-Break">each application.</span></li>
<li>You will find complete Helm charts for the <strong class="source-inline">simplestlab</strong> application, alongside some value configurations for deploying the application. The specific values used in this file will depend on your environment, and we have provided an explanation to help. You can test and deploy the Helm charts using <span class="No-Break">local configurations.</span></li>
<li>We will deploy and use GitLab to store all the application code, Helm charts, container images, and application configurations. Steps to create groups, subgroups, repositories, and required users <span class="No-Break">are included.</span></li>
<li>The code and Helm charts folders included in the <strong class="source-inline">Chapter13</strong> repository come with a <strong class="source-inline">.gitlab-ci.yml</strong> file that describes and prepares CI automation to validate our Dockerfile <a id="_idIndexMarker1590"/>using <strong class="bold">Hadolint</strong> (a Docker linter) and finally build our image <a id="_idIndexMarker1591"/>using <strong class="bold">Kaniko</strong> (a tool to build container images from a Dockerfile inside a container or Kubernetes cluster). This tool doesn’t depend on the Docker container runtime and executes each command within a Dockerfile completely in user space, which is great for security. This way, we can build images inside any standard <span class="No-Break">Kubernetes cluster.</span></li>
<li>We will use <strong class="source-inline">git</strong> commands, different branches, and tags to trigger the different automations included in the example pipeline for the code and the <span class="No-Break">Helm charts.</span></li>
<li>The automation creates <strong class="source-inline">dev</strong> and <strong class="source-inline">release</strong> images using different container image tags. Development images will be added to the code repositories, but the release images will be considered ready for production and will be stored in a separate container <span class="No-Break">images repository.</span></li>
<li>Helm charts are created using an umbrella structure; hence, the <strong class="source-inline">simplestlab</strong> chart deploys all the components at once. This chart includes dependencies for different applications’ components, and these dependencies should be solved before it is deployed. We will see how this works with a local example and then automate the Helm <span class="No-Break">chart creation.</span></li>
<li>Argo CD provides the CD part. While GitLab can be used to deploy directly on your Kubernetes cluster, Argo CD works by following the GitOps model. We will configure Argo CD to review any change in the <strong class="source-inline">values</strong> repository, and it will deploy the application using the resources stored in GitLab (container images, Helm charts, and the file with the values required for deploying the application). We will give you a brief discussion of the steps included in this lab and recommend you follow the full description written in the <span class="No-Break"><strong class="source-inline">Chapter13/Readme.md</strong></span><span class="No-Break"> file.</span><p class="list-inset">We have prepared for <a id="_idIndexMarker1592"/>you three <span class="No-Break">main directories:</span></p><ul><li><strong class="source-inline">ArgoCD</strong>: Contains the installation of the Argo CD component and the Application resource we will use to deploy our <span class="No-Break"><strong class="source-inline">simplestlab</strong></span><span class="No-Break"> application</span></li><li><strong class="source-inline">GitLab</strong>: Contains the installation of <span class="No-Break">GitLab components</span></li><li><strong class="source-inline">simplestlab</strong>: This directory contains all the code, Helm charts, and values used for deploying a <strong class="source-inline">simplestlab</strong> <span class="No-Break">application instance</span></li></ul><p class="list-inset">We will need the following tools in <span class="No-Break">our environment:</span></p><ul><li><strong class="bold">Minikube</strong> (and<a id="_idIndexMarker1593"/> Docker, if you follow my steps using a fixed<a id="_idIndexMarker1594"/> IP for <span class="No-Break">the lab)</span></li><li><span class="No-Break"><strong class="bold">Git</strong></span></li><li><strong class="bold">Argo CD CLI</strong>: To create and modify the integration of Argo CD inside our <span class="No-Break">Kubernetes </span><span class="No-Break"><a id="_idIndexMarker1595"/></span><span class="No-Break">cluster</span></li><li><strong class="bold">OpenSSL or Certutil on MS Windows</strong>: To decode some <strong class="source-inline">base64</strong> strings in case<a id="_idIndexMarker1596"/> you don’t<a id="_idIndexMarker1597"/> <span class="No-Break">have </span><span class="No-Break"><strong class="source-inline">Base64</strong></span></li><li><strong class="bold">Helm</strong>: To deploy <a id="_idIndexMarker1598"/>your <span class="No-Break">Helm charts</span></li><li><strong class="source-inline">kubectl</strong>: To connect to our <span class="No-Break">Kubernetes cluster</span></li><li><strong class="source-inline">Base64</strong>: For decoding <span class="No-Break">some strings</span></li></ul></li>
</ol>
<p>Detailed steps for<a id="_idIndexMarker1599"/> installing these tools are included in the code repository. We will start the lab by setting up a Minikube environment. We will use Linux and Docker for running this environment to be able to set up a fixed IP address. This will help you in case you decide to take your time for the lab and start and stop the Minikube environment without changing the setup. Follow <span class="No-Break">these steps:</span></p>
<ol>
<li>Start <strong class="source-inline">minikube</strong> using the following <span class="No-Break">command line:</span><pre class="source-code">
<strong class="bold">Chapter13$ minikube start --driver=docker \</strong>
<strong class="bold">--memory=8gb --cpus=4 \</strong>
<strong class="bold">--addons=ingress,metrics-server --cni=calico \</strong>
<strong class="bold">--insecure-registry="172.16.0.0/16" \</strong>
<strong class="bold">--static-ip=172.31.255.254</strong></pre></li> <li>We will now prepare the <strong class="source-inline">simplestlab</strong> application using a directory to avoid conflicts between different Git environments because you downloaded this repository <span class="No-Break">from GitHub:</span><pre class="source-code">
<strong class="bold">Chapter13$ cp -R SimplestLab Simplestlab_WORKSPACE</strong></pre></li> <li>Remove all the hidden <strong class="source-inline">.git</strong> folders in the <strong class="source-inline">Simplestlab_WORKSPACE</strong> folder and subfolders (if any) every time you start with the lab. We will use these folders to push some code changes inside <strong class="source-inline">Code/simplestapp</strong>, push Helm charts included in the <strong class="source-inline">HelmCharts</strong> directory, and push deployment values included inside the <span class="No-Break"><strong class="source-inline">Values</strong></span><span class="No-Break"> folder.</span></li>
<li>Install GitLab following the instructions included in the code repository. We have prepared a setup script to help you customize the values file for deploying GitLab using Helm. The chart is included under the <span class="No-Break"><strong class="source-inline">chapter13/GitLab</strong></span><span class="No-Break"> directory.</span></li>
<li>Once it is installed, we will review the secret created with the credentials and log in to the<a id="_idIndexMarker1600"/> GitLab web UI, published <span class="No-Break">at </span><a href="https://gitlab.172.31.255.254.nip.io"><span class="No-Break">https://gitlab.172.31.255.254.nip.io</span></a><span class="No-Break">.</span></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">We used the <a href="http://nip.io">nip.io</a> domain to simplify all the qualified domain names for your environment. You can read more about this simplified domain <span class="No-Break">at </span><a href="https://nip.io/"><span class="No-Break">https://nip.io/</span></a><span class="No-Break">.</span></p>
<p class="list-inset">We include our GitLab environment inside the Minikube setup to allow Kubernetes to download images. Complete steps are described in the <span class="No-Break">GitLab repository.</span></p>
<ol>
<li value="6">We will then install Argo CD using a setup script and Helm. The script will customize a values file for your environment, and we will use it to deploy Argo CD using the Helm chart included in the <span class="No-Break"><strong class="source-inline">Chapter13/ArgoCD</strong></span><span class="No-Break"> directory.</span></li>
<li>Detailed steps are provided in the code repository. Once installed, you will be able to access Argo CD at <a href="https://argocd.172.31.255.254.nip.io">https://argocd.172.31.255.254.nip.io</a>. You will use the admin user with the password obtained from the deployment secret, following the procedure described in the <span class="No-Break">code repository.</span></li>
<li>We will then upload the code included in <strong class="source-inline">SimplestLab/Code</strong> directory to GitLab. But first, we will create a user (<strong class="source-inline">coder</strong> user) with developer privileges in GitLab. This user will be used to pull and push code only, without privileged access. Steps for creating this user and the different projects for managing the code, Helm charts, images, and the values for deploying the application are described in the <span class="No-Break">code repository.</span></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">Different permissions will be declared for different projects in GitLab. We have simplified the environment, setting up some projects as <strong class="source-inline">Public</strong>. Follow the instructions detailed in the <span class="No-Break"><strong class="source-inline">Chapter13</strong></span><span class="No-Break"> repository.</span></p>
<ol>
<li value="9">Using this <strong class="source-inline">coder</strong> user, we will push the code for the <strong class="source-inline">simplestapp</strong> component, included in the <strong class="source-inline">Chapter13/Simplestlab/Code/simplestapp</strong> directory, to our <span class="No-Break">GitLab instance.</span></li>
<li>Automation of a <a id="_idIndexMarker1601"/>Docker image build is triggered thanks to the existence of the <strong class="source-inline">.gitlab-ci.yml</strong> file in our code repository. This file describes the automated process and steps for verifying and building a custom image using our code. We included three stages in <span class="No-Break">the file:</span><ul><li><strong class="source-inline">test</strong> (which basically validates our <span class="No-Break">Dockerfile syntax)</span></li><li><strong class="source-inline">security</strong> (which reviews the content of the files to be included in the image before it <span class="No-Break">is built)</span></li><li><strong class="source-inline">build</strong> (using Kaniko instead of Docker to improve security, avoiding the need to use the Kubernetes host’s Docker or <span class="No-Break"><strong class="source-inline">containerd</strong></span><span class="No-Break"> engine)</span></li></ul><p class="list-inset">The process is described in detail in the <strong class="source-inline">Readme.md</strong> file included in the <span class="No-Break">code repository.</span></p></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">To avoid the need to add the GitLab environment SSL certificate to our client environment, we will configure Git to skip SSL verification (steps are included in the <span class="No-Break">code repository).</span></p>
<ol>
<li value="11">This <a id="_idIndexMarker1602"/>automation will use the following variables for executing the tasks defined in the <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">gitlab-ci.yaml</strong></span><span class="No-Break"> file:</span><ul><li><span class="No-Break"><strong class="source-inline">PROJECTGROUP_USERNAME</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">coder</strong></span></li><li><span class="No-Break"><strong class="source-inline">PROJECTGROUP_PASSWORD</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">C0der000</strong></span></li><li><strong class="source-inline">LABS_LOCAL_GITLAB_CERTIFICATE</strong>: Complete GitLab TLS certificate chain <strong class="source-inline">Base64</strong>-decoded value, obtained using the <span class="No-Break">following command:</span><pre class="source-code">
<strong class="bold">kubectl get secret -n gitlab -o yaml gitlab-wildcard-tls-chain -o jsonpath='{.data.gitlab\.172\.31\.255\.254\.nip\.io\.crt}'</strong></pre></li></ul><p class="list-inset">These variables should be included following the steps described in the repository <span class="No-Break">in GitLab.</span></p></li> <li>The GitLab automation file will trigger two types of image <span class="No-Break">construction processes:</span><ul><li><strong class="bold">Dev images</strong>: These <a id="_idIndexMarker1603"/>images will be built and included in the <strong class="source-inline">Code</strong> <span class="No-Break">project repository</span></li><li><strong class="bold">Release images</strong>: These<a id="_idIndexMarker1604"/> images will be built and included in the <strong class="source-inline">Images</strong> <span class="No-Break">project repository</span></li></ul><p class="list-inset">We will <a id="_idIndexMarker1605"/>create <strong class="source-inline">dev</strong> and <strong class="source-inline">main</strong> code branches, change some code, push it to GitLab, and switch between branches to see whether changes will trigger the build process or not. Once we are ready to build a release image, we will tag the commit with a release name, push it to GitLab, and verify how the automated pipeline will create the appropriate release image inside the image project in GitLab. Described steps for these tasks are included in the <strong class="source-inline">Chapter13/Readme.md</strong> file. Please follow them carefully, and review the pipeline results and files generated during the process in the different GitLab projects (<strong class="source-inline">Code</strong> and <strong class="source-inline">Images</strong>). Get familiar with the processes before continuing with the next step, in which we will push and build the Helm charts for deploying the different <span class="No-Break">applications’ components.</span></p></li>
<li> We will now manage the Helm charts’ code files and their associated projects’ repositories. We set up for you three Helm charts, one for each component (<strong class="source-inline">simplestlab-db</strong>, <strong class="source-inline">simplestlab-app</strong>, and <strong class="source-inline">simplestlab-lb</strong>), and one umbrella chart that will include the others as dependencies. Therefore, four project repositories must <span class="No-Break">be created:</span><ul><li><strong class="source-inline">simplestlab</strong>: This chart defines the umbrella Helm chart used to deploy all components at once and its Ingress resource. We didn’t add any Ingress resource on any <span class="No-Break">other component.</span></li><li><strong class="source-inline">simplestlab-app</strong>: Describes the application backend component Deployment <span class="No-Break">resource deployment.</span></li><li><strong class="source-inline">simplestlab-db</strong>: Describes the database component <span class="No-Break">StatefulSet deployment.</span></li><li><strong class="source-inline">simplestlab-lb</strong>: This describes the load balancer <span class="No-Break">DaemonSet deployment.</span></li></ul><p class="list-inset">This project should be <strong class="source-inline">Public</strong> in this demo because we will not declare any credentials in Argo CD. You will use credentials and <strong class="source-inline">Private</strong> repositories in your production and development platforms, but this will definitely require more configurations for this <span class="No-Break">demo environment.</span></p></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">The <strong class="source-inline">simplestlab</strong> umbrella chart depends on <strong class="source-inline">simplestlab-app</strong>, <strong class="source-inline">simplestlab-db</strong>, and <strong class="source-inline">simplestlab-lb</strong> charts. Whatever change you make to any of these projects requires a Helm chart dependencies update on the <strong class="source-inline">simplestlab</strong> umbrella chart. While you use the prepared CI/CD environment, you will need to run the <strong class="source-inline">simplestlab</strong> umbrella chart project pipeline again to rebuild these dependencies. If you want to manually update them, you will use a Helm dependencies update in the <strong class="source-inline">HelmCharts/simplestlab</strong> directory. We prepared various scenarios in the <strong class="source-inline">Chart.yaml</strong> file in case you want to test it locally (review the <strong class="source-inline">Chapter13/Simplestlab/Values/simplestlab/values.yaml</strong> <span class="No-Break">file comments).</span></p>
<p class="list-inset">Once the<a id="_idIndexMarker1606"/> Helm charts’ project repositories are created, we can push the Helm charts’ code into their GitLab-associated repositories. The code for the charts is located in <strong class="source-inline">Chapter13/Simplestlab/HelmCharts</strong>. Push each component’s code to the <span class="No-Break">appropriate repository.</span></p>
<ol>
<li value="14">We have included in the charts’ code the <strong class="source-inline">.gitlab-ci.yaml</strong> file for GitLab automation. This file describes <span class="No-Break">three stages:</span><ul><li><strong class="source-inline">test</strong> (which validates the Helm chart using its <span class="No-Break">own linter)</span></li><li><strong class="source-inline">dependencies</strong> (which validates the chart dependencies if any <span class="No-Break">are declared)</span></li><li><strong class="source-inline">build</strong> (which packages the code into a Helm chart <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">tgz</strong></span><span class="No-Break"> file)</span></li></ul></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">We need to include two new variables, <strong class="source-inline">DOCKERHUB_USERNAME</strong> (with your Docker Hub username) and <strong class="source-inline">DOCKERHUB_PASSWORD</strong> (with your Docker Hub password). These variables should be defined in the <strong class="source-inline">HelmChart/SimplestLab</strong> umbrella chart only. This repository is <strong class="source-inline">Public</strong>, and anyone will be able to read your password, but you are using your own demo environment. You can secure this password by making it <strong class="source-inline">Private</strong>, but you will need to prepare some username authentication (new user or even coder user here) and include it in the Argo CD <span class="No-Break">OCI repository.</span></p>
<ol>
<li value="15">The GitLab<a id="_idIndexMarker1607"/> automation file will trigger two types of package <span class="No-Break">construction processes:</span><ul><li><strong class="bold">Dev packages</strong>: These <a id="_idIndexMarker1608"/>packages will be built and included in each <strong class="source-inline">HelmChart</strong> <span class="No-Break">project repository.</span></li><li><strong class="bold">Release packages</strong>: These packages will be built, included, and pushed to Docker Hub. We will just use<a id="_idIndexMarker1609"/> this procedure to build the umbrella <span class="No-Break"><strong class="source-inline">simplestlab</strong></span><span class="No-Break"> chart.</span></li></ul><p class="list-inset">We will create <strong class="source-inline">dev</strong> and <strong class="source-inline">main</strong> code branches and verify the build process when we push code to GitLab. Steps for making some changes and pushing them to GitLab are described in the <strong class="source-inline">Chapter13/Readme.md</strong> file. The <strong class="source-inline">simplestlab</strong> umbrella chart will be pushed to Docker Hub, and we will be ready to use it, but first, we will need to add the <strong class="source-inline">values.yaml</strong> file to the <strong class="source-inline">Values</strong> <span class="No-Break">project repository.</span></p></li>
<li>We will create a <strong class="source-inline">Simplestlab/values/simplestlab</strong> repository to manage a simple values file that will be used to deploy the <strong class="source-inline">simplestlab</strong> application using the <strong class="source-inline">simplestlab</strong> umbrella Helm chart. The file contains <span class="No-Break">different sections:</span><ul><li><strong class="source-inline">simplestlab-lb</strong>: Defines the values to overwrite when deploying the <strong class="source-inline">simplestlab-lb</strong> Helm chart, added as a dependency in the <span class="No-Break">umbrella chart.</span></li><li><strong class="source-inline">simplestlab-app</strong>: Defines the values to overwrite when deploying the <strong class="source-inline">simplestlab-app</strong> Helm chart, added as a dependency in the <span class="No-Break">umbrella chart.</span></li><li><strong class="source-inline">simplestlab-db</strong>: Defines the values to overwrite when deploying the <strong class="source-inline">simplestlab-db</strong> Helm chart, added as a dependency in the <span class="No-Break">umbrella chart.</span></li><li><strong class="bold">Rest of the file</strong>: The rest of the definitions included will manage the behavior of the umbrella chart. We included parameters for deploying the Ingress <span class="No-Break">resource here.</span></li></ul><p class="list-inset">We have prepared this file for you with comments for two different labs using <span class="No-Break">Argo CD:</span></p><ul><li>The first test will deploy a configuration with the wrong database service name for the <strong class="source-inline">App</strong> component (<strong class="source-inline">__dbhost: db__</strong>). The correct data is commented: <strong class="source-inline">__dbhost: simplestlab-simplestlab-db__</strong>. Thus, when you create the Argo CD application for the first time, the application component and the load balancer components will fail. Until you change the correct mentioned value in the <strong class="source-inline">values</strong> YAML file, this will not fix the problem in the load <span class="No-Break">balancer component.</span></li><li>The second<a id="_idIndexMarker1610"/> test will deploy a new configuration that will fix the load balancer component by deploying a completely new <strong class="source-inline">nginx.conf</strong> ConfigMap. To make this happen, uncomment the <strong class="source-inline">nginxConfig</strong> key in <strong class="source-inline">simplestlab-lb</strong>. Indentation is key; uncomment all the lines (you can leave the <strong class="source-inline">###################################</strong> <span class="No-Break">line).</span></li></ul><p class="list-inset">When an Application resource is created in Argo CD, the synchronization with the different reports starts, and every time you change either the Helm chart package or the values file, the misconfigurations will be reflected in the Argo <span class="No-Break">CD environment.</span></p></li>
<li>Create a <strong class="source-inline">simplestlab</strong> values repository (<strong class="source-inline">Project</strong>) inside the <strong class="source-inline">Values</strong> project, and push the file from <strong class="source-inline">Chapter13/Simplestlab/values/simplestlab</strong> into this <span class="No-Break">new repository.</span></li>
<li>We will now integrate our application into Argo CD. We will use the Argo CD CLI to manage the integration of our Kubernetes cluster with Argo CD. To connect Kubernetes with Argo CD, create a ServiceAccount resource with cluster privileges to manage applications cluster-wide. Detailed instructions for integrating our Minikube Kubernetes cluster are included in the <strong class="source-inline">Chapter13</strong> repository. Follow these<a id="_idIndexMarker1611"/> instructions, and then log in to Argo CD to create the <span class="No-Break">following repositories:</span><ul><li><strong class="bold">Code repository type</strong>: <a href="https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git">https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git</a> This repository will be used to integrate our values YAML file, used to run the umbrella Helm chart and deploy the full application. This repository requires authentication; we will use <strong class="source-inline">coder</strong> as the username and <strong class="source-inline">c0der000</strong> as <span class="No-Break">the password.</span></li><li><strong class="bold">OCI type</strong> (<a href="http://registry.172.31.255.254.nip.io/simplestlab/helmcharts/simplestlab.git">registry.172.31.255.254.nip.io/simplestlab/helmcharts/simplestlab.git</a>)This includes the <span class="No-Break"><strong class="source-inline">simplestlab-chart</strong></span><span class="No-Break"> package.</span></li><li><strong class="bold">OCI type</strong> (<a href="http://docker.io">docker.io</a>): This includes the <strong class="source-inline">simplestlab-chart</strong> package uploaded at Docker Hub as a workaround for an issue in Argo CD with self-signed <span class="No-Break">certificates (</span><a href="https://github.com/argoproj/argo-cd/issues/12371"><span class="No-Break">https://github.com/argoproj/argo-cd/issues/12371</span></a><span class="No-Break">).</span></li></ul><p class="list-inset">Screenshots are provided in the instructions to guide you through the <span class="No-Break">setup process.</span></p></li>
<li>Once the repositories are created in Argo CD, we can create an Argo CD Application resource. The Argo CD GUI does not allow us to use multiple repositories, hence we will not be able to use a code repository for the values file and another one for the Helm chart package artifact. In these circumstances, we need to prepare the Application resource using a YAML file. We included a YAML file for you in <strong class="source-inline">Chapter13/ArgoCD/Applications</strong>. The <strong class="source-inline">minikube-simplestlab.yaml</strong> file includes both the values file repository (<a href="https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git">https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git</a>) and the Helm chart repository (<a href="http://docker.io/frjaraur">docker.io/frjaraur</a>). If you have followed all the steps, you can use your own Helm chart repository. Mine is public, and you will be able to use it at any time. The <strong class="source-inline">Applications</strong> manifest includes the sources for deploying an application and the destination environment – the Minikube lab environment in <span class="No-Break">our case.</span><p class="list-inset">We will create this new resource <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">kubectl</strong></span><span class="No-Break">:</span></p><pre class="source-code">
<strong class="bold">Chapter13$ kubectl create \</strong>
<strong class="bold">-f ArgoCD/Applications/minikube-simplestlab.yaml</strong></pre></li> <li>As soon as the Argo CD application is set and the repositories are available, Argo CD deploys the application for us. Review the Argo CD environment and verify the synchronization between the different repositories. Screenshots of the different environment views are included in the <span class="No-Break"><strong class="source-inline">Chapter13</strong></span><span class="No-Break"> repository.</span></li>
</ol>
<p class="callout-heading">Important note</p>
<p class="callout">We have included in the Argo CD Application resource the <strong class="source-inline">simplestlab</strong> namespace. This namespace should be created before the application is <span class="No-Break">actually deployed.</span></p>
<ol>
<li value="21">Next, we <a id="_idIndexMarker1612"/>change the database host lab. The first thing you will notice is that the application’s <strong class="source-inline">App</strong> component does not work. This is due to the fact that the connection string is wrong (check the comments included in the <strong class="source-inline">Chapter13/Simplestlab/Values/simplestlab/values.yaml</strong> file). Change the <strong class="source-inline">dbhost</strong> key to <strong class="source-inline">simplestlab-simplestlab-db</strong> and verify the changes in <span class="No-Break">Argo CD.</span></li>
<li>Verify the new name, automatically created by the Helm chart template (these names could have been fixed, but this is a common error and we can see how to solve it in <span class="No-Break">this example):</span><pre class="source-code">
<strong class="bold">Chapter13$ kubectl get svc -n simplestlab</strong>
<strong class="bold">NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</strong>
<strong class="bold">simplestlab-simplestlab-app   ClusterIP   10.96.6.93      &lt;none&gt;        3000/TCP   2d14h</strong>
<strong class="bold">simplestlab-simplestlab-db    ClusterIP   10.98.159.97    &lt;none&gt;        5432/TCP   2d14h</strong>
<strong class="bold">simplestlab-simplestlab-lb    ClusterIP   10.103.79.186   &lt;none&gt;        8080/TCP   2d14h</strong></pre></li> <li>We now know the new name for the database server, and we can change the <strong class="source-inline">dbhost</strong> value in the <span class="No-Break"><strong class="source-inline">values.yaml</strong></span><span class="No-Break"> file:</span><pre class="source-code">
  envVariables:
    dbhost: simplestlab-simplestlab-db</pre></li> <li>Commit the<a id="_idIndexMarker1613"/> new changes and push the file to our repository in GitLab <span class="No-Break">using Git.</span><p class="list-inset">The changes will be shown on Argo CD in a few seconds. We haven’t configured auto-sync, hence we will see a misconfiguration of the values (out of sync). Current values in the cluster are different from those expected by the configuration. We will just proceed to sync the application (screenshots are included in the repository). This will create a new Secret resource. We will delete the <strong class="source-inline">App</strong> component Pods, and the new changes will be applied to <span class="No-Break">this component.</span></p></li>
<li>Once the first problem is solved, you will find a new error because the <strong class="source-inline">Loadbalancer</strong> component isn’t able to reach the <strong class="source-inline">App</strong> component. So, next, we need to fix the <strong class="source-inline">Loadbalancer</strong> component. In this case, we will change the <strong class="source-inline">__nginx.conf__</strong> file required by <strong class="source-inline">Nginx ___Lb___</strong>. It is included as a ConfigMap resource and managed by the <strong class="source-inline">___nginxConfig___</strong> key in the values file. We need to change the name of the application backend service (<strong class="source-inline">___App___</strong> component). By default, it uses <strong class="source-inline">___app___</strong>, as you can see in the default values file included in the <strong class="source-inline">___simplest-lb___</strong> Helm <span class="No-Break">chart (</span><span class="No-Break"><strong class="source-inline">SimplestLab/HelmCharts/simplestlab/values.yaml</strong></span><span class="No-Break">).</span><p class="list-inset">We first verify the name of the <strong class="source-inline">App</strong> <span class="No-Break">component service:</span></p><pre class="source-code">
<strong class="bold">Chapter13$ kubectl get svc -n simplestlab</strong>
<strong class="bold">NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</strong>
<strong class="bold">simplestlab-simplestlab-app   ClusterIP   10.96.6.93      &lt;none&gt;        3000/TCP   2d14h</strong>
<strong class="bold">simplestlab-simplestlab-db    ClusterIP   10.98.159.97    &lt;none&gt;        5432/TCP   2d14h</strong>
<strong class="bold">simplestlab-simplestlab-lb    ClusterIP   10.103.79.186   &lt;none&gt;        8080/TCP   2d14h</strong></pre></li> <li>Next, we again review the <strong class="source-inline">Chapter13/Simplestlab/Values/simplestlab/values.yaml</strong> file. This time, you will need to uncomment the <strong class="source-inline">nginxConfig</strong> key. Please be very careful with the indentation as it may break the integration with Argo CD. If the application isn’t synced, verify the values fail because it may contain some <span class="No-Break">unexpected characters.</span><p class="list-inset">We <a id="_idIndexMarker1614"/>uncomment the <strong class="source-inline">___nginxConfig___</strong>  key value prepared for you. After uncommenting the value, you should have something <span class="No-Break">like this:</span></p><pre class="source-code">
  # Second Test Update -- Uncomment this section
  nginxConfig: |
    user  nginx;
    worker_processes  auto;
    error_log  /tmp/nginx/error.log warn;
    pid        /tmp/nginx/nginx.pid;
    events {
      worker_connections  1024;
    }
    http {
      server {
        listen 8080;
        location /healthz {
          add_header Content-Type text/plain;
          return 200 'OK';
        }
        location / {
          proxy_pass http://simplestlab-simplestlab-app:3000;
        }
      }
    }</pre></li> <li>We <a id="_idIndexMarker1615"/>commit and push the new changes. Argo CD will show the changes in a few seconds, and we will sync the resources and delete the <strong class="source-inline">Lb</strong> Pod, associated with the DaemonSet, to fix the NGINX configuration issue. After the synchronization and removal of the Pod, the new Pod works fine, and Argo CD will show the application as healthy <span class="No-Break">and synced.</span></li>
</ol>
<p>We’ve now reached the end of this long and complex lab, but we divided it into different stages to make it easier to follow. You can make changes to either your configurations, code, or Helm charts and trigger pipelines or GitOps integration to manage your application status and behavior. We can’t explain in a single lab all the configurations we have done to make all the workflow work; we gave you some tips that will help, and you can deep dive by yourself, exploring the already prepared configuration and <span class="No-Break">script steps.</span></p>
<p>It would be useful to follow the lab by including the NetworkPolicy resources created in <a href="B19845_11.xhtml#_idTextAnchor244"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> and the NGINX and Postgres Prometheus exporters prepared in <a href="B19845_12.xhtml#_idTextAnchor267"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>. After the completion of this lab, you will understand how the different automations work and will be ready to create your own using any other popular DevOps tool because the basic concepts are the same, no matter whether you use a cloud solution or deploy your DevOps tools in your own <span class="No-Break">data center.</span></p>
<h1 id="_idParaDest-296"><a id="_idTextAnchor314"/>Summary</h1>
<p>In this chapter, we described the life cycle of an application using software containers. We used most of the content learned in this book so far to prepare a CI/CD workflow, while we quickly reviewed the different stages involved in the creation of an application based on containers. We also presented some of the most popular applications used by DevOps teams to implement and automate the complete supply chain of an application and learned how to use them in the <em class="italic">Labs</em> section. This final lab showed you the different stages involved in the life cycle of an application. We coded our application, prepared our container images to use as our application’s artifacts, and prepared Helm charts, which we used to deploy the application in Kubernetes. Finally, we triggered the execution of the application in the Kubernetes cluster using Argo CD to deliver the application after its configuration was done. All changes will be tracked, and the automation and orchestration functionalities help us to deliver changes quickly and reliably. You are now ready to employ the content of this book to create your own supply chain or use one already created using other common DevOps tools. Best of luck preparing and delivering your applications using <span class="No-Break">software containers!</span></p>
</div>
</div></body></html>