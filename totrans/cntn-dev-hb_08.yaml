- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Deploying Applications with the Kubernetes Orchestrator
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 编排器部署应用
- en: Developing containers for your applications on your workstation or laptop really
    improves your development process by running other applications’ components while
    you focus on your own code. This simple standalone architecture works perfectly
    in your development stage, but it does not provide **high availability** (**HA**)
    for your applications. Deploying container orchestrators cluster-wide will help
    you to constantly keep your applications running healthy. In the previous chapter,
    we briefly reviewed Docker Swarm, which is simpler and can be a good introductory
    platform before moving on to more complex orchestrators. In this chapter, we will
    learn how to prepare and run our applications on top of **Kubernetes**, which
    is considered a standard nowadays for running containers cluster-wide.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作站或笔记本电脑上为你的应用开发容器，确实能通过运行其他应用的组件来改善开发过程，让你专注于自己的代码。这种简单的独立架构在开发阶段非常适用，但它并不为你的应用提供
    **高可用性**（**HA**）。在集群范围内部署容器编排器将帮助你保持应用的健康运行。在上一章中，我们简要回顾了 Docker Swarm，它更简单，是进入更复杂的编排器平台的好入门平台。在本章中，我们将学习如何在
    **Kubernetes** 上准备并运行我们的应用，Kubernetes 现在被认为是运行集群容器的标准。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Introducing the main features of Kubernetes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Kubernetes 的主要特点
- en: Understanding Kubernetes’ HA
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 的高可用性（HA）
- en: Interacting with Kubernetes using `kubectl`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `kubectl` 与 Kubernetes 交互
- en: Deploying a functional Kubernetes cluster
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署一个功能齐全的 Kubernetes 集群
- en: Creating Pods and Services
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 Pods 和 Services
- en: Deploying orchestrated resources
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署编排资源
- en: Improving your applications’ security with Kubernetes
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 提高应用的安全性
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the labs for this chapter at https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter8,
    where you will find some extended explanations, omitted in the chapter’s content
    to make it easier to follow. The *Code In Action* video for this chapter can be
    found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的实验可以在 [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter8](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter8)
    找到，在这里你将看到一些扩展的解释，这些内容在本章的正文中被省略，以便更易于跟进。关于本章的 *Code In Action* 视频可以在 [https://packt.link/JdOIY](https://packt.link/JdOIY)
    找到。
- en: Now, let’s start this chapter by learning about the main features of Kubernetes
    and why this orchestrator has become so popular.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从了解 Kubernetes 的主要特点开始，看看为什么这个编排器如此受欢迎。
- en: Introducing the main features of Kubernetes
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Kubernetes 的主要特点
- en: We can say without any doubt that Kubernetes is the new standard for deploying
    applications based on containers. However, its success didn’t happen overnight;
    Kubernetes started in 2015 as a community project based on Google’s own workload
    orchestrator, **Borg**. The first commit in Kubernetes’ GitHub repository occurred
    in 2014, and a year later, the first release was published. Two years later, Kubernetes
    went mainstream thanks to its great community. I have to say that you will probably
    not use Kubernetes alone; you will deploy multiple components to achieve a fully
    functional platform, but this isn’t a bad thing, as you can customize a Kubernetes
    platform to your specific needs. Also, Kubernetes by default has a lot of integrations
    with cloud platforms, as it was designed from the very beginning with them in
    mind. For example, cloud storage solutions can be used without additional components.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以毫无疑问地说，Kubernetes 已经成为基于容器部署应用的新标准。然而，它的成功并非一蹴而就；Kubernetes 于 2015 年作为一个社区项目启动，基于
    Google 自有的工作负载编排器 **Borg**。Kubernetes GitHub 仓库中的第一次提交发生在 2014 年，一年后，发布了第一个版本。两年后，Kubernetes
    凭借其强大的社区成为主流。我必须说，你可能不会单独使用 Kubernetes；你将部署多个组件，以实现一个完全功能的平台，但这并不是什么坏事，因为你可以根据具体需求定制
    Kubernetes 平台。此外，Kubernetes 默认与云平台有很多集成，因为它从一开始就考虑到了这些平台。例如，云存储解决方案可以无需额外组件即可使用。
- en: Let’s take a moment to briefly compare Kubernetes’ features with those of Docker
    Swarm.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍作停顿，简单比较一下 Kubernetes 的特点与 Docker Swarm 的区别。
- en: Comparing Kubernetes and Docker Swarm
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较 Kubernetes 和 Docker Swarm
- en: I have to declare that, personally, my first impressions of Kubernetes weren’t
    good. For me, it provided a lot of features for many simple tasks that I was able
    to solve with Docker Swarm at that time. However, the more complex your applications
    are, the more features you require, and Docker Swarm eventually became too simple
    as it hasn’t evolved too much. Docker Swarm works well with simple projects, but
    microservices architecture usually requires complex interactions and a lot of
    portability features. Kubernetes has a really steep learning curve, and it’s continuously
    evolving, which means you need to follow the project almost every day. Kubernetes’
    core features are usually improved upon in each new release, and lots of pluggable
    features and side projects also continuously appear, which makes the platform’s
    ecosystem grow daily.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须声明，个人而言，我对 Kubernetes 的初步印象并不好。对我来说，它提供了许多功能来解决一些简单的任务，而这些任务当时我可以通过 Docker
    Swarm 解决。然而，随着应用程序变得越来越复杂，你需要更多的功能，Docker Swarm 最终变得过于简单，因为它并没有太多发展。Docker Swarm
    对于简单项目来说表现良好，但微服务架构通常需要复杂的交互和大量的可移植性功能。Kubernetes 的学习曲线非常陡峭，并且它在不断发展，这意味着你几乎每天都需要跟进该项目。Kubernetes
    的核心功能通常会在每个新版本中得到改进，许多可插拔功能和附加项目也会不断出现，这使得该平台的生态系统日益增长。
- en: We will see some differences between the Docker Swarm orchestration model and
    the Kubernetes model. We can start with the definition of the workloads within
    a cluster. We mentioned in [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147), *Orchestrating
    with Swarm*, that Docker Swarm doesn’t schedule containers; in fact, it schedules
    **Services**. In Kubernetes, we schedule **Pods**, which is the minimum scheduling
    unit in this orchestrator. A Pod can contain multiple Pods, although most of them
    will just run one. We will explore and learn more about Pods later in this chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到 Docker Swarm 编排模型与 Kubernetes 模型之间的一些差异。我们可以从集群中工作负载的定义开始。我们在[*第七章*](B19845_07.xhtml#_idTextAnchor147)《使用
    Swarm 进行编排》中提到过，Docker Swarm 并不调度容器；实际上，它调度的是**服务**。在 Kubernetes 中，我们调度的是**Pods**，这是这个编排系统中的最小调度单元。一个
    Pod 可以包含多个容器，尽管大多数情况下它只运行一个。我们将在本章后面深入探讨并学习更多关于 Pods 的内容。
- en: Exploring the control plane
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索控制平面
- en: Container orchestrators should provide a **control plane** for all management
    tasks, providing us with scheduling capabilities to execute our application workloads
    on a data plane and cluster-wide networking features. The Kubernetes control plane
    components are designed to manage every cluster component, schedule workloads,
    and review events that emerge in the platform. It also manages the node components,
    which really execute containers for us thanks to their container runtimes. Kubernetes
    follows the manager-worker model, as with Docker Swarm, in which two different
    node roles are defined. Manager nodes will manage the control plane components,
    while worker nodes will execute the tasks assigned by the control plane nodes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 容器编排器应提供一个**控制平面**来处理所有管理任务，提供调度能力，以便在数据平面上执行我们的应用工作负载，并提供集群范围的网络功能。Kubernetes
    控制平面组件旨在管理每个集群组件，调度工作负载，并审查平台中出现的事件。它还管理节点组件，实际通过容器运行时执行容器。Kubernetes 遵循与 Docker
    Swarm 相似的管理者-工作者模型，定义了两种不同的节点角色。管理节点将管理控制平面组件，而工作节点将执行控制平面节点分配的任务。
- en: Now, let’s review some key processes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一些关键进程。
- en: Understanding the key processes
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解关键进程
- en: 'The following is a list of the key processes that run in the Kubernetes control
    plane:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Kubernetes 控制平面中运行的关键进程列表：
- en: '**kube-apiserver**: The API server is a component that interacts with all other
    components and the user. There isn’t any direct communication between components;
    hence, kube-apiserver is essential in every Kubernetes cluster. All the cluster
    management is provided by exposing this component’s API, and we can use different
    clients to interact with the cluster. Different endpoints allow us to retrieve
    and set Kubernetes resources.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-apiserver**：API 服务器是与所有其他组件和用户进行交互的组件。组件之间没有直接的通信，因此 kube-apiserver
    在每个 Kubernetes 集群中都是至关重要的。所有集群管理通过暴露该组件的 API 提供，我们可以使用不同的客户端与集群进行交互。不同的端点使我们能够检索和设置
    Kubernetes 资源。'
- en: '**etcd**: This is a component that provides data storage for all cluster components.
    It is a key-value store that can be consumed via its HTTP REST API. This reliable
    key-value store contains sensitive data, but, as mentioned before, only the kube-apiserver
    component can access it.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**etcd**：这是一个为所有集群组件提供数据存储的组件。它是一个键值存储，可以通过其HTTP REST API进行访问。这个可靠的键值存储包含敏感数据，但如前所述，只有kube-apiserver组件可以访问它。'
- en: '**kube-scheduler**: This is in charge of allocating workloads to the container
    runtimes deployed in the nodes. To decide which nodes will run the different containers,
    kube-scheduler will ask kube-apiserver for the hardware resources and availability
    of all nodes included in the cluster.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-scheduler**：负责将工作负载分配给节点上部署的容器运行时。为了决定哪些节点运行不同的容器，kube-scheduler会向kube-apiserver请求集群中所有节点的硬件资源和可用性信息。'
- en: '**kube-controller-manager**: Different controller processes run inside the
    Kubernetes cluster to maintain the status of the platform and the applications
    running inside. The kube-controller-manager is responsible for managing these
    controllers, and different tasks are delegated to each controller:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-controller-manager**：不同的控制器进程在Kubernetes集群内运行，负责维护平台和运行在其中的应用程序的状态。kube-controller-manager负责管理这些控制器，并将不同的任务委派给每个控制器：'
- en: The **node controller** manages nodes’ statuses
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点控制器**管理节点的状态。'
- en: The **job controller** is responsible for managing workloads’ tasks and creating
    Pods to run them
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**job控制器**负责管理工作负载的任务，并创建Pod来运行它们。'
- en: The **endpoint controller** creates endpoint resources to expose Pods
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端点控制器**创建端点资源以暴露Pod。'
- en: The **service account controller** and **token controller** manage accounts
    and API access token authorizations
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务账户控制器**和**令牌控制器**管理账户和API访问令牌授权。'
- en: '**cloud-controller-manager**: This is a separate component that manages different
    controllers that talk with underlying cloud providers’ APIs:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**cloud-controller-manager**：这是一个独立的组件，管理与底层云提供商API交互的不同控制器：'
- en: The **node controller** manages the state and health of nodes deployed in your
    cloud provider.
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点控制器**管理部署在云提供商上的节点的状态和健康状况。'
- en: The **route controller** creates routes in the cloud provider, using its specific
    API to access your deployed workloads.
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路由控制器**通过使用特定API在云提供商中创建路由，以访问你部署的工作负载。'
- en: The **service controller** manages cloud providers’ load balancer resources.
    You will never deploy this component in your own local data center because it
    is designed for cloud integrations.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务控制器**管理云提供商的负载均衡器资源。你不会在本地数据中心部署这个组件，因为它是为云集成设计的。'
- en: Next, let’s review **node components**, which are in charge of executing and
    giving visibility to the workload processes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们回顾一下**节点组件**，它们负责执行并展示工作负载进程。
- en: Understanding node components
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解节点组件。
- en: 'Node components run on worker nodes (as in Docker Swarm, manager nodes can
    also have the worker role). Let’s take a closer look at them:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 节点组件运行在工作节点上（如同在Docker Swarm中，管理节点也可以具有工作角色）。让我们深入了解一下它们：
- en: '**Container runtime**: The runtime for running containers is key, as it will
    execute all the workloads for us. The Kubernetes orchestrator schedules Pods on
    each host, and they run the containers for us.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器运行时**：运行容器的运行时是关键，因为它将为我们执行所有工作负载。Kubernetes调度器将在每个主机上调度Pod，它们为我们运行容器。'
- en: '**kubelet**: We can consider kubelet as the Kubernetes integration agent. All
    nodes with the worker role have to run kubelet in order to communicate with the
    control plane. In fact, the control plane will manage communications to receive
    the health of each worker node and the status of their running workloads. kubelet
    will only manage containers deployed in the Kubernetes cluster; in other words,
    you can still execute containers in the workers’ container runtime, but those
    containers will not be managed by Kubernetes.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kubelet**：我们可以将kubelet视为Kubernetes的集成代理。所有具有工作角色的节点都必须运行kubelet，以便与控制平面通信。事实上，控制平面将管理与工作节点的通信，以接收每个工作节点的健康状况和运行负载的状态。kubelet只会管理部署在Kubernetes集群中的容器；换句话说，你仍然可以在工作节点的容器运行时中执行容器，但这些容器不会由Kubernetes管理。'
- en: '**kube-proxy**: This component is responsible for Kubernetes communications.
    It is important to mention here that Kubernetes does not really provide full networking
    capabilities by itself, and this component will only manage the integration of
    Kubernetes Service resources within a cluster. Additional communications components
    will be required to have a fully functional cluster. It is fair to say that kube-proxy
    works at the worker-node level, publishing the applications within the cluster,
    but more components will be needed in order to reach other Services deployed in
    other cluster nodes.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-proxy**：这个组件负责 Kubernetes 的通信。需要在此提及的是，Kubernetes 本身并没有提供完整的网络功能，这个组件仅管理
    Kubernetes 集群内的服务资源集成。要实现一个完全功能的集群，还需要其他通信组件。可以公平地说，kube-proxy 在工作节点级别工作，发布集群内的应用程序，但为了访问部署在其他集群节点上的其他服务，还需要更多的组件。'
- en: Important note
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: A **Service resource** (or simply **Service**) is designed to make your applications’
    Pods accessible. Different options are available to publish our applications either
    internally or externally for users. Service resources will get their own IP address
    to access the associated Pods’ endpoints. We can consider Service resources as
    logical components. We will use Services to access our applications because Pods
    can die and be recreated, acquiring new IP addresses, but Services will remain
    visible with their specified IP address.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务资源**（或简称 **Service**）旨在使应用程序的 Pods 可访问。有多种选项可以将我们的应用程序发布到内部或外部供用户使用。服务资源将获得自己的
    IP 地址来访问相关 Pods 的端点。我们可以将服务资源视为逻辑组件。我们将使用服务来访问我们的应用程序，因为 Pods 可能会消失并被重新创建，获得新的
    IP 地址，但服务将始终保持可见，并具有指定的 IP 地址。'
- en: Worker nodes can be replaced when necessary; we can perform maintenance tasks
    whenever it’s required, moving workloads from one node to another. However, control
    plane components can’t be replaced. To achieve Kubernetes’ HA, we need to execute
    more than one replica of control plane components. In the case of etcd, we must
    have an odd number of replicas, which means that at least three are required for
    HA. This requirement leads us to a minimum of three manager nodes (or master nodes,
    in Kubernetes nomenclature) to deploy a Kubernetes cluster with HA, although other
    components will provide HA with only two replicas. Conversely, the number of worker
    nodes may vary. This really depends on your application’s HA, although a minimum
    of two workers is always recommended.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要时，工作节点可以被替换；我们可以在需要时执行维护任务，将工作负载从一个节点移动到另一个节点。然而，控制平面组件不能被替换。为了实现 Kubernetes
    的高可用性（HA），我们需要执行多个控制平面组件的副本。在 etcd 的情况下，我们必须拥有奇数个副本，这意味着至少需要三个副本才能实现 HA。这个要求使我们需要至少三个管理节点（或
    Kubernetes 术语中的主节点）来部署具有 HA 的 Kubernetes 集群，尽管其他组件可以通过两个副本提供 HA。相反，工作节点的数量可以变化，这真的取决于你应用程序的
    HA，尽管始终推荐至少两个工作节点。
- en: Networking in Kubernetes
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 网络
- en: 'It is important to remember that Kubernetes networking differs from the Docker
    Swarm model. By itself, Kubernetes does not provide cluster-wide communications,
    but a standardized interface, the **Container Network Interface** (**CNI**), is
    provided. Kubernetes defines a set of rules that any project integrating a communications
    interface must follow:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，Kubernetes 的网络架构与 Docker Swarm 模型有所不同。Kubernetes 本身并不提供集群范围的通信，但提供了一个标准化接口，即
    **容器网络接口**（**CNI**）。Kubernetes 定义了一组规则，任何集成通信接口的项目都必须遵循这些规则：
- en: '`localhost` to resolve their internal communications. This really simplifies
    communications when multiple containers need to work together.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `localhost` 来解决它们的内部通信问题。当多个容器需要协同工作时，这确实简化了通信。
- en: '**Host-to-container communications**: Each host can communicate with Pods running
    locally using its container runtime.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主机到容器通信**：每个主机可以使用其容器运行时与本地运行的 Pods 进行通信。'
- en: '**Pod-to-Pod communications**: These communications will work locally but not
    cluster-wide, and Kubernetes imposes that communications must be provided without
    any **network address translation** (**NAT**). This is something the CNI must
    resolve.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod到Pod通信**：这些通信在本地工作，但无法跨集群工作，Kubernetes 强制要求通信必须在没有任何 **网络地址转换**（**NAT**）的情况下进行。这是
    CNI 必须解决的问题。'
- en: '**Pod-to-Service interactions**: Pods will never consume other Pods as their
    IP address can change over time. We will use Services to expose Pods, and Kubernetes
    will manage their IP addresses, but the CNI must manage them cluster-wide.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod 到 Service 的交互**：Pod 永远不会相互通信，因为它们的 IP 地址可能会随着时间变化。我们将使用 Services 来暴露
    Pods，而 Kubernetes 会管理它们的 IP 地址，但 CNI 必须在集群范围内管理它们。'
- en: '**Publishing Services**: Different approaches exist to publish our applications,
    but they are resolved by Service types and Ingress resources, and cluster-wide
    communications must be included in the CNI.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布服务**：发布应用程序有多种方法，但它们通过 Service 类型和 Ingress 资源来解决，集群范围的通信必须包含在 CNI 中。'
- en: Because NAT isn’t allowed, this model declares a flat network, where Pods can
    see each other when the CNI is included in the Kubernetes deployment. This is
    completely different from Docker Swarm, where applications or projects can run
    in isolated networks. In Kubernetes, we need to implement additional mechanisms
    to isolate our applications.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于不允许使用 NAT，这种模型声明了一个平面网络，在 Kubernetes 部署中包含 CNI 后，Pods 可以彼此看到。这与 Docker Swarm
    完全不同，在 Docker Swarm 中，应用程序或项目可以运行在隔离的网络中。在 Kubernetes 中，我们需要实现额外的机制来隔离我们的应用程序。
- en: 'There are a lot of CNI plugins available to implement these cluster-wide communications.
    You can use any of them, but some are more popular than others; the following
    list shows recommended ones with some of their key features:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多 CNI 插件可用于实现这些集群范围的通信。你可以使用任何一个，但有些比其他的更受欢迎；以下列表显示了推荐的一些插件及其关键特性：
- en: '**Flannel** is a simple overlay network provider that works very well out of
    the box. It creates a VXLAN between nodes to propagate the Pods’ IP address cluster-wide,
    but it doesn’t provide network policies. These are Kubernetes resources that can
    drop or allow Pods’ connectivity.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Flannel** 是一个简单的覆盖网络提供者，开箱即用效果非常好。它在节点之间创建 VXLAN 来传播 Pods 的 IP 地址到集群范围，但它不提供网络策略。这些是
    Kubernetes 资源，可以限制或允许 Pods 的连接性。'
- en: '**Calico** is a network plugin that supports different network configurations,
    including non-overlay and overlay networks, with or without **Border Gateway Protocol**
    (**BGP**). This plugin provides network policies, and it’s adequate for almost
    all small environments.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Calico** 是一个网络插件，支持不同的网络配置，包括非覆盖网络和覆盖网络，可以使用或不使用 **边界网关协议**（**BGP**）。该插件提供网络策略，并且足以满足几乎所有小型环境的需求。'
- en: '**Canal** is used by default in SUSE’s Rancher environments. It combines Flannel’s
    simplicity and Calico’s policy features.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Canal** 默认在 SUSE 的 Rancher 环境中使用。它结合了 Flannel 的简单性和 Calico 的策略功能。'
- en: '**Cilium** is a very interesting network plugin because it integrates **extended
    Berkeley Packet Filter** (**eBPF**) Linux kernel features in Kubernetes. This
    network provider is intended for multi-cluster environments or when you want to
    integrate network observability into your platform.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cilium** 是一个非常有趣的网络插件，因为它将 **扩展伯克利数据包过滤器**（**eBPF**）Linux 内核特性集成到 Kubernetes
    中。这个网络提供商适用于多集群环境，或者当你想将网络可观察性集成到你的平台时。'
- en: '**Multus** can be used to deploy multiple CNI plugins in your cluster.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Multus** 可用于在你的集群中部署多个 CNI 插件。'
- en: Cloud providers offer their own cloud-specific CNIs that allow us to implement
    different network scenarios and manage Pods’ IP addresses within our own private
    cloud infrastructure.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云服务提供商提供了他们自己的云特定的 CNI，使我们能够实现不同的网络场景，并在我们自己的私有云基础设施中管理 Pods 的 IP 地址。
- en: The CNI plugin should always be deployed once the Kubernetes control plane has
    started because some components, such as the internal DNS or kube-apiserver, need
    to be reachable cluster-wide.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: CNI 插件应该在 Kubernetes 控制平面启动后始终部署，因为一些组件（如内部 DNS 或 kube-apiserver）需要在集群范围内可访问。
- en: Namespace scope isolation
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名空间范围隔离
- en: 'Kubernetes provides project or application isolation by using **namespaces**,
    which allow us to group resources. Kubernetes provides both cluster-scoped and
    namespace-scoped resources:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 通过使用 **命名空间** 提供项目或应用程序的隔离，命名空间允许我们对资源进行分组。Kubernetes 提供了集群范围和命名空间范围的资源：
- en: '**Cluster-scoped** resources are resources available cluster-wide, and we can
    consider most of them as cluster management resources, owned by the cluster administrators.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群范围** 的资源是集群范围内可用的资源，我们可以将它们大多数视为集群管理资源，由集群管理员拥有。'
- en: '**Namespace-scoped** resources are those confined at the namespace level. Services
    and Pods, for example, are defined at the namespace level, while node resources
    are available cluster-wide.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命名空间范围** 的资源是那些仅限于命名空间级别的资源。例如，Services 和 Pods 是在命名空间级别定义的，而节点资源则是集群范围可用的。'
- en: Namespace resources are key to isolating applications and restricting users
    from accessing resources. Kubernetes provides different authentication and authorization
    methods, although we can integrate and combine additional components such as an
    external **Lightweight Directory Access Protocol** (**LDAP**) or Microsoft Active
    Directory.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间资源是隔离应用程序并限制用户访问资源的关键。Kubernetes提供不同的认证和授权方法，虽然我们可以集成和结合额外的组件，如外部**轻量级目录访问协议**（**LDAP**）或微软的Active
    Directory。
- en: Internal resolution
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内部解析
- en: The internal DNS is based on the `SERVICE_NAME.NAMESPACE.svc.cluster.local`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 内部DNS基于`SERVICE_NAME.NAMESPACE.svc.cluster.local`。
- en: Attaching data to containers
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将数据附加到容器
- en: 'Kubernetes includes different resource types to attach storage to our workloads:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes包含不同类型的资源来将存储附加到我们的工作负载：
- en: '`emptyDir`), host storage, and **Network File System** (**NFS**), among other
    remote storage solutions. Other very important volume-like resources are Secrets
    and ConfigMaps, which can be used to manage sensitive data and configurations
    cluster-wide, respectively.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`emptyDir`）、主机存储和**网络文件系统**（**NFS**），以及其他远程存储解决方案。其他非常重要的类卷资源包括Secrets和ConfigMaps，分别可用于管理集群范围内的敏感数据和配置。'
- en: '**Persistent volumes** are the preferred solution when you work on production
    in a local data center. Storage vendors provide their own drivers to integrate
    **network-attached storage** (**NAS**) and **storage area network** (**SAN**)
    solutions in our applications.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持久卷**是当你在本地数据中心进行生产工作时的首选解决方案。存储供应商提供自己的驱动程序，将**网络附加存储**（**NAS**）和**存储区域网络**（**SAN**）解决方案集成到我们的应用程序中。'
- en: '**Projected volumes** are used to map several volumes inside a unique Pod container’s
    directory.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投影卷**用于映射一个独特Pod容器目录中的多个卷。'
- en: Providing persistent storage to our applications is key in container orchestrators,
    and Kubernetes integrates very well with different dynamic provisioning solutions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为我们的应用程序提供持久存储是容器编排器中的关键，Kubernetes与不同的动态配置解决方案集成得非常好。
- en: Publishing applications
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发布应用程序
- en: Finally, we will introduce the concept of **Ingress** resources. These resources
    simplify and secure the publishing of applications running in Kubernetes by linking
    Service resources with specific applications’ URLs. An Ingress controller is required
    to manage these resources, and we can integrate into this component many different
    options, such as NGINX, Traefik, or even more complex solutions, such as Istio.
    It is also remarkable that many network device vendors have also prepared their
    own integrations with Kubernetes platforms, improving performance and security.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将介绍**Ingress**资源的概念。这些资源通过将服务资源与特定应用程序的URL关联起来，简化并保障了在Kubernetes中运行应用程序的发布。需要一个Ingress控制器来管理这些资源，我们可以在这个组件中集成多种不同的选项，如NGINX、Traefik，甚至更复杂的解决方案，如Istio。值得注意的是，许多网络设备供应商也准备了自己的Kubernetes平台集成，提升了性能和安全性。
- en: Now that we have been quickly introduced to Kubernetes, we can take a deep dive
    into the platform’s components and features.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经快速了解了Kubernetes，接下来可以深入探讨该平台的组件和功能。
- en: Understanding Kubernetes’ HA
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Kubernetes的高可用性（HA）
- en: Deploying our applications with HA requires a Kubernetes environment with HA.
    At least three replicas of etcd are required and two replicas of other control
    plane components. Some production architectures deploy etcd externally in dedicated
    hosts, while other components are deployed in additional master nodes. This isolates
    completely the key-value store from the rest of the control plane components,
    improving security, but it adds additional complexity to the environment. You
    will usually find three master nodes and enough worker nodes to deploy your production
    applications.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用HA部署我们的应用程序需要一个具有HA的Kubernetes环境。至少需要三个etcd副本和其他控制平面组件的两个副本。一些生产架构将etcd部署在专用主机上，而其他组件则部署在额外的主节点上。这完全隔离了键值存储与其余控制平面组件，提升了安全性，但也增加了环境的复杂性。通常，你会找到三个主节点和足够的工作节点来部署你的生产应用程序。
- en: 'A Kubernetes installation configures and manages its own internal **certificate
    authority** (**CA**) and then deploys certificates for the different control plane
    and kubelet components. This ensures TLS communications between kube-apiserver
    and other components. The following architecture diagram shows the different Kubernetes
    components in a single-master node scenario:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 安装配置并管理其自己的内部 **证书颁发机构** (**CA**)，然后为不同的控制平面和 kubelet 组件部署证书。这确保了
    kube-apiserver 与其他组件之间的 TLS 通信。下图展示了单主节点场景下的 Kubernetes 不同组件架构：
- en: '![Figure 8.1 – Kubernetes cluster architecture with HA](img/B19845_08_01.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 带有高可用性的 Kubernetes 集群架构](img/B19845_08_01.jpg)'
- en: Figure 8.1 – Kubernetes cluster architecture with HA
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 带有高可用性的 Kubernetes 集群架构
- en: Worker nodes are those designated to run workloads. Depending on the Kubernetes
    installation method, you will be able to run specific workloads on master nodes
    if they also run the kubelet and kube-proxy components. We can use different affinity
    and anti-affinity rules to identify which nodes should finally execute a container
    in your cluster.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点是用于运行工作负载的节点。根据 Kubernetes 的安装方式，如果主节点同时运行 kubelet 和 kube-proxy 组件，你也可以在主节点上运行特定的工作负载。我们可以使用不同的亲和性和反亲和性规则来确定哪些节点最终应该执行集群中的容器。
- en: However, simply replicating the control plane does not provide HA or resilience
    to your applications. You will need a CNI to manage communications between your
    containers cluster-wide. Internal load balancing will route requests to deployed
    Pods within your Kubernetes cluster.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅复制控制平面并不能为你的应用程序提供高可用性或弹性。你需要一个 CNI 来管理容器之间在集群范围内的通信。内部负载均衡将请求路由到 Kubernetes
    集群中已部署的 Pods。
- en: Running your applications on different hosts requires appropriate storage solutions.
    Whenever a container starts with a container runtime, the required volumes should
    be attached. If you work on-premises, you will probably use a **Container Storage
    Interface** (**CSI**) in your infrastructure. However, as a developer, you should
    consider your storage requirements, and your infrastructure administrators will
    provide you with the best solution. Different providers will present filesystems,
    blocks, or object storage, and you can choose which best fits your application.
    All of them will work cluster-wide and help you provide HA.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同的主机上运行应用程序需要合适的存储解决方案。每当容器使用容器运行时启动时，所需的卷应该被附加。如果你在本地部署，你可能会在你的基础设施中使用 **容器存储接口**
    (**CSI**)。然而，作为开发者，你应该考虑你的存储需求，你的基础设施管理员会为你提供最佳的解决方案。不同的提供商会提供文件系统、块存储或对象存储，你可以选择最适合你的应用程序的存储方案。所有这些都将在集群范围内工作，并帮助你提供高可用性。
- en: Finally, you have to think about how your application’s components work with
    multiple replicas. Your infrastructure provides resilience to your containers,
    but your application’s logic must support replication.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你必须考虑你的应用程序组件如何与多个副本一起工作。你的基础设施为容器提供了弹性，但你的应用程序逻辑必须支持复制。
- en: Running a production cluster can be hard, but deploying our own cluster to learn
    how Kubernetes works is a task that I really recommend to anyone who wants to
    deploy applications on these container architectures. Using **kubeadm** is recommended
    to create Kubernetes clusters for the first time.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 运行生产集群可能会很困难，但部署自己的集群来学习 Kubernetes 是如何工作的，我真的推荐给任何想在这些容器架构上部署应用程序的人。第一次创建 Kubernetes
    集群时，推荐使用 **kubeadm**。
- en: Kubeadm Kubernetes deployment
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubeadm Kubernetes 部署
- en: Kubeadm is a tool that can be used to easily deploy a fully functional Kubernetes
    cluster. In fact, we can even use it to deploy production-ready clusters.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeadm 是一个可以轻松部署完全功能的 Kubernetes 集群的工具。事实上，我们甚至可以使用它来部署生产就绪的集群。
- en: We will initialize a cluster from the first deployment node, executing `kubeadm
    init`. This will create and trigger the bootstrapping processes to deploy the
    cluster. The node in which we execute this action will become the cluster leader,
    and we will join new master and worker nodes by simply executing `kubeadm join`.
    This really simplifies the deployment process; every step required for creating
    the cluster is automated. First, we will create the control plane components;
    hence, `kubeadm join` will be executed in the rest of the designated master nodes.
    And once the master nodes are installed, we will join the worker nodes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从第一个部署节点初始化集群，执行 `kubeadm init`。这将创建并触发引导过程以部署集群。我们执行此操作的节点将成为集群的领导节点，我们只需执行
    `kubeadm join`，即可加入新的主节点和工作节点。这极大简化了部署过程；创建集群所需的每个步骤都是自动化的。首先，我们将创建控制平面组件；因此，`kubeadm
    join` 将在其余指定的主节点上执行。一旦主节点安装完成，我们将加入工作节点。
- en: Kubeadm is installed as a binary in your operating system. It is important to
    note here that the Kubernetes master role is only available on Linux operating
    systems. Therefore, we can’t install a Kubernetes cluster only with Microsoft
    Windows or macOS nodes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeadm 作为一个二进制文件安装在你的操作系统中。这里需要特别注意的是，Kubernetes 的主节点角色仅在 Linux 操作系统上可用。因此，我们不能仅通过
    Microsoft Windows 或 macOS 节点来安装 Kubernetes 集群。
- en: This tool does not only install a new cluster. It can be used to modify current
    kubeadm-deployed cluster configurations or upgrade them to a newer release. It
    is a very powerful tool, and it is good to know how to use it, but unfortunately,
    it is out of the scope of this book. Suffice it to say that there are many command-line
    arguments that will help us to fully customize Kubernetes deployment, such as
    the IP address to be used to manage communications within the control plane, the
    Pods’ IP address range, and the authentication and authorization model to use.
    If you have time and hardware resources, it is recommended to create at least
    a two-node cluster with kubeadm to understand the deployment process and the components
    deployed by default on a Kubernetes cluster.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具不仅仅是安装一个新的集群。它还可以用来修改当前 kubeadm 部署的集群配置或将其升级到更新的版本。这是一个非常强大的工具，了解如何使用它是很有帮助的，但不幸的是，这超出了本书的范围。可以简要地说，有许多命令行参数可以帮助我们完全定制
    Kubernetes 的部署，例如用于管理控制平面内部通信的 IP 地址、Pods 的 IP 地址范围以及要使用的认证和授权模型。如果你有时间和硬件资源，建议使用
    kubeadm 创建一个至少两节点的集群，以便了解部署过程和 Kubernetes 集群上默认部署的组件。
- en: 'Here is the link for a Kubernetes deployment process with the kubeadm tool:
    [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm).
    We will not use kubeadm to deploy Kubernetes in this book. We will use Docker
    Desktop, Rancher Desktop, or Minikube tools, which provide fully automated deployments
    that work out of the box on our laptop or desktop computers.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 kubeadm 工具进行 Kubernetes 部署过程的链接：[https://kubernetes.io/docs/setup/production-environment/tools/kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm)。在本书中，我们不会使用
    kubeadm 来部署 Kubernetes。我们将使用 Docker Desktop、Rancher Desktop 或 Minikube 工具，它们提供完全自动化的部署，能够即刻在我们的笔记本电脑或台式电脑上工作。
- en: Docker or any other container runtime just cares about containers. We learned
    in [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147), *Orchestrating with Swarm*,
    how Docker provides the command line to manage Docker Swarm clusters, but this
    doesn’t work with Kubernetes, as it is a completely different platform. The kube-apiserver
    component is the only component accessible to administrators and end users. The
    Kubernetes community project provides its own tool to manage Kubernetes clusters
    and the resources deployed on them. Thus, in the next subsection, we will learn
    the basics of `kubectl`, the tool that we will use in a lot of examples in this
    book to manage configurations, content, and workloads on clusters.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 或任何其他容器运行时只关心容器。我们在[*第7章*](B19845_07.xhtml#_idTextAnchor147)，*使用 Swarm
    进行编排* 中学到了 Docker 如何提供命令行来管理 Docker Swarm 集群，但这在 Kubernetes 中不起作用，因为它是一个完全不同的平台。kube-apiserver
    组件是管理员和最终用户唯一可以访问的组件。Kubernetes 社区项目提供了自己的工具来管理 Kubernetes 集群及其上部署的资源。因此，在下一小节中，我们将学习
    `kubectl` 的基础知识，这是我们在本书中将用来管理集群中的配置、内容和工作负载的工具。
- en: Interacting with Kubernetes using kubectl
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 kubectl 与 Kubernetes 交互
- en: In this section, we will learn the basics of the `kubectl` command line. It
    is the official Kubernetes client, and its features can be extended by adding
    plugins.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习`kubectl`命令行的基础知识。它是官方的Kubernetes客户端，可以通过添加插件扩展其功能。
- en: 'The installation process for this tool is quite simple, as it is a single binary
    written in the Go language; therefore, we can download it from the official Kubernetes
    binaries repository. To download from this repository, you must include the release
    to use in the URL. For example, [https://dl.k8s.io/release/v1.27.4/bin/linux/amd64/kubectl](https://dl.k8s.io/release/v1.27.4/bin/linux/amd64/kubectl)
    will link you to the `kubectl` Linux binary for Kubernetes 1.27.4\. You will be
    able to manage Kubernetes clusters using binaries from a different release, although
    it is recommended to maintain alignment with your client and Kubernetes server
    releases. How to install the tool for each platform is described in https://kubernetes.io/docs/tasks/tools/#kubectl.
    As we will use Microsoft Windows in the *Labs* section, we will use the following
    link to install the tool’s binary: [https://kubernetes.io/docs/tasks/tools/install-kubectl-windows](https://kubernetes.io/docs/tasks/tools/install-kubectl-windows).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具的安装过程相当简单，因为它是一个用Go语言编写的单一二进制文件；因此，我们可以从官方Kubernetes二进制文件库下载它。要从此库下载，必须在URL中包含要使用的发布版本。例如，[https://dl.k8s.io/release/v1.27.4/bin/linux/amd64/kubectl](https://dl.k8s.io/release/v1.27.4/bin/linux/amd64/kubectl)
    将链接到Kubernetes 1.27.4的`kubectl` Linux二进制文件。你可以使用来自不同发布版本的二进制文件来管理Kubernetes集群，尽管建议保持客户端和Kubernetes服务器版本的一致性。如何为每个平台安装该工具，请参见https://kubernetes.io/docs/tasks/tools/#kubectl。由于我们将在*实验室*部分使用Microsoft
    Windows，我们将使用以下链接来安装该工具的二进制文件：[https://kubernetes.io/docs/tasks/tools/install-kubectl-windows](https://kubernetes.io/docs/tasks/tools/install-kubectl-windows)。
- en: 'Let’s start with `kubectl` by learning the syntax for executing commands with
    this tool:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过学习使用此工具执行命令的语法来开始`kubectl`：
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`TYPE` indicates that `kubectl` can be used with many different Kubernetes
    resources. We can use the singular, plural, or abbreviated forms, and we will
    use them in case-insensitive format.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`TYPE`表示`kubectl`可以与许多不同的Kubernetes资源一起使用。我们可以使用单数、复数或缩写形式，且它们将以不区分大小写的方式使用。'
- en: The first thing to know before learning some of the uses of `kubectl` is how
    to configure access to any cluster. The `kubectl` command uses, by default, a
    `config` configuration file in the home of each user, under the `.kube` directory.
    We can change which configuration file to use by adding the `--kubeconfig <FILE_PATH_AND_NAME>`
    argument or setting the `KUBECONFIG` variable with the configuration file location.
    By changing the content of the `kubeconfig` file, we can easily have different
    cluster configurations. However, this path change is not really needed because
    the configuration file structure allows different contexts. Each context is used
    to uniquely configure a set of user and server values, allowing us to configure
    a context with our authentication and a Kubernetes cluster endpoint.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习`kubectl`的一些用法之前，首先要了解的是如何配置访问任何集群。默认情况下，`kubectl`命令使用每个用户主目录下`.kube`目录中的`config`配置文件。我们可以通过添加`--kubeconfig
    <FILE_PATH_AND_NAME>`参数或设置`KUBECONFIG`变量来改变使用的配置文件位置。通过更改`kubeconfig`文件的内容，我们可以轻松地拥有不同的集群配置。然而，这种路径更改实际上并不必要，因为配置文件结构允许不同的上下文。每个上下文用于唯一地配置一组用户和服务器值，允许我们配置一个包含身份验证信息和Kubernetes集群端点的上下文。
- en: Important note
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You will usually access a Kubernetes cluster using an FQDN (or its resolved
    IP address). This name or its IP address will be load-balanced to all Kubernetes
    clusters’ available instances of kube-apiserver; hence, a load balancer will be
    set in front of your cluster servers. In our local environments, we will use a
    simple IP address associated with our cluster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会通过FQDN（或其解析后的IP地址）访问Kubernetes集群。这个名称或其IP地址将被负载均衡到所有Kubernetes集群的可用kube-apiserver实例；因此，集群服务器前会设置负载均衡器。在我们的本地环境中，我们将使用与集群关联的简单IP地址。
- en: 'Let’s see what a configuration file looks like:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下配置文件的样子：
- en: '[PRE1]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We can add multiple servers and users and link them in multiple contexts. We
    can switch between defined contexts by using `kubectl config` `use-context CONTEXT_NAME`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以添加多个服务器和用户，并将它们链接到多个上下文中。我们可以通过使用`kubectl config` `use-context CONTEXT_NAME`在定义的上下文之间切换。
- en: 'We can use `kubectl api-resources` to retrieve the type of resources available
    in the defined cluster. This is important because the `kubectl` command line retrieves
    data from a Kubernetes cluster; hence, its behavior changes depending on the endpoint.
    The following screenshot shows the API resources available in a sample Kubernetes
    cluster:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `kubectl api-resources` 来获取定义集群中可用的资源类型。这很重要，因为 `kubectl` 命令行从 Kubernetes
    集群中检索数据，因此它的行为会根据终端点的不同而发生变化。以下截图展示了样本 Kubernetes 集群中的 API 资源：
- en: '![Figure 8.2 – Kubernetes API resources in a sample cluster](img/B19845_08_02.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – 样本集群中的 Kubernetes API 资源](img/B19845_08_02.jpg)'
- en: Figure 8.2 – Kubernetes API resources in a sample cluster
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 样本集群中的 Kubernetes API 资源
- en: As you can see, there is a column that indicates whether a Kubernetes resource
    is namespaced or not. This shows the scope where the resource must be defined.
    Resources can have a cluster scope, be defined and used at the cluster level,
    or be namespace-scoped, in which case they exist grouped inside a Kubernetes namespace.
    Kubernetes namespaces are resources that allow us to isolate and group resources
    within a cluster. The resources defined inside a namespace are unique within the
    namespace, as we will use the namespaces to identify them.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，有一列表示 Kubernetes 资源是否是命名空间限定的。这显示了资源必须定义的范围。资源可以具有集群范围，定义并在集群级别使用，也可以是命名空间限定的，在这种情况下，它们存在于
    Kubernetes 命名空间内并按命名空间分组。Kubernetes 命名空间是允许我们在集群内隔离和分组资源的资源。定义在命名空间内的资源在命名空间内是唯一的，因为我们将使用命名空间来标识它们。
- en: 'There are many commands available for `kubectl`, but we will focus in this
    section on just a few of them:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多 `kubectl` 命令可用，但在本节中我们将重点介绍其中的一些命令：
- en: '`create`: This action allows us to create Kubernetes resources from a file
    or our terminal `stdin`.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create`：此操作允许我们从文件或终端 `stdin` 创建 Kubernetes 资源。'
- en: '`apply`: This creates and updates resources in Kubernetes.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apply`：此操作用于创建和更新 Kubernetes 中的资源。'
- en: '`delete`: We can remove already created resources using `kubectl delete`.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delete`：我们可以使用 `kubectl delete` 删除已创建的资源。'
- en: '`run`: This action can be used to quickly deploy a simple workload and define
    a container image.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`run`：此操作可用于快速部署简单的工作负载并定义容器镜像。'
- en: '`get`: We can retrieve any Kubernetes resource definition by using `kubectl
    get`. A valid authorization is required to either create or retrieve any Kubernetes
    object. We can also use `kubectl describe`, which gives a detailed description
    of the cluster resource retrieved.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get`：我们可以使用 `kubectl get` 获取任何 Kubernetes 资源的定义。创建或检索任何 Kubernetes 对象需要有效的授权。我们还可以使用
    `kubectl describe`，它会提供被检索集群资源的详细描述。'
- en: '`edit`: We can modify some resources’ properties in order to change them within
    the cluster. This will also modify our applications’ behavior.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`edit`：我们可以修改一些资源的属性，以便在集群中进行更改。这也会改变我们应用程序的行为。'
- en: 'We can configure Kubernetes resources by using an **imperative** or **declarative**
    method:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过**命令式**或**声明式**方法配置 Kubernetes 资源：
- en: In an imperative configuration, we describe the configuration of the Kubernetes
    resource in the command line, using our terminal.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在命令式配置中，我们通过命令行描述 Kubernetes 资源的配置，使用我们的终端进行操作。
- en: By using a declarative configuration, we will create a file describing the configuration
    of a resource, and then we create or apply the content of the file to the Kubernetes
    cluster. This method is reproducible.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用声明式配置，我们将创建一个描述资源配置的文件，然后将该文件的内容创建或应用到 Kubernetes 集群中。这种方法是可重复的。
- en: Now that we have a basic idea of Kubernetes components, the installation process,
    how to interact with a cluster, and the requirements to run a functional Kubernetes
    platform, let’s see how to easily deploy our own environment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 Kubernetes 组件、安装过程、如何与集群交互以及运行功能性 Kubernetes 平台的要求有了基本的了解，接下来让我们看看如何轻松部署我们自己的环境。
- en: Deploying a functional Kubernetes cluster
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署一个功能性的 Kubernetes 集群
- en: In this section, we will review different methods to deploy Kubernetes for different
    purposes. As a developer, you do not need to deploy a production environment,
    but it’s important to understand the process and be able to create a minimal environment
    to test your applications. If you are really interested in the full process, it’s
    recommended to take a look at Kelsey Hightower’s GitHub repository, *Kubernetes
    the Hard Way* (https://github.com/kelseyhightower/kubernetes-the-hard-way). In
    this repository, you will find a step-by-step complete process to deploy manually
    a Kubernetes cluster. Understanding how a cluster is created really helps solve
    problems, although it’s out of the scope of this book. Here, we will review automated
    Kubernetes solutions in which you can focus on your code and not on the platform
    itself. We will start this section with the most popular container desktop solution.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾不同的 Kubernetes 部署方法，以满足不同的需求。作为开发者，你不需要部署生产环境，但理解这个过程并能够创建一个最简环境来测试你的应用程序是非常重要的。如果你真的对整个过程感兴趣，建议你查看
    Kelsey Hightower 的 GitHub 仓库，*Kubernetes the Hard Way*（https://github.com/kelseyhightower/kubernetes-the-hard-way）。在这个仓库中，你将找到逐步手动部署
    Kubernetes 集群的完整过程。理解集群是如何创建的，真的有助于解决问题，尽管这超出了本书的范围。在这里，我们将回顾一些自动化的 Kubernetes
    解决方案，你可以专注于代码而非平台本身。我们将从最流行的容器桌面解决方案开始这一节。
- en: Docker Desktop
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker Desktop
- en: 'We have used Docker Desktop in this book to create and run containers using
    a **Windows Subsystem for Linux** (**WSL**) terminal. Docker Desktop also includes
    a one-node Kubernetes environment. Let’s start using this by following these steps:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们使用 Docker Desktop 创建并运行容器，使用的是 **Windows Subsystem for Linux**（**WSL**）终端。Docker
    Desktop 还包含一个单节点的 Kubernetes 环境。让我们通过以下步骤开始使用它：
- en: 'Click **Settings** | **Enable Kubernetes**. The following screenshot shows
    how Kubernetes can be set up in your Docker Desktop environment:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **设置** | **启用 Kubernetes**。下图显示了如何在 Docker Desktop 环境中设置 Kubernetes：
- en: '![Figure 8.3 – The Docker Desktop Settings area where a Kubernetes cluster
    can be enabled](img/B19845_08_03.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – Docker Desktop 设置区域，可以启用 Kubernetes 集群](img/B19845_08_03.jpg)'
- en: Figure 8.3 – The Docker Desktop Settings area where a Kubernetes cluster can
    be enabled
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – Docker Desktop 设置区域，可以启用 Kubernetes 集群
- en: 'After the Kubernetes cluster is enabled, Docker Desktop starts the environment.
    The following screenshot shows the moment when Kubernetes starts:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在启用 Kubernetes 集群后，Docker Desktop 启动环境。下图显示了 Kubernetes 启动的时刻：
- en: '![Figure 8.4 – Kubernetes starting in the Docker Desktop environment](img/B19845_08_04.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – Kubernetes 在 Docker Desktop 环境中的启动](img/B19845_08_04.jpg)'
- en: Figure 8.4 – Kubernetes starting in the Docker Desktop environment
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – Kubernetes 在 Docker Desktop 环境中的启动
- en: Once started, we can access the cluster from our WSL terminal by using the `kubectl`
    command line. As you may have noticed, we haven’t installed any additional software.
    Docker Desktop integrates the commands for us by attaching the required files
    to our WSL environment.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦启动，我们可以通过 WSL 终端使用 `kubectl` 命令行来访问集群。正如你可能注意到的，我们没有安装任何额外的软件。Docker Desktop
    通过将所需的文件附加到我们的 WSL 环境中，为我们集成了命令。
- en: 'The status of the Kubernetes cluster is shown in the lower-left side of the
    Docker Desktop GUI, as we can see in the following screenshot:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Kubernetes 集群的状态显示在 Docker Desktop GUI 的左下角，如下图所示：
- en: '![ Figure 8.5 – Kubernetes’ status shown in Docker Desktop](img/B19845_08_05.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – Kubernetes 状态在 Docker Desktop 中显示](img/B19845_08_05.jpg)'
- en: Figure 8.5 – Kubernetes’ status shown in Docker Desktop
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – Kubernetes 状态在 Docker Desktop 中显示
- en: 'We can verify the number of nodes included in the deployed Kubernetes cluster
    by executing `kubectl` `get nodes`:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过执行 `kubectl` `get nodes` 来验证部署的 Kubernetes 集群中包含的节点数量：
- en: '[PRE2]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Notice that a Kubernetes configuration file was also added for this environment:'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，为此环境还添加了一个 Kubernetes 配置文件：
- en: '[PRE3]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: That was quite easy, and now we have a fully functional Kubernetes cluster.
    This cluster isn’t configurable, but it is all you need to prepare your applications’
    deployments and test them. This solution doesn’t allow us to decide which Kubernetes
    version to deploy, but we can reset the environment at any time from the Docker
    Desktop Kubernetes **Settings** page, which is very useful when we need to start
    the environment afresh. It can be deployed on either Microsoft Windows (using
    a **virtual machine** (**VM**) with Hyper-V or WSL, which is recommended as it
    consumes fewer resources), macOS (on Intel and Apple silicon architectures), or
    Linux (using a VM with **Kernel-Based Virtual** **Machine** (**KVM**)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常简单，现在我们有一个功能完备的 Kubernetes 集群。这个集群不可配置，但它是你准备应用部署和进行测试所需的一切。这个解决方案不允许我们决定要部署哪个版本的
    Kubernetes，但我们可以随时通过 Docker Desktop 的 Kubernetes **设置** 页面重置环境，这在我们需要从头开始时非常有用。它可以部署在
    Microsoft Windows（使用 **虚拟机**（**VM**）和 Hyper-V 或 WSL，推荐使用 WSL，因为它消耗的资源更少）、macOS（支持
    Intel 和 Apple Silicon 架构）或 Linux（使用带 **内核虚拟机**（**KVM**）的虚拟机）上。
- en: 'Docker prepares some images with all Kubernetes components and deploys them
    for us when we enable Kubernetes in Docker Desktop. By default, all containers
    created for such a purpose are hidden in the Docker Desktop GUI, but we can review
    them from the Docker command line. This Kubernetes solution is really suitable
    if you use the Docker command line to create your applications because everything
    necessary, from building to orchestrated execution, is provided. We can use different
    Kubernetes volume types because a `storageClass` resources in [*Chapter 10*](B19845_10.xhtml#_idTextAnchor231),
    *Leveraging Application Data Management* *in Kubernetes*. However, a few things
    are omitted in this Kubernetes deployment, which may impact your work, so it’s
    good to understand its limitations:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 为我们准备了一些包含所有 Kubernetes 组件的镜像，并在我们启用 Docker Desktop 中的 Kubernetes 时为我们部署它们。默认情况下，所有为此目的创建的容器都在
    Docker Desktop GUI 中隐藏，但我们可以通过 Docker 命令行查看它们。如果你使用 Docker 命令行创建应用程序，这种 Kubernetes
    解决方案非常合适，因为从构建到协调执行所需的一切都已提供。我们可以使用不同类型的 Kubernetes 卷，因为在[*第 10 章*](B19845_10.xhtml#_idTextAnchor231)，*在
    Kubernetes 中利用应用数据管理*中，有 `storageClass` 资源。不过，在此 Kubernetes 部署中省略了一些内容，这可能会影响你的工作，因此了解它的局限性是很有帮助的：
- en: Environment internal IP addresses can’t be changed.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境内部的 IP 地址不能更改。
- en: You cannot ping containers; this is due to the network settings of Docker Desktop,
    and it also affects the container runtime.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你无法 ping 容器；这是由于 Docker Desktop 的网络设置，且它也会影响容器的运行时。
- en: No CNI is provided; hence, no network policies can be applied.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不提供 CNI；因此，无法应用网络策略。
- en: No Ingress resource is provided by default. This is not really an issue because
    other desktop Kubernetes environments wouldn’t provide it either, but you may
    need to deploy your own and modify your `/etc/hosts` file (or Microsoft Windows’s
    equivalent `C:\Windows\system32\drivers\etc\hosts` file) to access your applications.
    We will learn about Ingress resources and controllers in [*Chapter 11*](B19845_11.xhtml#_idTextAnchor244),
    *Publishing Applications*.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下未提供 Ingress 资源。其实这并不是问题，因为其他桌面 Kubernetes 环境也不会提供它，但你可能需要部署自己的 Ingress，并修改你的
    `/etc/hosts` 文件（或 Microsoft Windows 中的等效文件 `C:\Windows\system32\drivers\etc\hosts`）以访问你的应用程序。在[*第
    11 章*](B19845_11.xhtml#_idTextAnchor244)，*发布应用程序* 中，我们将了解 Ingress 资源和控制器。
- en: These are the more important issues you will find by using Docker Desktop for
    Kubernetes deployment. It is important to understand that performance will be
    impacted when you enable Kubernetes, and you will need at least 4 GB of RAM free
    and four **virtual** **cores** (**vCores**).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在使用 Docker Desktop 部署 Kubernetes 时你会遇到的较重要问题。启用 Kubernetes 后，性能会受到影响，且你需要至少
    4 GB 的空闲内存和四个 **虚拟** **核心**（**vCores**）。
- en: As specified in the official documentation, Docker Desktop is not an open source
    project, and it is licensed under the *Docker Subscription Service Agreement*.
    This means that it is free for small businesses (that is, fewer than 250 employees
    and less than $10 million in annual revenue), personal use, education, and non-commercial
    open source projects; otherwise, it requires a paid subscription for professional
    use.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如官方文档所述，Docker Desktop 不是一个开源项目，它的授权基于 *Docker 订阅服务协议*。这意味着对于小型企业（即员工少于 250
    人且年收入低于 1000 万美元）、个人使用、教育和非商业性开源项目，它是免费的；否则，对于专业用途，则需要付费订阅。
- en: We will now review another desktop solution to deploy a simplified Kubernetes
    environment.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将回顾另一种桌面解决方案，用于部署简化的 Kubernetes 环境。
- en: Rancher Desktop
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Rancher Desktop
- en: 'This solution comes from SUSE, and it really provides you with the Kubernetes
    Rancher deployment experience on your laptop or desktop computer. Rancher Desktop
    can be installed on Windows systems, using WSL or VMs, or macOS and Linux, using
    only VMs. It is an open source project and includes Moby components, `containerd`,
    and other components that leverage the experience of Rancher, allowing the development
    of new and different projects such as **RancherOS** (a container-oriented operating
    system) or **K3s** (a lightweight certified Kubernetes distribution). There are
    some interesting features on Rancher Desktop:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案来自 SUSE，它确实为你提供了在笔记本电脑或台式计算机上体验 Kubernetes Rancher 部署的体验。Rancher Desktop
    可以在 Windows 系统上安装，使用 WSL 或虚拟机，或在 macOS 和 Linux 上，仅使用虚拟机。它是一个开源项目，包含了 Moby 组件、`containerd`
    以及其他借助 Rancher 经验的组件，允许开发新的不同项目，比如**RancherOS**（一个容器导向的操作系统）或**K3s**（一个轻量级的认证
    Kubernetes 发行版）。Rancher Desktop 具有一些有趣的功能：
- en: We can choose which container runtime to use for the environment. This is a
    key difference and makes it important to test your applications using `containerd`
    directly.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以选择为环境使用哪种容器运行时。这是一个关键区别，使得使用 `containerd` 直接测试你的应用程序变得非常重要。
- en: We can set the Kubernetes version to deploy.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以设置要部署的 Kubernetes 版本。
- en: It is possible to define the resources used for the VM (on Mac and Linux).
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以定义用于虚拟机的资源（在 Mac 和 Linux 上）。
- en: It provides the Rancher Dashboard, which combines perfectly with your infrastructure
    when your server’s environments also run Kubernetes and Rancher.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了 Rancher 控制面板，当你的服务器环境也运行 Kubernetes 和 Rancher 时，它与基础设施完美结合。
- en: 'The following screenshot shows how can we set up a Kubernetes release from
    the Rancher Desktop GUI, in the **Preferences** area. This way, we will be able
    to test our applications using different API releases, which may be very interesting
    before moving our applications to the staging or production stages. Each Kubernetes
    release provides its own set of API resources; you should read each release note
    to find out changes in the API versions and resources that may affect your project
    – for example, if some *beta* resources are now included in the release, or some
    are deprecated. The following screenshot shows the Kubernetes releases available
    for deploying in Rancher Desktop:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了我们如何在 Rancher Desktop GUI 中的**偏好设置**区域设置 Kubernetes 发布。通过这种方式，我们可以使用不同的
    API 发布测试我们的应用程序，这在将应用程序移动到预发布或生产阶段之前非常有趣。每个 Kubernetes 发布都提供了自己的 API 资源集；你应该阅读每个发布说明，以了解
    API 版本和资源的变化，这些变化可能会影响你的项目——例如，某些*beta*资源现在可能已包含在发布中，或某些资源已被弃用。以下截图展示了可以在 Rancher
    Desktop 中部署的 Kubernetes 发布：
- en: '![Figure 8.6 – Different Kubernetes releases can be chosen](img/B19845_08_06.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 可以选择不同的 Kubernetes 发布](img/B19845_08_06.jpg)'
- en: Figure 8.6 – Different Kubernetes releases can be chosen
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 可以选择不同的 Kubernetes 发布
- en: 'As we have seen in Docker Desktop, Rancher Desktop also provides a simple button
    to completely reset the Kubernetes cluster. The following screenshot shows the
    **Troubleshooting** area, where we can reset the cluster:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 Docker Desktop 中看到的，Rancher Desktop 也提供了一个简单的按钮来完全重置 Kubernetes 集群。以下截图展示了**故障排除**区域，在这里我们可以重置集群：
- en: '![Figure 8.7 – The Troubleshooting area from the Rancher Desktop GUI](img/B19845_08_07.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – Rancher Desktop GUI 中的故障排除区域](img/B19845_08_07.jpg)'
- en: Figure 8.7 – The Troubleshooting area from the Rancher Desktop GUI
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – Rancher Desktop GUI 中的故障排除区域
- en: Rancher Desktop also deploys its own Ingress controller based on Traefik. This
    controller will help us to publish our applications, as we will learn in [*Chapter
    11*](B19845_11.xhtml#_idTextAnchor244), *Publishing Applications*. We can remove
    this component and deploy our own Ingress controller by unselecting the **Traefik**
    option in the **Kubernetes** **Preferences** section, but it is quite interesting
    to have one by default.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Rancher Desktop 还部署了基于 Traefik 的 Ingress 控制器。这个控制器将帮助我们发布应用程序，正如我们在 [*第 11 章*](B19845_11.xhtml#_idTextAnchor244)
    中学习的，*发布应用程序*。我们可以通过在**Kubernetes** **偏好设置**部分取消选中**Traefik**选项来移除这个组件并部署我们自己的
    Ingress 控制器，但默认提供一个还是很有趣的。
- en: 'The Rancher Dashboard is accessible by clicking on the Rancher Desktop notification
    icon and selecting **Open cluster dashboard**. Rancher Dashboard provides access
    to many Kubernetes resources graphically, which can be very useful for beginners.
    The following screenshot shows the Rancher Dashboard main page, where you can
    review and modify different deployed Kubernetes resources:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点击 Rancher Desktop 通知图标并选择**打开集群仪表盘**，可以访问 Rancher Dashboard。Rancher Dashboard
    以图形化方式提供对许多 Kubernetes 资源的访问，这对于初学者来说非常有用。以下截图显示了 Rancher Dashboard 主页面，在这里你可以查看和修改不同的已部署
    Kubernetes 资源：
- en: '![Figure 8.8 – The Rancher Dashboard main page](img/B19845_08_08.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8 – Rancher Dashboard 主页面](img/B19845_08_08.jpg)'
- en: Figure 8.8 – The Rancher Dashboard main page
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – Rancher Dashboard 主页面
- en: 'We can verify the Kubernetes environment from a WSL terminal by checking its
    version:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在 WSL 终端中检查其版本来验证 Kubernetes 环境：
- en: '[PRE4]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Important note
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: We can build images for the Kubernetes environment without using an external
    registry by using `nerdctl` with the `-–namespace k8s.io` argument. This way,
    images will be available directly for our deployments.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `nerdctl` 并加上 `-–namespace k8s.io` 参数，在不使用外部注册表的情况下构建 Kubernetes 环境的镜像。这样，镜像将直接可用于我们的部署。
- en: It is interesting that this Kubernetes implementation is aligned with the expected
    network features from Kubernetes; hence, we can ping Pods and Services, or even
    access the Service ports from the WSL environment. It also makes our applications
    accessible by adding a `.localhost` suffix to our host definitions (we will deep
    dive into this option in [*Chapter 11*](B19845_11.xhtml#_idTextAnchor244), *Publishing
    Applications*). However, this cluster is still a standalone node, and we can’t
    test the behavior of our applications under certain failures or movements between
    nodes. If you really need to test these features, we need to go further and deploy
    additional nodes with other solutions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这种 Kubernetes 实现与 Kubernetes 预期的网络功能保持一致；因此，我们可以通过 ping Pods 和 Services，甚至从
    WSL 环境访问 Service 端口。通过在主机定义中添加 `.localhost` 后缀，它还使我们的应用程序可访问（我们将在[*第 11 章*](B19845_11.xhtml#_idTextAnchor244)《发布应用程序》一章中深入探讨这个选项）。然而，这个集群仍然是一个独立节点，我们无法测试在某些故障或节点之间迁移时应用程序的行为。如果你真的需要测试这些功能，我们需要进一步操作，部署其他节点并使用其他解决方案。
- en: Both Docker Desktop and Rancher Desktop provide GUI-based Kubernetes deployments,
    but usually, if you don’t need any GUI, we can even deploy more lightweight solutions.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Desktop 和 Rancher Desktop 都提供基于 GUI 的 Kubernetes 部署，但通常，如果不需要任何 GUI，我们甚至可以部署更轻量的解决方案。
- en: We will now review Minikube, which may be the most complete and pluggable solution.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将回顾 Minikube，它可能是最完整且可插拔的解决方案。
- en: Minikube
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Minikube
- en: The Minikube Kubernetes environment is very configurable and consumes considerably
    fewer hardware resources than other solutions, allowing us to deploy more than
    one node per cluster, or even multiple clusters on one single computer host. We
    can create a Kubernetes cluster by using either Docker, QEMU, Hyperkit, Hyper-V,
    KVM, Parallels, Podman, VirtualBox, or VMware Fusion/Workstation. We can use many
    different virtualization solutions or even container runtimes, and Minikube can
    be deployed on Microsoft Windows, macOS, or Linux operating systems.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube Kubernetes 环境非常可配置，并且比其他解决方案消耗更少的硬件资源，允许我们每个集群部署多个节点，甚至在单个计算机主机上部署多个集群。我们可以使用
    Docker、QEMU、Hyperkit、Hyper-V、KVM、Parallels、Podman、VirtualBox 或 VMware Fusion/Workstation
    创建一个 Kubernetes 集群。我们可以使用许多不同的虚拟化解决方案，甚至容器运行时，Minikube 可以在 Microsoft Windows、macOS
    或 Linux 操作系统上部署。
- en: 'These are some of the features of Minikube:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Minikube 的一些功能：
- en: It supports different Kubernetes releases
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它支持不同的 Kubernetes 版本
- en: Different container runtimes can be used
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用不同的容器运行时
- en: A direct API endpoint improves image management
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个直接的 API 端点改进了镜像管理
- en: Advanced Kubernetes customization such as the addition of **feature gates**
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级 Kubernetes 自定义配置，如添加 **feature gates**
- en: It is a pluggable solution, so we can include add-ons such as Ingress for extended
    Kubernetes features
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个可插拔的解决方案，因此我们可以包括像 Ingress 这样的插件，以扩展 Kubernetes 功能
- en: It supports integration with common CI environments
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它支持与常见 CI 环境的集成
- en: 'Kubernetes deployment is easy, and you just require a single binary for Linux
    systems. Different arguments can be used to set up the environment. Let’s review
    some of the most important:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 部署非常简单，对于 Linux 系统只需要一个二进制文件。可以使用不同的参数来设置环境。让我们回顾一些最重要的：
- en: '`start`: This action creates and starts a Kubernetes cluster. We can use the
    argument `--nodes` to define the number of nodes to deploy and `--driver` to specify
    which method to use to create a cluster. Virtual hardware resources can also be
    defined by using `--cpu` and `--memory`; by default, 2 CPUs and 2 GB of memory
    will be used. We can even choose a specific CNI to deploy with the `--cni` argument
    (`auto`, `bridge`, `calico`, `cilium`, `flannel`, and `kindnet` are available,
    but we can add our own path to a CNI manifest).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start`：此操作创建并启动一个Kubernetes集群。我们可以使用`--nodes`参数来定义要部署的节点数量，使用`--driver`来指定创建集群时使用的方法。虚拟硬件资源也可以通过使用`--cpu`和`--memory`来定义；默认情况下，将使用2个CPU和2GB内存。我们甚至可以选择特定的CNI进行部署，使用`--cni`参数（`auto`，`bridge`，`calico`，`cilium`，`flannel`和`kindnet`可用，但我们也可以添加自己的CNI清单路径）。'
- en: '`status`: This action shows the status of the Minikube cluster.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`status`：此操作显示Minikube集群的状态。'
- en: '`stop`: This stops a running Minikube cluster.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stop`：此命令停止正在运行的Minikube集群。'
- en: '`delete`: This action deletes a previously created cluster.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delete`：此操作删除之前创建的集群。'
- en: '`dashboard`: An open source Kubernetes Dashboard can be deployed as an add-on,
    which can be accessed by using `minikube dashboard`.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dashboard`：可以作为插件部署一个开源的Kubernetes Dashboard，使用`minikube dashboard`即可访问。'
- en: '`service`: This option can be very interesting to expose a deployed application
    Service. It returns the Service URL that can be used to access it.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service`：此选项非常有用，可以公开部署的应用服务。它返回一个服务URL，可以用来访问该服务。'
- en: '`mount`: We can mount host directories into the Minikube nodes with this option.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mount`：我们可以使用此选项将主机目录挂载到Minikube节点中。'
- en: '`ssh`: We can access Kubernetes deployed hosts by using `minikube` `ssh <NODE>`.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ssh`：我们可以通过使用`minikube` `ssh <NODE>`来访问部署的Kubernetes主机。'
- en: '`node`: This action allows us to manage cluster nodes.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node`：此操作允许我们管理集群节点。'
- en: '`kubectl`: This runs a `kubectl` binary matching the cluster version.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`：此命令运行与集群版本匹配的`kubectl`二进制文件。'
- en: '`addons`: One of the best features of Minikube is that we can extend its functionality
    with plugins to manage additional storage options for the cluster (for example,
    to define a specific a `csi-hostpath-driver`, or specify the default storage class
    to use, `default-storageclass`, or a dynamic `storage-provisioner`, among other
    options), Ingress controllers (`ingress`, `ingress-dns`, `istio`, and `kong`),
    and security (`pod-security-policy`). We can even deploy the Kubernetes Dashboard
    or the metrics server automatically, which recover metrics from all running workloads.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`addons`：Minikube的最佳功能之一是我们可以通过插件扩展其功能，以管理集群的附加存储选项（例如，定义一个特定的`csi-hostpath-driver`，或者指定要使用的默认存储类`default-storageclass`，或者动态`storage-provisioner`等选项），Ingress控制器（`ingress`，`ingress-dns`，`istio`，和`kong`），以及安全（`pod-security-policy`）。我们甚至可以自动部署Kubernetes
    Dashboard或指标服务器，从所有运行中的工作负载中恢复指标。'
- en: 'To create a cluster with two nodes (a master and a worker) we can simply execute
    `minikube start --nodes 2`. Let’s see this in action:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个包含两个节点（一个主节点和一个工作节点）的集群，我们只需执行`minikube start --nodes 2`。让我们来看一下这个操作：
- en: '[PRE5]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once deployed, we can review the cluster state using `kubectl`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，我们可以使用`kubectl`查看集群状态：
- en: '[PRE6]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Minikube is a very configurable solution that provides common Kubernetes features.
    In my opinion, it is the best in terms of performance and features.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube是一个非常可配置的解决方案，提供常见的Kubernetes功能。在我看来，它在性能和功能方面是最优秀的。
- en: Important note
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Minikube Kubernetes deployments in Microsoft Windows require administrator privileges
    if you use Hyper-V. Therefore, you need to open PowerShell or Command Prompt as
    administrator, but this may not be enough. PowerShell Hyper-V must also be included,
    and we will need to execute `Enable-WindowsOptionalFeature -Online -FeatureName
    Microsoft-Hyper-V-Tools-All –All` on a PowerShell console to enable it.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在Microsoft Windows上部署Minikube Kubernetes需要管理员权限，特别是当你使用Hyper-V时。因此，你需要以管理员身份打开PowerShell或命令提示符，但这可能还不够。还必须包括PowerShell的Hyper-V，并且我们需要在PowerShell控制台中执行`Enable-WindowsOptionalFeature
    -Online -FeatureName Microsoft-Hyper-V-Tools-All –All`来启用它。
- en: Alternative Kubernetes desktop deployments
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代的Kubernetes桌面部署
- en: 'Nowadays, there are other interesting options that use even fewer hardware
    resources, but they don’t provide as many features as Minikube. Let’s discuss
    some good candidates to try:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，还有一些其他有趣的选项，它们使用的硬件资源甚至更少，但它们提供的功能不如Minikube丰富。让我们讨论一些不错的尝试候选项：
- en: '**kind**: This solution takes advantage of a Docker runtime installation to
    deploy Kubernetes using containers and their own custom images. It is based on
    kubeadm deployment, and it really works very nicely on Linux desktop systems in
    which you don’t usually install Docker Desktop to run containers.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kind**：这个解决方案利用 Docker 运行时安装，通过容器及其自定义镜像来部署 Kubernetes。它基于 kubeadm 部署，并且在
    Linux 桌面系统中运行得非常顺畅，这些系统通常不会安装 Docker Desktop 来运行容器。'
- en: '**K3s**: This Kubernetes deployment is the basis for the Rancher Desktop Kubernetes
    feature. It deploys a lightweight environment using less memory with customized
    binaries. This may impact your application’s deployment if you use bleeding-edge
    features, as they will probably not be available. This solution comes from Rancher-SUSE,
    which also provides K3D to deploy Kubernetes using containers.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K3s**：这个 Kubernetes 部署是 Rancher Desktop Kubernetes 功能的基础。它使用定制的二进制文件部署一个轻量级的环境，消耗更少的内存。如果你使用前沿功能，这可能会影响应用程序的部署，因为这些功能可能无法使用。这个解决方案来自
    Rancher-SUSE，后者还提供 K3D，通过容器部署 Kubernetes。'
- en: '`containerd`. It is in its early stages, but it currently seems a good solution
    if you don’t use any Docker tool in your application development.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`containerd`。它仍处于初期阶段，但如果你在应用开发中不使用任何 Docker 工具，目前它似乎是一个不错的解决方案。'
- en: We can now continue and deep dive into the concepts of Pods and Services.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续深入探讨 Pods 和 Services 的概念。
- en: Creating Pods and Services
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Pods 和 Services
- en: In this section, we will learn about the resources we will use in the Kubernetes
    orchestration platform to deploy our applications. We will start by learning how
    containers are implemented inside Pods.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们将学习在 Kubernetes 编排平台中用于部署应用程序的资源。我们将从学习容器是如何在 Pods 内部实现的开始。
- en: Pods
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pods
- en: A `localhost`; hence, we can only use ports once. Volumes associated with a
    Pod are also shared between containers. We can consider a Pod as a small VM in
    which different processes (containers) run together. Pods are considered in a
    healthy state when all their containers run correctly.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`localhost`；因此，我们只能使用每个端口一次。与 Pod 相关联的卷也在容器之间共享。我们可以将 Pod 看作是一个小型的虚拟机，其中不同的进程（容器）一起运行。当
    Pod 中的所有容器都正常运行时，Pod 被视为处于健康状态。'
- en: As Pods can contain many containers, we can think of using a Pod to deploy applications
    with multiple components. All containers associated with a Pod run on the same
    cluster host. This way, we can ensure that all application components run together,
    and their intercommunications will definitely be faster. Because Pods are the
    smallest unit in Kubernetes, we are only able to scale up or down complete Pods;
    hence, all the containers included will also be executed multiple times, which
    probably isn’t what we need. Not all applications’ components should follow the
    same scaling rules; hence, it is better to deploy multiple Pods for an application.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Pods 可以包含多个容器，我们可以考虑使用 Pod 来部署具有多个组件的应用程序。与 Pod 相关联的所有容器都运行在同一个集群主机上。通过这种方式，我们可以确保所有应用程序组件一起运行，它们之间的通信也会更快。由于
    Pods 是 Kubernetes 中最小的单位，我们只能整体扩展或缩减 Pods；因此，所有包含的容器也会多次执行，这可能并不是我们需要的。并非所有应用组件都应该遵循相同的扩展规则；因此，最好为一个应用程序部署多个
    Pods。
- en: 'The following diagram shows a Pod. Two containers are included, and thus, they
    share the IP address and volumes of the same Pod:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了一个 Pod。它包含两个容器，因此，它们共享同一个 Pod 的 IP 地址和卷：
- en: '![Figure 8.9 – A schema of a Pod with two containers included](img/B19845_08_09.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.9 – 包含两个容器的 Pod 结构图](img/B19845_08_09.jpg)'
- en: Figure 8.9 – A schema of a Pod with two containers included
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – 包含两个容器的 Pod 结构图
- en: We can run Pods that share the host’s resources by using the host’s namespaces
    (the host’s network, **inter-process communications** or **IPCs**, processes,
    and so on). We should limit this type of Pod because they have direct access to
    a host’s processes, interfaces, and so on.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用主机的命名空间（主机的网络、**进程间通信**或 **IPC**、进程等）来运行共享主机资源的 Pods。我们应该限制这种类型的 Pod，因为它们可以直接访问主机的进程、接口等。
- en: 'The following example shows a declarative file to execute an example Pod:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了一个声明性文件，用于执行一个示例 Pod：
- en: '[PRE7]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can use JSON or YAML files to define Kubernetes resources, but YAML files
    are more popular; hence, you have to take care of indentation when preparing your
    deployment files. To deploy this Pod on our Kubernetes cluster, we will simply
    execute `kubectl create -``f <PATH_TO_THE_FILE>`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 JSON 或 YAML 文件来定义 Kubernetes 资源，但 YAML 文件更受欢迎；因此，在准备部署文件时，你需要特别注意缩进。为了将此
    Pod 部署到我们的 Kubernetes 集群中，我们只需执行`kubectl create -f <PATH_TO_THE_FILE>`。
- en: Important note
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'When you access a Kubernetes cluster, a namespace is associated with your profile
    or context. By default, the namespace associated is `default`; therefore, if we
    don’t specify any Kubernetes namespace as an argument to create a resource, the
    `default`namespace will be used. We can change the namespace for the current context
    to be applied to all commands hereafter, by executing `kubectl config use-context
    --current --namespace <NEW_NAMESPACE>`. The namespace for each resource can be
    included under the `metadata` key in the resource’s YAML manifest:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当你访问一个 Kubernetes 集群时，一个命名空间会与您的个人资料或上下文关联。默认情况下，关联的命名空间是`default`；因此，如果我们没有指定任何
    Kubernetes 命名空间作为创建资源的参数，`default`命名空间将被使用。我们可以通过执行`kubectl config use-context
    --current --namespace <NEW_NAMESPACE>`来更改当前上下文的命名空间，使其适用于后续的所有命令。每个资源的命名空间可以在该资源的
    YAML 清单中的`metadata`键下指定：
- en: '`...`'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`...`'
- en: '`metadata:`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`metadata:`'
- en: '`name: podname`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`name: podname`'
- en: '`namespace: my-namespace`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`namespace: my-namespace`'
- en: '`...`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`...`'
- en: We can modify any aspect used for the container by modifying the container image’s
    behavior, as we learned with the Docker command line in [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096),
    *Running* *Docker Containers*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过修改容器镜像的行为来修改容器的任何方面，正如我们在[*第 4 章*](B19845_04.xhtml#_idTextAnchor096)中学到的，*运行*
    *Docker 容器*。
- en: 'If you are not sure of the available keys or are learning how to use a new
    Kubernetes resource, you can use `kubectl explain <RESOURCE>` to retrieve an accurate
    description of the keys available and the expected values:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不确定可用的键，或者正在学习如何使用新的 Kubernetes 资源，你可以使用`kubectl explain <RESOURCE>`来获取可用键及其预期值的准确描述：
- en: '[PRE8]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can continue adding keys to obtain more specific definitions – for example,
    we can retrieve the keys under `pod.spec.containers.resources`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续添加键以获得更具体的定义——例如，我们可以检索`pod.spec.containers.resources`下的键：
- en: '[PRE9]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Each description shows extended information with links to the Kubernetes documentation.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 每个描述都显示了扩展信息，并附有指向 Kubernetes 文档的链接。
- en: Important note
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We can retrieve all available keys at once for a specific resource by using
    `kubectl explain pod --recursive`. This option really helps us to fully customize
    the resources.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`kubectl explain pod --recursive`一次性检索特定资源的所有可用键。这个选项真的帮助我们完全自定义资源。
- en: 'We can test a real Pod deployment using an NGINX web server. To do this, follow
    these steps:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 NGINX Web 服务器来测试真实的 Pod 部署。为此，按照以下步骤操作：
- en: 'We will use the imperative mode with `kubectl run`:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用命令式模式与`kubectl run`：
- en: '[PRE10]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can now list the Pods to verify whether the webserver is running:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以列出 Pods 来验证 webserver 是否正在运行：
- en: '[PRE11]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As we can see, it is starting. After a few seconds, we can verify that our
    web server is running:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们所见，它正在启动。几秒钟后，我们可以验证我们的 web 服务器是否正在运行：
- en: '[PRE12]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can get into the `minikube` node and verify the Pod’s connectivity. The
    following screenshot shows the interaction with the cluster node:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以进入`minikube`节点并验证 Pod 的连通性。以下截图显示了与集群节点的交互：
- en: '![Figure 8.10 – Testing connectivity from the minikube node](img/B19845_08_10.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10 – 测试来自 minikube 节点的连通性](img/B19845_08_10.jpg)'
- en: Figure 8.10 – Testing connectivity from the minikube node
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – 测试来自 minikube 节点的连通性
- en: 'If we now delete the Pod and create a new one, we can easily see that that
    new Pods can receive a new IP address, and thus, our application may need to change
    the IP addresses continuously:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们现在删除 Pod 并创建一个新的 Pod，我们可以轻松地看到新的 Pod 会获得一个新的 IP 地址，因此，我们的应用可能需要不断更改 IP 地址：
- en: '[PRE13]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is a real problem, and that’s why we never use Pod IP addresses. Let’s
    talk now about Services and how they can help us to solve this problem.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实际问题，这也是我们永远不使用 Pod IP 地址的原因。现在我们来讨论 Services，以及它们如何帮助我们解决这个问题。
- en: Services
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Services
- en: '**Services** are abstract objects in Kubernetes; they are used to expose a
    set of Pods and, thus, they serve an application component. They will get an IP
    address from the internal Kubernetes IPAM system, and we will use this to access
    the associated Pods. We can also associate Services with external resources to
    make them accessible to users. Kubernetes offers different types of Services to
    be published either internally or outside a cluster. Let’s quickly review the
    different Service types:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务** 是 Kubernetes 中的抽象对象；它们用于暴露一组 Pods，从而为应用组件提供服务。它们会从 Kubernetes 的内部 IPAM
    系统中获取一个 IP 地址，我们将使用这个地址来访问关联的 Pods。我们还可以将服务与外部资源关联，使其对用户可访问。Kubernetes 提供了不同类型的服务，可以将它们发布到集群内部或集群外部。让我们快速回顾一下不同的服务类型：'
- en: '`ClusterIP`: This is the default Service type. Kubernetes associates an IP
    address from the defined Service’s IP address range, and containers will be able
    to access this Service by either its IP address or its name. Containers running
    in the same namespace will be able to simply use the Service’s name, while other
    containers will need to use its Kubernetes FQDN (`SERVICE_NAME.SERVICE_NAMESPACE.svc.cluster.local`,
    where `cluster.local` is the FQDN of the Kubernetes cluster itself). This is due
    to Kubernetes’ internal **service discovery** (**SD**), which creates DNS entries
    for all Services cluster-wide.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ClusterIP`：这是默认的服务类型。Kubernetes 会从定义的服务 IP 地址范围中分配一个 IP 地址，容器可以通过其 IP 地址或名称访问此服务。运行在同一命名空间中的容器将能够简单地使用服务的名称，而其他容器则需要使用其
    Kubernetes FQDN（`SERVICE_NAME.SERVICE_NAMESPACE.svc.cluster.local`，其中 `cluster.local`
    是 Kubernetes 集群本身的 FQDN）。这是由于 Kubernetes 的内部 **服务发现** (**SD**)，它为所有服务在集群范围内创建
    DNS 条目。'
- en: '`Headless`: These Services are a variant of the `ClusterIP` type. They don’t
    receive an IP address, and the Service’s name will resolve all the associated
    Pods’ IP addresses. We commonly use headless Services to interact with non-Kubernetes
    SD solutions.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Headless`：这些服务是 `ClusterIP` 类型的一种变体。它们不接收 IP 地址，服务的名称将解析为所有关联 Pods 的 IP 地址。我们通常使用无头服务来与非
    Kubernetes SD 解决方案进行交互。'
- en: '`NodePort`: When we use a `NodePort` Service, we associate a set of hosts’
    ports with the Service `clusterIP`’s defined IP address. This makes the Service
    accessible from outside a cluster. We can connect from a client computer to any
    of the cluster hosts in the defined port, and Kubernetes will route requests to
    the Service, associated with the `ClusterIP` address via internal DNS, no matter
    which node received the request. Thus, the Pods associated with the Service receive
    network traffic from the client.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NodePort`：当我们使用 `NodePort` 服务时，我们将一组主机端口与服务的 `clusterIP` 定义的 IP 地址关联。这使得服务能够从集群外部进行访问。我们可以从客户端计算机连接到定义端口中的任何集群主机，Kubernetes
    将通过内部 DNS 将请求路由到服务，关联到 `ClusterIP` 地址，无论哪个节点接收到请求。因此，关联该服务的 Pods 将接收来自客户端的网络流量。'
- en: '`LoadBalancer`: The `LoadBalancer` Service type is used to publish a defined
    Service in an external load balancer. It uses the external load balancer’s API
    to define the required rules to reach the cluster, and indeed, this model uses
    a `NodePort` Service type to reach the Service cluster-wide. This Service type
    is mainly used to publish Services in cloud providers’ Kubernetes clusters, although
    some vendors also provide this feature on-premises.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LoadBalancer`：`LoadBalancer` 服务类型用于在外部负载均衡器中发布定义好的服务。它使用外部负载均衡器的 API 来定义到达集群所需的规则，实际上，该模型使用
    `NodePort` 服务类型来实现集群范围内访问服务。此服务类型主要用于在云提供商的 Kubernetes 集群中发布服务，尽管一些厂商也在本地提供此功能。'
- en: We have seen how Services can be published outside the Kubernetes cluster to
    be consumed by other external applications or even our users, but we can also
    do the opposite. We can include external Services, available in our real network,
    inside our Kubernetes clusters by using the `External` Service type.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何将服务发布到 Kubernetes 集群外部，以便其他外部应用程序甚至我们的用户使用，但我们也可以做相反的操作。我们可以通过使用 `External`
    服务类型，将我们实际网络中的外部服务包含到 Kubernetes 集群内。
- en: 'The following schema represents a `NodePort` Service in which we publish port
    `7000`, attached to port `5000`, and exposed in the containers in this example:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 以下架构表示一个 `NodePort` 服务，我们在该服务中发布端口 `7000`，并将其附加到端口 `5000`，在本示例中的容器中暴露：
- en: '![Figure 8.11 – NodePort Service schema](img/B19845_08_11.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.11 – NodePort 服务架构](img/B19845_08_11.jpg)'
- en: Figure 8.11 – NodePort Service schema
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – NodePort 服务架构
- en: In this example, the external requests from users are load-balanced to port
    `7000`, listening on all cluster hosts. All traffic from the users will be internally
    load-balanced to port `5000`, making it available on all Services’ assigned Pods.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，来自用户的外部请求会负载均衡到端口`7000`，该端口监听所有集群主机。所有来自用户的流量会被内部负载均衡到端口`5000`，使其在所有服务分配的Pod上都能使用。
- en: 'The following example shows the manifest of a Kubernetes Service, obtained
    by using the **imperative method** to retrieve the output only:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了一个Kubernetes服务的清单，这是通过使用**命令式方法**仅检索输出得到的：
- en: '[PRE14]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this example, the Service resource isn’t created because we added the `-o
    yaml` argument to show the output in the YAML format and `–dry-run=client`. This
    option shows the output of the creation command executed against kube-apiserver.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，服务资源没有被创建，因为我们添加了`-o yaml`参数以显示YAML格式的输出，并使用了`–dry-run=client`。这个选项显示了执行创建命令时返回的输出结果，该命令是针对kube-apiserver执行的。
- en: Let’s move on now to learn how to deploy workloads in a cluster because Pods
    don’t provide resilience; they run as unmanaged standalone workloads without a
    controller.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们学习如何在集群中部署工作负载，因为Pod不提供弹性；它们作为未管理的独立工作负载运行，缺乏控制器。
- en: Deploying orchestrated resources
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署编排资源
- en: Now that we know how to deploy Pods using imperative and declarative modes,
    we will define new resources that can manage the Pods’ life cycle. Pods executed
    directly with the `kubectl` command line are not recreated if their containers
    die. To control the workloads within a Kubernetes cluster, we will need to deploy
    additional resources, managed by Kubernetes controllers. These controllers are
    control loops that monitor the state of different Kubernetes resources and make
    or request changes when needed. Each controller tracks some resources and tries
    to maintain their defined state. Kubernetes’ kube-controller-manager manages these
    controllers that maintain the overall desired state of different cluster resources.
    Each controller can be accessed via an API, and we will use `kubectl` to interact
    with them.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道如何使用命令式和声明式模式来部署Pod，我们将定义可以管理Pod生命周期的新资源。直接使用`kubectl`命令行执行的Pod如果容器终止，将不会被重新创建。为了控制Kubernetes集群中的工作负载，我们需要部署额外的资源，由Kubernetes控制器进行管理。这些控制器是控制循环，它们监控不同Kubernetes资源的状态，并在需要时进行更改或请求更改。每个控制器都会跟踪一些资源，并尽力保持它们的定义状态。Kubernetes的kube-controller-manager管理这些控制器，以保持不同集群资源的整体期望状态。每个控制器都可以通过API访问，我们将使用`kubectl`与它们进行交互。
- en: In this section, we will learn the basics of Kubernetes controllers and dive
    deep into how to use them in [*Chapter 9*](B19845_09.xhtml#_idTextAnchor202),
    *Implementing* *Architecture Patterns*.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习Kubernetes控制器的基础知识，并深入了解如何在[*第9章*](B19845_09.xhtml#_idTextAnchor202)中使用它们，*实现*
    *架构模式*。
- en: ReplicaSets
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 副本集
- en: 'The most simple resource that allows us to maintain a defined state for our
    application is a ReplicaSet. It will keep a set of replica Pods running. To create
    a ReplicaSet, we will use a Pod manifest as a template to create multiple replicas.
    Let’s see a quick example:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的可以保持应用程序定义状态的资源是副本集。它会保持一组副本Pod的运行。为了创建副本集，我们将使用Pod清单作为模板来创建多个副本。让我们来看一个简单的示例：
- en: '[PRE15]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This ReplicaSet will run three Pods with the same `docker.io/nginx:alpine` image;
    the `template` section defines the specifications for these three Pod resources,
    with one container each. The ReplicaSet identifies Pods to manage by using the
    defined `application` label and its `webserver` value, defined in the Pod’s `template`
    section of the manifest.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这个副本集将运行三个具有相同`docker.io/nginx:alpine`镜像的Pod；`template`部分定义了这三个Pod资源的规格，每个Pod一个容器。副本集通过使用在Pod的`template`部分定义的`application`标签及其`webserver`值，来识别需要管理的Pod。
- en: When we deploy this ReplicaSet, the cluster creates these three Pods, and whenever
    any of them dies, the controller manages this change and triggers the creation
    of a new one.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们部署这个副本集时，集群会创建这三个Pod，每当其中任何一个Pod终止时，控制器会管理这个变化并触发新的Pod创建。
- en: We will continue to review more resources, but keep in mind that the basic idea
    of a `template` section embedded inside a more general definition applies to all
    of them.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续审查更多资源，但请记住，`template`部分嵌入在更一般的定义中的基本概念适用于所有资源。
- en: Deployments
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署
- en: We may think of a Deployment as an evolution of a ReplicaSet. It allows us to
    update them because a deployment manages a set of replicas but only runs one.
    Every time we create a new deployment, we create an associated ReplicaSet. And
    when we update this deployment, a new ReplicaSet is created with a new definition,
    reflecting the changes from the previous resource.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将Deployment视为ReplicaSet的进化版本。它允许我们更新这些副本，因为一个Deployment管理着一组副本，但只运行其中一个。每次我们创建一个新的Deployment时，都会创建一个关联的ReplicaSet。当我们更新这个Deployment时，会创建一个新的ReplicaSet，带有新的定义，反映前一个资源的更改。
- en: DaemonSets
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DaemonSets
- en: With a DaemonSet, we can ensure that all cluster nodes get one replica of our
    workload, but we cannot define the number of replicas in a DaemonSet.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DaemonSet，我们可以确保所有集群节点都有一个工作负载副本，但我们无法在DaemonSet中定义副本的数量。
- en: StatefulSets
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StatefulSets
- en: A StatefulSet allows more advanced features in our workloads. It allows us to
    manage the order and uniqueness of Pods, ensuring that each replica gets its own
    unique set of resources, such as volumes. Although Pods are created from the same
    template section, a StatefulSet maintains a different identity for each Pod.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet允许我们在工作负载中使用更高级的特性。它使我们能够管理Pods的顺序和唯一性，确保每个副本获得自己唯一的资源集，例如卷。尽管Pods是从相同的模板部分创建的，但StatefulSet为每个Pod维护不同的身份。
- en: Jobs
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作业
- en: A Job creates one or more Pods at a time, but it will continue creating them
    until a defined number of them terminate successfully. When a Pod exits, the controller
    verifies whether the number of required completions was reached, and if not, it
    creates a new one.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Job会一次创建一个或多个Pods，但它会持续创建，直到创建的Pod数量达到定义的成功终止数量。当一个Pod退出时，控制器会验证所需完成的Pod数量是否已达到，如果没有，它会创建一个新的Pod。
- en: CronJobs
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CronJobs
- en: We can schedule Pods by using CronJobs, as they schedule jobs. When the execution
    time comes, a Job is created and triggers the creation of defined Pods. As we
    will learn in [*Chapter 9*](B19845_09.xhtml#_idTextAnchor202), *Implementing Architecture
    Patterns*, CronJobs manifests include two `template` sections – one to create
    jobs and another one to define how Pods will be created.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用CronJobs来调度Pods，因为它们负责调度任务。当执行时间到达时，会创建一个Job，并触发创建定义的Pods。正如我们在[*第9章*](B19845_09.xhtml#_idTextAnchor202)《实现架构模式》中所学到的那样，CronJobs清单包括两个`template`部分——一个用于创建作业，另一个用于定义如何创建Pods。
- en: ReplicationControllers
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReplicationControllers
- en: We can consider ReplicationControllers a previous version of the current ReplicaSet
    resource types. They work similarly to how we keep a number of Pod replicas alive,
    but they differ in how they group the monitored Pods because ReplicationControllers
    do not support set-based selectors. This selector method allows ReplicaSets to
    acquire the state management of Pods created outside of their own manifest; hence,
    if a Pod already running matches the ReplicaSet label’s selection, it will be
    automatically included in the pool of replicated Pods.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将ReplicationControllers视为当前ReplicaSet资源类型的前身。它们的工作方式与我们保持一定数量的Pod副本活跃类似，但它们在分组监控的Pods时有所不同，因为ReplicationControllers不支持基于集的选择器。这个选择器方法使ReplicaSets能够获取由其自身清单之外创建的Pods的状态管理；因此，如果一个已运行的Pod符合ReplicaSet标签的选择，它将自动被包括在复制Pod池中。
- en: Now that we have an overview of different resources that allow us to create
    orchestrated resources cluster-wide, we can learn some of the Kubernetes features
    that can improve our applications’ security.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对允许我们创建跨集群编排资源的不同资源有了概览，接下来可以学习一些Kubernetes的功能，这些功能可以提高我们应用程序的安全性。
- en: Improving your applications’ security with Kubernetes
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes提高应用程序的安全性
- en: Applications running in containers offer many new different features. We can
    run multiple applications’ releases at a time in a host; they start and stop in
    seconds. We can scale components easily, and different applications can coexist
    without even interaction between them. An application’s resilience is also inherited
    from the container runtime features (exited containers autostarting).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行的应用程序提供了许多全新的功能。我们可以在主机上同时运行多个应用程序版本；它们可以在几秒钟内启动和停止。我们可以轻松地扩展组件，不同的应用程序可以共存，甚至不需要彼此之间的交互。应用程序的弹性也继承自容器运行时的特性（例如，退出的容器会自动重新启动）。
- en: 'However, we can also improve our applications by running them in Kubernetes.
    Each Kubernetes cluster is composed of multiple container runtimes running together
    and in coordination. Container runtimes isolate the hosts’ resources thanks to
    kernel namespaces and **control groups** (**cgroups**), but Kubernetes adds some
    interesting features:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们也可以通过在Kubernetes中运行应用程序来提升它们的性能。每个Kubernetes集群由多个容器运行时共同运行并协调工作。容器运行时通过内核命名空间和**控制组**（**cgroups**）隔离主机的资源，但Kubernetes增加了一些有趣的功能：
- en: '**Namespaces**: Namespaces are Kubernetes resources that group other resources
    and are designed to distribute Kubernetes resources between multiple users, grouped
    in teams or projects.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命名空间**：命名空间是Kubernetes资源，它们将其他资源分组并设计用于在多个用户之间分配Kubernetes资源，这些用户按团队或项目进行分组。'
- en: '**Authentication strategies**: Requests from Kubernetes clients may use different
    authentication mechanisms, such as client certificates, bearer tokens, or an authenticating
    proxy to authenticate them.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**认证策略**：来自Kubernetes客户端的请求可以使用不同的认证机制，如客户端证书、持有者令牌或身份验证代理来进行认证。'
- en: '**Authorization requests**: Users request the Kubernetes API after passing
    authentication, authorization, and different admission controllers. The authorization
    phase involves granting permission to access Kubernetes’ resources and features.
    Requests’ attributes are evaluated against policies, and they are allowed or denied.
    The user, group, API, request path, namespace, verb, and so on that are provided
    in the requests are used for these validations.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**授权请求**：用户在通过认证、授权和不同的准入控制器后，向Kubernetes API发出请求。授权阶段涉及授予访问Kubernetes资源和功能的权限。请求的属性会根据策略进行评估，并决定是允许还是拒绝。请求中提供的用户、组、API、请求路径、命名空间、动词等都用于这些验证。'
- en: '`root`, or simply change the final resulting user to a non-privileged user
    in order to maintain cluster security.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`root`，或者简单地将最终结果用户更改为非特权用户，以保持集群安全。'
- en: '`kubectl` to check whether some verbs are available for us or even for another
    user, by using impersonation:'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`kubectl`检查是否有某些动词可供我们使用，或者是否可以通过模拟其他用户来检查：
- en: '[PRE16]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Secrets and ConfigMaps**: We already learned how to deploy certain configurations
    in orchestrated environments in [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147),
    *Orchestrating with Swarm*. In Kubernetes, we also have Secrets and ConfigMaps
    resources, but they can be retrieved by users if they are allowed (RBAC). It is
    important to understand that Secrets are packaged in the Base64 format; hence,
    sensitive data can be accessed if we don’t prepare appropriate roles. The kubelet
    Kubernetes component will mount Secrets and ConfigMaps automatically for you,
    and we can use them as files or environment variables in our application deployments.
    Kubernetes can encrypt Secrets at rest to ensure that operating systems administrators
    can’t retrieve them from the etcd database files, but this capability is disabled
    by default.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Secrets 和 ConfigMaps**：我们已经在[*第7章*](B19845_07.xhtml#_idTextAnchor147)《使用Swarm进行编排》中学习了如何在编排环境中部署某些配置。在Kubernetes中，我们也有Secrets和ConfigMaps资源，但如果允许，用户可以检索它们（RBAC）。理解Secrets是以Base64格式打包的非常重要；因此，如果我们没有准备合适的角色，敏感数据可能会被访问。kubelet
    Kubernetes组件将自动为你挂载Secrets和ConfigMaps，我们可以在应用程序部署中将它们作为文件或环境变量使用。Kubernetes可以加密静态的Secrets，以确保操作系统管理员无法从etcd数据库文件中检索它们，但此功能默认是禁用的。'
- en: '`securityContext` profiles, and this is essential because we can ensure that
    a Pod doesn’t run as root, privileged, or use non-read-only containers on any
    defined namespace.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`securityContext`配置文件，这是至关重要的，因为我们可以确保一个Pod不会以root身份运行，或者不会在任何定义的命名空间中使用特权容器或非只读容器。'
- en: '**Network policies**: Kubernetes deploys a flat network by default; hence,
    all containers can reach each other. To avoid such a situation, Kubernetes also
    provides NetworkPolicies and GlobalNetworkPolicies (applied at the cluster level).
    Not all CNIs are able to implement this feature. Kubernetes only provides **custom
    resource** (**CR**) types, which will be used to implement the **network policies**.
    Verify that your network provider can implement them to be able to use this feature
    (lots of popular CNI plugins such as Calico, Canal, and Cilium are completely
    capable). It is a good recommendation to implement some default global policies
    to drop all external accesses and allow the required communications for each application
    at the namespace level. Network policies define both Ingress and Egress rules.
    These rules work at the connectivity level; hence, we don’t have raw packet logging
    (although some CNI plugins provide some logging features). We will learn how to
    implement rules following best practices in [*Chapter 11*](B19845_11.xhtml#_idTextAnchor244),
    *Publishing Applications*.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络策略**：Kubernetes 默认部署一个扁平化网络，因此所有容器都能相互访问。为了避免这种情况，Kubernetes 还提供了 NetworkPolicies
    和 GlobalNetworkPolicies（在集群级别应用）。并非所有的 CNI 都能够实现这一功能。Kubernetes 仅提供 **自定义资源**（**CR**）类型，这些类型将用于实现
    **网络策略**。请确保你的网络提供程序能够实现这些策略，以便能够使用此功能（许多流行的 CNI 插件如 Calico、Canal 和 Cilium 完全支持）。强烈建议实现一些默认的全局策略，拒绝所有外部访问，并在命名空间级别允许每个应用所需的通信。网络策略定义了入站和出站规则。这些规则在连接级别工作，因此我们没有原始的数据包日志（尽管一些
    CNI 插件提供了日志功能）。我们将在 [*第11章*](B19845_11.xhtml#_idTextAnchor244) *发布应用* 中学习如何按照最佳实践实现这些规则。'
- en: Now that we have an overview of the most important features available in Kubernetes
    that help us to protect both our applications and the entire cluster, we can continue
    by creating some simple labs that will cover the basic usage of a Kubernetes environment.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经概览了 Kubernetes 中可用的一些最重要功能，这些功能帮助我们保护应用程序和整个集群，我们可以继续进行一些简单的实验，涵盖 Kubernetes
    环境的基本使用。
- en: Labs
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: Now, we will have a short lab section that will help us to learn and understand
    the basics of deploying a local Kubernetes environment with Minikube, testing
    some of its resource types to validate the cluster.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将进行一个简短的实验环节，帮助我们学习和理解如何使用 Minikube 部署本地 Kubernetes 环境，并测试其中的一些资源类型来验证集群。
- en: The code for the labs is available in this book’s GitHub repository at https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git.
    Ensure you have the latest revision available by simply executing `git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git`
    to download all its content or `git pull` if you already downloaded the repository
    before. All commands and content used in these labs will be located inside the
    `Containers-for-Developers-Handbook/Chapter8` directory.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 本书实验的代码可在其 GitHub 仓库 https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git
    中找到。通过执行 `git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git`
    来下载所有内容，或如果你已经下载过该仓库，则执行 `git pull` 获取最新版本。所有实验中使用的命令和内容都位于 `Containers-for-Developers-Handbook/Chapter8`
    目录下。
- en: We will start by deploying a Minikube cluster with two nodes (one master and
    one worker). We will deploy them with 3 GB of RAM each, which will be more than
    enough to test application behavior when some of the cluster node dies, but you
    will probably not need two nodes for your daily usage.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过部署一个包含两个节点（一个主节点和一个工作节点）的 Minikube 集群开始。我们将为每个节点分配 3 GB 的 RAM，这足以在某些集群节点宕机时测试应用程序的行为，但对于日常使用来说，你可能不需要两个节点。
- en: Deploying a Minikube cluster with two nodes
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署一个包含两个节点的 Minikube 集群
- en: 'In this lab, we will deploy a fully functional Kubernetes cluster locally,
    for testing purposes. We will continue working on a Windows 10 laptop with 16
    GB of RAM, which is enough for the labs in this book. Follow these steps:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们将在本地部署一个完全功能的 Kubernetes 集群，用于测试目的。我们将继续在一台拥有 16 GB RAM 的 Windows 10
    笔记本电脑上进行操作，这对于本书中的实验来说已经足够了。请按照以下步骤操作：
- en: Install Minikube. First, download it from https://minikube.sigs.k8s.io/docs/start/,
    choose the appropriate installation method, and follow the simple installation
    steps for your operating system. We will use Hyper-V; hence, it must be enabled
    and running on your desktop computer or laptop.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Minikube。首先，从 https://minikube.sigs.k8s.io/docs/start/ 下载 Minikube，选择合适的安装方法，并按照操作系统的简单安装步骤进行安装。我们将使用
    Hyper-V，因此必须在桌面电脑或笔记本电脑上启用并运行它。
- en: 'Once Minikube is installed, we will open an administrator PowerShell terminal.
    Minikube deployments using Hyper-V require execution with administrator privileges.
    This is due to the Hyper-V layer; hence, admin privileges won’t be required if
    you use VirtualBox as your hypervisor or Linux as your operating system (other
    hypervisors can be used, such as KVM, which works very nicely with Minikube).
    Admin rights are also required to remove the Minikube cluster. Once the PowerShell
    terminal is ready, we execute the following command:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 Minikube 安装完成，我们将打开一个管理员 PowerShell 终端。使用 Hyper-V 部署 Minikube 需要以管理员权限执行。这是由于
    Hyper-V 层的原因；因此，如果您使用 VirtualBox 作为虚拟化程序或 Linux 作为操作系统，则不需要管理员权限（其他虚拟化程序也可以使用，例如
    KVM，它与 Minikube 配合得非常好）。如果需要删除 Minikube 集群，管理员权限也是必需的。一旦 PowerShell 终端准备好，我们执行以下命令：
- en: '[PRE17]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: PS C:\> kubectl get nodes
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PS C:\> kubectl get nodes
- en: NAME           STATUS   ROLES           AGE   VERSION
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NAME           STATUS   ROLES           AGE   VERSION
- en: minikube       Ready    control-plane   23m   v1.26.3
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: minikube       Ready    control-plane   23m   v1.26.3
- en: minikube-m02 node does not show any role. This is due to the fact that everything
    in Kubernetes is managed by labels. Remember that we saw how selectors are used
    to identify which Pods belong to a specific ReplicaSet.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: minikube-m02 节点没有显示任何角色。这是因为 Kubernetes 中的一切都是通过标签进行管理的。记住，我们之前看到如何使用选择器来识别哪些
    Pods 属于特定的 ReplicaSet。
- en: '[PRE19]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can review the node labels and create a new one for the worker node. This
    will show us how we can modify the resource’s behavior by using labels:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看节点标签并为工作节点创建一个新标签。这将向我们展示如何通过使用标签修改资源的行为：
- en: '[PRE20]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We now add a new label to the worker node by using a `kubectl` label, `<``RESOURCE>
    <LABEL_TO_ADD>`:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在通过使用 `kubectl` label、`<RESOURCE> <LABEL_TO_ADD>` 为工作节点添加一个新标签：
- en: '[PRE21]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We will now show you how you can use the deployed Kubernetes cluster.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将展示如何使用已部署的 Kubernetes 集群。
- en: Interacting with the Minikube deployed cluster
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 Minikube 部署集群进行交互
- en: 'In this lab, we will interact with the current cluster, reviewing and creating
    some new resources:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们将与当前集群进行交互，回顾并创建一些新资源：
- en: 'We will start by listing all Pods deployed in the cluster using `kubectl get
    pods --A`. This will list all Pods in the cluster. We are able to list them after
    the Minikube installation because we connect as administrators. The following
    screenshot shows the output of `kubectl get pods -A`, followed by a list of the
    current namespaces, using `kubectl` `get namespaces`:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从列出集群中所有部署的 Pods 开始，使用 `kubectl get pods --A`。这将列出集群中所有的 Pods。由于我们作为管理员连接，在
    Minikube 安装后我们能够列出它们。以下截图展示了 `kubectl get pods -A` 的输出，接着是使用 `kubectl` `get namespaces`
    命令列出的当前命名空间：
- en: '![Figure 8.12 – The output of the kubectl get pods –A and kubectl get namespace
    commands](img/B19845_08_12.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.12 – kubectl get pods –A 和 kubectl get namespace 命令的输出](img/B19845_08_12.jpg)'
- en: Figure 8.12 – The output of the kubectl get pods –A and kubectl get namespace
    commands
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – kubectl get pods –A 和 kubectl get namespace 命令的输出
- en: 'Let’s create a new namespace, `chapter8`, by using `kubectl create` `ns chapter8`:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过使用 `kubectl create` `ns chapter8` 来创建一个新的命名空间 `chapter8`：
- en: '[PRE22]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: PS C:\> kubectl get pods -n chapter8
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PS C:\> kubectl get pods -n chapter8
- en: 'ingress-nginx namespace. We will list all the resources deployed in this namespace
    using kubectl get all, as we can see in the following screenshot:'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ingress-nginx 命名空间。我们将使用 kubectl get all 列出该命名空间中部署的所有资源，正如以下截图所示：
- en: '[PRE23]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Figure 8.13 – The output of kubectl get all –n ingress-nginx](img/B19845_08_13.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.13 – kubectl get all –n ingress-nginx 的输出](img/B19845_08_13.jpg)'
- en: Figure 8.13 – The output of kubectl get all –n ingress-nginx
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – kubectl get all –n ingress-nginx 的输出
- en: Now, we know how we can filter resources associated with a specific namespace.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们知道如何筛选与特定命名空间关联的资源。
- en: 'Let’s now create a simple Pod in the `chapter8` namespace by using the imperative
    format. We will execute `kubectl run webserver --image=nginx:alpine` to run a
    Pod with one container using the `docker.io/nginx:alpine` image:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们通过使用命令式格式在 `chapter8` 命名空间中创建一个简单的 Pod。我们将执行 `kubectl run webserver --image=nginx:alpine`
    来运行一个包含一个容器的 Pod，使用 `docker.io/nginx:alpine` 镜像：
- en: '[PRE24]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![Figure 8.14 – The output of kubectl get pods --namespace chapter8 -o yaml
    webserver](img/B19845_08_14.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.14 – kubectl get pods --namespace chapter8 -o yaml webserver 的输出](img/B19845_08_14.jpg)'
- en: Figure 8.14 – The output of kubectl get pods --namespace chapter8 -o yaml webserver
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – kubectl get pods --namespace chapter8 -o yaml webserver 的输出
- en: 'Let’s see which node executes our Pod by using either `kubectl get pods -o
    wide`, which shows extended information, or by filtering the `hostIP` key from
    the YAML output:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过使用`kubectl get pods -o wide`来查看是哪个节点执行了我们的Pod，该命令显示扩展信息，或者通过从YAML输出中筛选`hostIP`键：
- en: '[PRE25]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This can also be done by using the JSON path template (https://kubernetes.io/docs/reference/kubectl/jsonpath/):'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这也可以通过使用JSON路径模板（https://kubernetes.io/docs/reference/kubectl/jsonpath/）来完成：
- en: '[PRE26]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Important note
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: You can see that the node name is also available in the `spec` section (`spec.nodeName`),
    but this section is where Pod specifications are presented. We will learn in the
    next chapter how we can change the workload behavior by changing the specifications
    from the online manifests, directly in Kubernetes. The `status` section is read-only
    because it shows the actual state of the resource, while some of the sections
    in either the `metadata` or `spec` sections can be modified – for example, by
    adding new labels or annotations.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到节点名称也可以在`spec`部分（`spec.nodeName`）中找到，但这一部分是Pod规格呈现的地方。我们将在下一章学习如何通过直接修改Kubernetes中的在线清单来改变工作负载的行为。`status`部分是只读的，因为它显示了资源的实际状态，而`metadata`或`spec`部分的一些内容可以被修改——例如，可以通过添加新的标签或注释来修改。
- en: Before ending the labs from this chapter, we will expose the deployed Pod by
    adding a `NodePort` Service, which will guide our requests to the running web
    server Pod.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的实验结束前，我们将通过添加一个`NodePort`服务来暴露已部署的Pod，这将引导我们的请求到正在运行的Web服务器Pod。
- en: Exposing a Pod with a NodePort Service
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用NodePort服务暴露Pod
- en: 'In this quick lab, we will use the imperative model to deploy a `NodePort`
    Service to expose the already deployed web server Pod:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个快速实验中，我们将使用命令式模型部署一个`NodePort`服务，以暴露已经部署的Web服务器Pod：
- en: 'Because we haven’t defined the container port in the `webserver` Pod, Kubernetes
    will not know which port must be associated with the Service; hence, we need to
    pass the `--target-port 80` argument to specify that the Service should link the
    NGINX container port that is listening. We will use port `8080` for the Service,
    and we will let Kubernetes choose one `NodePort` port for us:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们没有在`webserver` Pod中定义容器端口，Kubernetes将无法知道哪个端口必须与服务关联；因此，我们需要传递`--target-port
    80`参数，以指定服务应连接到监听的NGINX容器端口。我们将使用端口`8080`作为服务端口，并让Kubernetes为我们选择一个`NodePort`端口：
- en: '[PRE27]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: PS C:\> kubectl get all -n chapter8
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PS C:\> kubectl get all -n chapter8
- en: NAME            READY   STATUS    RESTARTS   AGE
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 名称                就绪   状态    重启次数    存活时间
- en: pod/webserver   1/1     Running   0          50m
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pod/webserver   1/1     运行中    0          50m
- en: NAME                TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 名称                类型        集群-IP       外部-IP    端口（S）        存活时间
- en: 32317 is associated with the Service’s port, 8080, which is associated with
    the webserver Pod’s port, 80 (the NGINX container listens on that port).
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 32317与服务的端口8080相关联，该端口与webserver Pod的端口80（NGINX容器在该端口上监听）相关联。
- en: '[PRE28]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We can now access the published `NodePort` port on any host, even if it does
    not run any Service-related Pod. We can use the IP address of any of the Minikube
    cluster nodes or use `minikube service -n chapter8 webserver` to automatically
    open our default web browser in the associated URL.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以在任何主机上访问已发布的`NodePort`端口，即使该主机没有运行任何与服务相关的Pod。我们可以使用任何Minikube集群节点的IP地址，或者使用`minikube
    service -n chapter8 webserver`命令自动在关联的URL中打开默认的Web浏览器。
- en: 'The following screenshot shows the output in both cases. First, we obtained
    the host’s IP addresses by using `kubectl get nodes –o wide`. We used PowerShell’s
    `Invoke-WebRequest` command to access a combination of IP addresses of the nodes
    and the `NodePort`-published port. Then, we used Minikube’s built-in DNS to resolve
    the Service’s URL by using the `minikube` Service:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了两种情况的输出。首先，我们使用`kubectl get nodes –o wide`获取了主机的IP地址。我们使用PowerShell的`Invoke-WebRequest`命令访问了节点的IP地址与`NodePort`发布端口的组合。然后，我们使用Minikube的内置DNS解析了服务的URL，通过使用`minikube`服务：
- en: '![Figure 8.15 – The output of kubectl get nodes, different tests using the
    cluster nodes, and the minikube Service URL resolution](img/B19845_08_15.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图8.15 – kubectl get nodes的输出，使用集群节点进行不同测试，以及Minikube服务URL解析](img/B19845_08_15.jpg)'
- en: Figure 8.15 – The output of kubectl get nodes, different tests using the cluster
    nodes, and the minikube Service URL resolution
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15 – kubectl get nodes的输出，使用集群节点进行不同测试，以及Minikube服务URL解析
- en: 'As you can see, we used the IP addresses of both the master and worker nodes
    for the tests, and they worked, even though the Pod only ran on the worker node.
    This output also shows how easy it is to test Services by using Minikube’s integrated
    Services resolution. It automatically opened our default web browser, and we can
    access our Service directly, as we can see in the following screenshot:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，我们使用了主节点和工作节点的 IP 地址进行了测试，它们可以正常工作，尽管 Pod 只在工作节点上运行。此输出还显示了通过使用 Minikube
    的集成服务解析来测试服务有多么容易。它自动打开了我们的默认网络浏览器，我们可以直接访问我们的服务，如下面的屏幕截图所示：
- en: '![Figure 8.16 – The default web browser accessing the webserver Service’s NodePort
    port](img/B19845_08_16.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.16 – 默认网络浏览器访问 Web 服务器服务的 NodePort 端口](img/B19845_08_16.jpg)'
- en: Figure 8.16 – The default web browser accessing the webserver Service’s NodePort
    port
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 – 默认网络浏览器访问 Web 服务器服务的 NodePort 端口
- en: 'We can now remove all the resources created in this chapter. It is important
    to first remove the Pod, the Service, and then the namespace. Removing the namespace
    first triggers the removal of all associated resources in cascade, and there may
    be some issues if Kubernetes isn’t able to remove some resources. It will never
    happen in this simple lab, but it is a good practice to remove resources inside
    a namespace before deleting the namespace itself:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以移除本章中创建的所有资源。首先移除 Pod，然后移除 Service，最后移除命名空间是很重要的。先移除命名空间将触发级联删除所有关联资源，如果
    Kubernetes 无法删除某些资源可能会出现一些问题。在这个简单的实验中永远不会发生，但在删除命名空间本身之前移除命名空间内的资源是一个良好的做法：
- en: '[PRE29]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You are now ready to learn more advanced Kubernetes topics in the next chapter.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经准备好在下一章中学习更高级的 Kubernetes 主题了。
- en: Summary
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored Kubernetes, the most popular and extended container
    orchestrator. We had an overall architecture review, describing each component
    and how we can implement an environment with HA, and we learned the basics of
    some of the most important Kubernetes resources. To be able to prepare our applications
    to run in Kubernetes clusters, we learned some applications that will help us
    to implement fully functional Kubernetes environments on our desktop computers
    or laptops.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探索了 Kubernetes，这是最流行和扩展的容器编排器。我们进行了整体架构审查，描述了每个组件以及我们如何实现具有高可用性的环境，并学习了一些最重要的
    Kubernetes 资源的基础知识。为了能够准备我们的应用程序在 Kubernetes 集群中运行，我们学习了一些应用程序，这些应用程序将帮助我们在我们的台式计算机或笔记本电脑上实现完全功能的
    Kubernetes 环境。
- en: In the next chapter, we will deep dive into the resource types we will use to
    deploy our applications, reviewing interesting use cases and examples and learning
    different architecture patterns to apply to our applications’ components.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨我们将用于部署应用程序的资源类型，审查有趣的用例和示例，并学习应用于我们应用程序组件的不同架构模式。
- en: Part 3:Application Deployment
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：应用程序部署
- en: This part will describe how applications run in production, and we will use
    different models and Kubernetes features to help us deliver reliable applications
    securely.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分将描述应用程序在生产环境中的运行情况，我们将使用不同的模型和 Kubernetes 特性来帮助我们安全地交付可靠的应用程序。
- en: 'This part has the following chapters:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分包括以下章节：
- en: '[*Chapter 9*](B19845_09.xhtml#_idTextAnchor202), *Implementing Architecture
    Patterns*'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B19845_09.xhtml#_idTextAnchor202), *实施架构模式*'
- en: '[*Chapter 10*](B19845_10.xhtml#_idTextAnchor231), *Leveraging Application Data
    Management in Kubernetes*'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B19845_10.xhtml#_idTextAnchor231), *在 Kubernetes 中利用应用程序数据管理*'
- en: '[*Chapter 11*](B19845_11.xhtml#_idTextAnchor244), *Publishing Applications*'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B19845_11.xhtml#_idTextAnchor244), *发布应用程序*'
- en: '[*Chapter 12*](B19845_12.xhtml#_idTextAnchor267), *Gaining Application Insights*'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B19845_12.xhtml#_idTextAnchor267), *获取应用程序洞察*'
