<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer211">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">12</span></h1>
<h1 class="chapterTitle" id="_idParaDest-348"><span class="koboSpan" id="kobo.2.1">Data Engineering for Solution Architecture</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">In the previous chapter, you learned about the DevOps process, which automates the application deployment pipeline and fosters a culture of collaboration among development, operations, and security teams. </span><span class="koboSpan" id="kobo.3.2">This chapter will introduce you to data engineering, including the various tools and techniques used to collect data from different parts of your application to gain insights that can drive your business.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.4.1">Data is being generated everywhere with high velocity and volume in the internet and digitization era. </span><span class="koboSpan" id="kobo.4.2">Getting insights from these enormous amounts of data at a fast pace is challenging. </span><span class="koboSpan" id="kobo.4.3">We must continuously innovate to ingest, store, and process this data to derive business outcomes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.5.1">With the convergence of cloud, mobile, and social technologies, advancements in many fields, such as genomics and life sciences, are growing ever-increasingly. </span><span class="koboSpan" id="kobo.5.2">Tremendous value is found in mining this data for more insight. </span><span class="koboSpan" id="kobo.5.3">Modern stream processing systems must produce continual results based on data with high input rates at low latency.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.6.1">The concept of </span><em class="italic"><span class="koboSpan" id="kobo.7.1">big data</span></em><span class="koboSpan" id="kobo.8.1"> refers to more than just the collection and analysis of data. </span><span class="koboSpan" id="kobo.8.2">The actual value for organizations in their data can be used to gain insight and create competitive </span><a id="_idIndexMarker1542"/><span class="koboSpan" id="kobo.9.1">advantages. </span><span class="koboSpan" id="kobo.9.2">Not all big data solutions must end in visualization. </span><span class="koboSpan" id="kobo.9.3">Many solutions, such as </span><strong class="keyWord"><span class="koboSpan" id="kobo.10.1">machine learning</span></strong><span class="koboSpan" id="kobo.11.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.12.1">ML</span></strong><span class="koboSpan" id="kobo.13.1">) and other predictive analytics, feed these answers programmatically into other software or applications, extracting the information and responding as designed.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.14.1">As with most things, getting faster results costs more, and big data is no exception. </span><span class="koboSpan" id="kobo.14.2">Some answers might not be needed immediately, so the solution’s latency and throughput can be flexible enough to take hours to complete. </span><span class="koboSpan" id="kobo.14.3">Other responses, such as in predictive analytics, may be needed as soon as the data is available.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.15.1">In this chapter, you will learn about the following topics to handle and manage your big data needs:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.16.1">What is big data architecture?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.17.1">Designing big data processing pipelines</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.18.1">Data ingestion, storage, processing, and analytics</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.19.1">Visualizing data </span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.20.1">Designing big data architectures</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.21.1">Big data architecture best practices</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.22.1">By the end of this chapter, you will know how to design big data and analytics architecture. </span><span class="koboSpan" id="kobo.22.2">You will learn about the big data pipeline steps, including data ingestion, storage, processing, visualization, and architecture patterns.</span></p>
<h1 class="heading-1" id="_idParaDest-349"><span class="koboSpan" id="kobo.23.1">What is big data architecture?</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.24.1">The sheer volume of collected data can cause problems. </span><span class="koboSpan" id="kobo.24.2">With the accumulation of more and more data, managing and moving data along with its underlying big data infrastructure </span><a id="_idIndexMarker1543"/><span class="koboSpan" id="kobo.25.1">becomes increasingly difficult. </span><span class="koboSpan" id="kobo.25.2">The rise of cloud providers has facilitated the ability to move applications to the cloud. </span><span class="koboSpan" id="kobo.25.3">Multiple sources of data result in increased volumes, velocity, and variety. </span><span class="koboSpan" id="kobo.25.4">The following are some common computer-generated data sources:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.26.1">Application server logs</span></strong><span class="koboSpan" id="kobo.27.1">: Application </span><a id="_idIndexMarker1544"/><span class="koboSpan" id="kobo.28.1">logs and games</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.29.1">Clickstream logs</span></strong><span class="koboSpan" id="kobo.30.1">: From </span><a id="_idIndexMarker1545"/><span class="koboSpan" id="kobo.31.1">website clicks and browsing</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.32.1">Sensor data</span></strong><span class="koboSpan" id="kobo.33.1">: Weather, water, wind </span><a id="_idIndexMarker1546"/><span class="koboSpan" id="kobo.34.1">energy, and smart grids</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.35.1">Images and videos</span></strong><span class="koboSpan" id="kobo.36.1">: Traffic </span><a id="_idIndexMarker1547"/><span class="koboSpan" id="kobo.37.1">and security cameras</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.38.1">Computer-generated data can vary from semi-structured logs to unstructured binaries. </span><span class="koboSpan" id="kobo.38.2">Computer-generated data sources can produce pattern matching or correlations in data that generate recommendations for social networking and online gaming. </span><span class="koboSpan" id="kobo.38.3">You can also use computer-generated data, such as blogs, reviews, emails, pictures, and brand perceptions, to track applications or service behavior.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.39.1">Human-generated data includes email searches, natural language queries, sentiment analysis on products or companies, and product recommendations. </span><span class="koboSpan" id="kobo.39.2">Social graph analysis can produce </span><a id="_idIndexMarker1548"/><span class="koboSpan" id="kobo.40.1">product recommendations based on your circle of friends, jobs you may find interesting, or even reminders based on your circle of friends’ birthdays, anniversaries, and so on.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.41.1">Typical barriers you hear from analytics teams that prevent them from delivering the most value to their organizations are:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.42.1">Limited insight into customer experiences and operations</span></strong><span class="koboSpan" id="kobo.43.1">: To create new customer experiences, organizations need better visibility into their business. </span><span class="koboSpan" id="kobo.43.2">Complex and costly data collection, processing systems, and added scale costs require organizations to limit the types and amount of data they collect and analyze.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.44.1">Need to make quicker decisions</span></strong><span class="koboSpan" id="kobo.45.1">: This is a two-part problem:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.46.1">Traditional data systems are overwhelmed, resulting in workloads taking a long time to complete.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.47.1">More decisions need to be made in seconds or minutes, requiring systems to collect and process data in real time.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.48.1">Enabling innovation with ML</span></strong><span class="koboSpan" id="kobo.49.1">: Organizations are adding and growing their data science teams to help optimize and grow their business. </span><span class="koboSpan" id="kobo.49.2">These users need more access to data with their choice of tools without the traditional red tape and processes that will slow them down.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.50.1">Technical staff and cost to scale self-managed infrastructures</span></strong><span class="koboSpan" id="kobo.51.1">: Customers who manage infrastructure on-premises need help to quickly scale to meet business demand. </span><span class="koboSpan" id="kobo.51.2">Managing infrastructure, high availability, scaling, and operational monitoring takes time, especially at scale.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.52.1">In </span><strong class="keyWord"><span class="koboSpan" id="kobo.53.1">big data architecture</span></strong><span class="koboSpan" id="kobo.54.1">, the general flow of a significant data pipeline starts with data and ends with insight. </span><span class="koboSpan" id="kobo.54.2">How you get from start to finish depends on a lot of factors. </span><span class="koboSpan" id="kobo.54.3">The following diagram illustrates a data workflow pipeline that will help you design your data architecture:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.55.1"><img alt="" role="presentation" src="../Images/B21336_12_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.56.1">Figure 12.1: Big data pipeline for data architecture design</span></p>
<p class="normal"><span class="koboSpan" id="kobo.57.1">As shown </span><a id="_idIndexMarker1549"/><span class="koboSpan" id="kobo.58.1">in the preceding diagram, the standard workflow of the big data pipeline includes the following steps:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.59.1">Data is collected (ingested) by an appropriate tool.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.60.1">The data is stored persistently.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.61.1">The data is processed or analyzed. </span><span class="koboSpan" id="kobo.61.2">The data processing/analysis solution takes the data from storage, performs operations, and then stores the processed data again.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.62.1">The data is then used by other processing/analysis tools or by the same tool again to get further answers from the data.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.63.1">To make </span><a id="_idIndexMarker1550"/><span class="koboSpan" id="kobo.64.1">answers useful to business users, they are visualized using a </span><strong class="keyWord"><span class="koboSpan" id="kobo.65.1">business intelligence</span></strong><span class="koboSpan" id="kobo.66.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.67.1">BI</span></strong><span class="koboSpan" id="kobo.68.1">) tool or fed into an ML algorithm to make future predictions. </span><span class="koboSpan" id="kobo.68.2">Once the appropriate answers have been presented to the user, this gives them insight into the data they can use to make further business decisions.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.69.1">The tools you deploy in your pipeline determine your </span><em class="italic"><span class="koboSpan" id="kobo.70.1">time to answer</span></em><span class="koboSpan" id="kobo.71.1">, which is the latency between when your data was created and when you can get insight from it. </span><span class="koboSpan" id="kobo.71.2">The best way to architect data solutions while considering latency is to determine how to balance throughput with cost because a higher performance and reduced latency usually result in a higher price. </span><span class="koboSpan" id="kobo.71.3">For example, a financial trading platform requires real-time analytics to provide its users with immediate insights for quick decision making. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.72.1">To achieve this, the platform might employ an expensive data processing pipeline that includes in-memory databases, real-time stream processing, and high-speed data ingestion services. </span><span class="koboSpan" id="kobo.72.2">This setup ensures low latency, allowing traders to respond to market changes instantaneously. </span><span class="koboSpan" id="kobo.72.3">Here, the business necessity for real-time analytics justifies the high costs associated with the low-latency architecture.</span></p>
<h1 class="heading-1" id="_idParaDest-350"><span class="koboSpan" id="kobo.73.1">Designing big data processing pipelines</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.74.1">One of the critical mistakes many big data architectures make is handling multiple data pipeline </span><a id="_idIndexMarker1551"/><span class="koboSpan" id="kobo.75.1">stages with one tool. </span><span class="koboSpan" id="kobo.75.2">A fleet of servers managing the end-to-end data pipeline, from data storage and transformation to visualization, may be the most straightforward architecture, but it is also the most vulnerable to breakdowns in the pipeline. </span><span class="koboSpan" id="kobo.75.3">Such tightly coupled big data architecture typically does not provide the best possible balance of throughput and cost for your needs. </span><span class="koboSpan" id="kobo.75.4">When you are designing a data architecture, use FLAIR data principles as explained in the following:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.76.1">F – Findability</span></strong><span class="koboSpan" id="kobo.77.1">: This refers to the capability to easily locate available data assets and access their metadata, which includes information like ownership and data classification, along with other crucial attributes necessary for data governance and compliance.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.78.1">L – Lineage</span></strong><span class="koboSpan" id="kobo.79.1">: The ability to trace the origin of data, track its movement and history, and understand as well as visualize how data flows from its sources to its points of consumption.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.80.1">A – Accessibility</span></strong><span class="koboSpan" id="kobo.81.1">: This involves the facility to request and obtain security credentials that grant the right to access a specific data asset. </span><span class="koboSpan" id="kobo.81.2">It also implies the need for a networking infrastructure that supports efficient data access.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.82.1">I – Interoperability</span></strong><span class="koboSpan" id="kobo.83.1">: Ensuring that data is stored in formats that are accessible and usable by most, if not all, internal processing systems within the organization.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.84.1">R – Reusability</span></strong><span class="koboSpan" id="kobo.85.1">: Data should be documented with a known schema, and the source of </span><a id="_idIndexMarker1552"/><span class="koboSpan" id="kobo.86.1">the data should be clearly attributed. </span><span class="koboSpan" id="kobo.86.2">This aspect often includes principles of </span><strong class="keyWord"><span class="koboSpan" id="kobo.87.1">master data management</span></strong><span class="koboSpan" id="kobo.88.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.89.1">MDM</span></strong><span class="koboSpan" id="kobo.90.1">), which focuses on the management of critical data from different domains to provide, with accuracy and consistency, a single point of reference.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.91.1">Big data architects recommend decoupling the pipeline between ingestion, storage, processing, and getting insight. </span><span class="koboSpan" id="kobo.91.2">There are several advantages to decoupling storage and processing in multiple stages, including increased </span><em class="italic"><span class="koboSpan" id="kobo.92.1">fault tolerance</span></em><span class="koboSpan" id="kobo.93.1">. </span><span class="koboSpan" id="kobo.93.2">For example, if something goes wrong in the second round of processing and the hardware dedicated to that task fails, you won’t have to start again from the beginning of the pipeline; your system can resume from the second storage stage. </span><span class="koboSpan" id="kobo.93.3">Decoupling your storage from various processing tiers allows you to read and write to multiple data stores.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.94.1">The following </span><a id="_idIndexMarker1553"/><span class="koboSpan" id="kobo.95.1">diagram illustrates various tools and processes to consider when designing a big data architecture pipeline:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.96.1"><img alt="" role="presentation" src="../Images/B21336_12_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.97.1">Figure 12.2: Tools and processes for big data architecture design</span></p>
<p class="normal"><span class="koboSpan" id="kobo.98.1">The things you should consider when determining the right tools for your big data architectures include the following:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.99.1">The structure of your data</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.100.1">Maximum acceptable latency</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.101.1">Minimum acceptable throughput</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.102.1">Typical access patterns of your system’s end users</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.103.1">Your data structure impacts both the tools you use to process it and where you store it. </span><span class="koboSpan" id="kobo.103.2">The ordering of your data and the size of each object you’re storing and retrieving are also essential considerations. </span><span class="koboSpan" id="kobo.103.3">How your solution weighs latency/throughput and cost determines the time to answer.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.104.1">User access patterns are another essential component to consider. </span><span class="koboSpan" id="kobo.104.2">Some jobs require regularly </span><a id="_idIndexMarker1554"/><span class="koboSpan" id="kobo.105.1">joining many related tables, and others require daily or less frequent data storage. </span><span class="koboSpan" id="kobo.105.2">Some jobs require comparing data from a wide range of data sources, and other jobs pull data from only one unstructured table. </span><span class="koboSpan" id="kobo.105.3">Knowing how your end users will most often use the data will help you determine the breadth and depth of your big data architecture. </span><span class="koboSpan" id="kobo.105.4">Let’s dive deep into each process and the tools involved in big data architecture.</span></p>
<h1 class="heading-1" id="_idParaDest-351"><span class="koboSpan" id="kobo.106.1">Data ingestion, storage, processing, and analytics</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.107.1">To turn raw data into actionable intelligence that can inform decision making and strategic planning for businesses, data needs to be managed through several key stages, beginning with </span><strong class="keyWord"><span class="koboSpan" id="kobo.108.1">data ingestion</span></strong><span class="koboSpan" id="kobo.109.1">—the collection of data from various sources. </span><span class="koboSpan" id="kobo.109.2">This can include everything from user-generated data to machine logs, or real-time </span><a id="_idIndexMarker1555"/><span class="koboSpan" id="kobo.110.1">streaming data. </span><span class="koboSpan" id="kobo.110.2">Once collected, the data needs to be stored in </span><strong class="keyWord"><span class="koboSpan" id="kobo.111.1">data storage</span></strong><span class="koboSpan" id="kobo.112.1">, which can be done in databases, data lakes, or cloud storage solutions, depending on the data type and intended use.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.113.1">Following </span><a id="_idIndexMarker1556"/><span class="koboSpan" id="kobo.114.1">storage, </span><strong class="keyWord"><span class="koboSpan" id="kobo.115.1">data processing and analytics</span></strong><span class="koboSpan" id="kobo.116.1"> come into play, which involves </span><a id="_idIndexMarker1557"/><span class="koboSpan" id="kobo.117.1">sorting, aggregating, or transforming the data into a more usable form, where analytics can be performed on the processed data to extract meaningful insights. </span><span class="koboSpan" id="kobo.117.2">Analytics can range from simple queries and reporting to complex ML algorithms and predictive modeling. </span><span class="koboSpan" id="kobo.117.3">Let’s learn about these stages in detail.</span></p>
<h2 class="heading-2" id="_idParaDest-352"><span class="koboSpan" id="kobo.118.1">Data ingestion</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.119.1">Data ingestion is </span><a id="_idIndexMarker1558"/><span class="koboSpan" id="kobo.120.1">the act of collecting data for transfer and storage. </span><span class="koboSpan" id="kobo.120.2">There are lots of places from where data can be onboarded. </span><span class="koboSpan" id="kobo.120.3">Predominantly, data ingestion falls into one of the categories of databases, streams, logs, and files. </span><span class="koboSpan" id="kobo.120.4">Among these, databases are the most popular. </span><span class="koboSpan" id="kobo.120.5">These typically consist of your main upstream transactional systems that are the primary data storage for your applications. </span><span class="koboSpan" id="kobo.120.6">They take on both relational and non-relational flavors, and several techniques for extracting data from them exist.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.121.1">Streams are open-ended sequences of time-series data, such as clickstream data from websites or </span><strong class="keyWord"><span class="koboSpan" id="kobo.122.1">Internet of Things</span></strong><span class="koboSpan" id="kobo.123.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.124.1">IoT</span></strong><span class="koboSpan" id="kobo.125.1">) devices, usually published in an API we host. </span><span class="koboSpan" id="kobo.125.2">Applications, services, and operating systems generate logs. </span><span class="koboSpan" id="kobo.125.3">As shown in the following diagram, use the </span><a id="_idIndexMarker1559"/><span class="koboSpan" id="kobo.126.1">type of data your environment collects, and how it is collected, to determine what kind of ingestion solution is ideal for your needs:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.127.1"><img alt="" role="presentation" src="../Images/B21336_12_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.128.1">Figure 12.3: Type of data ingestion</span></p>
<p class="normal"><span class="koboSpan" id="kobo.129.1">As shown, transactional </span><a id="_idIndexMarker1560"/><span class="koboSpan" id="kobo.130.1">data storage must be able to store and retrieve data quickly. </span><span class="koboSpan" id="kobo.130.2">End users need quick and straightforward data access, making app and web </span><a id="_idIndexMarker1561"/><span class="koboSpan" id="kobo.131.1">servers the ideal ingestion methods. </span><span class="koboSpan" id="kobo.131.2">For the same reasons, NoSQL and </span><strong class="keyWord"><span class="koboSpan" id="kobo.132.1">relational database management system</span></strong><span class="koboSpan" id="kobo.133.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.134.1">RDBMS</span></strong><span class="koboSpan" id="kobo.135.1">) databases are usually the best solutions for these kinds of processes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.136.1">Data transmitted through individual files is typically ingested from connected devices. </span><span class="koboSpan" id="kobo.136.2">A large amount of file data does not require fast storage and retrieval compared to transactional data. </span><span class="koboSpan" id="kobo.136.3">For file data, often a transfer is one way, where data is produced by multiple resources and ingested into a single object or file storage for later use.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.137.1">Stream data such as clickstream logs should be ingested through an appropriate solution such as </span><strong class="keyWord"><span class="koboSpan" id="kobo.138.1">Apache Kafka</span></strong><span class="koboSpan" id="kobo.139.1"> or </span><strong class="keyWord"><span class="koboSpan" id="kobo.140.1">Fluentd</span></strong><span class="koboSpan" id="kobo.141.1">. </span><span class="koboSpan" id="kobo.141.2">Apache Kafka is a popular choice for this purpose, offering </span><a id="_idIndexMarker1562"/><span class="koboSpan" id="kobo.142.1">robust publish-subscribe capabilities that can handle massive </span><a id="_idIndexMarker1563"/><span class="koboSpan" id="kobo.143.1">amounts of data efficiently. </span><span class="koboSpan" id="kobo.143.2">Fluentd is another tool that can be used for data ingestion, particularly known for its log aggregation capabilities.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.144.1">Initially, these logs are stored in stream storage solutions such as Kafka, so they’re available for real-time processing and analysis. </span><span class="koboSpan" id="kobo.144.2">Long-term storage of these logs is best in a low-cost solution such as object storage.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.145.1">Streaming storage decouples your collection system (producers) from the processing system (consumers). </span><span class="koboSpan" id="kobo.145.2">It provides a persistent buffer for your incoming data. </span><span class="koboSpan" id="kobo.145.3">The data can be processed, and you can pump the data at a rate dependent on your needs. </span><span class="koboSpan" id="kobo.145.4">Let’s learn about some popular data ingestion technologies.</span></p>
<h3 class="heading-3" id="_idParaDest-353"><span class="koboSpan" id="kobo.146.1">Technology choices for data ingestion</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.147.1">Let’s look </span><a id="_idIndexMarker1564"/><span class="koboSpan" id="kobo.148.1">at some popular open source tools for data ingestion and transfer:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.149.1">Apache DistCp</span></strong><span class="koboSpan" id="kobo.150.1">: DistCp stands for </span><em class="italic"><span class="koboSpan" id="kobo.151.1">distributed copy</span></em><span class="koboSpan" id="kobo.152.1"> and is part of the Hadoop ecosystem. </span><span class="koboSpan" id="kobo.152.2">The DistCp tool is used to copy large data within a cluster or between </span><a id="_idIndexMarker1565"/><span class="koboSpan" id="kobo.153.1">clusters. </span><span class="koboSpan" id="kobo.153.2">DistCp achieves efficient and fast data copying by utilizing MapReduce’s parallel </span><a id="_idIndexMarker1566"/><span class="koboSpan" id="kobo.154.1">processing distribution capability. </span><span class="koboSpan" id="kobo.154.2">It distributes directories and files into map tasks to copy file partitions from source to target. </span><span class="koboSpan" id="kobo.154.3">DistCp also does error handling, recovery, and reporting across clusters.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.155.1">Apache Sqoop</span></strong><span class="koboSpan" id="kobo.156.1">: Sqoop is also part of the Hadoop ecosystem project and helps to </span><a id="_idIndexMarker1567"/><span class="koboSpan" id="kobo.157.1">transfer data between Hadoop and relational data stores such as RDBMS. </span><span class="koboSpan" id="kobo.157.2">Sqoop allows </span><a id="_idIndexMarker1568"/><span class="koboSpan" id="kobo.158.1">you to import data from a structured data store into the </span><strong class="keyWord"><span class="koboSpan" id="kobo.159.1">Hadoop Distributed File System</span></strong><span class="koboSpan" id="kobo.160.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.161.1">HDFS</span></strong><span class="koboSpan" id="kobo.162.1">) and to export data from the </span><a id="_idIndexMarker1569"/><span class="koboSpan" id="kobo.163.1">HDFS into a structured data store. </span><span class="koboSpan" id="kobo.163.2">Sqoop uses plugin connectors to connect to relational databases. </span><span class="koboSpan" id="kobo.163.3">You can use the Sqoop extension API to build a new connector or use one of the included connectors that support data exchange between Hadoop and standard relational database systems.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.164.1">Apache Flume</span></strong><span class="koboSpan" id="kobo.165.1">: Flume is open source software mainly used to ingest a large amount </span><a id="_idIndexMarker1570"/><span class="koboSpan" id="kobo.166.1">of log data. </span><span class="koboSpan" id="kobo.166.2">Apache Flume collects and aggregates </span><a id="_idIndexMarker1571"/><span class="koboSpan" id="kobo.167.1">data to Hadoop reliably and distributes it. </span><span class="koboSpan" id="kobo.167.2">Flume facilitates streaming data ingestion and allows analytics.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.168.1">More open source projects, such as Apache Storm and Apache Samza, are available for streaming to process unbounded data streams reliably.</span></p>
<h3 class="heading-3" id="_idParaDest-354"><span class="koboSpan" id="kobo.169.1">Ingesting data to the cloud</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.170.1">Ingesting data into the cloud is critical to managing and leveraging big data. </span><span class="koboSpan" id="kobo.170.2">The three major </span><a id="_idIndexMarker1572"/><span class="koboSpan" id="kobo.171.1">cloud providers—AWS, </span><strong class="keyWord"><span class="koboSpan" id="kobo.172.1">Google Cloud Platform</span></strong><span class="koboSpan" id="kobo.173.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.174.1">GCP</span></strong><span class="koboSpan" id="kobo.175.1">), and Azure—offer </span><a id="_idIndexMarker1573"/><span class="koboSpan" id="kobo.176.1">various data ingestion services. </span><span class="koboSpan" id="kobo.176.2">Each has unique features and capabilities tailored to different needs and data volumes. </span><span class="koboSpan" id="kobo.176.3">Let’s look </span><a id="_idIndexMarker1574"/><span class="koboSpan" id="kobo.177.1">at some of the unique </span><a id="_idIndexMarker1575"/><span class="koboSpan" id="kobo.178.1">features of these three cloud providers:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.179.1">AWS data ingestion services:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.180.1">AWS Direct Connect</span></strong><span class="koboSpan" id="kobo.181.1">: This offers a high-speed, private network connection to AWS, reducing latency and increasing bandwidth. </span><span class="koboSpan" id="kobo.181.2">It’s ideal for transferring large volumes of data and provides a more consistent network speed than internet-based transfers.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.182.1">AWS Snowball and Snowmobile</span></strong><span class="koboSpan" id="kobo.183.1">: These services provide physical devices for transferring vast volumes of data (in terabytes and </span><strong class="keyWord"><span class="koboSpan" id="kobo.184.1">petabytes</span></strong><span class="koboSpan" id="kobo.185.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.186.1">PBs</span></strong><span class="koboSpan" id="kobo.187.1">)) to AWS. </span><span class="koboSpan" id="kobo.187.2">Snowball is suitable for hundreds of terabytes, while Snowmobile can handle up to 100 PBs in a single transfer, ideal for huge datasets.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.188.1">AWS Database Migration Service (DMS)</span></strong><span class="koboSpan" id="kobo.189.1">: This facilitates the migration of databases to AWS. </span><span class="koboSpan" id="kobo.189.2">It supports both homogeneous and heterogeneous </span><a id="_idIndexMarker1576"/><span class="koboSpan" id="kobo.190.1">migrations and can handle ongoing data replication through </span><strong class="keyWord"><span class="koboSpan" id="kobo.191.1">change data capture</span></strong><span class="koboSpan" id="kobo.192.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.193.1">CDC</span></strong><span class="koboSpan" id="kobo.194.1">).</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.195.1">GCP </span><a id="_idIndexMarker1577"/><span class="koboSpan" id="kobo.196.1">data </span><a id="_idIndexMarker1578"/><span class="koboSpan" id="kobo.197.1">ingestion services:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.198.1">Google Cloud Storage Transfer Service</span></strong><span class="koboSpan" id="kobo.199.1">: This allows for the transfer of large volumes of data to Google Cloud Storage from online data sources like Amazon S3 and HTTP/HTTPS locations, as well as from on-premises data storage.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.200.1">Pub/Sub</span></strong><span class="koboSpan" id="kobo.201.1">: This offers real-time messaging and streaming data ingestion. </span><span class="koboSpan" id="kobo.201.2">It’s a scalable and flexible service that enables the ingestion </span><a id="_idIndexMarker1579"/><span class="koboSpan" id="kobo.202.1">of streaming data like logs and </span><a id="_idIndexMarker1580"/><span class="koboSpan" id="kobo.203.1">event data for real-time analytics.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.204.1">Dataflow</span></strong><span class="koboSpan" id="kobo.205.1">: An integrated </span><a id="_idIndexMarker1581"/><span class="koboSpan" id="kobo.206.1">service for both data ingestion and processing. </span><span class="koboSpan" id="kobo.206.2">It’s handy for </span><strong class="keyWord"><span class="koboSpan" id="kobo.207.1">extract, transform, and load</span></strong><span class="koboSpan" id="kobo.208.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.209.1">ETL</span></strong><span class="koboSpan" id="kobo.210.1">) tasks and real-time event stream processing.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.211.1">Azure </span><a id="_idIndexMarker1582"/><span class="koboSpan" id="kobo.212.1">data ingestion services:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.213.1">Azure Data Factory</span></strong><span class="koboSpan" id="kobo.214.1">: This data integration service supports both on-premises </span><a id="_idIndexMarker1583"/><span class="koboSpan" id="kobo.215.1">and cloud data movements and transformations. </span><span class="koboSpan" id="kobo.215.2">It enables the ingestion of data from a variety of sources, processing it using computing services like Azure HDInsight and Azure Batch, and subsequently publishing the processed data to storage solutions such as Azure SQL Data Warehouse.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.216.1">Azure Event Hubs</span></strong><span class="koboSpan" id="kobo.217.1">: A robust and scalable data streaming platform and event ingestion service, Azure Event Hubs is capable of handling millions of events per second. </span><span class="koboSpan" id="kobo.217.2">This makes it an ideal solution for real-time analytics on data originating from various sources like applications, websites, or IoT devices.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.218.1">Azure Import/Export service</span></strong><span class="koboSpan" id="kobo.219.1">: This service is designed for the bulk transfer of large data volumes to and from Azure Blob Storage and Azure Files. </span><span class="koboSpan" id="kobo.219.2">It leverages physical disks for data transfer, making it a viable option for situations where transferring large amounts of data over a network might be too slow or expensive.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.220.1">Each cloud provider offers a unique set of tools to meet various data ingestion needs, from real-time streaming to large-scale data migration, ensuring flexibility and scalability in big data management.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.221.1">Streaming data is also becoming very important to ingest and analyze. </span><span class="koboSpan" id="kobo.221.2">You will learn more about streaming data in the </span><em class="italic"><span class="koboSpan" id="kobo.222.1">Streaming data stores</span></em><span class="koboSpan" id="kobo.223.1"> section. </span><span class="koboSpan" id="kobo.223.2">Let’s learn more about the techniques you can use to choose the right storage and the available storage choices.</span></p>
<h2 class="heading-2" id="_idParaDest-355"><span class="koboSpan" id="kobo.224.1">Storing data</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.225.1">One of the most common mistakes when setting up storage for a big data environment is using one solution, frequently an RDBMS, to handle all of your data storage requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.226.1">You will </span><a id="_idIndexMarker1584"/><span class="koboSpan" id="kobo.227.1">have many tools available, but they need to be optimized for the task they need to complete. </span><span class="koboSpan" id="kobo.227.2">One solution is not necessarily the best for all of your needs; the best solution for your environment might be a combination of storage solutions that carefully balance latency with cost. </span><span class="koboSpan" id="kobo.227.3">An ideal storage solution uses the right tool for the right job. </span><span class="koboSpan" id="kobo.227.4">The following diagram combines multiple factors related to your data and the storage choice associated with it:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.228.1"><img alt="" role="presentation" src="../Images/B21336_12_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.229.1">Figure 12.4: Understanding data storage</span></p>
<p class="normal"><span class="koboSpan" id="kobo.230.1">As shown in the proceeding diagram, choosing a data store depends upon the following factors:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.231.1">How structured is your data?</span></strong><span class="koboSpan" id="kobo.232.1"> Does it adhere to a specific, well-formed schema, as with Apache weblogs (logs are generally poorly structured and unsuitable for relational databases), standardized data protocols, and contractual interfaces? </span><span class="koboSpan" id="kobo.232.2">Is it completely arbitrary binary data, as in images, audio, video, and PDF documents? </span><span class="koboSpan" id="kobo.232.3">Or is it semi-structured with a general structure but potentially high variability across the records, as in JSON or CSV?</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.233.1">How quickly does new data need to be available for querying?</span></strong><span class="koboSpan" id="kobo.234.1"> Is it a real-time scenario where decisions are made as new records stream in, such as campaign </span><a id="_idIndexMarker1585"/><span class="koboSpan" id="kobo.235.1">managers adjusting based on conversion rates or a website making product recommendations based on user behavior similarity? </span><span class="koboSpan" id="kobo.235.2">Is it a daily, weekly, or monthly batch scenario, such as model training, financial statement preparation, or product performance reporting? </span><span class="koboSpan" id="kobo.235.3">Or is it somewhere in between, such as with user engagement emails, where it doesn’t require real-time action, and you can have a buffer of a few minutes or even a few hours between the user action and the touchpoint?</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.236.1">What is the size of the data ingest?</span></strong><span class="koboSpan" id="kobo.237.1"> Is the data ingested recorded by the record as data comes in, such as with JSON payloads from REST APIs that measure at least a few KBs at best? </span><span class="koboSpan" id="kobo.237.2">Is it a large batch of records arriving simultaneously, such as system integrations and third-party data feeds? </span><span class="koboSpan" id="kobo.237.3">Or is it somewhere in between, such as with a few micro-batches of clickstream data aggregated together for more efficient processing?</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.238.1">What is the total volume of data and its growth rate?</span></strong><span class="koboSpan" id="kobo.239.1"> Are you in GBs and TBs, or do you intend to store data in PBs or </span><strong class="keyWord"><span class="koboSpan" id="kobo.240.1">exabytes</span></strong><span class="koboSpan" id="kobo.241.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.242.1">EBs</span></strong><span class="koboSpan" id="kobo.243.1">)? </span><span class="koboSpan" id="kobo.243.2">How much of this data is required for your specific analytics use cases? </span><span class="koboSpan" id="kobo.243.3">Do most of your queries only require a specific rolling window of time? </span><span class="koboSpan" id="kobo.243.4">Or, do you need a mechanism to query the entirety of your historical dataset?</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.244.1">What will the cost be to store and query the data in any particular location</span></strong><span class="koboSpan" id="kobo.245.1">? </span><span class="koboSpan" id="kobo.245.2">When it comes to any computing environment, we generally see a </span><em class="italic"><span class="koboSpan" id="kobo.246.1">triangle of constraints</span></em><span class="koboSpan" id="kobo.247.1"> between performance, resilience, and low cost. </span><span class="koboSpan" id="kobo.247.2">The better the performance and the higher the resilience you want your storage to have, the more expensive it will be. </span><span class="koboSpan" id="kobo.247.3">You can have quick queries over PBs of data but settle on querying TBs of data in a compressed format to meet your cost requirements.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.248.1">Finally, what type of analytic queries will run against the data? </span><span class="koboSpan" id="kobo.248.2">Will it power a dashboard with a fixed set of metrics and drill down? </span><span class="koboSpan" id="kobo.248.3">Will it participate in large numerical aggregations rolled up by various business dimensions? </span><span class="koboSpan" id="kobo.248.4">Or will it be used for diagnostics, leveraging string tokenization for full-text searching and pattern analysis?</span></p>
<p class="normal"><span class="koboSpan" id="kobo.249.1">When you determine your data’s characteristics and understand the data structure, you can assess which solution you need to use for your data storage. </span><span class="koboSpan" id="kobo.249.2">Let’s learn about the various solutions for storing data.</span></p>
<h3 class="heading-3" id="_idParaDest-356"><span class="koboSpan" id="kobo.250.1">Technology choices for data storage</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.251.1">As we discussed, a single tool can only do a few things. </span><span class="koboSpan" id="kobo.251.2">It would be best if you used the right tool for </span><a id="_idIndexMarker1586"/><span class="koboSpan" id="kobo.252.1">the right job, and a data lake enables you to build a highly configurable big data architecture to meet your specific needs. </span><span class="koboSpan" id="kobo.252.2">Business problems need to be narrower, deeper, and more complex for one tool to solve everything, especially big data and analytics.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.253.1">For example, hot data will need to be stored and processed in memory, so caches or in-memory databases like Redis or SAP HANA are appropriate. </span><span class="koboSpan" id="kobo.253.2">AWS offers the ElastiCache service, providing a managed Redis or memcached environment. </span><span class="koboSpan" id="kobo.253.3">NoSQL databases are ideal when facing high-velocity but small-sized records, for example, user-session information or IoT data. </span><span class="koboSpan" id="kobo.253.4">NoSQL databases are also useful for content management to store data catalogs. </span><span class="koboSpan" id="kobo.253.5">Let’s learn about the most popular and commonly used storage for structured data.</span></p>
<h3 class="heading-3" id="_idParaDest-357"><span class="koboSpan" id="kobo.254.1">Structured data stores</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.255.1">Structured data stores have been around for decades and are the most familiar technology </span><a id="_idIndexMarker1587"/><span class="koboSpan" id="kobo.256.1">choice for storing data. </span><span class="koboSpan" id="kobo.256.2">Most transactional databases such as Oracle, MySQL, SQL Server, and PostgreSQL are row-based due </span><a id="_idIndexMarker1588"/><span class="koboSpan" id="kobo.257.1">to dealing with frequent data writes from software applications. </span><span class="koboSpan" id="kobo.257.2">Organizations often repurpose transactional databases for reporting purposes, requiring frequent data reads but much fewer data writes. </span><span class="koboSpan" id="kobo.257.3">Looking at high data-read requirements, more innovation is coming into querying on structured data stores, such as the columnar file format, which helps to enhance data-read performance for analytics requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.258.1">Row-based formats store the data in rows in a file. </span><span class="koboSpan" id="kobo.258.2">Row-based writing is the fastest way to write the data to the disk, but it is not necessarily the quickest read option because you need to skip over a lot of irrelevant data. </span><span class="koboSpan" id="kobo.258.3">Column-based formats store all the column values together in the file. </span><span class="koboSpan" id="kobo.258.4">This leads to better compression because the same data types are grouped. </span><span class="koboSpan" id="kobo.258.5">It also typically provides better read performance because you can skip columns that are not required.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.259.1">Let’s look at common choices for the structured data store. </span><span class="koboSpan" id="kobo.259.2">For example, you need to query the total number of sales in a given month from the order table, which has fifty columns. </span><span class="koboSpan" id="kobo.259.3">The query </span><a id="_idIndexMarker1589"/><span class="koboSpan" id="kobo.260.1">will scan the entire table with all fifty columns in </span><a id="_idIndexMarker1590"/><span class="koboSpan" id="kobo.261.1">a row-based architecture. </span><span class="koboSpan" id="kobo.261.2">In columnar architecture, the query will scan the order sales column, thus improving data query performance. </span><span class="koboSpan" id="kobo.261.3">Let’s look into more details about relational databases, focusing on transaction data and data warehousing to handle data analytics needs.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.262.1">Relational databases</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.263.1">A RDBMS is more </span><a id="_idIndexMarker1591"/><span class="koboSpan" id="kobo.264.1">suitable for </span><strong class="keyWord"><span class="koboSpan" id="kobo.265.1">online transaction processing</span></strong><span class="koboSpan" id="kobo.266.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.267.1">OLTP</span></strong><span class="koboSpan" id="kobo.268.1">) applications. </span><span class="koboSpan" id="kobo.268.2">Some popular relational databases are Oracle, MSSQL, MariaDB, PostgreSQL, and so on. </span><span class="koboSpan" id="kobo.268.3">Some of these traditional databases have been </span><a id="_idIndexMarker1592"/><span class="koboSpan" id="kobo.269.1">around for decades. </span><span class="koboSpan" id="kobo.269.2">Many applications, including e-commerce, banking, and hotel booking, are backed by relational databases. </span><span class="koboSpan" id="kobo.269.3">Relational </span><a id="_idIndexMarker1593"/><span class="koboSpan" id="kobo.270.1">databases are very good at handling transaction data where complex joint queries between tables are required. </span><span class="koboSpan" id="kobo.270.2">Looking </span><a id="_idIndexMarker1594"/><span class="koboSpan" id="kobo.271.1">at transaction data needs, the relational database should adhere to the </span><strong class="keyWord"><span class="koboSpan" id="kobo.272.1">atomicity, consistency, isolation, and durability</span></strong><span class="koboSpan" id="kobo.273.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.274.1">ACID</span></strong><span class="koboSpan" id="kobo.275.1">) principles as follows:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.276.1">Atomicity</span></strong><span class="koboSpan" id="kobo.277.1">: Atomicity means the transaction will be executed fully from end to end, and, in the case of any error, the entire transaction will roll back.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.278.1">Consistency</span></strong><span class="koboSpan" id="kobo.279.1">: Consistency means that all data should be committed to the database when transactions are completed.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.280.1">Isolation</span></strong><span class="koboSpan" id="kobo.281.1">: Isolation requires multiple transactions to run concurrently in isolation without interfering with each other.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.282.1">Durability</span></strong><span class="koboSpan" id="kobo.283.1">: In case of any interruption, such as a network or power failure, the transaction should be able to resume to the last known state.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.284.1">Data from relational databases is often offloaded to data warehousing solutions for reporting and aggregation purposes. </span><span class="koboSpan" id="kobo.284.2">Let’s learn more about data warehousing.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.285.1">Data warehousing</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.286.1">Data </span><a id="_idIndexMarker1595"/><span class="koboSpan" id="kobo.287.1">warehouses are central repositories </span><a id="_idIndexMarker1596"/><span class="koboSpan" id="kobo.288.1">that store accumulations of data from one or multiple sources. </span><span class="koboSpan" id="kobo.288.2">They store current and historical data to help create analytical reports for business data analytics. </span><span class="koboSpan" id="kobo.288.3">However, data warehouses store data centrally from various systems, but they cannot be treated as data lakes. </span><span class="koboSpan" id="kobo.288.4">Data warehouses handle only structured relational data, while data lakes work with structured and unstructured data, such as JSON logs and CSV data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.289.1">Data warehouse databases are more suitable for </span><strong class="keyWord"><span class="koboSpan" id="kobo.290.1">online analytical processing</span></strong><span class="koboSpan" id="kobo.291.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.292.1">OLAP</span></strong><span class="koboSpan" id="kobo.293.1">) applications. </span><span class="koboSpan" id="kobo.293.2">These databases are optimized for operations that involve reading large amounts of data, allowing for the aggregation and summarization of data to extract valuable business insights.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.294.1">Take, for example, a banking scenario where a bank maintains a data warehouse that stores comprehensive information about customer accounts, transactions, loan details, and branch information. </span><span class="koboSpan" id="kobo.294.2">Additionally, the bank collects and stores data on customer interactions, service usage, and online banking activities in a related system.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.295.1">Through OLAP, the bank can perform complex analyses of this combined data. </span><span class="koboSpan" id="kobo.295.2">It can query the data </span><a id="_idIndexMarker1597"/><span class="koboSpan" id="kobo.296.1">warehouse to uncover trends, such as identifying </span><a id="_idIndexMarker1598"/><span class="koboSpan" id="kobo.297.1">the most popular types of accounts or loans, analyzing transaction volumes over time, or assessing the usage patterns of online versus in-branch banking services. </span><span class="koboSpan" id="kobo.297.2">This analytical capability enables the bank to make informed decisions on product offerings, customer service improvements, and operational strategies, ultimately enhancing customer satisfaction and driving business growth.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.298.1">Data warehouses provide fast aggregation capabilities over vast volumes of structured data. </span><span class="koboSpan" id="kobo.298.2">While these </span><a id="_idIndexMarker1599"/><span class="koboSpan" id="kobo.299.1">technologies, such as Amazon </span><strong class="keyWord"><span class="koboSpan" id="kobo.300.1">Redshift</span></strong><span class="koboSpan" id="kobo.301.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.302.1">Netezza</span></strong><span class="koboSpan" id="kobo.303.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.304.1">Teradata</span></strong><span class="koboSpan" id="kobo.305.1">, are designed </span><a id="_idIndexMarker1600"/><span class="koboSpan" id="kobo.306.1">to execute complex aggregate queries quickly, they must be </span><a id="_idIndexMarker1601"/><span class="koboSpan" id="kobo.307.1">optimized for high volumes of concurrent writes. </span><span class="koboSpan" id="kobo.307.2">So, data needs to be loaded in batches, preventing warehouses from serving real-time insights over hot data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.308.1">Modern data warehouses use a columnar base to enhance query performance. </span><span class="koboSpan" id="kobo.308.2">Examples of this include Amazon Redshift, Snowflake, and Google BigQuery. </span><span class="koboSpan" id="kobo.308.3">These data warehouses provide fast query performance due to columnar storage and improved I/O efficiency. </span><span class="koboSpan" id="kobo.308.4">In addition, data warehouse systems such as Amazon Redshift increase query performance </span><a id="_idIndexMarker1602"/><span class="koboSpan" id="kobo.309.1">by parallelizing queries across multiple nodes and taking advantage of </span><strong class="keyWord"><span class="koboSpan" id="kobo.310.1">massively parallel processing</span></strong><span class="koboSpan" id="kobo.311.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.312.1">MPP</span></strong><span class="koboSpan" id="kobo.313.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.314.1">Columnar storage enhances query performance by storing data in columns rather than rows, enabling improved data compression, selective data reading, and faster operations. </span><span class="koboSpan" id="kobo.314.2">This approach allows for more effective compression as similar data is stored sequentially, facilitating faster data retrieval as only necessary columns are accessed during queries. </span><span class="koboSpan" id="kobo.314.3">It also optimizes CPU cache utilization by loading relevant data into memory, enhancing the processing speed. </span><span class="koboSpan" id="kobo.314.4">Additionally, columnar storage supports massive parallel processing, where multiple processors can work on different data segments simultaneously, significantly boosting performance for analytical tasks that involve large datasets and require quick aggregation and filtering.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.315.1">Data warehouse solutions such as Amazon Redshift can process PBs of data and provide decoupled compute and storage capabilities to save costs. </span><span class="koboSpan" id="kobo.315.2">In addition to columnar storage, Redshift uses data encoding, distribution, and zone maps to increase query performance. </span><span class="koboSpan" id="kobo.315.3">More traditional row-based data warehousing solutions include Netezza, Teradata, and Greenplum.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.316.1">Data warehouses </span><a id="_idIndexMarker1603"/><span class="koboSpan" id="kobo.317.1">lead to the physical separation </span><a id="_idIndexMarker1604"/><span class="koboSpan" id="kobo.318.1">of data from different applications, necessitating data architects to construct new infrastructures around these warehouses. </span><span class="koboSpan" id="kobo.318.2">The constraints of traditional data warehouses have become more pronounced with the growing diversity of enterprise data, including text, IoT data, images, audio, and video. </span><span class="koboSpan" id="kobo.318.3">Moreover, the advent </span><a id="_idIndexMarker1605"/><span class="koboSpan" id="kobo.319.1">of ML and </span><strong class="keyWord"><span class="koboSpan" id="kobo.320.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.321.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.322.1">AI</span></strong><span class="koboSpan" id="kobo.323.1">) has brought forth iterative algorithms that demand direct data access and do not rely on SQL, thus highlighting the limitations of conventional data warehouse models. </span><span class="koboSpan" id="kobo.323.2">You will learn more about overcoming these challenges later in this chapter, in the </span><em class="italic"><span class="koboSpan" id="kobo.324.1">Designing big data architectures</span></em><span class="koboSpan" id="kobo.325.1"> section.</span></p>
<h3 class="heading-3" id="_idParaDest-358"><span class="koboSpan" id="kobo.326.1">NoSQL databases</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.327.1">NoSQL databases such as DynamoDB, Cassandra, and MongoDB address the scaling and performance </span><a id="_idIndexMarker1606"/><span class="koboSpan" id="kobo.328.1">challenges you often experience with a relational database. </span><span class="koboSpan" id="kobo.328.2">As the name suggests, NoSQL is a non-relational database. </span><span class="koboSpan" id="kobo.328.3">NoSQL databases store data </span><a id="_idIndexMarker1607"/><span class="koboSpan" id="kobo.329.1">without an explicit and structured mechanism to link data from different tables (no joins, foreign keys, or normalization enforced).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.330.1">NoSQL utilizes several data models, including columnar, key-value, search, document, and graph. </span><span class="koboSpan" id="kobo.330.2">NoSQL databases provide scalable performance, high availability, and resilience. </span><span class="koboSpan" id="kobo.330.3">NoSQL typically does not enforce a strict schema, and every item can have an arbitrary number of columns (attributes), meaning one row can have four columns. </span><span class="koboSpan" id="kobo.330.4">In contrast, another can have ten columns in the same table. </span><span class="koboSpan" id="kobo.330.5">The partition key is used to retrieve values or documents containing related attributes. </span><span class="koboSpan" id="kobo.330.6">NoSQL databases are highly distributed and can be replicated. </span><span class="koboSpan" id="kobo.330.7">They are durable and don’t experience performance issues when highly available.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.331.1">SQL versus NoSQL databases</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.332.1">SQL databases </span><a id="_idIndexMarker1608"/><span class="koboSpan" id="kobo.333.1">have existed for decades, and most </span><a id="_idIndexMarker1609"/><span class="koboSpan" id="kobo.334.1">are already familiar with relational databases. </span><span class="koboSpan" id="kobo.334.2">Let’s learn about some significant differences between SQL and NoSQL databases:</span></p>
<table class="table-container" id="table001-5">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.335.1">Properties</span></strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.336.1">SQL Databases</span></strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.337.1">NoSQL Databases</span></strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.338.1">Data model</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.339.1">The relational model normalizes data in SQL databases into tables containing rows and columns. </span><span class="koboSpan" id="kobo.339.2">A schema includes tables, columns, relationships between tables, indexes, and other database elements.</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.340.1">NoSQL databases operate without enforcing a fixed schema, offering flexibility in data storage and retrieval. </span><span class="koboSpan" id="kobo.340.2">They often utilize a partition key to access values from sets of columns. </span><span class="koboSpan" id="kobo.340.3">This type of database is well-suited for storing semi-structured data, including formats like JSON, XML, and various other document types, such as data catalogs and file indexes.</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.341.1">Transaction</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.342.1">SQL-based traditional RDBMSs support and comply with ACID transactional data properties.</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.343.1">NoSQL databases sometimes trade certain ACID properties, which are characteristic of traditional RDBMSs, in order to facilitate horizontal scaling and enhance flexibility in their data models.</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.344.1">Performance</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.345.1">SQL-based RDBMSs were used to optimize storage when storage was expensive and minimize the disk footprint. </span><span class="koboSpan" id="kobo.345.2">For traditional RDBMSs, performance has mostly relied on the disk. </span><span class="koboSpan" id="kobo.345.3">Index creation and table structure modifications are required to achieve performance query optimizations.</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.346.1">In NoSQL systems, the performance is significantly influenced by factors such as the size of the underlying hardware cluster, network latency, and the manner in which the application interacts with the database.</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.347.1">Scale</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.348.1">SQL-based RDBMS databases are most straightforward to scale vertically with high-configuration hardware. </span><span class="koboSpan" id="kobo.348.2">The additional effort requires relational tables to span distributed systems, such as performing data sharding.</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.349.1">NoSQL databases are engineered to scale out horizontally, utilizing distributed clusters composed of cost-effective hardware. </span><span class="koboSpan" id="kobo.349.2">This approach is aimed at boosting throughput while minimizing any impact on latency.</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.350.1">Table 12.1 – SQL versus NoSQL database comparison</span></p>
<p class="normal"><span class="koboSpan" id="kobo.351.1">Depending </span><a id="_idIndexMarker1610"/><span class="koboSpan" id="kobo.352.1">on your data, various categories </span><a id="_idIndexMarker1611"/><span class="koboSpan" id="kobo.353.1">of NoSQL data stores exist to solve a specific problem. </span><span class="koboSpan" id="kobo.353.2">Let’s learn about the types of NoSQL databases.</span></p>
<h4 class="heading-4"><span class="koboSpan" id="kobo.354.1">Types of NoSQL databases</span></h4>
<p class="normal"><span class="koboSpan" id="kobo.355.1">The following </span><a id="_idIndexMarker1612"/><span class="koboSpan" id="kobo.356.1">are the major NoSQL database types:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.357.1">Columnar databases</span></strong><span class="koboSpan" id="kobo.358.1">: Apache Cassandra and Apache HBase are the popular columnar databases. </span><span class="koboSpan" id="kobo.358.2">A columnar data store helps you scan a particular column when querying the data rather than scanning the entire row. </span><span class="koboSpan" id="kobo.358.3">Suppose an item table has ten columns with one million rows, and you want to query the number of items available in inventory. </span><span class="koboSpan" id="kobo.358.4">In that case, the columnar database will apply the query to the item quantity column rather than scanning the entire table.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.359.1">Document databases</span></strong><span class="koboSpan" id="kobo.360.1">: Some of the most popular document databases are </span><strong class="keyWord"><span class="koboSpan" id="kobo.361.1">MongoDB</span></strong><span class="koboSpan" id="kobo.362.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.363.1">Couchbase</span></strong><span class="koboSpan" id="kobo.364.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.365.1">MarkLogic</span></strong><span class="koboSpan" id="kobo.366.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.367.1">DynamoDB</span></strong><span class="koboSpan" id="kobo.368.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.369.1">DocumentDB</span></strong><span class="koboSpan" id="kobo.370.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.371.1">Cassandra</span></strong><span class="koboSpan" id="kobo.372.1">. </span><span class="koboSpan" id="kobo.372.2">You can use a document database to store semi-structured data in JSON and XML formats.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.373.1">Graph databases</span></strong><span class="koboSpan" id="kobo.374.1">: Popular graph database choices include </span><strong class="keyWord"><span class="koboSpan" id="kobo.375.1">Amazon Neptune</span></strong><span class="koboSpan" id="kobo.376.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.377.1">JanusGraph</span></strong><span class="koboSpan" id="kobo.378.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.379.1">TinkerPop</span></strong><span class="koboSpan" id="kobo.380.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.381.1">Neo4j</span></strong><span class="koboSpan" id="kobo.382.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.383.1">OrientDB</span></strong><span class="koboSpan" id="kobo.384.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.385.1">GraphDB</span></strong><span class="koboSpan" id="kobo.386.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.387.1">GraphX</span></strong><span class="koboSpan" id="kobo.388.1"> in Spark. </span><span class="koboSpan" id="kobo.388.2">A graph database stores vertices and links between vertices called </span><strong class="keyWord"><span class="koboSpan" id="kobo.389.1">edges</span></strong><span class="koboSpan" id="kobo.390.1">. </span><span class="koboSpan" id="kobo.390.2">Graphs can be built on both relational and non-relational databases.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.391.1">In-memory key-value stores</span></strong><span class="koboSpan" id="kobo.392.1">: Some of the most popular in-memory key-value stores are Redis and Memcached. </span><span class="koboSpan" id="kobo.392.2">They store data in memory for heavy reading applications. </span><span class="koboSpan" id="kobo.392.3">Any query from an application first goes to an in-memory database, and if the data is available in the cache, it doesn’t hit the master database. </span><span class="koboSpan" id="kobo.392.4">The in-memory database is suitable for storing user-session information, which results in complex queries and frequently requests data such as user profiles.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.393.1">NoSQL has many use cases, but you must index all your data to build a search. </span><span class="koboSpan" id="kobo.393.2">Let’s learn more about search data stores.</span></p>
<h3 class="heading-3" id="_idParaDest-359"><span class="koboSpan" id="kobo.394.1">Search data stores</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.395.1">The Elasticsearch service is one of the most popular search engines for big data use cases like </span><a id="_idIndexMarker1613"/><span class="koboSpan" id="kobo.396.1">clickstream and log analysis. </span><span class="koboSpan" id="kobo.396.2">Search engines work well for warm data that can be queried ad hoc across any number of attributes, including string tokens.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.397.1">Amazon </span><a id="_idIndexMarker1614"/><span class="koboSpan" id="kobo.398.1">OpenSearch Service provides data search capabilities and the support of open source Elasticsearch clusters, including API access. </span><span class="koboSpan" id="kobo.398.2">It also provides Kibana as a visualization mechanism to search for indexed data stores. </span><span class="koboSpan" id="kobo.398.3">AWS manages capacity, scaling, and patching of clusters, removing any operational overhead. </span><span class="koboSpan" id="kobo.398.4">Log search and analysis is a popular big data use case where OpenSearch helps you analyze log data from websites, server fleets, IoT sensors, and so on. </span><span class="koboSpan" id="kobo.398.5">Various applications in industries such as banking, gaming, marketing, application monitoring, advertisement technology, fraud detection, recommendations, and IoT utilize OpenSearch and Elasticsearch. </span><span class="koboSpan" id="kobo.398.6">ML-based search services, such as Amazon Kendra, are also available, providing </span><a id="_idIndexMarker1615"/><span class="koboSpan" id="kobo.399.1">more advanced search capabilities using </span><strong class="keyWord"><span class="koboSpan" id="kobo.400.1">natural language processing</span></strong><span class="koboSpan" id="kobo.401.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.402.1">NLP</span></strong><span class="koboSpan" id="kobo.403.1">).</span></p>
<h3 class="heading-3" id="_idParaDest-360"><span class="koboSpan" id="kobo.404.1">Unstructured data stores</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.405.1">When you look at the requirements for an unstructured data store, Hadoop is a perfect choice </span><a id="_idIndexMarker1616"/><span class="koboSpan" id="kobo.406.1">because it is scalable, extensible, and very flexible. </span><span class="koboSpan" id="kobo.406.2">It can run on consumer hardware, has a vast ecosystem of tools, and appears cost-effective. </span><span class="koboSpan" id="kobo.406.3">Hadoop uses a </span><em class="italic"><span class="koboSpan" id="kobo.407.1">master-and-child-node</span></em><span class="koboSpan" id="kobo.408.1"> model, where data is distributed between </span><a id="_idIndexMarker1617"/><span class="koboSpan" id="kobo.409.1">multiple child nodes, and the primary node coordinates jobs for running queries on data. </span><span class="koboSpan" id="kobo.409.2">The Hadoop system is based on MPP, making it fast to perform queries on all data types, whether structured or unstructured.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.410.1">When a Hadoop cluster is created, each child node created from the server comes with a block of the attached disk storage called a local HDFS disk store. </span><span class="koboSpan" id="kobo.410.2">You can run the query against stored data using common processing frameworks like Hive, Pig, and Spark. </span><span class="koboSpan" id="kobo.410.3">However, data on the local disk persists only for the life of the associated instance.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.411.1">If you use Hadoop’s storage layer (HDFS) to store your data, you are coupling storage with compute. </span><span class="koboSpan" id="kobo.411.2">Increasing storage space means adding more machines, which also increases compute capacity. </span><span class="koboSpan" id="kobo.411.3">For maximum flexibility and cost-effectiveness, you need to separate compute and storage and scale them independently. </span><span class="koboSpan" id="kobo.411.4">Overall, object storage is more suited </span><a id="_idIndexMarker1618"/><span class="koboSpan" id="kobo.412.1">to data lakes to store all kinds of data </span><a id="_idIndexMarker1619"/><span class="koboSpan" id="kobo.413.1">cost-effectively and efficiently. </span><span class="koboSpan" id="kobo.413.2">Cloud-based data lakes backed by object storage provide flexibility to decouple compute and storage. </span><span class="koboSpan" id="kobo.413.3">Let’s learn more about object storage.</span></p>
<h3 class="heading-3" id="_idParaDest-361"><span class="koboSpan" id="kobo.414.1">Object storage</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.415.1">Object storage refers to data stored and accessed with units often referred to as objects stored in buckets. </span><span class="koboSpan" id="kobo.415.2">In object storage, files or objects are not split into data blocks, but data and </span><a id="_idIndexMarker1620"/><span class="koboSpan" id="kobo.416.1">metadata are kept together. </span><span class="koboSpan" id="kobo.416.2">There is no limit on the number of objects stored in a bucket, and they are accessed using API calls (usually through </span><code class="inlineCode"><span class="koboSpan" id="kobo.417.1">HTTP</span></code><span class="koboSpan" id="kobo.418.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.419.1">GET</span></code><span class="koboSpan" id="kobo.420.1">, or </span><code class="inlineCode"><span class="koboSpan" id="kobo.421.1">PUT</span></code><span class="koboSpan" id="kobo.422.1">) to read and write to and from buckets. </span><span class="koboSpan" id="kobo.422.2">Typically, object storage is not mounted as a filesystem on operating systems because the latency of API-based file requests and lack of file-level locking provide poor performance as a filesystem. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.423.1">Object storage offers scale and has a flat namespace, reducing management overhead and metadata management. </span><span class="koboSpan" id="kobo.423.2">Object storage has become more popular with the public cloud and is the go-to storage to build a scalable data lake in the cloud. </span><span class="koboSpan" id="kobo.423.3">Amazon S3, Azure Blob Storage, and Google Cloud Storage in GCP are the most popular object storage options.</span></p>
<h3 class="heading-3" id="_idParaDest-362"><span class="koboSpan" id="kobo.424.1">Vector Database (VectorDB)</span></h3>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.425.1">VectorDB</span></strong><span class="koboSpan" id="kobo.426.1"> has become </span><a id="_idIndexMarker1621"/><span class="koboSpan" id="kobo.427.1">very popular recently due to an increased focus on generative AI and ML. </span><span class="koboSpan" id="kobo.427.2">Vector data typically refers to high-dimensional data points, often used in </span><a id="_idIndexMarker1622"/><span class="koboSpan" id="kobo.428.1">the context of ML models. </span><span class="koboSpan" id="kobo.428.2">For example, an image, text, or audio file can be converted into a vector representation (a list of numbers) that captures its essential features. </span><span class="koboSpan" id="kobo.428.3">These vectors are used in ML tasks such as similarity search (finding the most similar items), clustering, or classification. </span><span class="koboSpan" id="kobo.428.4">For example, if you want to build customer segmentation, vector embeddings can be used to cluster customers into different groups based on their purchasing behavior or preferences. </span><span class="koboSpan" id="kobo.428.5">By analyzing the vector representations of customers’ purchase histories or interactions with a website, businesses can identify distinct clusters of similar customers. </span><span class="koboSpan" id="kobo.428.6">This enables them to tailor marketing strategies, personalize offers, or develop targeted products for each specific customer group, enhancing customer satisfaction and loyalty.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.429.1">VectorDB</span></strong><span class="koboSpan" id="kobo.430.1">, or vector databases, represent an emerging category in the database technology landscape, primarily focused on efficiently handling vector data. </span><span class="koboSpan" id="kobo.430.2">This data type is often </span><a id="_idIndexMarker1623"/><span class="koboSpan" id="kobo.431.1">associated with ML, particularly in areas like image recognition, NLP, and recommendation systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.432.1">A vector database’s core functionality is storing and managing vector data efficiently. </span><span class="koboSpan" id="kobo.432.2">This involves </span><a id="_idIndexMarker1624"/><span class="koboSpan" id="kobo.433.1">storing the high-dimensional data points and optimizing the database architecture to support quick and efficient querying, often in the form of nearest neighbor search.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.434.1">Advanced vector databases may incorporate ML models directly into the database, enabling on-the-fly transformation of raw data (like images or text) into vectors, which can then be stored or queried.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.435.1">A common use case is finding items similar to a given query item. </span><span class="koboSpan" id="kobo.435.2">For instance, the database can quickly retrieve images most similar to the query image in an image search. </span><span class="koboSpan" id="kobo.435.3">Vector databases can power recommendation engines by matching user profiles with product vectors to suggest relevant items. </span><span class="koboSpan" id="kobo.435.4">They can efficiently handle and query large-scale text data transformed into vector space for various NLP applications. </span><span class="koboSpan" id="kobo.435.5">The following are </span><a id="_idIndexMarker1625"/><span class="koboSpan" id="kobo.436.1">the pros of </span><strong class="keyWord"><span class="koboSpan" id="kobo.437.1">VectorDB</span></strong><span class="koboSpan" id="kobo.438.1">:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.439.1">Speed and efficiency</span></strong><span class="koboSpan" id="kobo.440.1">: Tailored to handle high-dimensional data, vector databases can perform similarity searches much faster than traditional databases.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.441.1">Scalability</span></strong><span class="koboSpan" id="kobo.442.1">: They are designed to scale with the size of the data, which is crucial in ML applications where datasets are often large.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.443.1">Integration with ML/AI pipelines</span></strong><span class="koboSpan" id="kobo.444.1">: Seamless integration with ML workflows, allowing direct querying and manipulation of vector data.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.445.1">Let’s look at </span><a id="_idIndexMarker1626"/><span class="koboSpan" id="kobo.446.1">some of the cons of </span><strong class="keyWord"><span class="koboSpan" id="kobo.447.1">VectorDB</span></strong><span class="koboSpan" id="kobo.448.1"> as well:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.449.1">Complexity</span></strong><span class="koboSpan" id="kobo.450.1">: The management and indexing of high-dimensional vector data can be complex.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.451.1">Resource intensive</span></strong><span class="koboSpan" id="kobo.452.1">: These databases might require significant computational resources, especially for large-scale datasets.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.453.1">Emerging technology</span></strong><span class="koboSpan" id="kobo.454.1">: Being relatively new, the ecosystem around vector databases might not be as mature as traditional databases, which can be a consideration for enterprise adoption.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.455.1">Vector databases are part of a broader trend towards specialized databases tailored for specific types of data and workloads, particularly in the context of ML and AI. </span><span class="koboSpan" id="kobo.455.2">They represent a significant step in evolving database technology to keep pace with data science and </span><a id="_idIndexMarker1627"/><span class="koboSpan" id="kobo.456.1">analytics advancements. </span><span class="koboSpan" id="kobo.456.2">As this technology matures, it’s likely to become </span><a id="_idIndexMarker1628"/><span class="koboSpan" id="kobo.457.1">an integral part of the data infrastructure in organizations heavily invested in ML and AI.</span></p>
<h3 class="heading-3" id="_idParaDest-363"><span class="koboSpan" id="kobo.458.1">Blockchain data stores</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.459.1">Blockchain technology, commonly associated with cryptocurrencies, offers a revolutionary approach to data management and transaction processing in various sectors beyond </span><a id="_idIndexMarker1629"/><span class="koboSpan" id="kobo.460.1">finance. </span><span class="koboSpan" id="kobo.460.2">Blockchain data stores offer a robust mechanism for decentralized verification, fundamentally altering how transactions are </span><a id="_idIndexMarker1630"/><span class="koboSpan" id="kobo.461.1">recorded and validated across various sectors. </span><span class="koboSpan" id="kobo.461.2">In a blockchain-based land registry system, for instance, every transaction involving property sales or purchases is recorded on a shared ledger, instantly accessible and verifiable by all network participants. </span><span class="koboSpan" id="kobo.461.3">This transparency contrasts with traditional centralized systems, where data is managed by a single authority, reducing the risk of fraud and enhancing trust among participants.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.462.1">The immutability and security features of blockchain further increase its application across industries. </span><span class="koboSpan" id="kobo.462.2">In healthcare, for example, blockchain ensures that once patient records are entered into the system, they remain unchanged and secure. </span><span class="koboSpan" id="kobo.462.3">This immutability is vital for medical professionals who depend on accurate historical data for treatment decisions. </span><span class="koboSpan" id="kobo.462.4">Additionally, the cryptographic security of blockchain protects sensitive health information, allowing access only to authorized users and ensuring patient privacy. </span><span class="koboSpan" id="kobo.462.5">These attributes make blockchain an invaluable tool in sectors where data integrity and security are paramount.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.463.1">To achieve immutability, blockchain networks play a key role, which is a decentralized digital ledger that records transactions across multiple computers in a way that ensures the integrity and security of the data. </span><span class="koboSpan" id="kobo.463.2">In a blockchain network, transactions are grouped into blocks, and each block is linked to the previous one, forming a chain. </span><span class="koboSpan" id="kobo.463.3">This structure makes it extremely difficult to alter information retroactively without the consensus of the network participants. </span><span class="koboSpan" id="kobo.463.4">The following are the types of blockchain networks:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.464.1">Public blockchain</span></strong><span class="koboSpan" id="kobo.465.1">: Ethereum </span><a id="_idIndexMarker1631"/><span class="koboSpan" id="kobo.466.1">is often </span><a id="_idIndexMarker1632"/><span class="koboSpan" id="kobo.467.1">used for </span><strong class="keyWord"><span class="koboSpan" id="kobo.468.1">decentralized applications</span></strong><span class="koboSpan" id="kobo.469.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.470.1">DApps</span></strong><span class="koboSpan" id="kobo.471.1">) and smart contracts. </span><span class="koboSpan" id="kobo.471.2">Ethereum is open, and anyone can join and participate in the network. </span><span class="koboSpan" id="kobo.471.3">For instance, a developer might create </span><a id="_idIndexMarker1633"/><span class="koboSpan" id="kobo.472.1">a DApp for </span><strong class="keyWord"><span class="koboSpan" id="kobo.473.1">decentralized finance</span></strong><span class="koboSpan" id="kobo.474.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.475.1">DeFi</span></strong><span class="koboSpan" id="kobo.476.1">) on the Ethereum network, allowing users to engage in financial transactions without traditional banks.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.477.1">Private blockchain</span></strong><span class="koboSpan" id="kobo.478.1">: This type of blockchain is restricted and controlled by an organization, offering more privacy and control. </span><span class="koboSpan" id="kobo.478.2">A pharmaceutical company might </span><a id="_idIndexMarker1634"/><span class="koboSpan" id="kobo.479.1">use a private blockchain </span><a id="_idIndexMarker1635"/><span class="koboSpan" id="kobo.480.1">to manage its drug development process. </span><span class="koboSpan" id="kobo.480.2">Access to the blockchain is restricted to company researchers and regulators, ensuring sensitive data is kept confidential.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.481.1">Consortium blockchain</span></strong><span class="koboSpan" id="kobo.482.1">: This involves multiple organizations managing a blockchain </span><a id="_idIndexMarker1636"/><span class="koboSpan" id="kobo.483.1">network, balancing decentralization with control. </span><span class="koboSpan" id="kobo.483.2">An example would be a group of </span><a id="_idIndexMarker1637"/><span class="koboSpan" id="kobo.484.1">shipping companies forming a consortium to manage a shared blockchain. </span><span class="koboSpan" id="kobo.484.2">This blockchain could be used to track cargo shipments across the globe, with each company maintaining a node on the network.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.485.1">Cloud </span><a id="_idIndexMarker1638"/><span class="koboSpan" id="kobo.486.1">providers like </span><strong class="keyWord"><span class="koboSpan" id="kobo.487.1">Amazon Web Services</span></strong><span class="koboSpan" id="kobo.488.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.489.1">AWS</span></strong><span class="koboSpan" id="kobo.490.1">) offer blockchain as a service, simplifying the setup and management of blockchain networks. </span><span class="koboSpan" id="kobo.490.2">Amazon </span><strong class="keyWord"><span class="koboSpan" id="kobo.491.1">Quantum Ledger Database</span></strong><span class="koboSpan" id="kobo.492.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.493.1">QLDB</span></strong><span class="koboSpan" id="kobo.494.1">) is an example of a centralized ledger </span><a id="_idIndexMarker1639"/><span class="koboSpan" id="kobo.495.1">database that provides an immutable and cryptographically verifiable record of transactions. </span><span class="koboSpan" id="kobo.495.2">Popular managed blockchain services </span><a id="_idIndexMarker1640"/><span class="koboSpan" id="kobo.496.1">include </span><strong class="keyWord"><span class="koboSpan" id="kobo.497.1">Amazon Managed Blockchain</span></strong><span class="koboSpan" id="kobo.498.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.499.1">AMB</span></strong><span class="koboSpan" id="kobo.500.1">), </span><strong class="keyWord"><span class="koboSpan" id="kobo.501.1">R3 Corda</span></strong><span class="koboSpan" id="kobo.502.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.503.1">Ethereum</span></strong><span class="koboSpan" id="kobo.504.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.505.1">Hyperledger</span></strong><span class="koboSpan" id="kobo.506.1">, catering to various needs from financial </span><a id="_idIndexMarker1641"/><span class="koboSpan" id="kobo.507.1">transactions to supply chain management.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.508.1">Streaming </span><a id="_idIndexMarker1642"/><span class="koboSpan" id="kobo.509.1">data processing </span><a id="_idIndexMarker1643"/><span class="koboSpan" id="kobo.510.1">used to be a niche technology, but now it’s becoming common as every organization wants to get fast insight from real-time data processing. </span><span class="koboSpan" id="kobo.510.2">Let’s learn more about streaming data stores.</span></p>
<h3 class="heading-3" id="_idParaDest-364"><span class="koboSpan" id="kobo.511.1">Streaming data stores</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.512.1">Streaming data has a continuous data flow with no start and end. </span><span class="koboSpan" id="kobo.512.2">Lots of data from various </span><a id="_idIndexMarker1644"/><span class="koboSpan" id="kobo.513.1">real-time resources, such as stock trading, autonomous </span><a id="_idIndexMarker1645"/><span class="koboSpan" id="kobo.514.1">cars, smart spaces, social media, e-commerce, gaming, ride apps, and so on, needs to be stored and processed quickly. </span><span class="koboSpan" id="kobo.514.2">Netflix provides real-time recommendations based on the content you are watching, and Lyft uses streaming to connect passengers to a driver in real time.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.515.1">Storing and processing streaming data is challenging as there is a continuous stream of data coming in, and you cannot predict the storage capacity. </span><span class="koboSpan" id="kobo.515.2">Along with high volume, streaming data comes with very high velocity, which requires a scalable storage system that can store the data and provide the ability to replay it. </span><span class="koboSpan" id="kobo.515.3">Data streams can become very expensive to maintain and complex to manage over time. </span><span class="koboSpan" id="kobo.515.4">Popular streaming data storage services are </span><a id="_idIndexMarker1646"/><span class="koboSpan" id="kobo.516.1">Apache Kafka, Apache Flink, Apache Spark </span><a id="_idIndexMarker1647"/><span class="koboSpan" id="kobo.517.1">Structured Streaming, Apache Samza, and Amazon Kinesis. </span><span class="koboSpan" id="kobo.517.2">AWS </span><a id="_idIndexMarker1648"/><span class="koboSpan" id="kobo.518.1">provides managed Kafka, known as Amazon Managed Streaming for Kafka. </span><span class="koboSpan" id="kobo.518.2">Let’s learn more details about streaming data ingestion and storage technology:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.519.1">Amazon Kinesis</span></strong><span class="koboSpan" id="kobo.520.1">: Amazon Kinesis </span><a id="_idIndexMarker1649"/><span class="koboSpan" id="kobo.521.1">offers three capabilities. </span><span class="koboSpan" id="kobo.521.2">The first, </span><strong class="keyWord"><span class="koboSpan" id="kobo.522.1">Kinesis Data Streams </span></strong><span class="koboSpan" id="kobo.523.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.524.1">KDS</span></strong><span class="koboSpan" id="kobo.525.1">), is a place to store a raw data stream </span><a id="_idIndexMarker1650"/><span class="koboSpan" id="kobo.526.1">to perform any downstream processing of the desired records. </span><span class="koboSpan" id="kobo.526.2">The second is </span><strong class="keyWord"><span class="koboSpan" id="kobo.527.1">Amazon Kinesis Data Firehose </span></strong><span class="koboSpan" id="kobo.528.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.529.1">KDF</span></strong><span class="koboSpan" id="kobo.530.1">), which </span><a id="_idIndexMarker1651"/><span class="koboSpan" id="kobo.531.1">facilitates transferring these records into common analytic environments like Amazon S3, Elasticsearch, Redshift, and Splunk. </span><span class="koboSpan" id="kobo.531.2">Firehose will automatically buffer up all the records in the stream and flush out to the target as a single file or set of records based on either a time or data-size threshold that you can configure or whichever is reached first.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.532.1">The third is </span><strong class="keyWord"><span class="koboSpan" id="kobo.533.1">Kinesis Data Analytics </span></strong><span class="koboSpan" id="kobo.534.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.535.1">KDA</span></strong><span class="koboSpan" id="kobo.536.1">), which performs analytics on stream </span><a id="_idIndexMarker1652"/><span class="koboSpan" id="kobo.537.1">records using Apache Flink. </span><span class="koboSpan" id="kobo.537.2">The output can subsequently flow into further streams you create to build an entire serverless streaming pipeline.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.538.1">Amazon Managed Streaming for Kafka </span></strong><span class="koboSpan" id="kobo.539.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.540.1">MSK</span></strong><span class="koboSpan" id="kobo.541.1">): MSK is a fully managed, highly </span><a id="_idIndexMarker1653"/><span class="koboSpan" id="kobo.542.1">available, and secure service. </span><span class="koboSpan" id="kobo.542.2">Amazon MSK runs applications on Apache Kafka in the AWS cloud without needing Apache Kafka infrastructure management expertise. </span><span class="koboSpan" id="kobo.542.3">Amazon MSK provides a managed Apache Kafka cluster with a ZooKeeper cluster to maintain configuration and build a producer/consumer for data ingestion and processing.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.543.1">Apache Flink</span></strong><span class="koboSpan" id="kobo.544.1">: Flink is </span><a id="_idIndexMarker1654"/><span class="koboSpan" id="kobo.545.1">another open source platform for streaming data and batch data processing. </span><span class="koboSpan" id="kobo.545.2">Flink consists of a streaming dataflow engine that can process bounded and unbounded data streams. </span><span class="koboSpan" id="kobo.545.3">A bounded data stream has a defined start and end, while an unbounded data stream has a start but no end. </span><span class="koboSpan" id="kobo.545.4">Flink can perform batch processing on its streaming engine and supports batch optimizations.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.546.1">Apache Spark Streaming</span></strong><span class="koboSpan" id="kobo.547.1">: Spark Streaming helps ingest live data streams with high </span><a id="_idIndexMarker1655"/><span class="koboSpan" id="kobo.548.1">throughput and a fault-tolerant, scalable manner. </span><span class="koboSpan" id="kobo.548.2">Spark Streaming divides the incoming data streams into batches before sending them to the Spark engine for processing. </span><span class="koboSpan" id="kobo.548.3">Spark Streaming </span><a id="_idIndexMarker1656"/><span class="koboSpan" id="kobo.549.1">uses DStreams, which are sequences of </span><strong class="keyWord"><span class="koboSpan" id="kobo.550.1">resilient distributed datasets</span></strong><span class="koboSpan" id="kobo.551.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.552.1">RDDs</span></strong><span class="koboSpan" id="kobo.553.1">).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.554.1">Apache Kafka</span></strong><span class="koboSpan" id="kobo.555.1">: Kafka is one of the most popular open source streaming platforms </span><a id="_idIndexMarker1657"/><span class="koboSpan" id="kobo.556.1">that helps you publish and subscribe to a data stream. </span><span class="koboSpan" id="kobo.556.2">A Kafka cluster stores a recorded stream in a Kafka topic. </span><span class="koboSpan" id="kobo.556.3">A producer can publish data in a Kafka topic, and consumers can take the output data stream by subscribing to the Kafka topic.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.557.1">Streaming storage needs to persist a continuous stream of data and provide the ability to maintain the order if required. </span><span class="koboSpan" id="kobo.557.2">You will learn more about streaming architecture in the upcoming section, </span><em class="italic"><span class="koboSpan" id="kobo.558.1">Streaming data architecture</span></em><span class="koboSpan" id="kobo.559.1">.</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-365"><span class="koboSpan" id="kobo.560.1">Data storage in the cloud</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.561.1">Cloud data storage is a crucial aspect of modern IT infrastructure, offering scalability, flexibility, and cost-effectiveness. </span><span class="koboSpan" id="kobo.561.2">The leading cloud service providers – AWS, GCP, and Azure – provide </span><a id="_idIndexMarker1658"/><span class="koboSpan" id="kobo.562.1">various data storage options to cater to different needs, from simple file storage to complex databases and data warehousing solutions. </span><span class="koboSpan" id="kobo.562.2">The </span><a id="_idIndexMarker1659"/><span class="koboSpan" id="kobo.563.1">following lists the key characteristics of cloud data storage across these platforms.</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.564.1">AWS:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.565.1">Amazon Simple Storage Service (S3)</span></strong><span class="koboSpan" id="kobo.566.1">: This is a highly scalable object storage </span><a id="_idIndexMarker1660"/><span class="koboSpan" id="kobo.567.1">service known </span><a id="_idIndexMarker1661"/><span class="koboSpan" id="kobo.568.1">for its high data availability, security, and performance. </span><span class="koboSpan" id="kobo.568.2">Amazon S3 is versatile, perfect for storing any volume of data applicable in various scenarios like websites, mobile apps, backup and restoration, archival needs, enterprise applications, IoT devices, and big data analytics.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.569.1">Amazon Elastic Block Store (EBS)</span></strong><span class="koboSpan" id="kobo.570.1">: EBS offers block-level storage volumes </span><a id="_idIndexMarker1662"/><span class="koboSpan" id="kobo.571.1">for use with EC2 instances. </span><span class="koboSpan" id="kobo.571.2">It’s particularly suitable for data that demands </span><a id="_idIndexMarker1663"/><span class="koboSpan" id="kobo.572.1">consistent and low-latency performance, such as databases or ERP (Enterprise Resource Planning) systems.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.573.1">Amazon Relational Database Service</span></strong> <strong class="keyWord"><span class="koboSpan" id="kobo.574.1">(RDS)</span></strong><span class="koboSpan" id="kobo.575.1">: RDS streamlines the setup, operation, and scaling of a relational database in the cloud. </span><span class="koboSpan" id="kobo.575.2">It offers </span><a id="_idIndexMarker1664"/><span class="koboSpan" id="kobo.576.1">a cost-effective solution with resizable capacity while </span><a id="_idIndexMarker1665"/><span class="koboSpan" id="kobo.577.1">automating many of the time-consuming tasks associated with database administration.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.578.1">Amazon S3 Glacier</span></strong><span class="koboSpan" id="kobo.579.1">: This service provides secure, durable, and low-cost </span><a id="_idIndexMarker1666"/><span class="koboSpan" id="kobo.580.1">cloud storage for archiving </span><a id="_idIndexMarker1667"/><span class="koboSpan" id="kobo.581.1">and long-term backup. </span><span class="koboSpan" id="kobo.581.2">Amazon S3 Glacier is ideal for storing data that is accessed infrequently, offering a solution for long-term data retention.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.582.1">GCP:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.583.1">Google Cloud Storage</span></strong><span class="koboSpan" id="kobo.584.1">: This </span><a id="_idIndexMarker1668"/><span class="koboSpan" id="kobo.585.1">offers object </span><a id="_idIndexMarker1669"/><span class="koboSpan" id="kobo.586.1">storage </span><a id="_idIndexMarker1670"/><span class="koboSpan" id="kobo.587.1">for companies of all sizes. </span><span class="koboSpan" id="kobo.587.2">It’s highly scalable and flexible, providing secure </span><a id="_idIndexMarker1671"/><span class="koboSpan" id="kobo.588.1">and durable storage for high-demand applications and workloads.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.589.1">Persistent Disk</span></strong><span class="koboSpan" id="kobo.590.1">: This provides block storage for Google Compute Engine </span><a id="_idIndexMarker1672"/><span class="koboSpan" id="kobo.591.1">instances. </span><span class="koboSpan" id="kobo.591.2">It </span><a id="_idIndexMarker1673"/><span class="koboSpan" id="kobo.592.1">offers high-performance SSD and HDD storage that can be attached to instances running in Compute </span><a id="_idIndexMarker1674"/><span class="koboSpan" id="kobo.593.1">Engine or </span><strong class="keyWord"><span class="koboSpan" id="kobo.594.1">Google Kubernetes Engine</span></strong><span class="koboSpan" id="kobo.595.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.596.1">GKE</span></strong><span class="koboSpan" id="kobo.597.1">).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.598.1">Cloud SQL</span></strong><span class="koboSpan" id="kobo.599.1">: A fully </span><a id="_idIndexMarker1675"/><span class="koboSpan" id="kobo.600.1">managed </span><a id="_idIndexMarker1676"/><span class="koboSpan" id="kobo.601.1">database service that makes it easy to set up, maintain, manage, and administer relational databases on Google Cloud.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.602.1">Google Cloud Bigtable</span></strong><span class="koboSpan" id="kobo.603.1">: A </span><a id="_idIndexMarker1677"/><span class="koboSpan" id="kobo.604.1">scalable, fully </span><a id="_idIndexMarker1678"/><span class="koboSpan" id="kobo.605.1">managed NoSQL database service for large analytical and operational workloads.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.606.1">Microsoft Azure:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.607.1">Azure Blob Storage</span></strong><span class="koboSpan" id="kobo.608.1">: This is Azure’s object storage solution designed for the </span><a id="_idIndexMarker1679"/><span class="koboSpan" id="kobo.609.1">cloud. </span><span class="koboSpan" id="kobo.609.2">It excels at storing large amounts </span><a id="_idIndexMarker1680"/><span class="koboSpan" id="kobo.610.1">of unstructured data, such as text or binary data. </span><span class="koboSpan" id="kobo.610.2">This includes various types </span><a id="_idIndexMarker1681"/><span class="koboSpan" id="kobo.611.1">of content like documents, media files, backups, and logs, making it highly versatile for a wide range of uses.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.612.1">Azure File Storage</span></strong><span class="koboSpan" id="kobo.613.1">: Offers cloud-based, fully managed file shares that </span><a id="_idIndexMarker1682"/><span class="koboSpan" id="kobo.614.1">are accessible using the standard </span><a id="_idIndexMarker1683"/><span class="koboSpan" id="kobo.615.1">SMB protocol. </span><span class="koboSpan" id="kobo.615.2">This service is particularly useful for businesses looking to migrate their existing on-premises file shares to the cloud environment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.616.1">Azure SQL Database</span></strong><span class="koboSpan" id="kobo.617.1">: A comprehensive, fully managed relational database </span><a id="_idIndexMarker1684"/><span class="koboSpan" id="kobo.618.1">service in the cloud. </span><span class="koboSpan" id="kobo.618.2">It </span><a id="_idIndexMarker1685"/><span class="koboSpan" id="kobo.619.1">provides the capabilities of SQL Server, but without the need for extensive infrastructure and database administration tasks, simplifying database management.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.620.1">Azure Disk Storage</span></strong><span class="koboSpan" id="kobo.621.1">: This delivers high-performance, reliable block storage </span><a id="_idIndexMarker1686"/><span class="koboSpan" id="kobo.622.1">for Azure Virtual Machines. </span><span class="koboSpan" id="kobo.622.2">Azure </span><a id="_idIndexMarker1687"/><span class="koboSpan" id="kobo.623.1">Disk Storage includes both SSD and HDD options, catering to a range of requirements from high-speed performance to cost efficiency.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.624.1">Cloud data </span><a id="_idIndexMarker1688"/><span class="koboSpan" id="kobo.625.1">storage services across these platforms are designed to provide secure, scalable, and accessible storage solutions, accommodating various applications and use cases. </span><span class="koboSpan" id="kobo.625.2">Each service has its specific strengths, making them suitable for different performance, scalability, data access, and cost requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.626.1">Once you ingest and store data, processing the data in the desired structure is essential to visualize and analyze it for business insights. </span><span class="koboSpan" id="kobo.626.2">Let’s learn more about data processing and transformation.</span></p>
<h2 class="heading-2" id="_idParaDest-366"><span class="koboSpan" id="kobo.627.1">Processing data and performing analytics</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.628.1">Data analytics is the process of ingesting, transforming, and visualizing data to discover valuable insights for business decision making. </span><span class="koboSpan" id="kobo.628.2">Over the previous decade, more data has been collected than ever before, and customers are looking for greater insights into their data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.629.1">These </span><a id="_idIndexMarker1689"/><span class="koboSpan" id="kobo.630.1">customers also want these insights in the least amount </span><a id="_idIndexMarker1690"/><span class="koboSpan" id="kobo.631.1">of time, sometimes even in real time. </span><span class="koboSpan" id="kobo.631.2">They want more ad hoc queries to answer more business questions. </span><span class="koboSpan" id="kobo.631.3">To answer these questions, customers need more powerful and efficient systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.632.1">Batch processing typically involves querying large amounts of cold data. </span><span class="koboSpan" id="kobo.632.2">In batch processing, it may take hours to get answers to business questions. </span><span class="koboSpan" id="kobo.632.3">For example, you may use batch processing to generate a billing report at the end of the month. </span><span class="koboSpan" id="kobo.632.4">Stream processing in real time typically involves querying small amounts of hot data, and it takes only a short amount of time to get answers. </span><span class="koboSpan" id="kobo.632.5">MapReduce-based systems such as Hadoop are examples of platforms that support the batch jobs category, while data warehouses are examples of platforms that support the query engine category.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.633.1">Streaming data processing activities ingest a data sequence and incrementally update functions in response to each data record. </span><span class="koboSpan" id="kobo.633.2">Typically, they ingest continuously produced streams of data records, such as metering data, monitoring data, audit logs, debugging logs, website clickstreams, and location-tracking events for devices, people, and physical goods.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.634.1">The following diagram illustrates a data lake pipeline for processing, transforming, and visualizing data using the AWS cloud tech stack:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.635.1"><img alt="" role="presentation" src="../Images/B21336_12_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.636.1">Figure 12.5: Data lake ETL pipeline for big data processing</span></p>
<p class="normal"><span class="koboSpan" id="kobo.637.1">Here, the ETL pipeline uses Amazon Athena for ad hoc querying of data stored in Amazon S3. </span><span class="koboSpan" id="kobo.637.2">The data </span><a id="_idIndexMarker1691"/><span class="koboSpan" id="kobo.638.1">ingested from various data sources (for example, web application servers) generates log files that persist into S3. </span><span class="koboSpan" id="kobo.638.2">These files are then transformed </span><a id="_idIndexMarker1692"/><span class="koboSpan" id="kobo.639.1">and cleansed into a set form required for </span><a id="_idIndexMarker1693"/><span class="koboSpan" id="kobo.640.1">meaningful insights using Amazon </span><strong class="keyWord"><span class="koboSpan" id="kobo.641.1">Elastic MapReduce</span></strong><span class="koboSpan" id="kobo.642.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.643.1">EMR</span></strong><span class="koboSpan" id="kobo.644.1">) and loaded into Amazon S3. </span><span class="koboSpan" id="kobo.644.2">Amazon EMR provides a managed Hadoop server in the cloud to perform data processing using various open source technologies </span><a id="_idIndexMarker1694"/><span class="koboSpan" id="kobo.645.1">such as </span><strong class="keyWord"><span class="koboSpan" id="kobo.646.1">Hive</span></strong><span class="koboSpan" id="kobo.647.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.648.1">Pig</span></strong><span class="koboSpan" id="kobo.649.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.650.1">Spark</span></strong><span class="koboSpan" id="kobo.651.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.652.1">These transformed </span><a id="_idIndexMarker1695"/><span class="koboSpan" id="kobo.653.1">files are loaded into Amazon Redshift using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.654.1">COPY</span></code><span class="koboSpan" id="kobo.655.1"> command </span><a id="_idIndexMarker1696"/><span class="koboSpan" id="kobo.656.1">and visualized using Amazon QuickSight. </span><span class="koboSpan" id="kobo.656.2">Using Amazon Athena, you can query the data directly from Amazon S3 when the data is stored and after transformation (with aggregated datasets). </span><span class="koboSpan" id="kobo.656.3">You can visualize the data from Athena in Amazon QuickSight. </span><span class="koboSpan" id="kobo.656.4">You can easily query these files without changing your existing dataflow.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.657.1">Let’s look at some popular tools for data processing.</span></p>
<h3 class="heading-3" id="_idParaDest-367"><span class="koboSpan" id="kobo.658.1">Technology choices for data processing and analysis</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.659.1">The following </span><a id="_idIndexMarker1697"/><span class="koboSpan" id="kobo.660.1">are some of the most popular data processing technologies that help you to perform transformation and processing for a large amount of data:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.661.1">Apache Hadoop</span></strong><span class="koboSpan" id="kobo.662.1"> uses a distributed processing architecture in which a task is mapped to </span><a id="_idIndexMarker1698"/><span class="koboSpan" id="kobo.663.1">a cluster of commodity servers for processing. </span><span class="koboSpan" id="kobo.663.2">Each piece of work distributed to the cluster servers can be run or re-run on any server. </span><span class="koboSpan" id="kobo.663.3">The cluster servers frequently use the HDFS to store </span><a id="_idIndexMarker1699"/><span class="koboSpan" id="kobo.664.1">data locally for processing. </span><span class="koboSpan" id="kobo.664.2">The Hadoop framework takes a big job, splits it into discrete tasks, and processes them in parallel. </span><span class="koboSpan" id="kobo.664.3">It allows for massive scalability across an enormous number of Hadoop clusters. </span><span class="koboSpan" id="kobo.664.4">It’s also designed for fault tolerance, where each worker node periodically reports its status to a primary node, and the primary node can redistribute work from a cluster that doesn’t respond positively. </span><span class="koboSpan" id="kobo.664.5">Some of the most popular frameworks used with Hadoop are </span><strong class="keyWord"><span class="koboSpan" id="kobo.665.1">Hive</span></strong><span class="koboSpan" id="kobo.666.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.667.1">Presto</span></strong><span class="koboSpan" id="kobo.668.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.669.1">Pig</span></strong><span class="koboSpan" id="kobo.670.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.671.1">Spark</span></strong><span class="koboSpan" id="kobo.672.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.673.1">Apache Spark</span></strong><span class="koboSpan" id="kobo.674.1"> is an in-memory processing framework. </span><span class="koboSpan" id="kobo.674.2">Apache Spark is a massively </span><a id="_idIndexMarker1700"/><span class="koboSpan" id="kobo.675.1">parallel processing system with different executors that can take apart a Spark job and run tasks in parallel. </span><span class="koboSpan" id="kobo.675.2">To increase </span><a id="_idIndexMarker1701"/><span class="koboSpan" id="kobo.676.1">the parallelism of a job, add nodes to the cluster. </span><span class="koboSpan" id="kobo.676.2">Spark supports batch, interactive, and streaming data sources. </span><span class="koboSpan" id="kobo.676.3">Spark </span><a id="_idIndexMarker1702"/><span class="koboSpan" id="kobo.677.1">uses </span><strong class="keyWord"><span class="koboSpan" id="kobo.678.1">directed acyclic graphs</span></strong><span class="koboSpan" id="kobo.679.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.680.1">DAGs</span></strong><span class="koboSpan" id="kobo.681.1">) for all the stages during the execution of a job. </span><span class="koboSpan" id="kobo.681.2">The DAGs can keep track of your data or lineage transformations during the jobs and efficiently minimize the I/O by storing the DataFrames in memory. </span><span class="koboSpan" id="kobo.681.3">Spark is also partition-aware to avoid network-intensive shuffles.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.682.1">Hadoop User Experience</span></strong><span class="koboSpan" id="kobo.683.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.684.1">HUE</span></strong><span class="koboSpan" id="kobo.685.1">) enables you to run queries and scripts on your cluster </span><a id="_idIndexMarker1703"/><span class="koboSpan" id="kobo.686.1">through a browser-based </span><strong class="keyWord"><span class="koboSpan" id="kobo.687.1">user interface</span></strong><span class="koboSpan" id="kobo.688.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.689.1">UI</span></strong><span class="koboSpan" id="kobo.690.1">) instead of the command line. </span><span class="koboSpan" id="kobo.690.2">HUE provides the most common Hadoop </span><a id="_idIndexMarker1704"/><span class="koboSpan" id="kobo.691.1">components in a UI. </span><span class="koboSpan" id="kobo.691.2">It enables browser-based viewing and tracking of Hadoop operations. </span><span class="koboSpan" id="kobo.691.3">Multiple </span><a id="_idIndexMarker1705"/><span class="koboSpan" id="kobo.692.1">users can </span><a id="_idIndexMarker1706"/><span class="koboSpan" id="kobo.693.1">access the cluster via HUE’s login portal, and administrators can manage access manually or with </span><strong class="keyWord"><span class="koboSpan" id="kobo.694.1">Lightweight Directory Access Protocol</span></strong><span class="koboSpan" id="kobo.695.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.696.1">LDAP</span></strong><span class="koboSpan" id="kobo.697.1">), </span><strong class="keyWord"><span class="koboSpan" id="kobo.698.1">Pluggable Authentication Modules</span></strong><span class="koboSpan" id="kobo.699.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.700.1">PAM</span></strong><span class="koboSpan" id="kobo.701.1">), </span><strong class="keyWord"><span class="koboSpan" id="kobo.702.1">Simple and Protected GSSAPI Negotiation Mechanism</span></strong><span class="koboSpan" id="kobo.703.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.704.1">SPNEGO</span></strong><span class="koboSpan" id="kobo.705.1">), OpenID, OAuth, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.706.1">Security Assertion Markup Language 2.0</span></strong><span class="koboSpan" id="kobo.707.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.708.1">SAML2</span></strong><span class="koboSpan" id="kobo.709.1">) authentication. </span><span class="koboSpan" id="kobo.709.2">HUE </span><a id="_idIndexMarker1707"/><span class="koboSpan" id="kobo.710.1">allows you to view logs in real time and provides a metastore manager to manipulate Hive metastore contents.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.711.1">Pig</span></strong><span class="koboSpan" id="kobo.712.1"> is typically </span><a id="_idIndexMarker1708"/><span class="koboSpan" id="kobo.713.1">used to process large amounts of raw data before storing it in a structured format (SQL tables). </span><span class="koboSpan" id="kobo.713.2">Pig is well suited to ETL operations such as data validation, loading, transformation, and combining data from </span><a id="_idIndexMarker1709"/><span class="koboSpan" id="kobo.714.1">multiple sources in multiple formats. </span><span class="koboSpan" id="kobo.714.2">In addition to ETL, Pig supports relational operations such as nested data, joins, and grouping. </span><span class="koboSpan" id="kobo.714.3">Pig scripts can input unstructured and semi-structured data (such as web server logs or clickstream logs). </span><span class="koboSpan" id="kobo.714.4">In contrast, Hive consistently enforces a schema on input data. </span><span class="koboSpan" id="kobo.714.5">Pig Latin scripts contain instructions on filtering, grouping, and joining data, but Pig is not intended to be a query language. </span><span class="koboSpan" id="kobo.714.6">Hive is better suited to querying data. </span><span class="koboSpan" id="kobo.714.7">The Pig script compiles and runs to transform the data based on the instructions in the Pig Latin script.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.715.1">Hive </span></strong><span class="koboSpan" id="kobo.716.1">is an open source data warehouse and query package that runs on top of a Hadoop </span><a id="_idIndexMarker1710"/><span class="koboSpan" id="kobo.717.1">cluster. </span><span class="koboSpan" id="kobo.717.2">Being able to use SQL is a skill that </span><a id="_idIndexMarker1711"/><span class="koboSpan" id="kobo.718.1">helps the team easily transition into the big data world. </span><span class="koboSpan" id="kobo.718.2">Hive uses </span><a id="_idIndexMarker1712"/><span class="koboSpan" id="kobo.719.1">a SQL-like language called </span><strong class="keyWord"><span class="koboSpan" id="kobo.720.1">Hive Query Language</span></strong><span class="koboSpan" id="kobo.721.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.722.1">HQL</span></strong><span class="koboSpan" id="kobo.723.1">), making it easy to query and process data in a Hadoop system. </span><span class="koboSpan" id="kobo.723.2">Hive abstracts the complexity of writing programs in a coding language like Java to perform analytics jobs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.724.1">Presto </span></strong><span class="koboSpan" id="kobo.725.1">is a Hive-like </span><a id="_idIndexMarker1713"/><span class="koboSpan" id="kobo.726.1">query engine, but it is much faster. </span><span class="koboSpan" id="kobo.726.2">It supports </span><a id="_idIndexMarker1714"/><span class="koboSpan" id="kobo.727.1">the </span><strong class="keyWord"><span class="koboSpan" id="kobo.728.1">American National Standards Institute</span></strong><span class="koboSpan" id="kobo.729.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.730.1">ANSI</span></strong><span class="koboSpan" id="kobo.731.1">) SQL standard, which is easy to learn and the most popular skill set. </span><span class="koboSpan" id="kobo.731.2">Presto </span><a id="_idIndexMarker1715"/><span class="koboSpan" id="kobo.732.1">supports complex queries, joins, and aggregation functions. </span><span class="koboSpan" id="kobo.732.2">Unlike Hive or MapReduce, Presto executes queries in memory, which reduces latency and improves query performance. </span><span class="koboSpan" id="kobo.732.3">You need to be careful while selecting the server capacity for Presto, as it needs to have high memory. </span><span class="koboSpan" id="kobo.732.4">A Presto job will restart in the event of memory spillover.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.733.1">HBase</span></strong><span class="koboSpan" id="kobo.734.1"> is a NoSQL </span><a id="_idIndexMarker1716"/><span class="koboSpan" id="kobo.735.1">database developed as a part of </span><a id="_idIndexMarker1717"/><span class="koboSpan" id="kobo.736.1">the open source Hadoop project. </span><span class="koboSpan" id="kobo.736.2">HBase runs on the HDFS to provide non-relational database capabilities for the Hadoop ecosystem. </span><span class="koboSpan" id="kobo.736.3">HBase helps to store large quantities of data in a columnar format with compression. </span><span class="koboSpan" id="kobo.736.4">Also, it provides a fast lookup because large portions of the data cache are kept in memory while cluster instance storage is still used.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.737.1">Apache Zeppelin</span></strong><span class="koboSpan" id="kobo.738.1"> is a web-based editor for data analytics built on top of the Hadoop system, also </span><a id="_idIndexMarker1718"/><span class="koboSpan" id="kobo.739.1">known as a Zeppelin notebook. </span><span class="koboSpan" id="kobo.739.2">It uses </span><a id="_idIndexMarker1719"/><span class="koboSpan" id="kobo.740.1">the concept of an interpreter for its backend </span><a id="_idIndexMarker1720"/><span class="koboSpan" id="kobo.741.1">language and allows any language to be plugged into Zeppelin. </span><span class="koboSpan" id="kobo.741.2">Apache Zeppelin includes some basic charts and pivot charts. </span><span class="koboSpan" id="kobo.741.3">It’s very flexible in terms of any output from any language backend that can be recognized and visualized.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.742.1">Ganglia</span></strong><span class="koboSpan" id="kobo.743.1"> is a Hadoop cluster monitoring tool. </span><span class="koboSpan" id="kobo.743.2">However, you need to install Ganglia </span><a id="_idIndexMarker1721"/><span class="koboSpan" id="kobo.744.1">on the cluster during launch. </span><span class="koboSpan" id="kobo.744.2">The Ganglia UI runs on the primary node, which you can see using an SSH tunnel. </span><span class="koboSpan" id="kobo.744.3">Ganglia is </span><a id="_idIndexMarker1722"/><span class="koboSpan" id="kobo.745.1">an open source project designed to monitor clusters without impact on their performance. </span><span class="koboSpan" id="kobo.745.2">Ganglia can help to inspect the performance of the individual servers in your cluster and the performance of clusters as a whole.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.746.1">JupyterHub</span></strong><span class="koboSpan" id="kobo.747.1"> is a multi-user Jupyter notebook. </span><span class="koboSpan" id="kobo.747.2">Jupyter Notebook is one of the most </span><a id="_idIndexMarker1723"/><span class="koboSpan" id="kobo.748.1">popular tools among data scientists to perform data </span><a id="_idIndexMarker1724"/><span class="koboSpan" id="kobo.749.1">engineering and ML. </span><span class="koboSpan" id="kobo.749.2">The JupyterHub notebook server provides each user with a Jupyter Notebook web-based IDE. </span><span class="koboSpan" id="kobo.749.3">Multiple users can use their Jupyter notebooks simultaneously to write and execute code for exploratory data analytics.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-368"><span class="koboSpan" id="kobo.750.1">Data processing in the cloud</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.751.1">Data processing in the cloud is a fundamental aspect of modern big data and analytics strategies. </span><span class="koboSpan" id="kobo.751.2">Three major </span><a id="_idIndexMarker1725"/><span class="koboSpan" id="kobo.752.1">cloud service providers—AWS, GCP, and Azure—offer various data processing services, each with unique features and capabilities. </span><span class="koboSpan" id="kobo.752.2">The following are some unique features of each of them:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.753.1">AWS Data Processing Services:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.754.1">Amazon EMR</span></strong><span class="koboSpan" id="kobo.755.1">: This provides a cloud-native Hadoop environment, supporting a wide range of big data frameworks like Apache Spark, Hadoop, HBase, and Presto. </span><span class="koboSpan" id="kobo.755.2">EMR is ideal for processing large datasets, and it offers flexibility by separating compute and storage, allowing for cost-efficient scaling.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.756.1">AWS Glue</span></strong><span class="koboSpan" id="kobo.757.1">: This is a fully managed ETL service that simplifies data preparation for analytics. </span><span class="koboSpan" id="kobo.757.2">It automates the cumbersome data preparation work, generates ETL scripts, and facilitates data movement between various AWS services. </span><span class="koboSpan" id="kobo.757.3">Glue is particularly effective for data cataloging and job scheduling.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.758.1">Amazon Athena</span></strong><span class="koboSpan" id="kobo.759.1">: A serverless, interactive query service that allows SQL queries directly on data stored in Amazon S3. </span><span class="koboSpan" id="kobo.759.2">It is highly useful for ad hoc data analysis and BI querying, with no infrastructure management required.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.760.1">GCP Data </span><a id="_idIndexMarker1726"/><span class="koboSpan" id="kobo.761.1">Processing Services:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.762.1">Google BigQuery</span></strong><span class="koboSpan" id="kobo.763.1">: This is a fully managed, serverless data warehouse solution designed for rapid, cost-efficient SQL querying across extensive datasets. </span><span class="koboSpan" id="kobo.763.2">BigQuery is particularly geared towards real-time analytics and is capable of handling streaming data effectively.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.764.1">Cloud Dataflow</span></strong><span class="koboSpan" id="kobo.765.1">: A fully managed service dedicated to processing data in both stream and batch modes. </span><span class="koboSpan" id="kobo.765.2">Built on Apache Beam, Cloud Dataflow offers a unified programming model, simplifying the development of parallel data processing pipelines. </span><span class="koboSpan" id="kobo.765.3">It’s adept at handling a range of tasks from complex ETL processes to batch and real-time streaming workloads.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.766.1">Cloud Dataprep</span></strong><span class="koboSpan" id="kobo.767.1">: An advanced data service that allows users to visually explore, clean, and prepare both structured and unstructured data for analysis. </span><span class="koboSpan" id="kobo.767.2">Seamlessly integrated with BigQuery and Cloud Dataflow, Cloud Dataprep enhances the capabilities of data exploration and transformation.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.768.1">Azure Data Processing Services:</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.769.1">Azure HDInsight</span></strong><span class="koboSpan" id="kobo.770.1">: A fully managed cloud service that makes it easy to process massive amounts of data with popular open source frameworks such as Apache, Hadoop, Spark, Kafka, and HBase. </span><span class="koboSpan" id="kobo.770.2">It suits various scenarios like ETL, data warehousing, ML, and IoT.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.771.1">Azure Databricks</span></strong><span class="koboSpan" id="kobo.772.1">: A fast, easy, and collaborative Apache Spark-based analytics platform. </span><span class="koboSpan" id="kobo.772.2">It integrates deeply with other Azure services and provides a unified platform for ETL processes, streaming analytics, ML, and data warehousing.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.773.1">Azure Synapse Analytics</span></strong><span class="koboSpan" id="kobo.774.1">: This is a comprehensive analytics service that merges the capabilities of big data and data warehousing. </span><span class="koboSpan" id="kobo.774.2">It provides a cohesive experience for ingesting, preparing, managing, and delivering data for instant BI and ML applications. </span><span class="koboSpan" id="kobo.774.3">Azure Synapse Analytics enables the simultaneous querying of both data lakes and databases, streamlining data analysis processes.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.775.1">Each cloud provider’s data processing services are designed to meet specific needs in the data life cycle, from processing and transforming large datasets to interactive querying and </span><a id="_idIndexMarker1727"/><span class="koboSpan" id="kobo.776.1">real-time analytics. </span><span class="koboSpan" id="kobo.776.2">This diversity ensures businesses can choose the most suitable tools and platforms according to their specific data processing requirements and objectives.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.777.1">Data analysis and processing are huge topics that warrant a book on their own. </span><span class="koboSpan" id="kobo.777.2">This section gave a high-level overview of popular and common tools used for data processing. </span><span class="koboSpan" id="kobo.777.3">There are many more proprietary and open source tools available. </span><span class="koboSpan" id="kobo.777.4">As a solutions architect, you must be aware of various available tools to make the right choice for your organization’s use case.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.778.1">Business analysts need to create reports and dashboards and perform ad hoc queries and analyses to identify data insights. </span><span class="koboSpan" id="kobo.778.2">Let’s learn about data visualization in the next section.</span></p>
<h1 class="heading-1" id="_idParaDest-369"><span class="koboSpan" id="kobo.779.1">Visualizing data</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.780.1">Data insights are used to answer important business questions such as revenue by customer, profit </span><a id="_idIndexMarker1728"/><span class="koboSpan" id="kobo.781.1">by region, or advertising referrals by site, among many others. </span><span class="koboSpan" id="kobo.781.2">In the big data pipeline, enormous amounts of data are collected from various sources. </span><span class="koboSpan" id="kobo.781.3">However, it is difficult for companies to find information about inventory per region, profitability, and increases in fraudulent account expenses. </span><span class="koboSpan" id="kobo.781.4">Some of the data you continuously collect for compliance purposes can also be leveraged for generating business.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.782.1">The two significant challenges of BI tools are the cost of implementation and the time it takes to implement a solution. </span><span class="koboSpan" id="kobo.782.2">Let’s look at some technology choices for data visualization.</span></p>
<h2 class="heading-2" id="_idParaDest-370"><span class="koboSpan" id="kobo.783.1">Technology choices for data visualization</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.784.1">The following </span><a id="_idIndexMarker1729"/><span class="koboSpan" id="kobo.785.1">are some of the most popular data visualization platforms, which help you prepare reports with data visualization as per your business requirements:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.786.1">Amazon QuickSight</span></strong><span class="koboSpan" id="kobo.787.1"> is a </span><a id="_idIndexMarker1730"/><span class="koboSpan" id="kobo.788.1">cloud-based BI tool for enterprise-grade data visualizations. </span><span class="koboSpan" id="kobo.788.2">It comes with a variety of </span><a id="_idIndexMarker1731"/><span class="koboSpan" id="kobo.789.1">visualization graph presets such as line graphs, pie charts, treemaps, heat maps, and histograms. </span><span class="koboSpan" id="kobo.789.2">Amazon QuickSight has a </span><a id="_idIndexMarker1732"/><span class="koboSpan" id="kobo.790.1">data-caching engine known as a </span><strong class="keyWord"><span class="koboSpan" id="kobo.791.1">Super-fast, Parallel, In-memory Calculation Engine</span></strong><span class="koboSpan" id="kobo.792.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.793.1">SPICE</span></strong><span class="koboSpan" id="kobo.794.1">), which helps render visualizations quickly. </span><span class="koboSpan" id="kobo.794.2">You can also perform data preparation tasks such as renaming and removing fields, changing data types, and creating new calculated fields. </span><span class="koboSpan" id="kobo.794.3">QuickSight also provides ML-based visualization insights and other ML-based features, such as auto forecast predictions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.795.1">Kibana</span></strong><span class="koboSpan" id="kobo.796.1"> is an open source data visualization tool for stream data visualization </span><a id="_idIndexMarker1733"/><span class="koboSpan" id="kobo.797.1">and log exploration. </span><span class="koboSpan" id="kobo.797.2">Kibana offers close </span><a id="_idIndexMarker1734"/><span class="koboSpan" id="kobo.798.1">integration with Elasticsearch and uses it as a default option to search for data on top of the Elasticsearch service. </span><span class="koboSpan" id="kobo.798.2">Like other BI tools, Kibana also provides popular visualization charts such as histograms, pie charts, and heat maps, and offers built-in geospatial support.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.799.1">Tableau</span></strong><span class="koboSpan" id="kobo.800.1"> is one </span><a id="_idIndexMarker1735"/><span class="koboSpan" id="kobo.801.1">of the most popular BI tools for </span><a id="_idIndexMarker1736"/><span class="koboSpan" id="kobo.802.1">data visualization. </span><span class="koboSpan" id="kobo.802.2">It uses a visual query engine, which is a purpose-built engine, to analyze big data faster than traditional queries. </span><span class="koboSpan" id="kobo.802.3">Tableau offers a drag-and-drop interface and the ability to blend data from multiple resources.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.803.1">Spotfire</span></strong><span class="koboSpan" id="kobo.804.1"> uses in-memory processing for faster response times, enabling extensive </span><a id="_idIndexMarker1737"/><span class="koboSpan" id="kobo.805.1">datasets from various resources. </span><span class="koboSpan" id="kobo.805.2">It allows </span><a id="_idIndexMarker1738"/><span class="koboSpan" id="kobo.806.1">you to plot your data on a geographical map and share it on Twitter. </span><span class="koboSpan" id="kobo.806.2">With Spotfire recommendations, it inspects your data automatically and suggests how to visualize it best.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.807.1">Jaspersoft</span></strong><span class="koboSpan" id="kobo.808.1"> enables </span><a id="_idIndexMarker1739"/><span class="koboSpan" id="kobo.809.1">self-service reporting and analysis. </span><span class="koboSpan" id="kobo.809.2">It </span><a id="_idIndexMarker1740"/><span class="koboSpan" id="kobo.810.1">also offers drag-and-drop designer capabilities.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.811.1">Power BI</span></strong><span class="koboSpan" id="kobo.812.1"> is a popular </span><a id="_idIndexMarker1741"/><span class="koboSpan" id="kobo.813.1">BI tool provided by Microsoft. </span><span class="koboSpan" id="kobo.813.2">It </span><a id="_idIndexMarker1742"/><span class="koboSpan" id="kobo.814.1">provides self-service analytics with a variety of visualization choices.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.815.1">Data visualization is an essential and massive topic for solutions architects. </span><span class="koboSpan" id="kobo.815.2">As a solutions architect, you need to be aware of the available tools and make the right choice per your business requirements for data visualization.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.816.1">You have learned about various data pipeline components, from ingestion, storage, and processing, to visualization. </span><span class="koboSpan" id="kobo.816.2">In the next section, let’s put them together and learn how to orchestrate a big data architecture.</span></p>
<h1 class="heading-1" id="_idParaDest-371"><span class="koboSpan" id="kobo.817.1">Designing big data architectures</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.818.1">Big data solutions are comprised of data ingestion, storage transformation, data processing, and visualization in a repeated manner to run daily business operations. </span><span class="koboSpan" id="kobo.818.2">You can build these </span><a id="_idIndexMarker1743"/><span class="koboSpan" id="kobo.819.1">workflows using the open source or cloud technologies you learned about in previous sections.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.820.1">First, you need to learn which architectural style is right for you by working backward from the business use case. </span><span class="koboSpan" id="kobo.820.2">You need to understand the end user of your big data architecture and create a user persona to understand the requirements better. </span><span class="koboSpan" id="kobo.820.3">To identify the key personas you are targeting with big data architecture, you need to understand some of the following points:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.821.1">Which teams, units, or departments inside your organization are they a part of?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.822.1">What is their level of data analysis and data engineering proficiency?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.823.1">What tools do they typically use?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.824.1">Do you need to cater to the organization’s employees, customers, or partners?</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.825.1">For your reference, taking an example of a retail store chain analysis, you may identify the following personas:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.826.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.827.1">product manager</span></strong><span class="koboSpan" id="kobo.828.1"> persona, who owns a product line/code but only sees turnover for their product.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.829.1">The</span><strong class="keyWord"><span class="koboSpan" id="kobo.830.1"> store manager</span></strong><span class="koboSpan" id="kobo.831.1"> persona, who wants to know the sales turnover and product mix for a single store (only able to see their store).</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.832.1">The</span><strong class="keyWord"><span class="koboSpan" id="kobo.833.1"> admin</span></strong><span class="koboSpan" id="kobo.834.1"> persona, who wants to have access to all data.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.835.1">The</span><strong class="keyWord"><span class="koboSpan" id="kobo.836.1"> data analyst</span></strong><span class="koboSpan" id="kobo.837.1">, who wants to access all data with PII data redacted.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.838.1">The</span><strong class="keyWord"><span class="koboSpan" id="kobo.839.1"> customer retention managers</span></strong><span class="koboSpan" id="kobo.840.1">, who want to understand repeated customer traffic.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.841.1">Data scientists</span></strong><span class="koboSpan" id="kobo.842.1"> need access to raw and processed data to build recommendations and forecasts.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.843.1">Once you </span><a id="_idIndexMarker1744"/><span class="koboSpan" id="kobo.844.1">have a clear understanding of your user persona, the next step is to identify the business use cases these personas aim to address. </span><span class="koboSpan" id="kobo.844.2">Some examples include:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.845.1">Customer spending trends</span></strong><span class="koboSpan" id="kobo.846.1">: Analyze how many customers are increasing or decreasing their spending over time. </span><span class="koboSpan" id="kobo.846.2">Characterize these customers based on their spending patterns.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.847.1">Growth categories among higher spenders</span></strong><span class="koboSpan" id="kobo.848.1">: Identify which product or service categories are witnessing faster growth among customers who are spending more over time.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.849.1">Decline categories among lower spenders</span></strong><span class="koboSpan" id="kobo.850.1">: Determine the categories where there is a noticeable decline in engagement among customers who are spending less over time.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.851.1">Impact of demographics on spending</span></strong><span class="koboSpan" id="kobo.852.1">: Investigate which demographic factors, such as household size, presence of children, or income level, influence customer spending habits. </span><span class="koboSpan" id="kobo.852.2">Also, assess which demographic factors impact engagement with specific product or service categories.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.853.1">Effectiveness of direct marketing</span></strong><span class="koboSpan" id="kobo.854.1">: Explore whether there is evidence to suggest that direct marketing campaigns lead to improved overall customer engagement.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.855.1">Cross-category impact of direct marketing</span></strong><span class="koboSpan" id="kobo.856.1">: Assess whether direct marketing efforts in one category have a positive effect on customer engagement in other categories.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.857.1">While you get details on the use case, the essential aspect of building your data architecture is to understand access patterns and data retention, which can be analyzed by using the following queries:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.858.1">How often do key users and personas run their reports, queries, or models?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.859.1">What is their expectation for data freshness?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.860.1">What is their expectation of data granularity?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.861.1">What portion of data is most frequently accessed for analysis?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.862.1">How long do you intend to retain data for analysis?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.863.1">At what point can data age out of the data lake environment?</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.864.1">There is always some sensitivity attached when you deal with data. </span><span class="koboSpan" id="kobo.864.2">Each country and area has its local regulatory compliance requirements, which solutions architects need to understand, such as:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.865.1">What compliance requirements does your business have?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.866.1">Are you subject to data locality, privacy, or redaction requirements?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.867.1">Who is authorized to see which records and which attributes in the dataset?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.868.1">How will you enforce the deletion of records on request?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.869.1">Where can you store data, for example, local to geolocation, county, or global?</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.870.1">As a data </span><a id="_idIndexMarker1745"/><span class="koboSpan" id="kobo.871.1">architect, you must also consider the return on investment and how it will help overall business decisions. </span><span class="koboSpan" id="kobo.871.2">To understand, you may want to go through the following points:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.872.1">What primary business processes and decisions does your data lake support?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.873.1">What level of granularity is required for these decisions?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.874.1">What is the impact of data latency on business decisions?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.875.1">How do you plan to measure success?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.876.1">What is the expected return on the time and material invested?</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.877.1">Ultimately, you want to build a data architecture where you can provide flexibility to make technology choices, for example, by using the best of cloud-based managed services and open source technologies to capitalize on existing skills and investments. </span><span class="koboSpan" id="kobo.877.2">You want to build big data solutions to use parallelism to achieve high performance and scalability. </span><span class="koboSpan" id="kobo.877.3">It is best to make sure any components of your big data pipeline can scale in or scale out independently so that you can adjust it according to different business workloads.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.878.1">To utilize the full potential of your solution, you want to provide interoperability with existing applications so that components of the big data architecture are also used for ML processing and enterprise BI solutions. </span><span class="koboSpan" id="kobo.878.2">It will enable you to create an integrated solution across data workloads. </span><span class="koboSpan" id="kobo.878.3">Let’s learn about some big data architecture patterns.</span></p>
<h2 class="heading-2" id="_idParaDest-372"><span class="koboSpan" id="kobo.879.1">Data lake architecture</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.880.1">A data lake serves as a centralized repository that accommodates both structured and unstructured data, encompassing the diverse data types present in a corporation. </span><span class="koboSpan" id="kobo.880.2">It has emerged as </span><a id="_idIndexMarker1746"/><span class="koboSpan" id="kobo.881.1">a solution for transferring all enterprise data into a cost-effective storage system, like Amazon S3. </span><span class="koboSpan" id="kobo.881.2">In a data lake, data can </span><a id="_idIndexMarker1747"/><span class="koboSpan" id="kobo.882.1">be accessed through generic APIs and open file formats, including </span><a id="_idIndexMarker1748"/><span class="koboSpan" id="kobo.883.1">Apache Parquet and </span><strong class="keyWord"><span class="koboSpan" id="kobo.884.1">Optimized Row Columnar</span></strong><span class="koboSpan" id="kobo.885.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.886.1">ORC</span></strong><span class="koboSpan" id="kobo.887.1">). </span><span class="koboSpan" id="kobo.887.2">This storage method preserves data in its original form, utilizing open source file formats, thereby facilitating direct analytics and ML applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.888.1">The data lake is becoming a popular way to store and analyze large volumes of data in a centralized repository. </span><span class="koboSpan" id="kobo.888.2">Data can be stored as is in its current format, and you don’t need to convert data into a predefined schema, which increases the data ingestion speed. </span><span class="koboSpan" id="kobo.888.3">As illustrated in the following diagram, the data lake is a single source of truth for all data in your organization:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.889.1"><img alt="" role="presentation" src="../Images/B21336_12_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.890.1">Figure 12.6: Object store for data lake</span></p>
<p class="normal"><span class="koboSpan" id="kobo.891.1">The following </span><a id="_idIndexMarker1749"/><span class="koboSpan" id="kobo.892.1">are the benefits of a data lake:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.893.1">Data ingestion from various sources</span></strong><span class="koboSpan" id="kobo.894.1">: Data lakes let you store and analyze data from </span><a id="_idIndexMarker1750"/><span class="koboSpan" id="kobo.895.1">multiple sources, such as relational and non-relational databases and streams, in one centralized location for a single source of truth. </span><span class="koboSpan" id="kobo.895.2">This answers questions such as </span><em class="italic"><span class="koboSpan" id="kobo.896.1">Why is the data distributed in many places?</span></em><span class="koboSpan" id="kobo.897.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.898.1">Where is the single source of truth?</span></em></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.899.1">Collecting and efficiently storing data</span></strong><span class="koboSpan" id="kobo.900.1">: A data lake can ingest any data structure, including semi-structured and unstructured data, without needing schema. </span><span class="koboSpan" id="kobo.900.2">This answers questions such as: </span><em class="italic"><span class="koboSpan" id="kobo.901.1">How can I ingest data quickly from various sources and in multiple formats and store it efficiently at scale?</span></em></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.902.1">Scale up with the volume of generated data</span></strong><span class="koboSpan" id="kobo.903.1">: Data lakes allow you to separate the </span><a id="_idIndexMarker1751"/><span class="koboSpan" id="kobo.904.1">storage and compute layers to scale each component separately. </span><span class="koboSpan" id="kobo.904.2">This answers questions such as: </span><em class="italic"><span class="koboSpan" id="kobo.905.1">How can I scale up with the volume of data generated?</span></em></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.906.1">Applying analytics to data from different sources</span></strong><span class="koboSpan" id="kobo.907.1">: With a data lake, you can determine the schema on reading and create a centralized data catalog on data collected from various resources. </span><span class="koboSpan" id="kobo.907.2">This enables you to perform quick ad hoc analysis. </span><span class="koboSpan" id="kobo.907.3">This answers questions such as: </span><em class="italic"><span class="koboSpan" id="kobo.908.1">Can I apply multiple analytics and processing frameworks to the same data?</span></em></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.909.1">It would help if you had an unlimited scalable data storage solution for your data lake. </span><span class="koboSpan" id="kobo.909.2">Decoupling your processing and storage provides many benefits, including the ability to process and </span><a id="_idIndexMarker1752"/><span class="koboSpan" id="kobo.910.1">analyze the same data with various </span><a id="_idIndexMarker1753"/><span class="koboSpan" id="kobo.911.1">tools. </span><span class="koboSpan" id="kobo.911.2">Although this may require an additional step to load your data into the right tool, Amazon S3, as your central data store, provides even more benefits than traditional storage options. </span><span class="koboSpan" id="kobo.911.3">The following diagram provides a view of the data lake using AWS services:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.912.1"><img alt="" role="presentation" src="../Images/B21336_12_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.913.1">Figure 12.7: Data lake architecture in the AWS platform</span></p>
<p class="normal"><span class="koboSpan" id="kobo.914.1">The preceding diagram depicts a data lake using Amazon S3 storage. </span><span class="koboSpan" id="kobo.914.2">Data is ingested into centralized storage from various resources such as relational databases and master data files. </span><span class="koboSpan" id="kobo.914.3">In the data lake’s raw layer, all data is kept in its original format. </span><span class="koboSpan" id="kobo.914.4">This data then undergoes cataloging and transformation via the AWS Glue service. </span><span class="koboSpan" id="kobo.914.5">AWS Glue is a serverless </span><a id="_idIndexMarker1754"/><span class="koboSpan" id="kobo.915.1">solution for data cataloging and ETL processes, built on the Spark framework within the AWS cloud platform. </span><span class="koboSpan" id="kobo.915.2">Here, the AWS Glue crawler helps in cataloging data stores. </span><span class="koboSpan" id="kobo.915.3">It automatically scans your </span><a id="_idIndexMarker1755"/><span class="koboSpan" id="kobo.916.1">data sources, identifies data formats, and infers schemas, creating and populating a data catalog with metadata information. </span><span class="koboSpan" id="kobo.916.2">The crawler classifies the data to understand its format and structure and creates table definitions in the data catalog, which makes it easy to build queries for data analytics. </span><span class="koboSpan" id="kobo.916.3">Once transformed, this data is stored in the data lake’s processed layer, making it available for various consumption purposes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.917.1">Data engineers can run ad hoc queries using Amazon Athena, a serverless query service built on top of managed Presto instances, and use SQL to query the data directly from Amazon S3. </span><span class="koboSpan" id="kobo.917.2">Business analysts can use Amazon QuickSight, Tableau, or Power BI to build visualizations for business users or load selective data in Amazon Redshift to create a data warehouse mart. </span><span class="koboSpan" id="kobo.917.3">Finally, data scientists can consume this data using Amazon SageMaker to perform ML.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.918.1">One tool cannot do everything. </span><span class="koboSpan" id="kobo.918.2">You need to use the right tool for the right job, and data lakes enable you to build a highly configurable big data architecture to meet your specific needs. </span><span class="koboSpan" id="kobo.918.3">Business problems must be narrower, deeper, and more complex for one tool to solve everything, especially big data and analytics.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.919.1">However, with time, organizations realized that data lakes have their limitations. </span><span class="koboSpan" id="kobo.919.2">As data lakes use </span><a id="_idIndexMarker1756"/><span class="koboSpan" id="kobo.920.1">cheap storage, organizations </span><a id="_idIndexMarker1757"/><span class="koboSpan" id="kobo.921.1">store as much of their data as they can in data lakes, providing the flexibility of open, direct access to files. </span><span class="koboSpan" id="kobo.921.2">Quickly, data lakes started becoming </span><strong class="keyWord"><span class="koboSpan" id="kobo.922.1">data swamps</span></strong><span class="koboSpan" id="kobo.923.1"> due to </span><a id="_idIndexMarker1758"/><span class="koboSpan" id="kobo.924.1">data quality issues and granular data security. </span><span class="koboSpan" id="kobo.924.2">However, to address the data lake’s performance and quality issues, organizations process a small subset of data in the data lake to a downstream data warehouse to use in BI applications for important decisions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.925.1">The dual system architecture between a data lake and a data warehouse requires continuous data engineering to maintain and process data between these two systems. </span><span class="koboSpan" id="kobo.925.2">Each step in data processing carries the risk of failures that can compromise data quality. </span><span class="koboSpan" id="kobo.925.3">Additionally, maintaining consistency between the data lake and the data warehouse can be both challenging and expensive. </span><span class="koboSpan" id="kobo.925.4">Users face the burden of paying double for storage—once for the data stored in the lake and again for data replicated in the warehouse. </span><span class="koboSpan" id="kobo.925.5">This is in addition to the ongoing costs associated with continuous data processing.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.926.1">To address the dual-system problem, a new type of architecture called the data lakehouse has been discovered. </span><span class="koboSpan" id="kobo.926.2">Let’s learn more about lakehouse architecture.</span></p>
<h2 class="heading-2" id="_idParaDest-373"><span class="koboSpan" id="kobo.927.1">Lakehouse architecture</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.928.1">The lakehouse architecture has emerged as a solution to bridge the gaps between traditional </span><a id="_idIndexMarker1759"/><span class="koboSpan" id="kobo.929.1">data lakes and data warehouses, integrating the strengths of both. </span><span class="koboSpan" id="kobo.929.2">This architecture is designed to harness the expansive storage capacity of </span><a id="_idIndexMarker1760"/><span class="koboSpan" id="kobo.930.1">data lakes for ingesting and keeping vast quantities of data in open formats, which are essential for analytics. </span><span class="koboSpan" id="kobo.930.2">Simultaneously, it aims to provide the ease of SQL-based querying and the reliability associated with data warehouses. </span><span class="koboSpan" id="kobo.930.3">Key characteristics of lakehouse architecture include:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.931.1">Data storage in open-data formats</span></strong><span class="koboSpan" id="kobo.932.1">: Lakehouse architecture stores data in open formats, facilitating interoperability and flexibility in data processing and analytics.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.933.1">Decoupled storage and compute</span></strong><span class="koboSpan" id="kobo.934.1">: It separates storage and computing resources, allowing independent scaling and optimization of each, leading to cost efficiency and performance improvement.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.935.1">Transactional guarantees</span></strong><span class="koboSpan" id="kobo.936.1">: Ensuring data integrity, lakehouse architecture provides transactional guarantees, akin to those in traditional database systems, supporting reliable concurrent access and modifications.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.937.1">Support for diverse consumption needs</span></strong><span class="koboSpan" id="kobo.938.1">: Designed to cater to a wide range of data consumption requirements, lakehouse architecture accommodates different data analytics and processing approaches, from batch to real-time streaming.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.939.1">Secure and governed</span></strong><span class="koboSpan" id="kobo.940.1">: The architecture emphasizes security and governance, ensuring that data access is controlled, and compliance with data privacy regulations is maintained.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.941.1">Unified platform</span></strong><span class="koboSpan" id="kobo.942.1">: Lakehouse architecture provides a unified platform for various data operations, from ETL processes and ML to BI and reporting, eliminating the need for disparate systems.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.943.1">Enhanced query performance</span></strong><span class="koboSpan" id="kobo.944.1">: By leveraging techniques like indexing, caching, and data clustering, lakehouse architecture improves query performance, making it suitable for complex analytical workloads.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.945.1">Cost-effective scalability</span></strong><span class="koboSpan" id="kobo.946.1">: The architecture offers cost-effective scalability options, balancing the need for performance with budgetary constraints, especially beneficial for growing data volumes.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.947.1">Flexible data management</span></strong><span class="koboSpan" id="kobo.948.1">: Lakehouse architecture supports flexible data management practices, accommodating evolving data schemas and structures, making it ideal for agile and evolving business environments.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.949.1">The lakehouse architecture </span><a id="_idIndexMarker1761"/><span class="koboSpan" id="kobo.950.1">represents a significant evolution in </span><a id="_idIndexMarker1762"/><span class="koboSpan" id="kobo.951.1">data management, offering a comprehensive, scalable, and efficient approach to handling vast and diverse datasets while ensuring data integrity, security, and easy accessibility.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.952.1">The following diagram shows a sample lakehouse architecture using Redshift Spectrum for data sharing. </span><span class="koboSpan" id="kobo.952.2">Amazon Redshift Spectrum provides the ability to query data from the data lake without storing data in the data warehouse. </span><span class="koboSpan" id="kobo.952.3">Suppose you were already using Amazon Redshift for data warehousing. </span><span class="koboSpan" id="kobo.952.4">In that case, you don’t need to load all the data into the Amazon Redshift cluster. </span><span class="koboSpan" id="kobo.952.5">Still, you can use Spectrum to query data directly from the Amazon S3 data lake and combine it with data warehouse data.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.953.1"><img alt="" role="presentation" src="../Images/B21336_12_08.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.954.1">Figure 12.8: Lakehouse architecture in the AWS cloud platform using Redshift Spectrum</span></p>
<p class="normal"><span class="koboSpan" id="kobo.955.1">Data is ingested </span><a id="_idIndexMarker1763"/><span class="koboSpan" id="kobo.956.1">from an on-premises </span><strong class="keyWord"><span class="koboSpan" id="kobo.957.1">enterprise data warehouse</span></strong><span class="koboSpan" id="kobo.958.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.959.1">EDW</span></strong><span class="koboSpan" id="kobo.960.1">) into S3 using the S3 API in the preceding diagram. </span><span class="koboSpan" id="kobo.960.2">AWS Glue </span><a id="_idIndexMarker1764"/><span class="koboSpan" id="kobo.961.1">stores the metadata and the credit </span><a id="_idIndexMarker1765"/><span class="koboSpan" id="kobo.962.1">and loan data individually. </span><span class="koboSpan" id="kobo.962.2">Data analysts in the loan department would be granted read-only access to the loan data for data access. </span><span class="koboSpan" id="kobo.962.3">Similarly, credit analysts would be granted read-only access to the credit data. </span><span class="koboSpan" id="kobo.962.4">For data sharing, if a credit analyst needs access to the loan data, the credit analyst can be given the loan data’s read-only schema.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.963.1">Lakehouse architecture has benefits; however, more is needed for large organizations with a complex application landscape driven by geographically separated business units. </span><span class="koboSpan" id="kobo.963.2">These business units have built data lakes and warehouses as their analytical sources. </span><span class="koboSpan" id="kobo.963.3">Each business unit may merge multiple internal application data lakes to support their business. </span><span class="koboSpan" id="kobo.963.4">Centralized enterprise data lakes or data lakehouses are challenging to achieve as the pace of change is generally low, and it isn’t easy to meet all requirements across different business units. </span><span class="koboSpan" id="kobo.963.5">To handle this problem, you need domain-oriented decentralized data ownership and architecture. </span><span class="koboSpan" id="kobo.963.6">That’s where data mesh comes into the picture. </span><span class="koboSpan" id="kobo.963.7">Let’s learn more about data mesh architecture.</span></p>
<h2 class="heading-2" id="_idParaDest-374"><span class="koboSpan" id="kobo.964.1">Data mesh architecture</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.965.1">The major difference between data mesh and data lake architecture is that data is intentionally </span><a id="_idIndexMarker1766"/><span class="koboSpan" id="kobo.966.1">left distributed rather than trying to combine multiple domains into a centrally managed data lake. </span><span class="koboSpan" id="kobo.966.2">Data mesh provides a </span><a id="_idIndexMarker1767"/><span class="koboSpan" id="kobo.967.1">pattern that allows a large organization to connect multiple data lakes/lakehouses within large enterprises and facilitate sharing with partners, academia, and even competitors.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.968.1">Data mesh </span><a id="_idIndexMarker1768"/><span class="koboSpan" id="kobo.969.1">represents a significant shift in both architecture and organizational approaches toward managing extensive analytical datasets. </span><span class="koboSpan" id="kobo.969.2">It is built upon four fundamental principles:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.970.1">Domain-oriented decentralization of ownership and architecture</span></strong><span class="koboSpan" id="kobo.971.1">: This principle emphasizes decentralizing data ownership and architecture decisions to specific business domains. </span><span class="koboSpan" id="kobo.971.2">It encourages individual domains to take responsibility for their data, leading to more tailored and effective data solutions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.972.1">Data served as a product</span></strong><span class="koboSpan" id="kobo.973.1">: Treating data as a product means it is maintained, improved, and presented with the end user in mind. </span><span class="koboSpan" id="kobo.973.2">It shifts the focus from data as a mere resource to a valuable asset that provides utility and solves user problems.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.974.1">Federated data governance with centralized audit controls</span></strong><span class="koboSpan" id="kobo.975.1">: This principle strikes a balance between decentralized data management and the need for overarching governance. </span><span class="koboSpan" id="kobo.975.2">It allows for domain-specific data governance while maintaining centralized controls for auditing and compliance.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.976.1">Common access that makes data consumable</span></strong><span class="koboSpan" id="kobo.977.1">: Ensuring data is accessible and usable across the organization, this principle focuses on creating a common framework that enables easy and efficient data consumption.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.978.1">It encourages data-driven agility and supports domain-local governance through a lightweight centralized policy. </span><span class="koboSpan" id="kobo.978.2">Data mesh provides better ownership by isolating data resources with clear accountability. </span><span class="koboSpan" id="kobo.978.3">The core concept of data mesh is to feature data domains as nodes in data lake accounts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.979.1">A data producer contributes one or more data products to a central catalog in a data mesh account where federated data governance is applied to sharing data products, delivering discoverable metadata and audibility. </span><span class="koboSpan" id="kobo.979.2">A data consumer searches for a catalog and gains </span><a id="_idIndexMarker1769"/><span class="koboSpan" id="kobo.980.1">access to a data product by accepting a resource share </span><a id="_idIndexMarker1770"/><span class="koboSpan" id="kobo.981.1">via the data mesh pattern. </span><span class="koboSpan" id="kobo.981.2">The following is a data mesh architecture in the AWS cloud:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.982.1"><img alt="" role="presentation" src="../Images/B21336_12_09.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.983.1">Figure 12.9: Data mesh architecture on the AWS cloud platform</span></p>
<p class="normal"><span class="koboSpan" id="kobo.984.1">The following are the components implemented to build a data mesh, as shown in the preceding diagram:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.985.1">The central AWS account is where data products are registered, comprising databases, tables, columns, and rows.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.986.1">Access control tags and tag access policies are managed centrally.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.987.1">It stores data permissions that implement sharing with a consumer. </span><span class="koboSpan" id="kobo.987.2">Permissions can be direct or based on tags.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.988.1">Applies security and governance policies to producer and consumer accounts and their published data products.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.989.1">With a data mesh architecture, you can accelerate the independent delivery of the business domain lakehouses. </span><span class="koboSpan" id="kobo.989.2">Data mesh increases data security and compliance within domains and enables self-service data product creation, discovery, and subscription, allowing consumers to access data products transparently. </span><span class="koboSpan" id="kobo.989.3">There is a growing need to provide fast insight and act quickly based on customer needs, which makes streaming data analytics an essential aspect of any business. </span><span class="koboSpan" id="kobo.989.4">Let’s learn more details about streaming data analytics architecture.</span></p>
<h2 class="heading-2" id="_idParaDest-375"><span class="koboSpan" id="kobo.990.1">Streaming data architecture</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.991.1">Streaming data, a rapidly expanding segment of data, requires the capability to ingest and swiftly </span><a id="_idIndexMarker1771"/><span class="koboSpan" id="kobo.992.1">process real-time data from </span><a id="_idIndexMarker1772"/><span class="koboSpan" id="kobo.993.1">a variety of sources. </span><span class="koboSpan" id="kobo.993.2">These sources include video, audio, application logs, website clickstreams, and IoT telemetry data, all aimed at </span><a id="_idIndexMarker1773"/><span class="koboSpan" id="kobo.994.1">delivering prompt business insights. </span><span class="koboSpan" id="kobo.994.2">The typical use cases for streaming data follow a consistent pattern:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.995.1">Data generation</span></strong><span class="koboSpan" id="kobo.996.1">: Sources continuously produce data.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.997.1">Ingestion</span></strong><span class="koboSpan" id="kobo.998.1">: This data is then delivered through an ingestion stage to a streaming storage layer.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.999.1">Stream storage</span></strong><span class="koboSpan" id="kobo.1000.1">: In this layer, the incoming data is durably captured and made accessible for real-time processing.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1001.1">Stream processing</span></strong><span class="koboSpan" id="kobo.1002.1">: Here, the data residing in the storage layer is processed. </span><span class="koboSpan" id="kobo.1002.2">This processing might involve filtering, aggregating, or analyzing the data as it streams.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1003.1">Data output</span></strong><span class="koboSpan" id="kobo.1004.1">: The processed data is then dispatched to a designated destination, which could be a database, a data lake, or another storage solution, for further use or long-term storage.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.1005.1">This flow ensures that data is not only captured as it is generated but also processed in a timely manner, leading to quicker decision making and more immediate business insights.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1006.1">Streaming data architecture is different as it needs to process a continuous massive data stream with very high velocity. </span><span class="koboSpan" id="kobo.1006.2">Often, this data is semi-structured and needs a lot of processing to get actionable insights. </span><span class="koboSpan" id="kobo.1006.3">While designing streaming data architecture, you need to quickly scale data storage while getting real-time pattern identification from time-series data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1007.1">It would be best to think about the producer who generated a stream of data, such as IoT sensors, how to store and process the data using a real-time data processing tool, and finally, how to query the data in real time. </span><span class="koboSpan" id="kobo.1007.2">The following diagram shows a streaming data analytics pipeline using a managed service on the AWS platform:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1008.1"><img alt="" role="presentation" src="../Images/B21336_12_10.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1009.1">Figure 12.10: Streaming data analytics for IoT data</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1010.1">In the preceding diagram, data is ingested from the wind farm to understand the health and speed of a wind turbine. </span><span class="koboSpan" id="kobo.1010.2">It’s important to control wind turbines in real time to avoid costly repairs in the case of high wind speeds beyond the wind turbine’s limit.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1011.1">The wind </span><a id="_idIndexMarker1774"/><span class="koboSpan" id="kobo.1012.1">turbine data is ingested into Kinesis Data Streams using AWS IoT Greengrass. </span><span class="koboSpan" id="kobo.1012.2">Kinesis Data Streams can retain the </span><a id="_idIndexMarker1775"/><span class="koboSpan" id="kobo.1013.1">streaming data for up to a year and provide replay capability. </span><span class="koboSpan" id="kobo.1013.2">These are subjected to the fan-out technique to deliver the data to multiple resources, where you can message data using Lambda and store it in Amazon S3 for further analytics using Amazon Kinesis Firehose.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1014.1">You can perform real-time queries on streaming data using simple SQL queries with Kinesis Data Analytics for SQL and you can automate a data pipeline to transform streaming data in real time using Kinesis Data Analytics for Java Flink and store the processed data in Amazon OpenSearch to get data insights. </span><span class="koboSpan" id="kobo.1014.2">You can also add Kibana to OpenSearch to visualize the wind turbine data in real time.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1015.1">The preceding solution is data agnostic and easily customizable, enabling customers to quickly modify pre-configured defaults and start writing code to include their specific business logic.</span></p>
<h2 class="heading-2" id="_idParaDest-376"><span class="koboSpan" id="kobo.1016.1">Choosing the right big data architecture </span></h2>
<p class="normal"><span class="koboSpan" id="kobo.1017.1">Choosing between data lake, lakehouse, and data mesh architectures depends on your specific </span><a id="_idIndexMarker1776"/><span class="koboSpan" id="kobo.1018.1">business requirements, data strategy, and technical capabilities. </span><span class="koboSpan" id="kobo.1018.2">Each architecture offers unique benefits and is suited for different data management and analytics scenarios. </span><span class="koboSpan" id="kobo.1018.3">To aid in making the right choice, the following list highlights the benefits, important considerations, and ideal use cases for each type of architecture:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1019.1">Data lake architecture</span></strong><span class="koboSpan" id="kobo.1020.1">: A data lake is primarily intended for the storage of large volumes of raw data in its original format.</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1021.1">Benefits</span></strong><span class="koboSpan" id="kobo.1022.1">: It provides high scalability and flexibility in handling various data types. </span><span class="koboSpan" id="kobo.1022.2">It’s cost-effective for storing large amounts of data and can be used as a central repository for all organizational data.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1023.1">Considerations</span></strong><span class="koboSpan" id="kobo.1024.1">: Without proper governance, data lakes can become unmanageable (“data swamps”). </span><span class="koboSpan" id="kobo.1024.2">They require careful management to ensure data quality and accessibility.</span><strong class="keyWord"> </strong></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1025.1">Use cases</span></strong><span class="koboSpan" id="kobo.1026.1">: It is suitable for big data analytics, ML, and situations where you need to store and analyze large volumes of diverse data at a low cost. </span><span class="koboSpan" id="kobo.1026.2">It is particularly suitable for situations where there is a requirement to store diverse types of data – including structured, semi-structured, and unstructured – without having a predetermined schema at the point of data entry.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1027.1">Lakehouse architecture</span></strong><span class="koboSpan" id="kobo.1028.1">: This combines elements of both data lakes and data warehouses.</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1029.1">Benefits</span></strong><span class="koboSpan" id="kobo.1030.1">: It aims to provide the low-cost scalability of data lakes with the robust schema and performance optimization of data warehouses. </span><span class="koboSpan" id="kobo.1030.2">It offers a unified platform for all types of data processing and analytics, reducing data silos. </span><span class="koboSpan" id="kobo.1030.3">It also supports ACID transactions and schema enforcement, improving data reliability and quality.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1031.1">Considerations</span></strong><span class="koboSpan" id="kobo.1032.1">: Implementing a lakehouse architecture can be complex, requiring integrating various components and ensuring consistency and reliability across different workloads.</span><strong class="keyWord"> </strong></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1033.1">Use cases</span></strong><span class="koboSpan" id="kobo.1034.1">: It is best for organizations requiring big data processing and traditional BI from a single platform. </span><span class="koboSpan" id="kobo.1034.2">It’s ideal for use cases that need real-time analytics and reporting on large and diverse datasets.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1035.1">Data mesh architecture</span></strong><span class="koboSpan" id="kobo.1036.1">: It focuses on decentralizing the data architecture and ownership. </span><span class="koboSpan" id="kobo.1036.2">It treats data as a product, with domain-oriented teams owning and providing their data as products to the rest of the organization.</span><ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1037.1">Benefits</span></strong><span class="koboSpan" id="kobo.1038.1">: It encourages a more agile and flexible data management and analytics approach. </span><span class="koboSpan" id="kobo.1038.2">It also promotes data democratization, allowing for faster decision making and innovation within domains.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1039.1">Considerations</span></strong><span class="koboSpan" id="kobo.1040.1">: It requires a cultural shift in how data is managed and shared. </span><span class="koboSpan" id="kobo.1040.2">It demands strong governance and standardization across domains to ensure data interoperability and quality.</span><strong class="keyWord"> </strong></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1041.1">Use cases</span></strong><span class="koboSpan" id="kobo.1042.1">: It is suitable for large organizations with multiple independent teams or departments, where different domains produce and consume data.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1043.1">The following </span><a id="_idIndexMarker1777"/><span class="koboSpan" id="kobo.1044.1">are some key decision factors:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1045.1">Organizational structure</span></strong><span class="koboSpan" id="kobo.1046.1">: Consider whether your organization is centralized or decentralized. </span><span class="koboSpan" id="kobo.1046.2">Data mesh is more suitable for the latter.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1047.1">Data volume and variety</span></strong><span class="koboSpan" id="kobo.1048.1">: Data lakes are ideal for massive, diverse datasets, while lakehouses provide a more structured environment for such data.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1049.1">Analytical needs</span></strong><span class="koboSpan" id="kobo.1050.1">: A lakehouse might be the best fit if you need real-time analytics combined with big data processing.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1051.1">Governance and compliance</span></strong><span class="koboSpan" id="kobo.1052.1">: Assess your data governance, quality, and compliance needs. </span><span class="koboSpan" id="kobo.1052.2">A lakehouse architecture tends to offer more robust governance mechanisms.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1053.1">Technical expertise</span></strong><span class="koboSpan" id="kobo.1054.1">: Implementing and managing a data mesh or lakehouse architecture requires specific technical expertise and resources.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1055.1">Ultimately, the choice depends on aligning the architecture with your business goals, technical capabilities, and data strategy. </span><span class="koboSpan" id="kobo.1055.2">Each architecture has its strengths, and the best choice may even be a hybrid approach, depending on your specific requirements.</span></p>
<h1 class="heading-1" id="_idParaDest-377"><span class="koboSpan" id="kobo.1056.1">Big data architecture best practices</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1057.1">You learned about various big data technology and architecture patterns in previous sections. </span><span class="koboSpan" id="kobo.1057.2">Let’s </span><a id="_idIndexMarker1778"/><span class="koboSpan" id="kobo.1058.1">look at the following reference architecture diagram with different layers of a data lake architecture to learn best practices.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1059.1"><img alt="" role="presentation" src="../Images/B21336_12_11.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1060.1">Figure 12.11: Data lake reference architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1061.1">The preceding diagram depicts an end-to-end data pipeline in a data lake architecture using the AWS cloud platform with the following components:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1062.1">AWS Direct Connect will set up a high-speed network connection between the on-premises data center and AWS to migrate data. </span><span class="koboSpan" id="kobo.1062.2">If you have large volumes of archive data, using the AWS Snow family to move it offline is better.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1063.1">A data ingestion layer with various components to ingest streaming data using Amazon </span><a id="_idIndexMarker1779"/><span class="koboSpan" id="kobo.1064.1">Kinesis, relational data using AWS </span><strong class="keyWord"><span class="koboSpan" id="kobo.1065.1">Data Migration Service</span></strong><span class="koboSpan" id="kobo.1066.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1067.1">DMS</span></strong><span class="koboSpan" id="kobo.1068.1">), secure file transfer using AWS Transfer </span><a id="_idIndexMarker1780"/><span class="koboSpan" id="kobo.1069.1">for </span><strong class="keyWord"><span class="koboSpan" id="kobo.1070.1">Secure Shell File Transfer Protocol</span></strong><span class="koboSpan" id="kobo.1071.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1072.1">SFTP</span></strong><span class="koboSpan" id="kobo.1073.1">), and AWS DataSync to update data files between cloud and on-premises systems.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1074.1">Centralized data storage for all data using Amazon S3, where data storage has multiple layers to store raw data, processed data, and archive data.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1075.1">Amazon Redshift is a cloud-native data warehouse solution with Redshift Spectrum to support lakehouse architecture.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1076.1">An ad hoc query functionality using Amazon Athena.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1077.1">A quick ETL pipeline based on Spark using AWS Glue.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1078.1">Amazon EMR will re-utilize existing Hadoop scripts and other Apache Hadoop frameworks.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1079.1">Amazon Lake Formation to build comprehensive data cataloging and granular access control at the data lake level.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1080.1">The AI/ML extension with Amazon SageMaker.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1081.1">Other </span><a id="_idIndexMarker1781"/><span class="koboSpan" id="kobo.1082.1">components include Amazon </span><strong class="keyWord"><span class="koboSpan" id="kobo.1083.1">Key Management Service </span></strong><span class="koboSpan" id="kobo.1084.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.1085.1">KMS</span></strong><span class="koboSpan" id="kobo.1086.1">) for data </span><a id="_idIndexMarker1782"/><span class="koboSpan" id="kobo.1087.1">encryption, Amazon </span><strong class="keyWord"><span class="koboSpan" id="kobo.1088.1">Identity and Access Management </span></strong><span class="koboSpan" id="kobo.1089.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.1090.1">IAM</span></strong><span class="koboSpan" id="kobo.1091.1">) for access control, Amazon Macie for PII data </span><a id="_idIndexMarker1783"/><span class="koboSpan" id="kobo.1092.1">detection to adhere to data compliance </span><a id="_idIndexMarker1784"/><span class="koboSpan" id="kobo.1093.1">such as </span><strong class="keyWord"><span class="koboSpan" id="kobo.1094.1">Payment Card Industry Data Security Standard</span></strong><span class="koboSpan" id="kobo.1095.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1096.1">PCI DSS</span></strong><span class="koboSpan" id="kobo.1097.1">), CloudWatch to monitor the operation, and CloudTrail to audit the data lake activities.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1098.1">You need to validate your big data architecture using the following criteria:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1099.1">Security:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1100.1">Classify data and define corresponding data protection policies using resource-based access control.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1101.1">Implement a </span><a id="_idIndexMarker1785"/><span class="koboSpan" id="kobo.1102.1">strong identity foundation using user permission and </span><strong class="keyWord"><span class="koboSpan" id="kobo.1103.1">single sign-on</span></strong><span class="koboSpan" id="kobo.1104.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.1105.1">SSO</span></strong><span class="koboSpan" id="kobo.1106.1">).</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1107.1">Enable environment and data traceability for audit purposes.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1108.1">Apply security at all layers and protect data in transit and at rest using SSL and encryption at all layers.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1109.1">Keep people away from data, such as locking down write access to production datasets.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.1110.1">Reliability:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1111.1">Enforce data hygiene using automated data profiling using data cataloging.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1112.1">Manage the life cycle of data assets, transitioning, and expiration using data tiering between the data warehouse and data lake.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1113.1">Preserve data lineage by maintaining the history of data movement through the data catalog.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1114.1">Design resiliency for analytics pipelines and monitor system SLAs with automated recovery of ETL job failures.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.1115.1">Performance efficiency:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1116.1">Use data profiling to improve performance with data validation and to build a sanitization layer.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1117.1">Continuously optimize data storage, such as using data compression with a Parquet format, data partition, file size optimization, and so on.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.1118.1">Cost optimization:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1119.1">Adopt a consumption model and determine whether you need an ad hoc or fast query pattern.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1120.1">Delete </span><a id="_idIndexMarker1786"/><span class="koboSpan" id="kobo.1121.1">out-of-use data; define data retention rules and delete or archive data out of the retention period.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1122.1">Decouple compute and storage with a data lake-based solution.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1123.1">Implement migration efficiency using different migration strategies for various data sources and volumes.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1124.1">Use managed and application-level services to reduce the cost of ownership.</span></li>
</ul>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.1125.1">Operational excellence:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.1126.1">Perform operations as code using tools such as CloudFormation, Terraform, and Ansible.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1127.1">Automate operations such as building an orchestration layer with Step Functions or Apache Airflow.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1128.1">Anticipate failure in advance by continuously monitoring and automating the recovery of ETL job failures.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.1129.1">Measure the health of your workload.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1130.1">You can use the preceding checklist as a guide to validate your big data architecture. </span><span class="koboSpan" id="kobo.1130.2">Data engineering is a vast topic that warrants multiple books to cover each topic in depth.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1131.1">In this chapter, you learned about various components of data engineering with a popular architecture pattern, which will help you get started and explore the topic in more depth.</span></p>
<h1 class="heading-1" id="_idParaDest-378"><span class="koboSpan" id="kobo.1132.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1133.1">In this chapter, you learned about the big data architecture and components for a big data pipeline design. </span><span class="koboSpan" id="kobo.1133.2">You learned about data ingestion and various technology choices available to collect batch and stream data for processing. </span><span class="koboSpan" id="kobo.1133.3">As the cloud is central to storing the vast amounts of data produced today, you learned about the various services available to ingest data in the AWS cloud ecosystem.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1134.1">Data storage is one of the central points of handling big data. </span><span class="koboSpan" id="kobo.1134.2">You learned about various kinds of data stores, including structured and unstructured data, NoSQL, and data warehousing, with the appropriate technology choices associated with each. </span><span class="koboSpan" id="kobo.1134.3">You learned about cloud data storage from popular public cloud providers.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1135.1">Once you collect and store data, you need to transform it to get insights into that data and visualize your business requirements. </span><span class="koboSpan" id="kobo.1135.2">You learned about data processing architecture and technology choices to choose open source and cloud-based data processing tools per your data requirements. </span><span class="koboSpan" id="kobo.1135.3">These tools help you get data insights and visualizations per the nature of your data and organizational needs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1136.1">You learned about various big data architecture patterns, including data lake, lakehouse, data mesh, streaming data architecture, reference architecture, and how to choose the right architecture for your data needs. </span><span class="koboSpan" id="kobo.1136.2">Finally, you learned big data architecture best practices by combining all your learning in the reference architecture.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1137.1">As you collect more data, it’s always beneficial to get future insights, which can be exceptionally beneficial for business. </span><span class="koboSpan" id="kobo.1137.2">You often need ML to predict future outcomes based on historical data. </span><span class="koboSpan" id="kobo.1137.3">In the next chapter, let’s learn more about ML and how to make your data architecture future-proof.</span></p>
<h1 class="heading-1" id="_idParaDest-379"><span class="koboSpan" id="kobo.1138.1">Join our book’s Discord space</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1139.1">Join the book’s Discord workspace to ask questions and interact with the authors and other solution architecture professionals: </span><a href="Chapter_12.xhtml"><span class="url"><span class="koboSpan" id="kobo.1140.1">https://packt.link/SAHandbook</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.1141.1"><img alt="" role="presentation" src="../Images/QR_Code930022060277868125.png"/></span></p>
</div>
</body></html>