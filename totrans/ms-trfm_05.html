<html><head></head><body>
<div id="_idContainer049">
<h1 class="chapter-number" id="_idParaDest-111"><a id="_idTextAnchor278"/><span class="koboSpan" id="kobo.1.1">5</span></h1>
<h1 id="_idParaDest-112"><a id="_idTextAnchor279"/><span class="koboSpan" id="kobo.2.1">Beyond VMs – Core Concepts of Containers and Kubernetes</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In the previous chapter, we familiarized ourselves with </span><strong class="bold"><span class="koboSpan" id="kobo.4.1">virtual machine</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.6.1">VM</span></strong><span class="koboSpan" id="kobo.7.1">) architecture and the core concepts and mechanics needed to automate VM-based solutions. </span><span class="koboSpan" id="kobo.7.2">In this book, we will build end-to-end solutions covering the three significant hyperscalars—</span><strong class="bold"><span class="koboSpan" id="kobo.8.1">Amazon Web Services</span></strong><span class="koboSpan" id="kobo.9.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.10.1">AWS</span></strong><span class="koboSpan" id="kobo.11.1">), Azure, and </span><strong class="bold"><span class="koboSpan" id="kobo.12.1">Google Cloud Platform</span></strong><span class="koboSpan" id="kobo.13.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.14.1">GCP</span></strong><span class="koboSpan" id="kobo.15.1">)—and covering three cloud computing paradigms: VMs, containers, and serverless. </span><span class="koboSpan" id="kobo.15.2">In this chapter, we will look at the core concepts needed to tackle container-based architecture solutions using the managed Kubernetes offerings from each </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">cloud platform.</span></span></p>
<p><span class="koboSpan" id="kobo.17.1">To accomplish this, we must understand the basics of containers, Kubernetes, and how they fit within the Terraform ecosystem. </span><span class="koboSpan" id="kobo.17.2">As with VMs and the surrounding toolchains used for configuration management and the </span><strong class="bold"><span class="koboSpan" id="kobo.18.1">build-versus-bake</span></strong><span class="koboSpan" id="kobo.19.1"> dilemma, with container-based architecture, we need to make some decisions about where the boundary between Terraform and other tools will exist and how best to integrate configuration management of our containers and container orchestrators with the cloud infrastructure that we provision to </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">host them.</span></span></p>
<p><span class="koboSpan" id="kobo.21.1">The chapter covers the </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.23.1">Understanding key concepts of </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">container architecture</span></span></li>
<li><span class="koboSpan" id="kobo.25.1">Leveraging Docker to build </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">container images</span></span></li>
<li><span class="koboSpan" id="kobo.27.1">Working with </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">container registries</span></span></li>
<li><span class="koboSpan" id="kobo.29.1">Understanding key concepts of container orchestration </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">and Kubernetes</span></span></li>
<li><span class="koboSpan" id="kobo.31.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">Kubernetes manifests</span></span></li>
<li><span class="koboSpan" id="kobo.33.1">Leveraging the Kubernetes provider to provision </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">Kubernetes resources</span></span></li>
<li><span class="koboSpan" id="kobo.35.1">Leveraging the Helm provider to provision </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">Kubernetes resources</span></span></li>
</ul>
<h1 id="_idParaDest-113"><a id="_idTextAnchor280"/><span class="koboSpan" id="kobo.37.1">Understanding key concepts of container architecture</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.38.1">VMs</span></strong><span class="koboSpan" id="kobo.39.1"> are great when </span><a id="_idIndexMarker357"/><span class="koboSpan" id="kobo.40.1">you want minimal changes to operate your applications and software in the cloud, but they also have drawbacks. </span><span class="koboSpan" id="kobo.40.2">With the maximum control you get from having a full VM—of whatever size you happened to provision—you are free to use as many (or as few) of the VM’s resources as you can. </span><span class="koboSpan" id="kobo.40.3">However, many organizations have found that their fleet of VMs is plagued by low utilization even when best practices</span><a id="_idIndexMarker358"/><span class="koboSpan" id="kobo.41.1"> in workload isolation or the </span><strong class="bold"><span class="koboSpan" id="kobo.42.1">single responsibility principle</span></strong><span class="koboSpan" id="kobo.43.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.44.1">SRP</span></strong><span class="koboSpan" id="kobo.45.1">) </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">are followed.</span></span></p>
<p><span class="koboSpan" id="kobo.47.1">Inversely, when maximum utilization is the objective, organizations load up a single VM with so many disparate services and components that each VM—while highly utilized—becomes a bit of a quagmire to manage and maintain. </span><span class="koboSpan" id="kobo.47.2">The VM will have a myriad of dependency conflicts, with resource contention cropping up between the horde of independent but cohabitating processes within the </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">same VM.</span></span></p>
<p><span class="koboSpan" id="kobo.49.1">This dilemma between workload isolation and resource utilization is the problem that container technology aims to solve and where container orchestrators, such as Kubernetes, help by bringing resiliency </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">and scalability.</span></span></p>
<p><span class="koboSpan" id="kobo.51.1">In this book, we will build an end-to-end solution using Kubernetes-based container technology on AWS, Azure, and GCP. </span><span class="koboSpan" id="kobo.51.2">To do so, you must understand some critical concepts that transcend cloud platforms to help you navigate the architecture and relevant Terraform resources within the respective cloud platform’s </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">Terraform provider</span><a id="_idTextAnchor281"/><span class="koboSpan" id="kobo.53.1">.</span></span></p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor282"/><span class="koboSpan" id="kobo.54.1">Containers</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.55.1">Containers</span></strong><span class="koboSpan" id="kobo.56.1"> allow</span><a id="_idIndexMarker359"/><span class="koboSpan" id="kobo.57.1"> you to package your applications into an isolated environment logically separated from other applications without the overhead incurred by virtualizing the underlying physical hardware and the resource consumption of a full-on operating system. </span><span class="koboSpan" id="kobo.57.2">Whether it is Windows or Linux, the operating system consumes resources that take away from </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1">your capacity.</span></span></p>
<p><span class="koboSpan" id="kobo.59.1">Containers use two Linux kernel primitives: </span><em class="italic"><span class="koboSpan" id="kobo.60.1">namespaces</span></em><span class="koboSpan" id="kobo.61.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.62.1">control groups</span></em><span class="koboSpan" id="kobo.63.1">. </span><span class="koboSpan" id="kobo.63.2">These constructs allow the container runtime to set up an isolated environment within the Linux operating system. </span><span class="koboSpan" id="kobo.63.3">Namespaces are all about isolation, which allows us to split the operating system into multiple virtual operating systems with their own process tree, root filesystem, user, and so on. </span><span class="koboSpan" id="kobo.63.4">Each container might feel like a regular operating system, but it’s not. </span><span class="koboSpan" id="kobo.63.5">Control groups police the allocation of the host system’s resources—including CPU, memory, and disk I/O—to ensure that the actual physical server is not overwhelmed by resources consumed by </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">the containers.</span></span></p>
<p><span class="koboSpan" id="kobo.65.1">The last</span><a id="_idIndexMarker360"/><span class="koboSpan" id="kobo.66.1"> component that enables containers is a layered filesystem. </span><span class="koboSpan" id="kobo.66.2">This is similar to how we used to build VM images—only with better isolation between layers. </span><span class="koboSpan" id="kobo.66.3">When we build a VM layer, when we apply changes to and create a new VM image, we can no longer sort out the base layer from the top layer. </span><span class="koboSpan" id="kobo.66.4">Containers can apply filesystem layers that contain only the differences between the lower layers. </span><span class="koboSpan" id="kobo.66.5">This approach creates an extremely compact and highly efficient way of layering changes onto each container image to compose the final filesystem that the container operates on—with the topmost layer being writable by the </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">container itself.</span></span></p>
<p><span class="koboSpan" id="kobo.68.1">One of the key benefits of containers is their efficiency. </span><span class="koboSpan" id="kobo.68.2">Unlike VMs, which require separate operating systems and resource allocations for each instance, containers directly leverage the host system’s kernel. </span><span class="koboSpan" id="kobo.68.3">This approach means they consume fewer resources and start up much faster than their VM counterparts. </span><span class="koboSpan" id="kobo.68.4">Multiple containers can run simultaneously on a single host, thus using system resources more efficiently. </span><span class="koboSpan" id="kobo.68.5">This allows us to create higher-density workloads—thus reducing the waste of valuable system resources such as CPU and memory to idleness, and when working in the cloud, this waste is like pouring money down </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">the dra</span><a id="_idTextAnchor283"/><span class="koboSpan" id="kobo.70.1">in!</span></span></p>
<p><span class="koboSpan" id="kobo.71.1">Now that we have a solid understanding of what a container is and how it differs from a VM, let’s look at the de facto tool for managing the configuration of an individual container: </span><strong class="bold"><span class="koboSpan" id="kobo.72.1">Docker</span></strong><span class="koboSpan" id="kobo.73.1">. </span><span class="koboSpan" id="kobo.73.2">While this book isn’t about Docker per se, if you are going to be a master of Terraform and work with container-based architectures, you will inevitably come into contact with this tool either directly or need to integrate it into the </span><strong class="bold"><span class="koboSpan" id="kobo.74.1">continuous integration/continuous deployment</span></strong><span class="koboSpan" id="kobo.75.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.76.1">CI/CD</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">) process.</span></span></p>
<h1 id="_idParaDest-115"><a id="_idTextAnchor284"/><span class="koboSpan" id="kobo.78.1">Leveraging Docker to build container images</span></h1>
<p><span class="koboSpan" id="kobo.79.1">The </span><a id="_idIndexMarker361"/><span class="koboSpan" id="kobo.80.1">Docker engine makes the process of setting up containers much simpler. </span><span class="koboSpan" id="kobo.80.2">It provides a consistent meta-language for describing containers and command-line tools for building, interrogating, and running </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">container ima</span><a id="_idTextAnchor285"/><span class="koboSpan" id="kobo.82.1">ges.</span></span></p>
<h2 id="_idParaDest-116"><a id="_idTextAnchor286"/><span class="koboSpan" id="kobo.83.1">Writing a Dockerfile</span></h2>
<p><span class="koboSpan" id="kobo.84.1">Docker uses</span><a id="_idIndexMarker362"/><span class="koboSpan" id="kobo.85.1"> a simple syntax that you can use to define basic information about your container. </span><span class="koboSpan" id="kobo.85.2">This basic structure includes what base image to build onto (</span><strong class="source-inline"><span class="koboSpan" id="kobo.86.1">FROM</span></strong><span class="koboSpan" id="kobo.87.1">), who the author is (</span><strong class="source-inline"><span class="koboSpan" id="kobo.88.1">MAINTAINER</span></strong><span class="koboSpan" id="kobo.89.1">), files to copy and commands to execute (</span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1">COPY</span></strong><span class="koboSpan" id="kobo.91.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.92.1">RUN</span></strong><span class="koboSpan" id="kobo.93.1">), and what the entry point process should </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">be (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.95.1">CMD</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.97.1">Much of this is similar to the structure of a Packer template, except for the entry point process. </span><span class="koboSpan" id="kobo.97.2">With Packer, it’s just a VM; whatever processes are running, based on how you configure, it will be running. </span><span class="koboSpan" id="kobo.97.3">With Docker, you need to explicitly state what process to start because containers run a single process </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">in isolation.</span></span></p>
<p><span class="koboSpan" id="kobo.99.1">You can also configure the runtime further by setting the working directory, adding environment variables, and exposing </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">network ports.</span></span></p>
<p><span class="koboSpan" id="kobo.101.1">A simple Dockerfile looks </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">like this:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.103.1">
# Use an official Python runtime as a parent image
FROM python:3.7-slim
# Set the working directory in the container to /app
WORKDIR /app
# Copy the current directory contents into the container at /app
COPY . </span><span class="koboSpan" id="kobo.103.2">/app
# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt
# Make port 80 available to the world outside this container
EXPOSE 80
# Run app.py when the container launches
CMD \["python", "app.py"]</span></pre> <p><span class="koboSpan" id="kobo.104.1">Notice that</span><a id="_idIndexMarker363"/><span class="koboSpan" id="kobo.105.1"> we are building from a base image called </span><strong class="source-inline"><span class="koboSpan" id="kobo.106.1">python:3-7slim</span></strong><span class="koboSpan" id="kobo.107.1"> and copying the current folder’s contents to the container’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.108.1">/app</span></strong><span class="koboSpan" id="kobo.109.1"> directory. </span><span class="koboSpan" id="kobo.109.2">This step will copy the </span><strong class="source-inline"><span class="koboSpan" id="kobo.110.1">app.py</span></strong><span class="koboSpan" id="kobo.111.1"> script into the container so that it is available when we set it as the execution point at the bottom of the file. </span><span class="koboSpan" id="kobo.111.2">This Python script sets up a web server and exposes it to </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">po</span><a id="_idTextAnchor287"/><span class="koboSpan" id="kobo.113.1">rt </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.114.1">80</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">.</span></span></p>
<h2 id="_idParaDest-117"><a id="_idTextAnchor288"/><span class="koboSpan" id="kobo.116.1">Building a Docker image</span></h2>
<p><span class="koboSpan" id="kobo.117.1">Just as with </span><a id="_idIndexMarker364"/><span class="koboSpan" id="kobo.118.1">Terraform, Docker uses the current working directory to derive its context. </span><span class="koboSpan" id="kobo.118.2">Therefore, when building a Docker image, you need to execute the </span><strong class="source-inline"><span class="koboSpan" id="kobo.119.1">docker build</span></strong><span class="koboSpan" id="kobo.120.1"> command from the same directory where your Dockerfile resides. </span><span class="koboSpan" id="kobo.120.2">However, you can override this by specifying a </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">different path:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.122.1">
docker build -t your-image-name .</span></pre> <p><span class="koboSpan" id="kobo.123.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.124.1">-t</span></strong><span class="koboSpan" id="kobo.125.1"> flag lets you tag your image with a memorable name. </span><span class="koboSpan" id="kobo.125.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.126.1">.</span></strong><span class="koboSpan" id="kobo.127.1"> instance may seem out of place, but it tells Docker to look for the Dockerfile in the </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">current directory.</span></span></p>
<p><span class="koboSpan" id="kobo.129.1">After the build completes, you can see your image listed by running the </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.131.1">
docker</span><a id="_idTextAnchor289"/><span class="koboSpan" id="kobo.132.1"> images</span></pre> <h2 id="_idParaDest-118"><a id="_idTextAnchor290"/><span class="koboSpan" id="kobo.133.1">Running Docker images</span></h2>
<p><span class="koboSpan" id="kobo.134.1">Docker images </span><a id="_idIndexMarker365"/><span class="koboSpan" id="kobo.135.1">are like the VM images we built using Packer, which represent a VM we have yet to start. </span><span class="koboSpan" id="kobo.135.2">They have potential energy but need to be launched as the operating system disk of a VM to achieve kinetic energy and become a running VM. </span><span class="koboSpan" id="kobo.135.3">Docker images are the same for containers. </span><span class="koboSpan" id="kobo.135.4">We need to start a container using the image and specify the </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">runtime configuration:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.137.1">
docker run -p 4000:80 your-image-name</span></pre> <p><span class="koboSpan" id="kobo.138.1">In this case, because we exposed port </span><strong class="source-inline"><span class="koboSpan" id="kobo.139.1">80</span></strong><span class="koboSpan" id="kobo.140.1"> in the container, we need to map a port to the container’s port </span><strong class="source-inline"><span class="koboSpan" id="kobo.141.1">80</span></strong><span class="koboSpan" id="kobo.142.1">. </span><span class="koboSpan" id="kobo.142.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">-p</span></strong><span class="koboSpan" id="kobo.144.1"> flag maps a network port inside the container to a port on the host machine. </span><span class="koboSpan" id="kobo.144.2">This setting will route traffic from port </span><strong class="source-inline"><span class="koboSpan" id="kobo.145.1">4000</span></strong><span class="koboSpan" id="kobo.146.1"> on the host to port </span><strong class="source-inline"><span class="koboSpan" id="kobo.147.1">80</span></strong><span class="koboSpan" id="kobo.148.1"> on </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">the container.</span></span></p>
<p><span class="koboSpan" id="kobo.150.1">You </span><a id="_idIndexMarker366"/><span class="koboSpan" id="kobo.151.1">can run as many containers as your host machine can handle. </span><span class="koboSpan" id="kobo.151.2">You are constrained only by the technical resources of the host machine. </span><span class="koboSpan" id="kobo.151.3">Sometimes, the cloud platform imposes constraints depending on what SKU of VM your host machine </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">is running.</span></span></p>
<p><span class="koboSpan" id="kobo.153.1">To see which containers are running, you can execute the following </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">Docker command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.155.1">
docker ps</span></pre> <p><span class="koboSpan" id="kobo.156.1">This section should help you understand the basic principles of working with Docker images. </span><span class="koboSpan" id="kobo.156.2">While there are many more commands and flags you can use with Docker to manage your images and containers, this is out of the scope of this book. </span><span class="koboSpan" id="kobo.156.3">I’m providing you with enough theory and practice to be productive in building container-based architectures </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">using Terraform.</span></span></p>
<p><span class="koboSpan" id="kobo.158.1">In this section, we familiarized ourselves with the command-line tool used to create container </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">images: Docker.</span></span></p>
<p><span class="koboSpan" id="kobo.160.1">In the next section, we’ll look at how to publish these container images that we create with Docker to container registries so that we can deploy containers </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">with them.</span></span></p>
<h1 id="_idParaDest-119"><a id="_idTextAnchor291"/><span class="koboSpan" id="kobo.162.1">Working with container registries</span></h1>
<p><span class="koboSpan" id="kobo.163.1">A </span><strong class="bold"><span class="koboSpan" id="kobo.164.1">container registry</span></strong><span class="koboSpan" id="kobo.165.1"> is </span><a id="_idIndexMarker367"/><span class="koboSpan" id="kobo.166.1">just a server-side application that acts as central storage and allows you to distribute container images to the host machines that need to run them. </span><span class="koboSpan" id="kobo.166.2">This approach is advantageous when leveraging a CI/CD pipeline where you need a central location to pull down your </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">container images.</span></span></p>
<p><span class="koboSpan" id="kobo.168.1">They often </span><a id="_idIndexMarker368"/><span class="koboSpan" id="kobo.169.1">provide versioning, labeling, and sharing mechanisms that let you keep track of different versions of your container images, maintain stable releases, and share images with others—either within your organization </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">or publicly.</span></span></p>
<p><span class="koboSpan" id="kobo.171.1">Just as with </span><strong class="source-inline"><span class="koboSpan" id="kobo.172.1">git</span></strong><span class="koboSpan" id="kobo.173.1">, anybody can set up a container registry on their own, but several managed services provide best-in-class service offerings on each of the respective clouds. </span><span class="koboSpan" id="kobo.173.2">There is also a cloud-agnostic and community-oriented solution: Docker Hub. </span><span class="koboSpan" id="kobo.173.3">Docker Hub is the default registry where Docker looks for images, and you can use it for both images you want to share publicly or keep private for internal purposes. </span><span class="koboSpan" id="kobo.173.4">It offers a free tier and paid plans with more storage </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">an</span><a id="_idTextAnchor292"/><span class="koboSpan" id="kobo.175.1">d features.</span></span></p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor293"/><span class="koboSpan" id="kobo.176.1">Docker Hub</span></h2>
<p><span class="koboSpan" id="kobo.177.1">The mechanics </span><a id="_idIndexMarker369"/><span class="koboSpan" id="kobo.178.1">of interacting with a container registry are broadly similar depending on the service—with only slight variations. </span><span class="koboSpan" id="kobo.178.2">As an example, because it is the default container registry that Docker uses, I’ll show you how to use </span><strong class="bold"><span class="koboSpan" id="kobo.179.1">Docker Hub</span></strong><span class="koboSpan" id="kobo.180.1"> to authenticate, tag, push, and pull </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">your images.</span></span></p>
<p><span class="koboSpan" id="kobo.182.1">First, you need to authenticate. </span><span class="koboSpan" id="kobo.182.2">Depending on your registry service, this step might require additional tools. </span><span class="koboSpan" id="kobo.182.3">However, you won’t need to install any other tools for Docker Hub but, naturally, you will need to register an account on </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">Docker Hub:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.184.1">
docker login</span></pre> <p><span class="koboSpan" id="kobo.185.1">The preceding command will initiate an interactive login process where you must supply your Docker Hub username </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">and password.</span></span></p>
<p><span class="koboSpan" id="kobo.187.1">Before you can push your image to a registry, you must tag it with the </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">registry’s address:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.189.1">
docker tag foo:1.0 markti/foo:1.0</span></pre> <p><span class="koboSpan" id="kobo.190.1">The preceding command first specifies the </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">my-image</span></strong><span class="koboSpan" id="kobo.192.1"> source image of a specific version, </span><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">1.0</span></strong><span class="koboSpan" id="kobo.194.1">. </span><span class="koboSpan" id="kobo.194.2">Then, it specifies a target image under my </span><strong class="source-inline"><span class="koboSpan" id="kobo.195.1">markti</span></strong><span class="koboSpan" id="kobo.196.1"> Docker Hub account for the same image and version. </span><span class="koboSpan" id="kobo.196.2">It’s crucial to synchronize the image name and version between your local and remote environments to maintain consistency between the environments. </span><span class="koboSpan" id="kobo.196.3">After your image is tagged, you can push it to </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">the registry:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.198.1">
docker push markti/foo:1.0</span></pre> <p><span class="koboSpan" id="kobo.199.1">The preceding command pushes the image to the remote container registry. </span><span class="koboSpan" id="kobo.199.2">Now, you can pull the image with the appropriate permissions using your Docker Hub username as the registry name, the container image name, and </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">the tag:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.201.1">
docker pull markti/foo:1.0</span></pre> <p><span class="koboSpan" id="kobo.202.1">Remember that container registries might have slightly different naming conventions and </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">authentication processes.</span></span></p>
<p><span class="koboSpan" id="kobo.204.1">In this section, we looked at how to work with container registries, which serve as a critical infrastructure for our container-based architecture. </span><span class="koboSpan" id="kobo.204.2">In the next section, we’re ready to look at Kubernetes—both from an architectural standpoint and at its practical usage as a developer, operator, and within </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">CI/CD pipelines.</span></span></p>
<h1 id="_idParaDest-121"><a id="_idTextAnchor294"/><span class="koboSpan" id="kobo.206.1">Understanding key concepts of container orchestration and Kubernetes</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.207.1">Kubernetes</span></strong><span class="koboSpan" id="kobo.208.1"> is a</span><a id="_idIndexMarker370"/><span class="koboSpan" id="kobo.209.1"> platform that expands on the responsibilities of the container runtime, which operates at an individual host level. </span><span class="koboSpan" id="kobo.209.2">Kubernetes’ job is to perform this across multiple nodes. </span><span class="koboSpan" id="kobo.209.3">As we learned in the first section of this chapter, the container runtime uses a Linux operating system construct—control groups—to protect the health of </span><a id="_idIndexMarker371"/><span class="koboSpan" id="kobo.210.1">the operating system by ensuring that the physical (or virtual) host that the containers are running on remains healthy. </span><span class="koboSpan" id="kobo.210.2">Kubernetes essentially does the same thing but across many, </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">many servers.</span></span></p>
<p><span class="koboSpan" id="kobo.212.1">Most applications or systems will naturally be organized into different components, layers, or microservices—each with its own responsibilities and corresponding application code and technology stack that implements its functionality. </span><span class="koboSpan" id="kobo.212.2">Each component within such a system will have its own container that has this </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">software installed.</span></span></p>
<p><span class="koboSpan" id="kobo.214.1">When we deploy systems using VMs, we do so in such a way that the same component is deployed to two more VMs, and we ensure that these VMs do not share the same underlying physical equipment. </span><span class="koboSpan" id="kobo.214.2">This separation could be as simple as a different physical host in the same rack, all the way up to a different physical host in an entirely different data center—sometimes separated by many tens, if not hundreds, of miles. </span><span class="koboSpan" id="kobo.214.3">This allows us to </span><a id="_idIndexMarker372"/><span class="koboSpan" id="kobo.215.1">achieve </span><strong class="bold"><span class="koboSpan" id="kobo.216.1">high availability</span></strong><span class="koboSpan" id="kobo.217.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.218.1">HA</span></strong><span class="koboSpan" id="kobo.219.1">) and resiliency during an outage or an issue affecting some underlying component of the </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">physical hardware.</span></span></p>
<p><span class="koboSpan" id="kobo.221.1">Unlike when using VMs, our application components don’t sit on isolated VMs; they sit on the cluster nodes, oftentimes with pods from </span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">other applications.</span></span></p>
<p><span class="koboSpan" id="kobo.223.1">Kubernetes tries to make sure that our application containers don’t sit on the same node. </span><span class="koboSpan" id="kobo.223.2">That way, if one of the cluster’s nodes fails, our application will not go down. </span><span class="koboSpan" id="kobo.223.3">Kubernetes also takes it a step further by intelligently reorganizing the containers on other health nodes. </span><span class="koboSpan" id="kobo.223.4">In order to do this, Kubernetes maintains a divide between its own internal </span><strong class="bold"><span class="koboSpan" id="kobo.224.1">logical layer</span></strong><span class="koboSpan" id="kobo.225.1"> and </span><a id="_idIndexMarker373"/><span class="koboSpan" id="kobo.226.1">the underlying </span><strong class="bold"><span class="koboSpan" id="kobo.227.1">physical layer</span></strong><span class="koboSpan" id="kobo.228.1"> and</span><a id="_idIndexMarker374"/><span class="koboSpan" id="kobo.229.1"> maps the device by assigning logical deployments, or pods, to physical deployments and nodes. </span><span class="koboSpan" id="kobo.229.2">This separation between the logical and the physical layers is one of Kubernetes’ huge advantages and what makes it so effective at managing applications and services on top of a potentially unlimited underlying </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">physical infrastructure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<span class="koboSpan" id="kobo.231.1"><img alt="Figure 5.1 – Logical-physical divide" src="image/B21183_05_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.232.1">Figure 5.1 – Logical-physical divide</span></p>
<p><span class="koboSpan" id="kobo.233.1">That’s pretty</span><a id="_idIndexMarker375"/><span class="koboSpan" id="kobo.234.1"> much it, but there are a lot of ways we can customize how our application’s components are deployed to Kubernetes to meet the specific needs of </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">our application.</span></span></p>
<p><span class="koboSpan" id="kobo.236.1">Kubernetes is flexible enough to run on a fleet of VMs on a cloud provider or physical bare-metal servers down to running on a single computer—such as your laptop. </span><span class="koboSpan" id="kobo.236.2">This flexibility makes it an ideal choice for hybrid cloud scenarios. </span><span class="koboSpan" id="kobo.236.3">It streamlines the problematic task of integration testing by allowing developers to run a copy of the entire solution on their laptop that closely mimics a </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">production environment.</span></span></p>
<p><span class="koboSpan" id="kobo.238.1">Kubernetes offers a rich set of features that fulfill most of the needs for running workloads at scale, such as service discovery, secrets management, horizontal scaling, automated rollouts and rollbacks, and self-healing capabilities—making it an ideal candidate to run both stateless and stateful applications at scale while avoiding </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">vendor lock-in.</span></span></p>
<p><span class="koboSpan" id="kobo.240.1">Kubernetes architecture </span><a id="_idIndexMarker376"/><span class="koboSpan" id="kobo.241.1">is a set of loosely coupled and extensible components. </span><span class="koboSpan" id="kobo.241.2">This modularity allows adaptations for different cloud providers to integrate with their specific solutions for networking, storage, service mesh, and </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.243.1">As with Terraform, Google designed Kubernetes to encourage the adoption of </span><strong class="bold"><span class="koboSpan" id="kobo.244.1">infrastructure as code</span></strong><span class="koboSpan" id="kobo.245.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.246.1">IaC</span></strong><span class="koboSpan" id="kobo.247.1">) by </span><a id="_idIndexMarker377"/><span class="koboSpan" id="kobo.248.1">leveraging a declarative approach for defining your application’s runtime environment. </span><span class="koboSpan" id="kobo.248.2">Due to the extensibility of both Terraform and Kubernetes, several integration options exist. </span><span class="koboSpan" id="kobo.248.3">In this chapter, we’ll discuss a few of those approaches and trade-offs that come along with each—but before we do that, we need to introduce some critical concepts of Kubernetes’ internal architecture and operating model. </span><span class="koboSpan" id="kobo.248.4">Only with this foundation can we maximize the potential of leveraging Terraform and </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">K</span><a id="_idTextAnchor295"/><span class="koboSpan" id="kobo.250.1">ubernetes together.</span></span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor296"/><span class="koboSpan" id="kobo.251.1">Kubernetes architecture</span></h2>
<p><span class="koboSpan" id="kobo.252.1">Kubernetes is a </span><a id="_idIndexMarker378"/><span class="koboSpan" id="kobo.253.1">distributed software system, and its design is relatively similar to that of other such systems. </span><span class="koboSpan" id="kobo.253.2">Because its responsibility spans a cluster of interconnected computer systems that can scale from just a few to literally thousands, it is organized like an army. </span><span class="koboSpan" id="kobo.253.3">There are officers, soldiers, and a central command. </span><span class="koboSpan" id="kobo.253.4">The soldiers are organized into smaller sub-groups, and each needs to maintain continuous contact with the central command in order to operate effectively by receiving new orders and providing the status of the current situation. </span><span class="koboSpan" id="kobo.253.5">The central commands receive status reports from the various officers that oversee their soldiers and operating orders and determine whether different areas of the battlefield need more troops or fewer troops, issuing orders to reallocate different sub-groups of the soldiers to different locations across the battlefield. </span><span class="koboSpan" id="kobo.253.6">Let’s dive into each compon</span><a id="_idTextAnchor297"/><span class="koboSpan" id="kobo.254.1">ent and </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">their roles.</span></span></p>
<h3><span class="koboSpan" id="kobo.256.1">Master node</span></h3>
<p><span class="koboSpan" id="kobo.257.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.258.1">master node</span></strong><span class="koboSpan" id="kobo.259.1"> is</span><a id="_idIndexMarker379"/><span class="koboSpan" id="kobo.260.1"> the central command of the Kubernetes cluster—it’s essentially where the generals of the army operate. </span><span class="koboSpan" id="kobo.260.2">For smaller skirmishes, there is typically only one central command, but for truly epic entanglement, you might need more than one for each theatre of war. </span><span class="koboSpan" id="kobo.260.3">It oversees the entire system and makes high-level decisions. </span><span class="koboSpan" id="kobo.260.4">As with any good central command, it must perform </span><span class="No-Break"><span class="koboSpan" id="kobo.261.1">several functions:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.262.1">API server</span></strong><span class="koboSpan" id="kobo.263.1">: Any army</span><a id="_idIndexMarker380"/><span class="koboSpan" id="kobo.264.1"> must take input from its civilian government, which provides objectives to complete and defines what success looks like. </span><span class="koboSpan" id="kobo.264.2">In many ways, this is very much like the role of the API server. </span><span class="koboSpan" id="kobo.264.3">Instead of taking input from politicians via that red telephone, it takes input from the end user (usually a system administrator or software developer) over a REST-based interface. </span><span class="koboSpan" id="kobo.264.4">The definition of success looks a bit different as well, which is the definition of how the end user’s applications and services should be deployed and how to tell if they </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">are healthy.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.266.1">Controller manager</span></strong><span class="koboSpan" id="kobo.267.1">: Napoleon Bonaparte famously said, “</span><em class="italic"><span class="koboSpan" id="kobo.268.1">An army marches on its stomach</span></em><span class="koboSpan" id="kobo.269.1">,” which </span><a id="_idIndexMarker381"/><span class="koboSpan" id="kobo.270.1">highlights the importance of sound logistics when waging war. </span><span class="koboSpan" id="kobo.270.2">An</span><a id="_idIndexMarker382"/><span class="koboSpan" id="kobo.271.1"> army is more than just boots and guns. </span><span class="koboSpan" id="kobo.271.2">You need food and water, uniforms and tents, and fuel for your trucks and trains. </span><span class="koboSpan" id="kobo.271.3">The controller manager performs a similar function as it is responsible for monitoring inventories and distributing resources so that the desired state of the army is maintained and they are empowered to accomplish </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">their mission.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.273.1">Scheduler</span></strong><span class="koboSpan" id="kobo.274.1">: Our very </span><a id="_idIndexMarker383"/><span class="koboSpan" id="kobo.275.1">own George Washington famously said “</span><em class="italic"><span class="koboSpan" id="kobo.276.1">Discipline is the soul of an army</span></em><span class="koboSpan" id="kobo.277.1">”—and to enforce that discipline, an army must have an officer corps that efficiently executes orders across the field of battle, assigning soldiers across the battlefield to where they are most needed. </span><span class="koboSpan" id="kobo.277.2">In this sense, it assigns pods to appropriate nodes based on resource availability and the objective to </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">be accomplished.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.279.1">etcd</span></strong><span class="koboSpan" id="kobo.280.1">: Any </span><a id="_idIndexMarker384"/><span class="koboSpan" id="kobo.281.1">army is made up of soldiers and organizational units; to keep track of all this complexity, there must be a sophisticated personnel management office that keeps records of assignments, deployments, career progression, and so on. </span><span class="koboSpan" id="kobo.281.2">They keep track of what everyone is doing and what they are doing in their military roles. </span><strong class="source-inline"><span class="koboSpan" id="kobo.282.1">etcd</span></strong><span class="koboSpan" id="kobo.283.1"> plays this role in Kubernetes by maintaining configuration data, the state of the cluster, and</span><a id="_idIndexMarker385"/><span class="koboSpan" id="kobo.284.1"> creating a </span><strong class="bold"><span class="koboSpan" id="kobo.285.1">sin</span><a id="_idTextAnchor298"/><span class="koboSpan" id="kobo.286.1">gle source of </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.287.1">truth</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.288.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.289.1">SSOT</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">).</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.291.1">Worker nodes</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.292.1">Worker nodes</span></strong><span class="koboSpan" id="kobo.293.1"> are</span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.294.1"> the battlefields where the soldiers of this army do what must be done to achieve the objective. </span><span class="koboSpan" id="kobo.294.2">They are the physical (or virtual) machines where your containers run. </span><span class="koboSpan" id="kobo.294.3">On any battlefield, there must be a sergeant who commands a squad of soldiers. </span><span class="koboSpan" id="kobo.294.4">The sergeant of Kubernetes is called the </span><strong class="bold"><span class="koboSpan" id="kobo.295.1">Kubelet</span></strong><span class="koboSpan" id="kobo.296.1">. </span><span class="koboSpan" id="kobo.296.2">As </span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.297.1">with a sergeant, the Kubelet is autonomous within its area of the battlefield, executing orders received from central command and commanding the troops within their squad—the pods—and it maintains the chain of command with its superiors at central command—or the master node—that might delegate </span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">new orders.</span></span></p>
<p><span class="koboSpan" id="kobo.299.1">The containers running within the node, being monitored by their attentive sergeant, the Kubelet, need a container runtime in order to operate. </span><span class="koboSpan" id="kobo.299.2">There are several different container runtimes, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.300.1">containerd</span></strong><span class="koboSpan" id="kobo.301.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.302.1">CRI-O</span></strong><span class="koboSpan" id="kobo.303.1">, or Docker, which we learned about in the first section of </span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.304.1">this chapter. </span><span class="koboSpan" id="kobo.304.2">Although there are many container runtimes, we still use the same tooling—Docker—to build images. </span><span class="koboSpan" id="kobo.304.3">The runtime is really only responsible for running the containers. </span><span class="koboSpan" id="kobo.304.4">There are some other details to it, and it’s definitely a rabbit hole, but this is what we need to know within the context of </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.306.1">With soldiers distributed across an expansive battlefield, there needs to be a way for messages to be sent back and forth between the soldiers, their officers, and the central command. </span><span class="koboSpan" id="kobo.306.2">On the battlefield, this has changed throughout history from flags, banners, smoke signals, drums, horns, and bugles to modern times with telegraph, radio, and satellite communication. </span><span class="koboSpan" id="kobo.306.3">For the pods, this is the network traffic that is being routed to the node. </span><span class="koboSpan" id="kobo.306.4">The </span><strong class="bold"><span class="koboSpan" id="kobo.307.1">kube-proxy</span></strong><span class="koboSpan" id="kobo.308.1">, as with the Kubelet, runs on every node and is responsible for routing </span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.309.1">network traf</span><a id="_idTextAnchor299"/><span class="koboSpan" id="kobo.310.1">fic to the </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">correct destination.</span></span></p>
<h3><span class="koboSpan" id="kobo.312.1">Pods</span></h3>
<p><span class="koboSpan" id="kobo.313.1">That’s</span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.314.1"> enough about the big hats. </span><span class="koboSpan" id="kobo.314.2">It’s time to talk soldiers. </span><span class="koboSpan" id="kobo.314.3">A soldier is the smallest participant on the battlefield, and soldiers, collectively, are the primary force in military operations. </span><span class="koboSpan" id="kobo.314.4">The same is true for pods within the context of </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.315.1">Kubernetes. </span><strong class="bold"><span class="koboSpan" id="kobo.316.1">Pods</span></strong><span class="koboSpan" id="kobo.317.1"> are where all the work actually happens. </span><span class="koboSpan" id="kobo.317.2">Everything else going on inside a Kubernetes cluster is to facilitate the effectiveness of pods in achieving their individual objectives, much like the myriad of characters that support our frontline troopers on the battlefield by making sound strategic decisions, allocating resources, organizing soldiers into units, and </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">assigning orders.</span></span></p>
<p><span class="koboSpan" id="kobo.319.1">A pod is not a container but a Kubernetes-specific construct and, as with the soldier, the smallest unit of deployment within a cluster. </span><span class="koboSpan" id="kobo.319.2">A pod can have one or more containers inside of it </span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.320.1">that share resources and configurations to perform a </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">common objective.</span></span></p>
<p><span class="koboSpan" id="kobo.322.1">Instead of </span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.323.1">directly deploying individual containers, you create a pod and place containers within it. </span><span class="koboSpan" id="kobo.323.2">When you declare more than one container within the same pod, you are tightly coupling them together—in that they share the same network</span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.324.1"> namespace, </span><strong class="bold"><span class="koboSpan" id="kobo.325.1">inter-process communication</span></strong><span class="koboSpan" id="kobo.326.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.327.1">IPC</span></strong><span class="koboSpan" id="kobo.328.1">), namespace, </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">and filesystem.</span></span></p>
<p><span class="koboSpan" id="kobo.330.1">The following diagram illustrates these core components of </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">Kubernetes architecture:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer040">
<span class="koboSpan" id="kobo.332.1"><img alt="Figure 5.2 – Key Kubernetes architectural components" src="image/B21183_05_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.333.1">Figure 5.2 – Key Kubernetes architectural components</span></p>
<p><span class="koboSpan" id="kobo.334.1">Now that we understand the core components of the architecture, we’ll delve into a couple of other important topics. </span><span class="koboSpan" id="kobo.334.2">I do want to call out that this book is about mastering Terraform, and while part of that journey is understanding the architectures that you will be designing and provisioning with Terraform, this book does not intend to be an in-depth guide to Kubernetes. </span><span class="koboSpan" id="kobo.334.3">Hence, I am focusing on just the key concepts that you need to be aware of when building solutions with </span><a id="_idTextAnchor300"/><span class="koboSpan" id="kobo.335.1">these technologies </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">using Terraform.</span></span></p>
<h3><span class="koboSpan" id="kobo.337.1">Services</span></h3>
<p><span class="koboSpan" id="kobo.338.1">For more</span><a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.339.1"> complex military operations, we may need to allocate a larger military unit to complete the mission successfully. </span><span class="koboSpan" id="kobo.339.2">This is where we have a lieutenant that would command multiple squads. </span><span class="koboSpan" id="kobo.339.3">The lieutenant delegates orders to the appropriate squads, with each deployed to a different area on the battlefield. </span><span class="koboSpan" id="kobo.339.4">This is similar to the role of a </span><strong class="bold"><span class="koboSpan" id="kobo.340.1">service</span></strong><span class="koboSpan" id="kobo.341.1"> in Kubernetes, which allows us to group pods together with a common purpose and distribute them across multiple nodes. </span><span class="koboSpan" id="kobo.341.2">The service is responsible for load balancing across pods, and any incoming requests intended for those pods would be addressed to the service to route accordingly—much like how orders from a captain or higher in the chain of command would be delegated down to a lieutenant, and they would take the necessary steps to dole them out to the squads under </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">their command.</span></span></p>
<p><span class="koboSpan" id="kobo.343.1">In this way, the service plays a crucial role in workloads that require a stable endpoint for communicating with pods, such as a web application or a REST API. </span><span class="koboSpan" id="kobo.343.2">This is because Kubernetes assigns a stable IP address and DNS name to the service, which remains unchanged even if the underlying pods change, enabling other applications or services within or outside the cluster to establish a r</span><a id="_idTextAnchor301"/><span class="koboSpan" id="kobo.344.1">eliable connection with </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">the service.</span></span></p>
<h3><span class="koboSpan" id="kobo.346.1">Namespaces</span></h3>
<p><span class="koboSpan" id="kobo.347.1">Lastly, we need to</span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.348.1"> cover an important concept of Kubernetes’ logical model: the </span><strong class="bold"><span class="koboSpan" id="kobo.349.1">namespace</span></strong><span class="koboSpan" id="kobo.350.1">. </span><span class="koboSpan" id="kobo.350.2">The namespace provides complete separation from all services and pods deployed within the cluster at the logical level. </span><span class="koboSpan" id="kobo.350.3">Namespaces do not apply to the physical resources of clusters, such as nodes or persistent volumes. </span><span class="koboSpan" id="kobo.350.4">They only apply within the logical realm of Kubernetes as it relates to pods and other related resources. </span><span class="koboSpan" id="kobo.350.5">You can think of it as branches within the military. </span><span class="koboSpan" id="kobo.350.6">Resources in different namespaces, as with soldiers in different branches of the army, share a central command, and they can communicate and coordinate with each other, but they are isolated in terms of chain of command and resource allocation. </span><span class="koboSpan" id="kobo.350.7">Therefore, pods in different namespaces can operate on the same nodes but can’t coexist in the same service since that, too, has </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">a namespace.</span></span></p>
<p><span class="koboSpan" id="kobo.352.1">We’ve covered the key components of Kubernetes architecture. </span><span class="koboSpan" id="kobo.352.2">There is definitely a lot more that is out of the scope of this book, but this should give you enough of the conceptual </span><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.353.1">overhead to understand Kubernetes architecture at a high level. </span><span class="koboSpan" id="kobo.353.2">Next, we’ll delve a bit deeper into some of the resources that ar</span><a id="_idTextAnchor302"/><span class="koboSpan" id="kobo.354.1">e used to configure pods </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">and services.</span></span></p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor303"/><span class="koboSpan" id="kobo.356.1">Configuration and secrets</span></h2>
<p><span class="koboSpan" id="kobo.357.1">One of the key areas where Terraform and Kubernetes will likely interact is the area of configuration and secrets. </span><span class="koboSpan" id="kobo.357.2">This is because, quite often, Terraform is provisioning other resources that will supply endpoint URLs, authentication credentials, logging, or identity configuration. </span><span class="koboSpan" id="kobo.357.3">Therefore, it’s important to understand which Kubernetes resources should be used to connect these configuration settings to the appropriate</span><a id="_idTextAnchor304"/><span class="koboSpan" id="kobo.358.1"> place in your </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">Kubernetes deployments.</span></span></p>
<h3><span class="koboSpan" id="kobo.360.1">ConfigMaps</span></h3>
<p><span class="koboSpan" id="kobo.361.1">A </span><strong class="bold"><span class="koboSpan" id="kobo.362.1">ConfigMap</span></strong><span class="koboSpan" id="kobo.363.1"> is a </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.364.1">special kind of Kubernetes resource that can be used to provide non-sensitive configuration to a pod. </span><span class="koboSpan" id="kobo.364.2">The configuration is stored as a set of key-value pairs, which can be used to configure either environment variables for containers or command-line arguments for an application that you want to run inside </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">the container.</span></span></p>
<p><span class="koboSpan" id="kobo.366.1">A pod can reference one or more ConfigMap objects, and then the application can reference the keys in the key-value pairs to obtain their values. </span><span class="koboSpan" id="kobo.366.2">This creates a separation of the application, which is running in the pod, from the configuration, which is stored in a ConfigMap. </span><span class="koboSpan" id="kobo.366.3">This means that the same ConfigMap can be used by more than one </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">pod specification.</span></span></p>
<p><span class="koboSpan" id="kobo.368.1">By default, only other pods within the same namespace can access ConfigMaps. </span><span class="koboSpan" id="kobo.368.2">If you want more granular security, you </span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.369.1">can app</span><a id="_idTextAnchor305"/><span class="koboSpan" id="kobo.370.1">ly for </span><strong class="bold"><span class="koboSpan" id="kobo.371.1">role-based access </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.372.1">control</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.373.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.374.1">RBAC</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">).</span></span></p>
<h3><span class="koboSpan" id="kobo.376.1">Secrets</span></h3>
<p><span class="koboSpan" id="kobo.377.1">While </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.378.1">Kubernetes does have an internal method for storing secrets and making them available to your pods, when you are deploying to the cloud, you will often use a cloud-specific secret provider instead. </span><span class="koboSpan" id="kobo.378.2">There are a number of advantages to leveraging an external secret store. </span><span class="koboSpan" id="kobo.378.3">First, with an external secret store, you would have more centralized management, which would make it easier for operators to manage the environment. </span><span class="koboSpan" id="kobo.378.4">Second, most external secret providers offer features and capabilities that the built-in secret storage in Kubernetes doesn’t have, such as the ability to version and rotate </span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.379.1">secrets. </span><span class="koboSpan" id="kobo.379.2">Lastly, offloading secret storage reduces the burden on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.380.1">etcd</span></strong><span class="koboSpan" id="kobo.381.1"> database on the cluster, thus freeing up more resources for workloads running in </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">your pods.</span></span></p>
<p><span class="koboSpan" id="kobo.383.1">When you leverage an external secret store, Terraform will likely be provisioning it along with the secrets that your pods will need. </span><span class="koboSpan" id="kobo.383.2">In order to take advantage of an external secret store, you will need to provision a </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1">SecretProviderClass</span></strong><span class="koboSpan" id="kobo.385.1"> resource that is specific to the external secret store you plan on using. </span><span class="koboSpan" id="kobo.385.2">It will provide a bridge between your pods and the secrets you store there. </span><span class="koboSpan" id="kobo.385.3">There are often platform-native configurations depending on the cloud platform you are using to configure this provider. </span><span class="koboSpan" id="kobo.385.4">Most managed Kubernetes service offerings provide built-in support for the corresponding secret storage service and streamline the authentication and authorization required for your pods to </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">access secrets.</span></span></p>
<p><span class="koboSpan" id="kobo.387.1">In this book, we will</span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.388.1"> be working </span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.389.1">with the Managed Kubernetes </span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.390.1">offerings of three cloud platforms: Amazon </span><strong class="bold"><span class="koboSpan" id="kobo.391.1">Elastic Kubernetes Service</span></strong><span class="koboSpan" id="kobo.392.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.393.1">EKS</span></strong><span class="koboSpan" id="kobo.394.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.395.1">Azure Kubernetes Servi</span><a id="_idTextAnchor306"/><span class="koboSpan" id="kobo.396.1">ce</span></strong><span class="koboSpan" id="kobo.397.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.398.1">AKS</span></strong><span class="koboSpan" id="kobo.399.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.400.1">Google Kubernetes </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.401.1">Engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.402.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.403.1">GKE</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">).</span></span></p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor307"/><span class="koboSpan" id="kobo.405.1">Continuous deployment (CD)</span></h2>
<p><span class="koboSpan" id="kobo.406.1">Kubernetes </span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.407.1">has a multitude of ways to provision resources. </span><span class="koboSpan" id="kobo.407.2">It has both imperative and declarative covered with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.408.1">kubectl</span></strong><span class="koboSpan" id="kobo.409.1"> command-line tool and Kubernetes YAML manifests (which also use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.410.1">kubectl</span></strong><span class="koboSpan" id="kobo.411.1"> command-line tool) respectively. </span><span class="koboSpan" id="kobo.411.2">Because this is a book on Terraform, I think it’s clear the approach we would prefer! </span><span class="koboSpan" id="kobo.411.3">Yes—declarative! </span><span class="koboSpan" id="kobo.411.4">And because Kubernetes also has its own REST API, it’s possible to build a Terraform provider that communicates with it as well. </span><span class="koboSpan" id="kobo.411.5">All of these approaches, using </span><strong class="source-inline"><span class="koboSpan" id="kobo.412.1">kubectl</span></strong><span class="koboSpan" id="kobo.413.1"> either with imperative commands or YAML manifests or using </span><strong class="source-inline"><span class="koboSpan" id="kobo.414.1">terraform</span></strong><span class="koboSpan" id="kobo.415.1"> and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.416.1">kubernetes</span></strong><span class="koboSpan" id="kobo.417.1"> Terraform provide</span><a id="_idTextAnchor308"/><span class="koboSpan" id="kobo.418.1">r, are examples of the traditional </span><span class="No-Break"><span class="koboSpan" id="kobo.419.1">push model.</span></span></p>
<h3><span class="koboSpan" id="kobo.420.1">Push model</span></h3>
<p><span class="koboSpan" id="kobo.421.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.422.1">push model</span></strong><span class="koboSpan" id="kobo.423.1"> is</span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.424.1"> when your CI/CD pipeline is executing the configuration of the Kubernetes environment externally from the cluster. </span><span class="koboSpan" id="kobo.424.2">This could be done with any tool. </span><span class="koboSpan" id="kobo.424.3">The most common approach is to provision the cloud environment using Terraform as the first step of the CI/CD pipeline and then execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.425.1">kubectl</span></strong><span class="koboSpan" id="kobo.426.1"> commands, either just plain old </span><strong class="source-inline"><span class="koboSpan" id="kobo.427.1">bash</span></strong><span class="koboSpan" id="kobo.428.1"> or YAML manifest files, using </span><strong class="source-inline"><span class="koboSpan" id="kobo.429.1">kubectl apply -</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">f foo.yaml</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer041">
<span class="koboSpan" id="kobo.432.1"><img alt="Figure 5.3 – CI/CD pipeline with Terraform and Kubernetes command-line interface" src="image/B21183_05_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.433.1">Figure 5.3 – CI/CD pipeline with Terraform and Kubernetes command-line interface</span></p>
<p><span class="koboSpan" id="kobo.434.1">In this case, the cloud environment is</span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.435.1"> defined in </span><strong class="bold"><span class="koboSpan" id="kobo.436.1">HashiCorp Configuration Language</span></strong><span class="koboSpan" id="kobo.437.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.438.1">HCL</span></strong><span class="koboSpan" id="kobo.439.1">), which is executed as part of the first stage of the pipeline, and then</span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.440.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.441.1">Kubernetes cluster configuration</span></strong><span class="koboSpan" id="kobo.442.1"> is output from this Terraform process to the next stage of the pipeline where </span><strong class="source-inline"><span class="koboSpan" id="kobo.443.1">kubectl</span></strong><span class="koboSpan" id="kobo.444.1"> is executed to create deployments on the newly created or existing Kubernetes cluster. </span><span class="koboSpan" id="kobo.444.2">The Kubernetes cluster’s existence will depend on whether it was the first time </span><strong class="source-inline"><span class="koboSpan" id="kobo.445.1">terraform apply</span></strong><span class="koboSpan" id="kobo.446.1"> was executed </span><span class="No-Break"><span class="koboSpan" id="kobo.447.1">or not.</span></span></p>
<p><span class="koboSpan" id="kobo.448.1">The next method is to use Terraform for both of these stages, replacing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.449.1">kubectl</span></strong><span class="koboSpan" id="kobo.450.1"> stage with a second Terraform stage, this time using a second Terraform root module that only uses the </span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.451.1">Kubernetes provider for Terraform. </span><span class="koboSpan" id="kobo.451.2">The Terraform root module that provisioned the cloud environment stays in its own folder and is completely isolated from this second Terraform </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">code base:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer042">
<span class="koboSpan" id="kobo.453.1"><img alt="Figure 5.4 – CI/CD pipeline with Terraform using the Kubernetes provider for Terraform" src="image/B21183_05_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.454.1">Figure 5.4 – CI/CD pipeline with Terraform using the Kubernetes provider for Terraform</span></p>
<p><span class="koboSpan" id="kobo.455.1">The first Terraform stage still uses our target cloud platform’s Terraform provider to provision the Kubernetes cluster and other required resources within our cloud environment. </span><span class="koboSpan" id="kobo.455.2">Likewise, the CI/CD pipeline still passes the Kubernetes cluster configuration that is output from this first Terraform stage to the second Terraform stage where we provision Kubernetes resources to our Kubernetes clus</span><a id="_idTextAnchor309"/><span class="koboSpan" id="kobo.456.1">ter using the Kubernetes provider </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">for Terraform.</span></span></p>
<h3><span class="koboSpan" id="kobo.458.1">Pull model</span></h3>
<p><span class="koboSpan" id="kobo.459.1">An alternative </span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.460.1">to the push model is the </span><strong class="bold"><span class="koboSpan" id="kobo.461.1">pull model</span></strong><span class="koboSpan" id="kobo.462.1">, which flips things upside down. </span><span class="koboSpan" id="kobo.462.2">Instead of the Kubernetes resources being provisioned by some actor outside of the Kubernetes cluster itself, the CI/CD pipeline installs a CD service on the cluster, and this service connects to a specified source code repository containing Kubernetes YAML manifests and provisions the resources on the </span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">Kubernetes cluster:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<span class="koboSpan" id="kobo.464.1"><img alt="Figure 5.5 – CI/CD pipeline with Terraform and ArgoCD" src="image/B21183_05_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.465.1">Figure 5.5 – CI/CD pipeline with Terraform and ArgoCD</span></p>
<p><span class="koboSpan" id="kobo.466.1">This approach takes advantage of the immutable and declarative aspects of YAML-based Kubernetes deployments and creates an SSOT for a Kubernetes deployment within a Git source code repository. </span><span class="koboSpan" id="kobo.466.2">As a result, this approach has become more and more identified as a best practice when it comes to fully embracing GitOps, which we’ll delve into more detail in the </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">next chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.468.1">In this section, we took a high-level look at Kubernetes—what purpose it serves, how it works, and how it can interconnect our containers with the underlying infrastructure that we provision. </span><span class="koboSpan" id="kobo.468.2">These are all critical things to understand as we use Terraform to provision and </span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.469.1">manage the Kubernetes infrastructure that we’ll use to run our containers. </span><span class="koboSpan" id="kobo.469.2">Next, let’s look at how Kubernetes natively handles deployments before we contrast that with what we can do with Terraform’s </span><span class="No-Break"><span class="koboSpan" id="kobo.470.1">Kubernetes providers.</span></span></p>
<h1 id="_idParaDest-125"><a id="_idTextAnchor310"/><span class="koboSpan" id="kobo.471.1">Understanding Kubernetes manifests</span></h1>
<p><span class="koboSpan" id="kobo.472.1">As we discussed in the previous section, </span><strong class="source-inline"><span class="koboSpan" id="kobo.473.1">kubectl</span></strong><span class="koboSpan" id="kobo.474.1"> is a command-line application that can be used to either imperatively or declaratively execute commands on a Kubernetes cluster. </span><span class="koboSpan" id="kobo.474.2">You can use </span><strong class="source-inline"><span class="koboSpan" id="kobo.475.1">kubectl</span></strong><span class="koboSpan" id="kobo.476.1"> to deploy resources and inspect and manage cluster reso</span><a id="_idTextAnchor311"/><span class="koboSpan" id="kobo.477.1">urces, among other common </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">operational activities.</span></span></p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor312"/><span class="koboSpan" id="kobo.479.1">Kubernetes manifests</span></h2>
<p><span class="koboSpan" id="kobo.480.1">When</span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.481.1"> deploying resources to a Kubernetes cluster, you can either use </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">kubectl</span></strong><span class="koboSpan" id="kobo.483.1"> commands directly to perform operations to provision resources or use YAML manifests to define the desired state of resources and use </span><strong class="source-inline"><span class="koboSpan" id="kobo.484.1">kubectl</span></strong><span class="koboSpan" id="kobo.485.1"> to execute against these manifests. </span><span class="koboSpan" id="kobo.485.2">These two different ways of using </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1">kubectl</span></strong><span class="koboSpan" id="kobo.487.1"> parallel the way there are imperative ways to provision resources to cloud platforms such as AWS and Azure through their respective command-line applications and the way Terraform provisions the desired state of resources during </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.488.1">terraform apply</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.489.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.490.1">When you’re using </span><strong class="source-inline"><span class="koboSpan" id="kobo.491.1">kubectl</span></strong><span class="koboSpan" id="kobo.492.1"> commands directly, you’re giving instructions right away in the command line. </span><span class="koboSpan" id="kobo.492.2">For example, if you want to create a deployment, you might issue a command such </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">as this:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.494.1">
kubectl run nginx --image=nginx</span></pre> <p><span class="koboSpan" id="kobo.495.1">In this case, </span><strong class="source-inline"><span class="koboSpan" id="kobo.496.1">kubectl</span></strong><span class="koboSpan" id="kobo.497.1"> will create a deployment for </span><strong class="source-inline"><span class="koboSpan" id="kobo.498.1">nginx</span></strong><span class="koboSpan" id="kobo.499.1"> with mostly default settings, and it will do </span><span class="No-Break"><span class="koboSpan" id="kobo.500.1">so immediately.</span></span></p>
<p><span class="koboSpan" id="kobo.501.1">This method can be useful for quick, one-off creations or when you need to make an </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">immediate change.</span></span></p>
<p><span class="koboSpan" id="kobo.503.1">When using YAML manifests, you’re writing the desired state of your resources in a declarative manner. </span><span class="koboSpan" id="kobo.503.2">For example, a deployment might be written like this in a </span><span class="No-Break"><span class="koboSpan" id="kobo.504.1">YAML file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.505.1">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80</span></pre> <p><span class="koboSpan" id="kobo.506.1">You </span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.507.1">would then use </span><strong class="source-inline"><span class="koboSpan" id="kobo.508.1">kubectl</span></strong><span class="koboSpan" id="kobo.509.1"> to apply this file, </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">like so:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.511.1">
kubectl apply -f my-deployment.yaml</span></pre> <p><span class="koboSpan" id="kobo.512.1">This tells Kubernetes to make the cluster’s actual state match the desired state described in </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">the file.</span></span></p>
<p><span class="koboSpan" id="kobo.514.1">The benefit of this approach is that the </span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.515.1">file serves as a </span><strong class="bold"><span class="koboSpan" id="kobo.516.1">source of truth</span></strong><span class="koboSpan" id="kobo.517.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.518.1">SOT</span></strong><span class="koboSpan" id="kobo.519.1">) for the resource configuration. </span><span class="koboSpan" id="kobo.519.2">The files can be version-controlled, making it easy to track changes, roll back if needed, and </span><span class="No-Break"><span class="koboSpan" id="kobo.520.1">reuse configurations.</span></span></p>
<p><span class="koboSpan" id="kobo.521.1">Generally, it’s considered a best practice to manage your Kubernetes resources using configuration files, especially in production environments. </span><span class="koboSpan" id="kobo.521.2">That being said, direct </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1">kubectl</span></strong><span class="koboSpan" id="kobo.523.1"> commands</span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.524.1"> are useful for debugging and quick prototyping tasks, but you should consider using a decla</span><a id="_idTextAnchor313"/><span class="koboSpan" id="kobo.525.1">rative approach to manage resources in the </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">long term.</span></span></p>
<h3><span class="koboSpan" id="kobo.527.1">Deployment manifest</span></h3>
<p><span class="koboSpan" id="kobo.528.1">When </span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.529.1">creating an application in Kubernetes, you</span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.530.1"> use a deployment to specify how you want it to be configured. </span><span class="koboSpan" id="kobo.530.2">Kubernetes will then automatically adjust the current state of the application to match your </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">desired configuration:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.532.1">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my-app:1.0
        ports:
        - containerPort: 8080</span></pre> <p><span class="koboSpan" id="kobo.533.1">This </span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.534.1">deployment manifest describes a desired state </span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.535.1">that includes running</span><a id="_idTextAnchor314"/><span class="koboSpan" id="kobo.536.1"> three instances (or replicas) of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.537.1">my-app</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.538.1"> application.</span></span></p>
<h3><span class="koboSpan" id="kobo.539.1">Service manifest</span></h3>
<p><span class="koboSpan" id="kobo.540.1">A </span><strong class="bold"><span class="koboSpan" id="kobo.541.1">service</span></strong><span class="koboSpan" id="kobo.542.1"> is a </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.543.1">method of grouping a collection of</span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.544.1"> pods that form an application, allowing them to be presented as a </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">network service:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.546.1">
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080</span></pre> <p><span class="koboSpan" id="kobo.547.1">This service manifest will create a network service that will route traffic to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">my-app</span></strong><span class="koboSpan" id="kobo.549.1"> pods on </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">port </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.551.1">8080</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">.</span></span></p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor315"/><span class="koboSpan" id="kobo.553.1">Configuration and secrets</span></h2>
<p><span class="koboSpan" id="kobo.554.1">Because Kubernetes is where we will host our applications and services, we need to have a way to provide runtime configuration settings, both non-sensitive </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">and secret.</span></span></p>
<h3><span class="koboSpan" id="kobo.556.1">ConfigMaps</span></h3>
<p><span class="koboSpan" id="kobo.557.1">As we </span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.558.1">discussed in the previous section, a ConfigMap is how we pass non-sensitive data into our pods. </span><span class="koboSpan" id="kobo.558.2">The ConfigMap is a key area where Terraform and Kubernetes integration takes place because many of the configuration settings are likely generated by Terraform. </span><span class="koboSpan" id="kobo.558.3">This is an important consideration when designing how you provision to Kubernetes, as you want to minimize the manual steps required to provision to Kubernetes. </span><span class="koboSpan" id="kobo.558.4">We’ll look at strategies on how to avoid this in future sections covering Kubernetes and </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">Helm providers:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.560.1">
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
data:
  my-value: "Hello, Kubernetes!"</span></pre> <p><span class="koboSpan" id="kobo.561.1">This ConfigMap is named </span><strong class="source-inline"><span class="koboSpan" id="kobo.562.1">my-config</span></strong><span class="koboSpan" id="kobo.563.1">, and it holds a key-value pair of </span><strong class="source-inline"><span class="koboSpan" id="kobo.564.1">my-value: </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.565.1">Hello, Kubernetes!</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.567.1">Now, when we want to reference this ConfigMap from one of our deployments, we simply use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.568.1">configMapRef</span></strong><span class="koboSpan" id="kobo.569.1"> block to pull in the correct value from the ConfigMap and set an environment variable inside </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">our container:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.571.1">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my-app:1.0
        env:
        - name: MY_VALUE
          valueFrom:
            configMapKeyRef:
              name: my-config
              key: my-value</span></pre> <p><span class="koboSpan" id="kobo.572.1">In this </span><a id="_idIndexMarker423"/><span class="koboSpan" id="kobo.573.1">deployment, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.574.1">my-app</span></strong><span class="koboSpan" id="kobo.575.1"> application has a </span><strong class="source-inline"><span class="koboSpan" id="kobo.576.1">MY_VALUE</span></strong><span class="koboSpan" id="kobo.577.1"> environment variable whose value is pulled from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.578.1">my-config</span></strong><span class="koboSpan" id="kobo.579.1"> ConfigMap, and when the pod is running, it can get a </span><strong class="source-inline"><span class="koboSpan" id="kobo.580.1">Hello, Kubernetes!</span></strong><span class="koboSpan" id="kobo.581.1"> value from that </span><span class="No-Break"><span class="koboSpan" id="kobo.582.1">environment variable.</span></span></p>
<h3><span class="koboSpan" id="kobo.583.1">Secrets</span></h3>
<p><span class="koboSpan" id="kobo.584.1">Just as </span><a id="_idIndexMarker424"/><span class="koboSpan" id="kobo.585.1">with the non-sensitive configuration settings, many of our secrets will be provisioned by Terraform using the target cloud platform’s secret management service. </span><span class="koboSpan" id="kobo.585.2">As a result, we won’t be using the Kubernetes </span><strong class="source-inline"><span class="koboSpan" id="kobo.586.1">Secret</span></strong><span class="koboSpan" id="kobo.587.1"> resource but will be defining a </span><strong class="source-inline"><span class="koboSpan" id="kobo.588.1">SecretProviderClass</span></strong><span class="koboSpan" id="kobo.589.1"> resource that will enable integration with the cloud platform’s secret management service and pull in the desired secrets. </span><span class="koboSpan" id="kobo.589.2">Because this is cloud platform-specific, we’ll cover this in more detail in each of the solutions we build on AWS, Azure, and GCP, using their respective managed </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">Kubernetes offerings.</span></span></p>
<p><span class="koboSpan" id="kobo.591.1">In this section, we looked at how Kubernetes handles deployments natively—both using its own </span><strong class="source-inline"><span class="koboSpan" id="kobo.592.1">kubectl</span></strong><span class="koboSpan" id="kobo.593.1"> command-line utility and its own YAML-based deployment manifests, which allow us to describe Kubernetes resources we want to provision in a declarative way—similar to what Terraform allows us to do with the underlying cloud infrastructure. </span><span class="koboSpan" id="kobo.593.2">In </span><a id="_idIndexMarker425"/><span class="koboSpan" id="kobo.594.1">the next section, we’ll look at the Kubernetes provider, which gives us a way of managing Kubernetes natively </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">using Terraform.</span></span></p>
<h1 id="_idParaDest-128"><a id="_idTextAnchor316"/><span class="koboSpan" id="kobo.596.1">Using the Kubernetes provider to provision Kubernetes resources</span></h1>
<p><span class="koboSpan" id="kobo.597.1">The </span><a id="_idIndexMarker426"/><span class="koboSpan" id="kobo.598.1">Kubernetes provider for Terraform is a plugin that allows Terraform to manage resources on a Kubernetes cluster. </span><span class="koboSpan" id="kobo.598.2">This includes creating, updating, and deleting resources such as deployments, services, </span><span class="No-Break"><span class="koboSpan" id="kobo.599.1">and pods.</span></span></p>
<p><span class="koboSpan" id="kobo.600.1">When using the Kubernetes Terraform provider, your infrastructure description is written in HCL instead of YAML. </span><span class="koboSpan" id="kobo.600.2">This is the language used by </span><a id="_idTextAnchor317"/><span class="koboSpan" id="kobo.601.1">Terraform to describe infrastructure and </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">service configurations.</span></span></p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor318"/><span class="koboSpan" id="kobo.603.1">The Kubernetes Terraform provider</span></h2>
<p><span class="koboSpan" id="kobo.604.1">As we discussed in the previous section, because Kubernetes has a REST API that acts as a uniform control plane for all management operations, it’s possible to create a Terraform provider that we can use to automate it in the same fashion that we do with the AWS, Azure, and GCP </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">cloud platforms.</span></span></p>
<p><span class="koboSpan" id="kobo.606.1">Just as with other cloud platforms, we need to authenticate against the control plane. </span><span class="koboSpan" id="kobo.606.2">One big difference with Kubernetes is that the management control plane is hosted on the Kubernetes cluster itself—more specifically, as we discussed in the </span><em class="italic"><span class="koboSpan" id="kobo.607.1">Understanding key concepts of container orchestration and Kubernetes</span></em><span class="koboSpan" id="kobo.608.1"> section of this chapter, on the master node. </span><span class="koboSpan" id="kobo.608.2">This means we need to specify the endpoint address of the Kubernetes cluster. </span><span class="koboSpan" id="kobo.608.3">This is usually provided by the Terraform resource that provisions the Kubernetes cluster on the target </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1">cloud platform.</span></span></p>
<p><span class="koboSpan" id="kobo.610.1">In order to authenticate with the Kubernetes cluster, we need to typically use a cluster certificate, but some cloud platforms support more sophisticated authentication methods that tie into your organization’s directory systems such as Microsoft </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">Entra ID.</span></span></p>
<p><span class="koboSpan" id="kobo.612.1">Here is an example of what the provider configuration would typically look like when using </span><span class="No-Break"><span class="koboSpan" id="kobo.613.1">certificate-based authentication:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.614.1">
provider "kubernetes" {
  host                   = var.cluster_endpoint
  client_certificate     = file(var.client_cert_path)
  client_key             = file(var.client_key_path)
  cluster_ca_certificate = file(var.cluster_ca_cert_path)
}</span></pre> <p><span class="koboSpan" id="kobo.615.1">Here’s what each</span><a id="_idIndexMarker427"/><span class="koboSpan" id="kobo.616.1"> field </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1">is for:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.618.1">host</span></strong><span class="koboSpan" id="kobo.619.1">: The hostname (in the form of URI) of the Kubernetes master. </span><span class="koboSpan" id="kobo.619.2">It can be sourced from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.620.1">KUBE_HOST</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.621.1">environment variable.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.622.1">client_certificate</span></strong><span class="koboSpan" id="kobo.623.1">: This is used for client authentication against the Kubernetes </span><span class="No-Break"><span class="koboSpan" id="kobo.624.1">REST API.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.625.1">client_key</span></strong><span class="koboSpan" id="kobo.626.1">: This is paired with </span><strong class="source-inline"><span class="koboSpan" id="kobo.627.1">client_certificate</span></strong><span class="koboSpan" id="kobo.628.1"> and is used as part of the </span><strong class="bold"><span class="koboSpan" id="kobo.629.1">Transport Layer Security</span></strong><span class="koboSpan" id="kobo.630.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.631.1">TLS</span></strong><span class="koboSpan" id="kobo.632.1">) handshake that happens between the Terraform</span><a id="_idIndexMarker428"/><span class="koboSpan" id="kobo.633.1"> provider and the Kubernetes </span><span class="No-Break"><span class="koboSpan" id="kobo.634.1">REST API.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.635.1">cluster_ca_certificate</span></strong><span class="koboSpan" id="kobo.636.1">: This is </span><a id="_idIndexMarker429"/><span class="koboSpan" id="kobo.637.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.638.1">certificate authority</span></strong><span class="koboSpan" id="kobo.639.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.640.1">CA</span></strong><span class="koboSpan" id="kobo.641.1">) for the Kubernetes cluster and is used to verify the authenticity of the Kubernetes cluster’s </span><span class="No-Break"><span class="koboSpan" id="kobo.642.1">REST API.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.643.1">Another common method for configuring the Kubernetes provider for Terraform is to use a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.644.1">kube_config</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.645.1"> file:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.646.1">
provider "kubernetes" {
  load_config_file = true
  config_path      = "~/.kube/config"
  context          = "foo"
}</span></pre> <p><span class="koboSpan" id="kobo.647.1">In this situation, all of the details needed to connect and authenticate with the cluster are stored within the file. </span><span class="koboSpan" id="kobo.647.2">We just need to point the provider at the location where the file exists. </span><span class="koboSpan" id="kobo.647.3">By default, this location is </span><strong class="source-inline"><span class="koboSpan" id="kobo.648.1">~/.kube/config</span></strong><span class="koboSpan" id="kobo.649.1">. </span><span class="koboSpan" id="kobo.649.2">Of course, this file can contain multiple cluster connections, each referred to as a </span><em class="italic"><span class="koboSpan" id="kobo.650.1">context</span></em><span class="koboSpan" id="kobo.651.1">. </span><span class="koboSpan" id="kobo.651.2">Therefore, we may need to specify the context. </span><span class="koboSpan" id="kobo.651.3">However, if you are running in a CI/CD pipelin</span><a id="_idTextAnchor319"/><span class="koboSpan" id="kobo.652.1">e, this is very unlikely because you will likely use a </span><span class="No-Break"><span class="koboSpan" id="kobo.653.1">custom path.</span></span></p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor320"/><span class="koboSpan" id="kobo.654.1">Kubernetes resources</span></h2>
<p><span class="koboSpan" id="kobo.655.1">When you use</span><a id="_idIndexMarker430"/><span class="koboSpan" id="kobo.656.1"> the Kubernetes provider for Terraform, we get the same declarative model that we get with Kubernetes’ native YAML manifests, but we get all the features and capabilities of HCL. </span><span class="koboSpan" id="kobo.656.2">This allows us to pass input variables, generate dynamic local values, and use string </span><span class="No-Break"><span class="koboSpan" id="kobo.657.1">interpolation—the works!</span></span></p>
<p><span class="koboSpan" id="kobo.658.1">However, the downside of all this is that we have to use HCL to define Kubernetes resources. </span><span class="koboSpan" id="kobo.658.2">This goes against the grain of the Kubernetes ecosystem as most Kubernetes documentation and practitioners asking and answering questions online will be using YAML. </span><span class="koboSpan" id="kobo.658.3">If we can tolerate the translation from YAML into HCL, then it might be worth considering using the Kubernetes provider </span><span class="No-Break"><span class="koboSpan" id="kobo.659.1">for Terraform:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.660.1">
resource "kubernetes_deployment" "my_app" {
  metadata {
    name = "my-app"
  }
  spec {
    replicas = 3
    selector {
      match_labels = {
        app = "my-app"
      }
    }
    template {
      metadata {
        labels = {
          app = "my-app"
        }
      }
      spec {
        container {
          image = "my-app:1.0"
          name  = "my-app"
          port {
            container_port = 8080
          }
        }
      }
    }
  }
}</span></pre> <p><span class="koboSpan" id="kobo.661.1">The preceding </span><a id="_idIndexMarker431"/><span class="koboSpan" id="kobo.662.1">example is of an HCL equivalent of the Kubernetes YAML that provisions a Kubernetes deployment resource. </span><span class="koboSpan" id="kobo.662.2">Notice the prolific use of curly braces, whi</span><a id="_idTextAnchor321"/><span class="koboSpan" id="kobo.663.1">ch can be rather jarring for somebody who is used to looking </span><span class="No-Break"><span class="koboSpan" id="kobo.664.1">at YAML.</span></span></p>
<h2 id="_idParaDest-131"><a id="_idTextAnchor322"/><span class="koboSpan" id="kobo.665.1">Evaluating the trade-offs</span></h2>
<p><span class="koboSpan" id="kobo.666.1">With this approach, your </span><a id="_idIndexMarker432"/><span class="koboSpan" id="kobo.667.1">Kubernetes resources are defined in HCL, and you then use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.668.1">terraform apply</span></strong><span class="koboSpan" id="kobo.669.1"> command to create or update those resources as opposed to using </span><strong class="source-inline"><span class="koboSpan" id="kobo.670.1">kubectl</span></strong><span class="koboSpan" id="kobo.671.1"> either imperatively </span><span class="No-Break"><span class="koboSpan" id="kobo.672.1">or declaratively.</span></span></p>
<p><span class="koboSpan" id="kobo.673.1">As with the native YAML approach for Kubernetes, this process is also declarative, meaning you describe what you want but leverage Terraform to figure out how to do it. </span><span class="koboSpan" id="kobo.673.2">This is similar to how Kubernetes itself works, but you’re using the Terraform provider to generate the plan and do </span><span class="No-Break"><span class="koboSpan" id="kobo.674.1">the work.</span></span></p>
<p><span class="koboSpan" id="kobo.675.1">While it may seem like a great thing to use one language—HCL—to manage other parts of your infrastructure (such as cloud resources on AWS or GCP) and use it to manage your Kubernetes resources, however, because most Kubernetes documentation and samples are in YAML, you will be spending a significant amount of time mapping from YAML into HCL. </span><span class="koboSpan" id="kobo.675.2">This can make it difficult to learn and effectively manage Kubernetes </span><span class="No-Break"><span class="koboSpan" id="kobo.676.1">at scale.</span></span></p>
<p><span class="koboSpan" id="kobo.677.1">Therefore, it is usually better to let Terraform manage the underlying infrastructure that Kubernetes sits on while managing Kubernetes using its own declarative approach using YAML and </span><strong class="source-inline"><span class="koboSpan" id="kobo.678.1">kubectl</span></strong><span class="koboSpan" id="kobo.679.1">. </span><span class="koboSpan" id="kobo.679.2">However, if you can overcome the translation from YAML into HCL—or an even better option that we’ll address later: encapsulate your Kubernetes deployments into Helm charts—then it might be easier to use Terraform’s Kubernetes provider to eliminate the additional integration with </span><strong class="source-inline"><span class="koboSpan" id="kobo.680.1">kubectl</span></strong><span class="koboSpan" id="kobo.681.1"> commands embedded in </span><strong class="source-inline"><span class="koboSpan" id="kobo.682.1">bash</span></strong><span class="koboSpan" id="kobo.683.1"> scripts that you’ll have to do at the end of your </span><strong class="source-inline"><span class="koboSpan" id="kobo.684.1">terraform </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.685.1">apply</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.686.1"> operation.</span></span></p>
<p><span class="koboSpan" id="kobo.687.1">There might also be certain Kubernetes resources that are tightly coupled with your cloud platform and the configuration that Terraform manages for you. </span><span class="koboSpan" id="kobo.687.2">These might be individual or standalone resources that connect a Kubernetes Service account to a cloud platform identity or a ConfigMap that sources the bulk of its values from </span><span class="No-Break"><span class="koboSpan" id="kobo.688.1">Terraform outputs.</span></span></p>
<p><span class="koboSpan" id="kobo.689.1">In this section, we looked at how we can use Terraform to provision resources to Kubernetes and compared and contrasted this approach to the native Kubernetes options using </span><strong class="source-inline"><span class="koboSpan" id="kobo.690.1">kubectl</span></strong><span class="koboSpan" id="kobo.691.1">—both imperatively and declaratively using YAML-based manifests. </span><span class="koboSpan" id="kobo.691.2">In the next section, we’ll look at the Helm provider to see if it provides a better alternative to the options we’ve evaluated </span><span class="No-Break"><span class="koboSpan" id="kobo.692.1">thus far.</span></span></p>
<h1 id="_idParaDest-132"><a id="_idTextAnchor323"/><span class="koboSpan" id="kobo.693.1">Leveraging the Helm provider to provision Kubernetes resources</span></h1>
<p><span class="koboSpan" id="kobo.694.1">As we discussed previously, Kubernetes has a built-in declarative model based on YAML that allows you to provide resources to your cluster. </span><span class="koboSpan" id="kobo.694.2">However, as we saw, one of the challenges of using this model is that there is no way to use dynamic values inside your YAML-based specifications. </span><span class="koboSpan" id="kobo.694.3">That’s where Helm comes in. </span><span class="koboSpan" id="kobo.694.4">In this section, we’ll look at what Helm is exactly, its basic structure, how to use it, and how we can integrate it with our Terraf</span><a id="_idTextAnchor324"/><span class="koboSpan" id="kobo.695.1">orm pipelines or use it directly with the Helm provider </span><span class="No-Break"><span class="koboSpan" id="kobo.696.1">for Terraform.</span></span></p>
<h2 id="_idParaDest-133"><a id="_idTextAnchor325"/><span class="koboSpan" id="kobo.697.1">What is Helm?</span></h2>
<p><span class="koboSpan" id="kobo.698.1">Helm is </span><a id="_idIndexMarker433"/><span class="koboSpan" id="kobo.699.1">widely referred to as a package manager for Kubernetes, but I find this definition a bit perplexing as a software developer who is used to working with package managers for software libraries such as Maven, NuGet, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.700.1">npm</span></strong><span class="koboSpan" id="kobo.701.1"> or operating system package managers such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.702.1">apt</span></strong><span class="koboSpan" id="kobo.703.1"> or Chocolatey. </span><span class="koboSpan" id="kobo.703.2">I suppose at some levels, they share a similarity in aggregating multiple components into a single, versioned package and providing a convenient way to pull these packages into other projects </span><span class="No-Break"><span class="koboSpan" id="kobo.704.1">for reuse.</span></span></p>
<p><span class="koboSpan" id="kobo.705.1">However, I think a big difference and a unique part of Helm’s architecture is the nature of the templating engine. </span><span class="koboSpan" id="kobo.705.2">At its core, Helm allows you to create templates containing one or more Kubernetes YAML manifests and allows you to infuse more dynamic customization within your Kubernetes resources, thus making your Kubernetes deployments much </span><a id="_idIndexMarker434"/><span class="koboSpan" id="kobo.706.1">more reusable and easier to manage and maintain. </span><span class="koboSpan" id="kobo.706.2">These templates are referred </span><a id="_idIndexMarker435"/><span class="koboSpan" id="kobo.707.1">to as </span><strong class="bold"><span class="koboSpan" id="kobo.708.1">charts</span></strong><span class="koboSpan" id="kobo.709.1"> or </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.710.1">Helm charts</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.711.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.712.1">In many ways, a Helm chart reminds me more of what a Terraform module is rather than a traditional package management software—whether it’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.713.1">apt</span></strong><span class="koboSpan" id="kobo.714.1"> or NuGet. </span><span class="koboSpan" id="kobo.714.2">The similarities abound when comparing a Terraform module with a Helm chart. </span><span class="koboSpan" id="kobo.714.3">They both operate within a folder and define a method for taking input variables and </span><span class="No-Break"><span class="koboSpan" id="kobo.715.1">producing outputs:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<span class="koboSpan" id="kobo.716.1"><img alt="Figure 5.6 – Terraform module inputs, outputs, and resources" src="image/B21183_05_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.717.1">Figure 5.6 – Terraform module inputs, outputs, and resources</span></p>
<p><span class="koboSpan" id="kobo.718.1">A Terraform module encapsulates an aggregation of several Terraform resources (or other modules) defined within </span><strong class="source-inline"><span class="koboSpan" id="kobo.719.1">.tf</span></strong><span class="koboSpan" id="kobo.720.1"> files, and HCL allows you to implement any number of dynamic configurations using built-in capabilities of </span><span class="No-Break"><span class="koboSpan" id="kobo.721.1">the language:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer045">
<span class="koboSpan" id="kobo.722.1"><img alt="Figure 5.7 – Helm chart inputs, outputs, and resources" src="image/B21183_05_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.723.1">Figure 5.7 – Helm chart inputs, outputs, and resources</span></p>
<p><span class="koboSpan" id="kobo.724.1">As mentioned, a Helm chart </span><a id="_idIndexMarker436"/><span class="koboSpan" id="kobo.725.1">performs a similar aggregation but with Kubernetes resources that are defined within </span><strong class="source-inline"><span class="koboSpan" id="kobo.726.1">.yaml</span></strong><span class="koboSpan" id="kobo.727.1"> files and use Kubernetes YAML-based markup. </span><span class="koboSpan" id="kobo.727.2">Helm defines its own templating engine based on Go templates that offers a wide range of features that allow you to implement a similar level of dynamic configuration that you can achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.728.1">with HCL.</span></span></p>
<p><span class="koboSpan" id="kobo.729.1">As you can see, the basic structure of a Helm chart is quite simple. </span><span class="koboSpan" id="kobo.729.2">It is not as simple as a Terraform module because we have nested folders that preclude users from being able to cleanly nest Helm charts within each other. </span><span class="koboSpan" id="kobo.729.3">Sub-charts need to be created in a special </span><strong class="source-inline"><span class="koboSpan" id="kobo.730.1">charts</span></strong><span class="koboSpan" id="kobo.731.1"> directory and can be completely encapsulated within this folder or simply reference an existing chart hosted elsewhere. </span><span class="koboSpan" id="kobo.731.2">This is similar to how Terraform modules work in that you can reference a local module or one hosted at any number of remote locations. </span><span class="koboSpan" id="kobo.731.3">A subtle difference is how Terraform modules can be declared in any </span><strong class="source-inline"><span class="koboSpan" id="kobo.732.1">.tf</span></strong><span class="koboSpan" id="kobo.733.1"> file, and their definition simply needs to be stored in another local folder or </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">remote location:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer046">
<span class="koboSpan" id="kobo.735.1"><img alt="Figure 5.8 – Helm chart anatomy" src="image/B21183_05_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.736.1">Figure 5.8 – Helm chart anatomy</span></p>
<p><span class="koboSpan" id="kobo.737.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.738.1">Chart.yaml</span></strong><span class="koboSpan" id="kobo.739.1"> file is a</span><a id="_idIndexMarker437"/><span class="koboSpan" id="kobo.740.1"> special file inside the Helm chart that acts as the main entry point file that contains key identification metadata and other dependencies such as other Helm charts defined either locally or in a </span><span class="No-Break"><span class="koboSpan" id="kobo.741.1">remote location:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.742.1">
apiVersion: v2
name: my-webapp
version: 0.1.0
description: A basic web application Helm chart</span></pre> <p><span class="koboSpan" id="kobo.743.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.744.1">values.yaml</span></strong><span class="koboSpan" id="kobo.745.1"> file is a file that defines the input variables for a Helm chart. </span><span class="koboSpan" id="kobo.745.2">This is an example where in HCL we have no restriction on where we put input variables, by convention—and for our own sanity, we put input variables into a </span><strong class="source-inline"><span class="koboSpan" id="kobo.746.1">variables.tf</span></strong><span class="koboSpan" id="kobo.747.1"> file. </span><span class="koboSpan" id="kobo.747.2">In Helm, this convention of isolating input variable declarations is canonized into a well-known file that is recognized beyond a </span><span class="No-Break"><span class="koboSpan" id="kobo.748.1">simple convention:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.749.1">
replicaCount: 1
image:
  repository: nginx
  tag: stable
  pullPolicy: IfNotPresent
service:
  type: ClusterIP
  port: 80
ingress:
  enabled: false
  annotations: {}
  path: /
  hosts:
    - my-webapp.local
  tls: []</span></pre> <p><span class="koboSpan" id="kobo.750.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.751.1">templates</span></strong><span class="koboSpan" id="kobo.752.1"> folder is </span><a id="_idIndexMarker438"/><span class="koboSpan" id="kobo.753.1">where all our YAML-based manifests will go. </span><span class="koboSpan" id="kobo.753.2">However, the YAML is a bit different because it will most likely have many dynamic values injected into it using a Go templating convention (</span><strong class="source-inline"><span class="koboSpan" id="kobo.754.1">{{</span></strong><span class="koboSpan" id="kobo.755.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.756.1">}}</span></strong><span class="koboSpan" id="kobo.757.1">) to denote symbolic references that Helm will resolve using the Go </span><span class="No-Break"><span class="koboSpan" id="kobo.758.1">templating engine:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.759.1">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ template "my-webapp.fullname" . </span><span class="koboSpan" id="kobo.759.2">}}
  labels:
    app: {{ template "my-webapp.name" . </span><span class="koboSpan" id="kobo.759.3">}}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ template "my-webapp.name" . </span><span class="koboSpan" id="kobo.759.4">}}
  template:
    metadata:
      labels:
        app: {{ template "my-webapp.name" . </span><span class="koboSpan" id="kobo.759.5">}}
    spec:
      containers:
        - name: {{ template "my-webapp.name" . </span><span class="koboSpan" id="kobo.759.6">}}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: 80</span></pre> <p><span class="koboSpan" id="kobo.760.1">Helm charts can then be installed </span><a id="_idIndexMarker439"/><span class="koboSpan" id="kobo.761.1">onto a Kubernetes cluster using a different command-line tool called </span><strong class="source-inline"><span class="koboSpan" id="kobo.762.1">helm</span></strong><span class="koboSpan" id="kobo.763.1">. </span><span class="koboSpan" id="kobo.763.2">This tool performs a number of different functions, including autogenerating a basic chart structure, packaging charts for distribution, managing chart repositories, and installing charts onto </span><span class="No-Break"><span class="koboSpan" id="kobo.764.1">the cluster.</span></span></p>
<p><span class="koboSpan" id="kobo.765.1">Both </span><strong class="source-inline"><span class="koboSpan" id="kobo.766.1">kubectl</span></strong><span class="koboSpan" id="kobo.767.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.768.1">helm</span></strong><span class="koboSpan" id="kobo.769.1"> use the same method to authenticate with a Kubernetes cluster, but they are used for different purposes when managing the cluster, just as with </span><strong class="source-inline"><span class="koboSpan" id="kobo.770.1">kubectl</span></strong><span class="koboSpan" id="kobo.771.1">, which can apply declarative Kubernetes configuration using the </span><span class="No-Break"><span class="koboSpan" id="kobo.772.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.773.1">
kubectl apply -f &lt;file&gt;.yaml</span></pre> <p><span class="koboSpan" id="kobo.774.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.775.1">helm</span></strong><span class="koboSpan" id="kobo.776.1"> command can be used to provision a Helm chart to a Kubernetes cluster using the </span><span class="No-Break"><span class="koboSpan" id="kobo.777.1">following command:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.778.1">
helm install my-webapp ./my-webapp</span></pre> <p><span class="koboSpan" id="kobo.779.1">In this regard, Helm could similarly be integrated into a Terraform CI/CD pipeline that first provisions the cloud environment using Terraform and the relevant cloud platform provider (for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.780.1">aws</span></strong><span class="koboSpan" id="kobo.781.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.782.1">azurerm</span></strong><span class="koboSpan" id="kobo.783.1">, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.784.1">googlecloud</span></strong><span class="koboSpan" id="kobo.785.1">) and then uses the </span><strong class="source-inline"><span class="koboSpan" id="kobo.786.1">helm</span></strong><span class="koboSpan" id="kobo.787.1"> command-line tool to install Helm charts onto the Kubernetes cluster using connection and authentication information provided by the output of the Terraform stage of </span><span class="No-Break"><span class="koboSpan" id="kobo.788.1">the pipeline:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer047">
<span class="koboSpan" id="kobo.789.1"><img alt="Figure 5.9 – Helm chart anatomy: Terraform and Helm integration in a CI/CD pipeline" src="image/B21183_05_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.790.1">Figure 5.9 – Helm chart anatomy: Terraform and Helm integration in a CI/CD pipeline</span></p>
<p><span class="koboSpan" id="kobo.791.1">In the next </span><a id="_idIndexMarker440"/><span class="koboSpan" id="kobo.792.1">subsection, we’ll look at how the same process could be streamlined using the Helm provider for Terraform, thus replacing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.793.1">bash</span></strong><span class="koboSpan" id="kobo.794.1"> sc</span><a id="_idTextAnchor326"/><span class="koboSpan" id="kobo.795.1">ripts executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.796.1">helm</span></strong><span class="koboSpan" id="kobo.797.1"> commands imperatively and managing it </span><span class="No-Break"><span class="koboSpan" id="kobo.798.1">with Terraform.</span></span></p>
<h2 id="_idParaDest-134"><a id="_idTextAnchor327"/><span class="koboSpan" id="kobo.799.1">The Helm Terraform provider</span></h2>
<p><span class="koboSpan" id="kobo.800.1">In the previous </span><a id="_idIndexMarker441"/><span class="koboSpan" id="kobo.801.1">section, we looked at how Helm works, the structure of a Helm chart, and how its structure and functionality compare and contrast to Terraform modules. </span><span class="koboSpan" id="kobo.801.2">Now, we’ll look at how we can use Terraform to manage our Kubernetes environment using the Helm provider for Terraform. </span><span class="koboSpan" id="kobo.801.3">This provider is a close brother to the Kubernetes provider for Terraform because they both interact with the Kubernetes REST API as the control plan for managing </span><span class="No-Break"><span class="koboSpan" id="kobo.802.1">Terraform resources.</span></span></p>
<p><span class="koboSpan" id="kobo.803.1">The advantage of using Terraform with Helm is that it enables you to manage your Kubernetes applications alongside your other infrastructure, using the same configuration language and tooling. </span><span class="koboSpan" id="kobo.803.2">As we know, Helm allows us to create parameterized</span><a id="_idIndexMarker442"/><span class="koboSpan" id="kobo.804.1"> templates using Kubernetes’ declarative YAML manifests and a templating language, but we still need to use </span><strong class="source-inline"><span class="koboSpan" id="kobo.805.1">bash</span></strong><span class="koboSpan" id="kobo.806.1"> scripts to execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.807.1">helm</span></strong><span class="koboSpan" id="kobo.808.1"> commands and pass in parameters to the Helm chart. </span><span class="koboSpan" id="kobo.808.2">Some Helm charts can have very complicated configurations with dozens of parameters. </span><span class="koboSpan" id="kobo.808.3">So, using Terraform eliminates the additional integration with external </span><strong class="source-inline"><span class="koboSpan" id="kobo.809.1">bash</span></strong><span class="koboSpan" id="kobo.810.1"> scripts that execute </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.811.1">helm</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.812.1"> commands.</span></span></p>
<p><span class="koboSpan" id="kobo.813.1">At the same time, it also allows Kubernetes practitioners to develop Kubernetes templates in their native toolset. </span><span class="koboSpan" id="kobo.813.2">So, if you have Kubernetes specialists in your organization who want to build their own custom Helm charts, this allows them to keep doing their thing while plugging into a declarative deployment approach using Terraform. </span><span class="koboSpan" id="kobo.813.3">This also allows you to leverage the massive ecosystem that already exists for Helm and Kubernetes without any additional translation </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">into HCL.</span></span></p>
<p><span class="koboSpan" id="kobo.815.1">As with the Kubernetes provider, you need to initialize the provider first by declaring it as a </span><span class="No-Break"><span class="koboSpan" id="kobo.816.1">required provider:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.817.1">
terraform {
    required_providers {
        helm = {
            source = "hashicorp/helm"
            version = "~&gt; 2.0.0"
        }
    }
}</span></pre> <p><span class="koboSpan" id="kobo.818.1">Then, in your root module, you need to create an instance of the provider. </span><span class="koboSpan" id="kobo.818.2">The provider configuration for the Helm provider closely resembles that of the </span><span class="No-Break"><span class="koboSpan" id="kobo.819.1">Kubernetes provider:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.820.1">
provider "helm" {
    kubernetes {
        config_path = "~/.kube/config"
    }
}</span></pre> <p><span class="koboSpan" id="kobo.821.1">In fact, both the Helm and Kubernetes providers can be used side by side in the same Terraform module in case some additional Kubernetes resources need to be provisioned to augment what’s in the Helm </span><span class="No-Break"><span class="koboSpan" id="kobo.822.1">chart itself.</span></span></p>
<p><span class="koboSpan" id="kobo.823.1">The Helm provider </span><a id="_idIndexMarker443"/><span class="koboSpan" id="kobo.824.1">can be used to create a two-stage Terraform CI/CD pipeline where the first stage provisions the cloud environment using Terraform and the corresponding cloud platform’s provider. </span><span class="koboSpan" id="kobo.824.2">The second stage uses the cluster connection and authentication settings output by the first stage to configure the Helm provider and runs </span><strong class="source-inline"><span class="koboSpan" id="kobo.825.1">terraform apply</span></strong><span class="koboSpan" id="kobo.826.1"> again using a different Terraform code base containing the </span><span class="No-Break"><span class="koboSpan" id="kobo.827.1">Helm configuration:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer048">
<span class="koboSpan" id="kobo.828.1"><img alt="Figure 5.10 – Helm chart anatomy: Terraform and Helm integration in a CI/CD pipeline" src="image/B21183_05_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.829.1">Figure 5.10 – Helm chart anatomy: Terraform and Helm integration in a CI/CD pipeline</span></p>
<p><span class="koboSpan" id="kobo.830.1">The Terraform code base for the second stage is often quite small, only using a single resource. </span><span class="koboSpan" id="kobo.830.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.831.1">helm_release</span></strong><span class="koboSpan" id="kobo.832.1"> resource is the only resource in the provider—which is quite different if you have ever used one of the cloud platform providers such as AWS, Azure, </span><span class="No-Break"><span class="koboSpan" id="kobo.833.1">or GCP!</span></span></p>
<p><span class="koboSpan" id="kobo.834.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.835.1">helm_release</span></strong><span class="koboSpan" id="kobo.836.1"> resource</span><a id="_idIndexMarker444"/><span class="koboSpan" id="kobo.837.1"> simply takes the inputs that we would expect to pass to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.838.1">helm install</span></strong><span class="koboSpan" id="kobo.839.1"> command by specifying the chart name and version and an external repository (</span><span class="No-Break"><span class="koboSpan" id="kobo.840.1">if necessary):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.841.1">
resource "helm_release" "my_application" {
    name       = "my-application"
    repository = https://kubernetes-charts.storage.googleapis.com/
    chart      = "my-application-chart</span><a id="_idTextAnchor328"/><span class="koboSpan" id="kobo.842.1">"
    version    = "1.0.0"
}</span></pre> <p><span class="koboSpan" id="kobo.843.1">This concludes the section on the </span><span class="No-Break"><span class="koboSpan" id="kobo.844.1">Helm provider.</span></span></p>
<h1 id="_idParaDest-135"><a id="_idTextAnchor329"/><span class="koboSpan" id="kobo.845.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.846.1">In this chapter, we learned the basic concepts needed to understand containers, container orchestrators, and the ways you can provision and manage container-based infrastructure using both Kubernetes native tooling via </span><strong class="source-inline"><span class="koboSpan" id="kobo.847.1">kubectl</span></strong><span class="koboSpan" id="kobo.848.1"> and Helm and the corresponding Terraform providers for both Kubernetes </span><span class="No-Break"><span class="koboSpan" id="kobo.849.1">and Helm.</span></span></p>
<p><span class="koboSpan" id="kobo.850.1">This is the end of the cross-platform, cloud-agnostic knowledge that we need to build both VM- and container-based architectures across all three hyperscalars. </span><span class="koboSpan" id="kobo.850.2">Since serverless is inherently platform-specific and offers significant abstraction from the underlying infrastructure, I will cover each hyperscalar’s offering in its </span><span class="No-Break"><span class="koboSpan" id="kobo.851.1">respective chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.852.1">In the next chapter, we will move beyond cloud architecture paradigms and spend some time understanding how teams deliver IAC solutions using CI/CD pipelines that fuse the infrastructure provisioning, configuration management, and application deployment processes into a cohesive, </span><span class="No-Break"><span class="koboSpan" id="kobo.853.1">end-to-end workflow.</span></span></p>
</div>
</body></html>