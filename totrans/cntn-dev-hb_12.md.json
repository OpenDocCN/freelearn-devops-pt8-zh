["```\nfrjaraur@sirius:~$ kubectl run kubectl2 \\\n--image=bitnami/kubectl:latest -- get pods\npod/kubectl2 created\n```", "```\n$ kubectl logs kubectl2\nError from server (Forbidden): pods is forbidden: User \"system:serviceaccount:default:default\" cannot list resource \"pods\" in API group \"\" in the namespace \"default\"\n```", "```\n    PS C:\\Users\\frjaraur> kubectl -n monitoring `\n    port-forward service/prometheus-operated 9090:9090\n    Forwarding from 127.0.0.1:9090 -> 9090\n    Forwarding from [::1]:9090 -> 9090\n    http://localhost:8080 in your browser to access Prometheus. If you click on Status, you will see the available pages related to the monitored endpoints:\n    ```", "```\n    PS C:\\Users\\frjaraur> kubectl create deployment `\n    webserver --image=nginx:alpine --port=80\n    deployment.apps/webserver created\n    ```", "```\n    PS C:\\Users\\frjaraur> kubectl get svc `\n    -n monitoring prometheus-prometheus-node-exporter `\n    -o jsonpath='{.spec}'\n    app.kubernetes.io/name=prometheus-node-exporter label.\n    ```", "```\nPS C:\\Users\\frjaraur> kubectl get Prometheus -A\nNAMESPACE    NAME           VERSION   DESIRED   READY   RECONCILED   AVAILABLE   AGE\nmonitoring   prometheus-kube-prom-prometheus   v2.45.0   1         1       True         True        17h\n```", "```\nPS C:\\Users\\frjaraur> kubectl get Prometheus -n monitoring prometheus-kube-prom-prometheus  -o yaml\napiVersion: monitoring.coreos.com/v1\nkind: Prometheus\n...\nspec:\n  podMonitorNamespaceSelector: {}\n  podMonitorSelector:\n    matchLabels:\n      release: prometheus-stack\n…\n  serviceMonitorNamespaceSelector: {}\n  serviceMonitorSelector:\n    matchLabels:\n      release: prometheus-stack\n```", "```\n    --set loki.commonConfig.replication_factor=1 --set loki.commonConfig.storage.type=filesystem --set singleBinary.replicas=1 --set loki.auth_enabled=false --set monitoring.lokiCanary.enabled=false --set test.enabled=false --set monitoring.selfMonitoring.enabled=false\n    ```", "```\n    PS C:\\Users\\frjaraur> helm show values `\n    grafana/promtail\n    …\n    config:\n    …\n      clients:\n        - url: http://loki-gateway/loki/api/v1/push\n    defaultVolumeMounts key in the chart values YAML file). All the files included will be read and managed by the Promtail agent and the data extracted will be sent to the URL defined in config.clients[].url. This is the basic configuration we need to review because, by default, Kubernetes logs will be included in the config.snippets section. Prometheus, Grafana Loki, and Promtail are quite configurable applications, and their customization can be very tricky. In this chapter, we are reviewing the basics for monitoring and logging your applications with them. It may be very useful for you to review the documentation of each mentioned tool to extend these configurations.\n    ```", "```\n    PS C:\\Users\\frjaraur> kubectl port-forward `\n    -n monitoring service/prometheus-grafana 8080:80\n    Forwarding from 127.0.0.1:8080 -> 3000\n    admin username with the prom-operator password), accessible at http://localhost:8080, we can configure the data sources by navigating to Home | Adminsitration | Datasources:\n    ```", "```\nimport { check } from \"k6\";\nimport http from \"k6/http\";\nexport default function() {\n  let res = http.get(\"https://www.example.com/\");\n  check(res, {\n    \"is status 200\": (r) => r.status === 200\n  });\n};\n```", "```\nimport http from 'k6/http';\nimport { sleep, check } from 'k6';\nimport {parseHTML} from \"k6/html\";\nexport default function() {\n    const res = http.get(\"https://k6.io/docs/\");\n    const doc = parseHTML(res.body);\n    sleep(1);\n    doc.find(\"link\").toArray().forEach(function (item) {\n        console.log(item.attr(\"href\"));\n     });\n}\n```", "```\nthat OpenTelemetry Collector has been deployed using a deployment that will monitor all the applications instead of selected ones. Please read the OpenTelemetry documentation (https://opentelemetry.io/docs) and specific guides available for the associated Helm Charts (https://github.com/open-telemetry/opentelemetry-operator and https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-operator).\n```", "```\n    Chapter12$ minikube start --driver=hyperv /\n    --memory=6gb --cpus=2 --cni=calico /\n    simplestlab application, which we used in previous chapters, on Kubernetes. The following steps will be executed inside the Chapter12 folder:\n\n    ```", "```\n\n    ```", "```\n    Chapter12$ helm install kube-prometheus-stack /\n    --namespace monitoring --create-namespace /\n    hosts file (/etc/hosts or c:\\windows\\system32\\drivers\\etc\\hosts) to include the Minikube IP address for grafana.local.lab and simplestlab.local.lab. We will now be able to access Grafana, published in our ingress controller, at https://grafana.local.lab.Then, we will deploy Grafana Loki to retrieve the logs from all the applications and the Kubernetes platform. We will use a custom values file (`loki.values.yaml`) to deploy Loki that’s included inside `Chapter12` directory. The file has already been prepared for you with the minimum requirements for deploying a functional Loki environment. We will use the following command:\n\n    ```", "```\n    container_cpu_usage_seconds_total and container_memory_max_usage_bytes metrics, which were retrieved using  Prometheus, and the simplestlab application logs in Loki thanks to the Promtail component.\n    ```", "```\n\n    ```", "```\n    apiVersion: monitoring.coreos.com/v1\n    kind: ServiceMonitor\n    metadata:\n      labels:\n        component: lb\n        app: simplestlab\n        release: kube-prometheus-stack\n      name: lb\n      namespace: simplestlab\n    spec:\n      endpoints:\n      - path: /metrics\n        port: exporter\n        interval: 30s\n      jobLabel: jobLabel\n      selector:\n        matchLabels:\n          component: lb\n          app: simplestlab\n    ```"]