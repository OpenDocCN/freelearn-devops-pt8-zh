<html><head></head><body>
		<div id="_idContainer167">
			<h1 id="_idParaDest-168" class="chapter-number"><a id="_idTextAnchor176"/>9</h1>
			<h1 id="_idParaDest-169"><a id="_idTextAnchor177"/>OpenShift Pipelines – Tekton</h1>
			<p>So far in this book, we’ve already discussed the challenges related to the current hybrid cloud world and covered aspects regarding the OpenShift architecture and deployment. Now, we are going to shift gears and bring you an exciting DevOps-related feature: <strong class="bold">OpenShift Pipelines</strong>!</p>
			<p>OpenShift Pipelines is a Kubernetes-native <strong class="bold">continuous integration and continuous delivery</strong> (<strong class="bold">CI/CD</strong>) tool based on the Tekton open source project, which is included at <em class="italic">no additional cost with Red Hat’s OpenShift subscription</em>. In this chapter, we will walk you through it and learn how to install and use it. By doing this, you will understand how it can be helpful in your DevOps pipelines and automation.</p>
			<p>After <a href="B18015_05.xhtml#_idTextAnchor090"><em class="italic">Chapter 5</em></a>, <em class="italic">OpenShift Deployment</em>, you should have an OpenShift cluster working in your environment. We will use that cluster in this chapter to implement some exercises. If you don’t have an OpenShift cluster available, then you can use <strong class="bold">CodeReady Containers</strong> (<strong class="bold">CRC</strong>) as a lab. Here, you can run an OpenShift cluster locally and quickly using an all-in-one VM.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>What is OpenShift Pipelines? </li>
				<li>Installing OpenShift Pipelines </li>
				<li>Creating a Tekton pipeline from scratch</li>
				<li>Using triggers with GitHub webhooks</li>
				<li>Fixing the failed PipelineRun due to YAML issues</li>
			</ul>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor178"/>Technical requirements</h1>
			<p>As we mentioned previously, OpenShift Pipelines is a Kubernetes native application and, as such, is a lightweight tool that uses <strong class="bold">Custom Resource Definitions</strong> (<strong class="bold">CRDs</strong>) to extend the OpenShift API’s functionalities. In the upcoming sections, you will see that the installation is fairly simple and only involves installing an operator – a <em class="italic">“Next, Next, Finish”</em> sort of experience. To be able to install it and run the exercises in this chapter, you only need an OpenShift cluster with the following available resources:</p>
			<ul>
				<li>2 vCPUs</li>
				<li>2 GB of RAM</li>
			</ul>
			<p>If you don’t have an OpenShift cluster available to use, we recommend that you try CRC to spin up a cluster locally on your machine. To use CRC, you need to have the following system requirements on your workstation:</p>
			<ul>
				<li>4 physical CPU cores (AMD64 or Intel 64)</li>
				<li>9 GB of free memory</li>
				<li>35 GB of storage space</li>
				<li>One of the following operating systems:<ul><li>Windows (Windows 10 Fall Creators Update or later)</li>
<li>macOS (10.14 Mojave or later)</li>
<li>Linux (Red Hat Enterprise Linux/CentOS 7.5 or later and on the latest two stable Fedora releases)</li>
<li>Linux (Ubuntu 18.04 LTS or newer and Debian 10 or newer <em class="italic">are not officially</em> supported and may require you to manually set up the host machine</li>
</ul></li>
			</ul>
			<p>The source code used in this chapter is available at <a href="https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter09">https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter09</a>.</p>
			<p>In this section, we will demonstrate how to install and use CRC using a Linux (Fedora) workstation. Please refer to the following site to find out more about the installation process on Windows or macOS: <a href="https://crc.dev/crc/">https://crc.dev/crc/</a>.</p>
			<p class="callout-heading">What Is a CRD?</p>
			<p class="callout">A CRD is a Kubernetes resource<a id="_idIndexMarker577"/> that allows you to expand the Kubernetes APIs by defining custom entities. A CRD is composed of a name and a schema that specify the API’s properties.</p>
			<h2 id="_idParaDest-171"><a id="_idTextAnchor179"/>Installing and using CRC</h2>
			<p>The CRC installation process<a id="_idIndexMarker578"/> is simple – you need to have the following<a id="_idIndexMarker579"/> packages installed in your box:</p>
			<pre class="source-code">$ sudo yum install NetworkManager libvirt –y</pre>
			<p>To install CRC, follow these steps:</p>
			<ol>
				<li>Download<a id="_idIndexMarker580"/> the latest release of CRC for your platform at <a href="https://console.redhat.com/openshift/create/local">https://console.redhat.com/openshift/create/local</a>.</li>
				<li>Extract the contents of the archive.</li>
				<li>In a terminal, go to the path where you extracted the archive.</li>
				<li>Run the following command to set up CRC:<p class="source-code">$ ./crc setup</p></li>
				<li>If you want to set up parameters, such as the amount of CPU and memory that’s available for CRC, run the following code:<p class="source-code">$ ./crc config set cpus 4</p><p class="source-code">$ ./crc config set memory 20480</p></li>
				<li>Start CRC by running the following command:<p class="source-code">$ ./crc start</p></li>
			</ol>
			<p>It is going to take up to 20 minutes to completely start the cluster. At the end of the process, you will see a screen similar to the following:</p>
			<div>
				<div id="_idContainer139" class="IMG---Figure">
					<img src="image/B18015_09_01.jpg" alt="Figure 9.1 – CRC startup "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – CRC startup</p>
			<p>Now that you have CRC<a id="_idIndexMarker581"/> or any other OpenShift cluster up<a id="_idIndexMarker582"/> and running, we are ready to introduce OpenShift Pipelines and learn what you can do with it.</p>
			<h1 id="_idParaDest-172"><a id="_idTextAnchor180"/>What is OpenShift Pipelines?</h1>
			<p>Now that you already<a id="_idIndexMarker583"/> have a lab environment, let’s start our engines and drive through OpenShift Pipelines! As we mentioned previously, OpenShift Pipelines is Red Hat’s implementation of the Tekton open source project. Let’s learn what Tekton is and how it differs from other CI/CD pipeline tools on the market.</p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor181"/>What is Tekton?</h2>
			<p>Tekton provides a framework for creating<a id="_idIndexMarker584"/> Kubernetes native CI/CD pipelines quickly and easily. It uses CRDs to extend the Kubernetes APIs functionalities and add some custom objects that are used to implement CI/CD pipelines. You can also integrate Tekton with industry-standard CI/CD pipeline tools such as Jenkins, GitLab CI, and any others to use the best technology for each case.</p>
			<p>Tekton is a part of the <strong class="bold">Continuous Delivery Foundation</strong>, which is sponsored by huge companies<a id="_idIndexMarker585"/> such as AWS, Red Hat, Google, Netflix, and <a id="_idIndexMarker586"/>many others. This is usually a good indication that a project will have a long life and stability – an important factor for an enterprise’s investment decisions.</p>
			<h2 id="_idParaDest-174"><a id="_idTextAnchor182"/>Main benefits</h2>
			<p>Using Tekton can bring<a id="_idIndexMarker587"/> you many benefits, such as the following:</p>
			<ul>
				<li>Tekton can be considered as a serverless CI/CD pipeline system that consumes resources on demand using isolated containers, which likely reduce the infrastructure or cloud costs associated with the CI/CD tool.</li>
				<li>It is tightly integrated with Kubernetes, working as an extension of it using CRDs. This means that you don’t need to spend time and resources with complex integrations between the CI/CD tools and OpenShift.</li>
				<li>Both the aforementioned aspects also mean that you will not need additional human resources to deploy, support, and maintain the CI/CD tool.</li>
				<li>As a Kubernetes native tool, you can define and run pipelines by applying a simple YAML file to Kubernetes (the same way you would do to create a Pod, Service, Or Deployment). This makes Tekton easy to use and integrate with other tools for complex pipelines that are composed of several components (legacy VMs, containers, microservices, and so on).</li>
				<li>By integrating Tekton with <strong class="bold">Argo CD</strong>, you can have a really powerful<a id="_idIndexMarker588"/> stack in which Tekton resides on the <em class="italic">continuous integration</em> side while Argo CD is responsible for the <em class="italic">continuous delivery</em> side. We will look at Argo CD in detail in <a href="B18015_10.xhtml#_idTextAnchor204"><em class="italic">Chapter 10</em></a>, <em class="italic">OpenShift GitOps – Argo CD</em>.</li>
				<li>It is a true open source solution that’s backed by a strong foundation, which is good evidence that it will be supported and evolve for years to come.</li>
			</ul>
			<h2 id="_idParaDest-175"><a id="_idTextAnchor183"/>Tekton components</h2>
			<p>In this section, we will walk through<a id="_idIndexMarker589"/> each of the Tekton components. In a nutshell, the main Tekton components are as follows:</p>
			<ul>
				<li><strong class="bold">Tekton Pipelines</strong>: It is composed of several<a id="_idIndexMarker590"/> CRDs, which are the building blocks for developing and running CI/CD pipelines.</li>
				<li><strong class="bold">Tekton Triggers</strong>: These are objects that listen<a id="_idIndexMarker591"/> to events and trigger a pipeline or task. They are often used to run a pipeline after a pull or push request in a GitHub repository.</li>
				<li><strong class="bold">Tekton CLI</strong>: The <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) (<strong class="source-inline">tkn</strong>) to interact<a id="_idIndexMarker592"/> with Tekton.</li>
				<li><strong class="bold">Tekton Catalog</strong>: A community-driven repository<a id="_idIndexMarker593"/> of tasks ready to be used in your pipelines.</li>
				<li><strong class="bold">Tekton Operator</strong>: This is used to easily install, manage, and<a id="_idIndexMarker594"/> remove Tekton from a Kubernetes cluster.</li>
			</ul>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor184"/>Concepts</h2>
			<p>To learn Tekton, you need<a id="_idIndexMarker595"/> to understand some concepts first:</p>
			<ul>
				<li><strong class="bold">Step</strong>: An action that has<a id="_idIndexMarker596"/> a set of inputs and produces a set of outputs.</li>
				<li><strong class="bold">Task</strong>: A set of structured steps required<a id="_idIndexMarker597"/> to run a specific task, such as cloning a GitHub repository or building source code.</li>
				<li><strong class="bold">Pipeline</strong>: A set of structured tasks<a id="_idIndexMarker598"/> that composes a CI/CD pipeline.</li>
				<li><strong class="bold">TaskRun</strong>: This object represents <a id="_idIndexMarker599"/>the instantiation of a task. While the task is the generic definition of it, a TaskRun defines the input parameters and the other components that are needed to run it.</li>
				<li><strong class="bold">PipelineRun</strong>: This is similar to a TaskRun, but<a id="_idIndexMarker600"/> for pipelines.</li>
			</ul>
			<p>To dive into these concepts, we will cover an example where we will build and run a meaningful pipeline.</p>
			<h1 id="_idParaDest-177"><a id="_idTextAnchor185"/>Installing OpenShift Pipelines</h1>
			<p>The installation process<a id="_idIndexMarker601"/> is really simple, as you will see in the following steps.</p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor186"/>Prerequisites</h2>
			<ol>
				<li value="1">You must have access<a id="_idIndexMarker602"/> to the OpenShift cluster with cluster-admin permissions.</li>
			</ol>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor187"/>Installation</h2>
			<p>Follow these<a id="_idIndexMarker603"/> steps:</p>
			<ol>
				<li value="1">Access the <strong class="bold">OpenShift Web Console </strong>from the administrator’s perspective.</li>
				<li>Navigate to <strong class="bold">Operators</strong> | <strong class="bold">OperatorHub</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer140" class="IMG---Figure">
					<img src="image/B18015_09_02.jpg" alt="Figure 9.2 – OperatorHub "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – OperatorHub</p>
			<ol>
				<li value="3">Search for <strong class="source-inline">OpenShift Pipelines</strong> using the <em class="italic">Filter by keyword</em> box:</li>
			</ol>
			<div>
				<div id="_idContainer141" class="IMG---Figure">
					<img src="image/B18015_09_03.jpg" alt="Figure 9.3 – Red Hat OpenShift Pipelines on OperatorHub "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Red Hat OpenShift Pipelines on OperatorHub</p>
			<ol>
				<li value="4">Click on the <strong class="bold">Red Hat OpenShift Pipelines</strong> tile and then<a id="_idIndexMarker604"/> the <strong class="bold">Install</strong> button to see the <strong class="bold">Install Operator</strong> screen:</li>
			</ol>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="image/B18015_09_04.jpg" alt="Figure 9.4 – Installing OpenShift Pipelines "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Installing OpenShift Pipelines</p>
			<ol>
				<li value="5">Now, select <strong class="bold">All namespaces on the cluster (default)</strong> for <strong class="bold">Installation mode</strong>. As such, the operator<a id="_idIndexMarker605"/> will be installed in the <strong class="source-inline">openshift-operators</strong> namespace and permits the operator to install OpenShift Pipelines instances in any target namespace.</li>
				<li>Select <strong class="bold">Automatic</strong> or <strong class="bold">Manual</strong> for the upgrade’s <strong class="bold">Approval Strategy</strong>. If you go for <strong class="bold">Automatic</strong>, upgrades will be performed automatically by the <strong class="bold">Operator Lifecycle Manager</strong> (<strong class="bold">OLM</strong>) as soon as they are released<a id="_idIndexMarker606"/> by Red Hat, while if you go for <strong class="bold">Manual</strong>, you need to approve it before it’s applied.</li>
				<li>Select an <strong class="bold">Update channel option</strong>. The stable channel is recommended as it contains the latest stable and <em class="italic">supported</em> version of the operator.</li>
				<li>Click the <strong class="bold">Install</strong> button:</li>
			</ol>
			<div>
				<div id="_idContainer143" class="IMG---Figure">
					<img src="image/B18015_09_05.jpg" alt="Figure 9.5 – Installing the operator "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Installing the operator</p>
			<ol>
				<li value="9">Wait up to 5 minutes until you see the following message:</li>
			</ol>
			<div>
				<div id="_idContainer144" class="IMG---Figure">
					<img src="image/B18015_09_06.jpg" alt="Figure 9.6 – Operator installed "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Operator installed</p>
			<p>Once you have installed<a id="_idIndexMarker607"/> OpenShift Pipelines, we recommend that you install the <strong class="source-inline">tkn</strong> CLI to help with ordinary tasks. Let’s learn how to install the <strong class="source-inline">tkn</strong> CLI.</p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor188"/>Installing the tkn CLI</h2>
			<p><strong class="source-inline">tkn</strong> is a CLI that makes it easier<a id="_idIndexMarker608"/> to work with Tekton. Through it, you can<a id="_idIndexMarker609"/> manage (list, delete, describe, get logs, and so on) tasks, pipelines, triggers, and all the available Tekton objects.</p>
			<p>To install the <strong class="source-inline">tkn</strong> CLI, follow these steps:</p>
			<ol>
				<li value="1">Download tkn from the URL link provided after you click the <em class="italic">question mark</em> icon of your OpenShift Web Console, as shown here:</li>
			</ol>
			<div>
				<div id="_idContainer145" class="IMG---Figure">
					<img src="image/B18015_09_07.jpg" alt="Figure 9.7 – Help menu | Command line tools "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Help menu | Command line tools</p>
			<ol>
				<li value="2">Download the client<a id="_idIndexMarker610"/> for your<a id="_idIndexMarker611"/> workstation:</li>
			</ol>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="image/B18015_09_08.jpg" alt="Figure 9.8 – tkn download links "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – tkn download links</p>
			<ol>
				<li value="3">After downloading it to your machine, you need to decompress it and add it to your path:<p class="source-code">$ tar -xvzf tkn-linux-amd64-0.17.2.tar.gz</p><p class="source-code">$ sudo cp tkn /usr/local/bin</p></li>
				<li>If everything went well, you will see the output below by running <strong class="source-inline">tkn version</strong>. Ignore the warning message you will see that specifies the pipeline version; it is an expected message as we haven’t logged any OpenShift clusters yet:<p class="source-code">$ tkn version</p><p class="source-code">Client version: 0.17.2</p><p class="source-code">Pipeline version: unknown, pipeline controller may be installed in another namespace please use tkn version -n {namespace}</p></li>
			</ol>
			<p>Now that you have installed<a id="_idIndexMarker612"/> OpenShift Pipelines and <strong class="source-inline">tkn</strong>, let’s use them<a id="_idIndexMarker613"/> to create a pipeline from scratch. In the next section, we will learn about Tekton’s main concepts while taking a practical approach.</p>
			<h1 id="_idParaDest-181"><a id="_idTextAnchor189"/>Creating a Tekton pipeline from scratch</h1>
			<p>In this section, we will create a Tekton pipeline<a id="_idIndexMarker614"/> from scratch so that we can learn from it. We are going to use a sample from our GitHub repository: <a href="https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook">https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook</a>. To practice the concepts we will cover here, fork this repository to your GitHub account and follow the instructions provided in this chapter.</p>
			<p>The pipeline that we will work on is simple but helpful. It will consist of the following tasks:</p>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="image/B18015_09_09.jpg" alt="Figure 9.9 – Build and deploy pipeline "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Build and deploy pipeline</p>
			<p>In the next few sections, you will learn how to use Tasks, TaksRuns, Pipelines, and PipelineRuns, which are Tekton’s main objects.</p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor190"/>Tasks</h2>
			<p>To create<a id="_idIndexMarker615"/> this pipeline, you need to understand the foundational concept<a id="_idIndexMarker616"/> of a task. As we mentioned previously, a task provides a set of structured steps for performing a certain action, such as cloning a GitHub repository or building source code. Now, let’s go deeper and learn about some important aspects of it. The first important aspect that you need to understand is the task scope, which defines whether you need to use a Task or a ClusterTask:</p>
			<ul>
				<li><strong class="bold">Task</strong>: A task is only available within a specific namespace. You will usually use tasks for actions that apply specifically to a certain application.</li>
				<li><strong class="bold">ClusterTask</strong>: This is identical to a task<a id="_idIndexMarker617"/> but can be used in any namespace. They are usually used with generic actions that can be applied to any application. </li>
			</ul>
			<p>In our example, we will use Tasks and ClusterTasks to understand how they work and the differences between them. A Task<a id="_idIndexMarker618"/> has the following elements. We will use these in our example:</p>
			<ul>
				<li><strong class="bold">Parameters</strong>: The parameters that are required to run the task.</li>
				<li><strong class="bold">Resources</strong>: This includes the input or output resources that are supplied by <strong class="bold">PipelineResources</strong> objects. We recommend that you use workspaces instead of PipelineResources since they are more difficult to troubleshoot, making tasks less reusable and more limited than workspaces. Due to that, we won’t be using PipelineResources in our example.</li>
				<li><strong class="bold">Steps</strong>: This is where you define the actions that will be performed in a task. You need to use a container image to run the actions. </li>
				<li><strong class="bold">Workspaces</strong>: This is an artifact that’s used to define a commonly shared storage volume between different tasks in a pipeline. Workspaces can be used for different purposes, such as sharing data between different tasks, a mount point for configurations (using ConfigMaps), credentials, and sensitive data (with secrets), and also to store reusable artifacts that have been shared between different tasks and pipelines. Workspaces are also helpful for caching artifacts to speed up builds and other jobs.</li>
				<li><strong class="bold">Results</strong>: These are string result<a id="_idIndexMarker619"/> variables that can be passed to other tasks in a pipeline.</li>
			</ul>
			<p>In our sample pipeline, we are going to reuse<a id="_idIndexMarker620"/> our existing tasks for the GitHub clone and build the source code. The last two tasks we will look at will be custom ones that we will create specifically for our pipeline. </p>
			<h3>Reusing tasks</h3>
			<p>First, let’s learn how to search<a id="_idIndexMarker621"/> for and reuse tasks to build a pipeline.</p>
			<p>The first place where you can look for existing tasks<a id="_idIndexMarker622"/> is your local OpenShift cluster. When you install OpenShift Pipelines, several <strong class="bold">ClusterTasks</strong> are installed with it. To check those ClusterTasks, you can use the <strong class="source-inline">tkn</strong> CLI or the OpenShift UI.</p>
			<p>The following code shows how to use <strong class="source-inline">tkn</strong>:</p>
			<pre class="source-code"># You need to login at the cluster first using "oc login"
$ oc login -u &lt;user&gt; https://&lt;ocp-api-url&gt;:6443
$ tkn clustertasks ls</pre>
			<p>The following is some example output:</p>
			<pre class="source-code">$ oc login -u kubeadmin https://api.crc.testing:6443
(.. omitted ..)
$ tkn clustertasks ls
NAME               DESCRIPTION              AGE
buildah            Buildah task builds...   2 days ago
buildah-1-5-0      Buildah task builds...   2 days ago
git-cli            This task can be us...   2 days ago
git-clone          These Tasks are Git...   2 days ago
(.. omitted ..)</pre>
			<p>To do the same using<a id="_idIndexMarker623"/> the OpenShift UI, go to <strong class="bold">Pipelines</strong> | <strong class="bold">Tasks</strong> using the Administrator Web Console and click on the <strong class="bold">ClusterTasks</strong> tab. You will see the same list that we found previously using the <strong class="source-inline">tkn</strong> CLI:</p>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="image/B18015_09_10.jpg" alt="Figure 9.10 – ClusterTasks for reuse "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – ClusterTasks for reuse</p>
			<p>Another great tool to look<a id="_idIndexMarker624"/> for and reuse existing tasks is <strong class="bold">Tekton Hub</strong>. We will use it shortly to extend our sample and validate<a id="_idIndexMarker625"/> our YAML files using the <strong class="bold">YAML Lint</strong> tool.</p>
			<p class="callout-heading">Notes</p>
			<p class="callout"><strong class="bold">Tekton Hub</strong> is a web portal where you can get reusable<a id="_idIndexMarker626"/> assets from Tekton Catalog. It can be accessed at <a href="https://hub.tekton.dev/">https://hub.tekton.dev/</a>.</p>
			<p class="callout"><strong class="bold">YAML Lint</strong> is a tool that validates YAML file<a id="_idIndexMarker627"/> syntax, checking indentation, trailing spaces, and many other possible issues. Go to <a href="https://yamllint.readthedocs.io/en/stable/">https://yamllint.readthedocs.io/en/stable/</a> to learn more.</p>
			<p>Using the ClusterTasks, we have decided to reuse the following:</p>
			<ul>
				<li><strong class="source-inline">git-clone</strong>: To clone the source code from the GitHub repository</li>
				<li><strong class="source-inline">buildah</strong>: To build the source code and generate a container image as a result</li>
			</ul>
			<p>Now, let’s learn how to create a custom task for when you need something specific.</p>
			<h3>Creating a new (custom) task</h3>
			<p>Defining a new task<a id="_idIndexMarker628"/> is as simple as creating a pod or deployment. For our example, we need to create three new tasks:</p>
			<ul>
				<li><strong class="source-inline">apply-manifests</strong>: This task will be responsible for applying some K8s manifest files that will deploy the application.</li>
				<li><strong class="source-inline">update-deployment</strong>: This task will update the deployment, replacing the container image with the one that has been built in the previous tasks.</li>
				<li><strong class="source-inline">check-app-health</strong>: This task checks the application pod’s status and the URL to validate whether the application is accessible.</li>
			</ul>
			<p>Let’s create these tasks, explore their content, and learn from them:</p>
			<pre class="source-code">apiVersion: tekton.dev/v1beta1 
kind: Task <strong class="bold">#[1]</strong>
metadata:
  name: apply-manifests <strong class="bold">#[2]</strong>
spec:
  workspaces: <strong class="bold">#[3]</strong>
  - name: source
  params: <strong class="bold">#[4]</strong>
  - name: manifest_dir
    description: The directory in the source that contains yaml manifests
    type: string
    default: "k8s"
  steps: <strong class="bold">#[5]</strong>
    - name: apply
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest <strong class="bold">#[6]</strong>
      workingDir: /workspace/source
<strong class="bold">#[7]</strong>
      command: ["/bin/bash", "-c"]
      args:
        - |-
          echo Applying manifests in $(inputs.params.manifest_dir) directory
          oc apply -f $(inputs.params.manifest_dir)
          echo -----------------------------------</pre>
			<p>In the preceding code, we have<a id="_idIndexMarker629"/> highlighted some parts with numbers. Let’s take a look:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: An object of this kind defines a new Tekton task.</li>
				<li><strong class="bold">[2]</strong>: The task’s name.</li>
				<li><strong class="bold">[3]</strong>: The workspace containing the k8s manifest source files. This is the shared workspace that was populated with the <strong class="source-inline">git-clone</strong> task (the first task).</li>
				<li><strong class="bold">[4]</strong>: The parameters that are required for the task to run.</li>
				<li><strong class="bold">[5]</strong>: The steps that are performed with the task.</li>
				<li><strong class="bold">[6]</strong>: The image that will run the <strong class="source-inline">step</strong> commands.</li>
				<li><strong class="bold">[7]</strong>: The commands that will perform the desired action – in this case, applying the k8s manifests.</li>
			</ul>
			<p>Now that we have looked at the task’s structure, let’s create it in our sample environment<a id="_idIndexMarker630"/> and run it using another object – <strong class="bold">TestRun</strong>:</p>
			<ol>
				<li value="1">Create a new project for our example:<p class="source-code">$ oc new-project pipelines-sample</p></li>
				<li>Now, check if the pipeline’s service account has been created automatically:<p class="source-code">$ oc get serviceaccount pipeline </p><p class="source-code">NAME       SECRETS   AGE</p><p class="source-code">pipeline   2         33s</p></li>
				<li>Create the <strong class="source-inline">apply-manifest</strong> task in the <strong class="source-inline">pipelines-sample</strong> namespace:<p class="source-code">$ oc apply -f  https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Tasks/apply-manifests.yaml</p><p class="source-code">task.tekton.dev/apply-manifests created</p></li>
				<li>Using <strong class="source-inline">tkn</strong> confirm<a id="_idIndexMarker631"/> that the task has been created:<p class="source-code">$ tkn tasks ls</p><p class="source-code">NAME              DESCRIPTION   AGE</p><p class="source-code">apply-manifests                 17 seconds ago</p></li>
				<li>Now, let’s create other custom tasks (<strong class="source-inline">update-image-version</strong> and <strong class="source-inline">check-route-health</strong>):<p class="source-code">$ oc apply -f  https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Tasks/update-image-version.yaml</p><p class="source-code">$ oc apply -f  https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Tasks/check-route-health.yaml</p><p class="source-code">$ tkn tasks ls</p><p class="source-code">NAME              DESCRIPTION   AGE</p><p class="source-code">apply-manifests                 17 seconds ago</p><p class="source-code">heck-app-health                     10 seconds ago</p><p class="source-code">update-deployment                 8 seconds ago</p></li>
			</ol>
			<p>Now that we have created<a id="_idIndexMarker632"/> our custom tasks, let’s learn how to run and test them using a <strong class="source-inline">TaskRun</strong> object.</p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor191"/>TaskRun</h2>
			<p>Our task needs a persistent<a id="_idIndexMarker633"/> volume to store the source code from GitHub. As such, before<a id="_idIndexMarker634"/> we run TaskRun, we need<a id="_idIndexMarker635"/> to create a <strong class="bold">PersistentVolumeClaim</strong>. Note that you need to have a <strong class="bold">StorageClass</strong> to provision a <strong class="bold">PersistentVolume</strong> automatically for you. If you don’t have<a id="_idIndexMarker636"/> one, the PersistentVolumeClaim<a id="_idIndexMarker637"/> will be <em class="italic">Pending</em>, waiting for the PersistentVolume to be created manually.  </p>
			<p>Run the following command to create the PersistentVolumeClaim:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/PipelineRun/pvc.yaml</pre>
			<p>Now, we must create two TaskRuns. In the first, we will use the <strong class="source-inline">git-clone</strong> ClusterTask to clone the GitHub repository and store it in the workspace that uses a PersistentVolume. In the second, we will use the custom task that we created previously, which deploys the application by applying some manifests (the <strong class="source-inline">apply-manifests</strong> task).</p>
			<p>The following code shows the structure of a TaskRun:</p>
			<pre class="source-code">apiVersion: tekton.dev/v1beta1 
kind: TaskRun 
metadata: 
  name: git-clone <strong class="bold">#[1]</strong>
spec: 
  taskRef: 
    name: git-clone <strong class="bold">#[2]</strong>
    kind: ClusterTask <strong class="bold">#[3]</strong>
  params: <strong class="bold">#[4]</strong>
  - name: url 
    value: "https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook"
  - name: subdirectory 
    value: "" 
  - name: deleteExisting 
    value: "true" 
  - name: revision 
    value: "main" 
  workspaces: <strong class="bold">#[5]</strong>
  - name: output 
    persistentVolumeClaim: 
      claimName: source-pvc  </pre>
			<p>Let’s look<a id="_idIndexMarker638"/> at this code <a id="_idIndexMarker639"/>in more detail:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: The name of the <strong class="source-inline">TaskRun</strong> object</li>
				<li><strong class="bold">[2]</strong>: The name of the task that will be run</li>
				<li><strong class="bold">[3]</strong>: This is required for <strong class="source-inline">ClusterTask</strong> but can be omitted for regular tasks</li>
				<li><strong class="bold">[4]</strong>: Parameter values to be used during the task’s execution</li>
				<li><strong class="bold">[5]</strong>: Workspaces to be used</li>
			</ul>
			<p>Run the following command to apply the <strong class="source-inline">TaskRun</strong> object:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Tasks/git-clone-taskrun.yaml</pre>
			<p>Once you have created the <strong class="source-inline">git-clone</strong> object, you can look at the logs using the following <strong class="source-inline">tkn</strong> command:</p>
			<pre class="source-code">$ tkn taskrun logs git-clone -f
[clone] + '[' false = true ']'
[clone] + '[' false = true ']'
[clone] + CHECKOUT_DIR=/workspace/output/
[clone] + '[' true = true ']'
[clone] + cleandir
[clone] + '[' -d /workspace/output/ ']'
(.. ommited ..)</pre>
			<p>Finally, run <strong class="source-inline">apply-manifests</strong> using<a id="_idIndexMarker640"/> the following<a id="_idIndexMarker641"/> TaskRun:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Tasks/apply-manifests-taskrun.yaml</pre>
			<p>Check the logs, as follows:</p>
			<pre class="source-code">$ tkn taskrun logs run-apply-manifests -f
[apply] Applying manifests in ./sample-go-app/articles-api/k8s directory
[apply] deployment.apps/clouds-api created
[apply] service/clouds-api created
[apply] route/clouds-api created</pre>
			<p>With that, you have learned how to run a particular task using a <strong class="source-inline">TaskRun</strong> object. You also know how to reuse and create a custom task. We will use this knowledge to create our first pipeline.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor192"/>Pipelines</h2>
			<p>In this section, we will create<a id="_idIndexMarker642"/> our first meaningful pipeline! I like to compare a pipeline’s design to a LEGO® set, in which you need to have all the pieces at hand before assembling it. If the LEGO set is too big to assemble at once, you need to break it into smaller blocks of meaningful parts. In our pipeline, the <em class="italic">LEGO pieces</em> are the <strong class="bold">tasks</strong> that we have already built and the ones we will reuse. We have all we need, so <em class="italic">let’s assemble our LEGO set</em>.</p>
			<p>We will use our example to understand<a id="_idIndexMarker643"/> how to define a pipeline object. The first part of any pipeline is its metadata:</p>
			<pre class="source-code">apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: build-and-deploy</pre>
			<p>The next part is its specification (<strong class="source-inline">spec</strong>), which is composed of the following items:</p>
			<ul>
				<li><strong class="bold">Workspaces</strong>: This is a shared workspace <a id="_idIndexMarker644"/>that’s required to store the source code and any other pipeline artifacts that need to be passed between the tasks:<p class="source-code">spec:</p><p class="source-code">  workspaces:</p><p class="source-code">  - name: shared-workspace</p></li>
				<li><strong class="bold">Parameters</strong>: These are the input parameters<a id="_idIndexMarker645"/> that are required to run the pipeline:<p class="source-code">  params:</p><p class="source-code">  - name: deployment-name</p><p class="source-code">    type: string</p><p class="source-code">    description: name of the deployment to be patched</p><p class="source-code">  - name: git-url</p><p class="source-code">    type: string</p><p class="source-code">    description: url of the git repo for the code of deployment</p><p class="source-code">  - name: git-revision</p><p class="source-code">    type: string</p><p class="source-code">    description: revision to be used from repo of the code for deployment</p><p class="source-code">    default: "master"</p><p class="source-code">  - name: IMAGE</p><p class="source-code">    type: string</p><p class="source-code">    description: image to be built from the code</p></li>
				<li><strong class="bold">Tasks</strong>: These are the tasks to be run. Each task<a id="_idIndexMarker646"/> must have a valid name<a id="_idIndexMarker647"/> and a <strong class="source-inline">taskRef</strong> (the reference to the task that will be used), as follows:<p class="source-code">- name: apply-manifests</p><p class="source-code">  taskRef:</p><p class="source-code">    name: apply-manifests</p><p class="source-code">  workspaces:</p><p class="source-code">  - name: source</p><p class="source-code">    workspace: shared-workspace</p><p class="source-code">  runAfter:</p><p class="source-code">  - build-image</p></li>
				<li>For <strong class="bold">ClusterTasks</strong>, you need to explicitly<a id="_idIndexMarker648"/> set the <strong class="source-inline">kind</strong> attribute within the <strong class="source-inline">taskRef</strong> group, like so:<p class="source-code">- name: fetch-repository</p><p class="source-code">  taskRef:</p><p class="source-code">    name: git-clone</p><p class="source-code">    kind: ClusterTask</p><p class="source-code">  workspaces:</p><p class="source-code">  - name: output</p><p class="source-code">    workspace: shared-workspace</p><p class="source-code">  params:</p><p class="source-code">  - name: url</p><p class="source-code">    value: $(params.git-url)</p><p class="source-code">  - name: subdirectory</p><p class="source-code">    value: ""</p><p class="source-code">  - name: deleteExisting</p><p class="source-code">    value: "true"</p><p class="source-code">  - name: revision</p><p class="source-code">    value: $(params.git-revision)</p></li>
			</ul>
			<p>You can find the complete pipeline at <a href="https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter06">https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter06</a>.</p>
			<p>Now, we are ready to create our pipeline. To do so, run the following command:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Pipeline/build-deploy.yaml
$ tkn pipelines ls
NAME               AGE            LAST RUN   STARTED   DURATION   STATUS
build-and-deploy   1 minute ago   ---        ---   </pre>
			<p>Now that we have defined<a id="_idIndexMarker649"/> our pipeline, let’s run it! </p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor193"/>PipelineRun</h2>
			<p>There are multiple ways<a id="_idIndexMarker650"/> to run the pipeline: through the OpenShift Console UI, using <strong class="source-inline">tkn</strong>, or by creating and applying a PipelineRun object manually. At the end of the day, no matter how you run it, a PipelineRun will always be created (the only difference is that the PipelineRun is created automatically for you when you use <strong class="source-inline">tkn</strong> or the web UI). For didactic reasons, we will do this using a <strong class="source-inline">PipelineRun</strong> object to learn about and understand it.</p>
			<p>The following code shows our <strong class="source-inline">PipelineRun</strong> object:</p>
			<pre class="source-code">apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: build-deploy-api-pipelinerun <strong class="bold">#[1]</strong>
spec:
  pipelineRef:
    name: build-and-deploy <strong class="bold">#[2]</strong>
  params: <strong class="bold">#[3]</strong>
  - name: deployment-name
    value: clouds-api
  - name: git-url
    value: https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook.git
  - name: IMAGE
    value:  image-registry.openshift-image-registry.svc:5000/pipelines-sample/clouds-api
  workspaces: <strong class="bold">#[4]</strong>
  - name: shared-workspace
    volumeClaimTemplate:
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 500Mi</pre>
			<p>Let’s look at this code<a id="_idIndexMarker651"/> in more detail:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: The name of the <strong class="source-inline">PipelineRun</strong> object</li>
				<li><strong class="bold">[2]</strong>: The pipeline to be run</li>
				<li><strong class="bold">[3]</strong>: The parameter values to be used with the pipeline</li>
				<li><strong class="bold">[4]</strong>: The workspace’s definition</li>
			</ul>
			<p>Apply the <strong class="source-inline">PipelineRun</strong> object and check the logs to see the pipeline’s execution:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/PipelineRun/clouds-api-build-deploy.yaml
$ tkn pipelinerun logs build-deploy-api-pipelinerun -f
[fetch-repository : clone] + '[' false = true ']'
[fetch-repository : clone] + '[' false = true ']'
[fetch-repository : clone] + CHECKOUT_DIR=/workspace/output/
(.. omitted ..)
[check-app-health : apply] Waiting for application articles-api to be ready.
[check-app-health : apply] Checking if application is available at the route endpoint
[check-app-health : apply] Application is available at http://articles-api-pipelines-sample.apps.cluster-gf.gf.sandbox1171.opentlc.com/cloud
[check-app-health : apply] ----------------------------------</pre>
			<p>With that, you have custom<a id="_idIndexMarker652"/> tasks and a pipeline that has been tested and is working already. Now, let’s make it even better by using a trigger to run this pipeline automatically when a Git push occurs in the repository.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor194"/>Using triggers with GitHub webhooks</h1>
			<p>In a CI/CD workflow, it is typical to use<a id="_idIndexMarker653"/> an event, such as a pull or push<a id="_idIndexMarker654"/> request on Git, to trigger a new<a id="_idIndexMarker655"/> pipeline run. With Tekton, you use <strong class="bold">EventListeners</strong> to listen for events and run one or more triggers. There<a id="_idIndexMarker656"/> are some out-of-the-box event processors, named <strong class="bold">Interceptors</strong>, for the following platforms:</p>
			<ul>
				<li><strong class="bold">GitHub</strong>: This allows you to validate<a id="_idIndexMarker657"/> and filter GitHub webhooks.</li>
				<li><strong class="bold">GitLab</strong>: The same as the previous<a id="_idIndexMarker658"/> point but for GitLab.</li>
				<li><strong class="bold">Bitbucket</strong>: The same as the previous<a id="_idIndexMarker659"/> points for Bitbucket.</li>
				<li><strong class="bold">CEL</strong>: This allows you to use <strong class="bold">Common Expression Language</strong> (<strong class="bold">CEL</strong>) to filter and modify<a id="_idIndexMarker660"/> payloads.</li>
				<li><strong class="bold">Webhook</strong>: This allows you to process any webhook<a id="_idIndexMarker661"/> payload and apply any business logic to it.</li>
			</ul>
			<p>In our example, we will use a GitHub interceptor to process a webhook, filter push events, and trigger the pipeline we created previously. You can also implement your custom interceptors by implementing an object named <strong class="source-inline">ClusterInterceptors</strong>. Check out the links in the <em class="italic">Further reading</em> section if you need to create a ClusterInterceptor or use any interceptor other than the GitHub one that we will use in our example. </p>
			<p>Note that the GitHub<a id="_idIndexMarker662"/> webhook requires a publicly accessible URL<a id="_idIndexMarker663"/> to send the HTTP webhook posts. Due to that, you will need an OpenShift cluster with a public IP and domain that can be accessed from the internet. That said, in this case, you will not be able to use CRC to test Tekton triggers using GitHub webhooks unless you make your CRC URL routes public on the internet.</p>
			<p class="callout-heading">What is CEL?</p>
			<p class="callout">CEL<a id="_idIndexMarker664"/> is a simple but fast and portable language for expression evaluation. Created and maintained by some Google engineers, it is an open source project that was released under the Apache License and used with many Google projects and services. For more<a id="_idIndexMarker665"/> information, go to <a href="https://opensource.google/projects/cel">https://opensource.google/projects/cel</a>.</p>
			<p>Besides the <strong class="bold">EventListener</strong>, a Tekton trigger is composed of several other objects:</p>
			<ul>
				<li><strong class="bold">Trigger</strong>: This defines which action<a id="_idIndexMarker666"/> will be performed after the EventListener detects a new event.</li>
				<li><strong class="bold">TriggerTemplate</strong>: This specifies a blueprint of objects<a id="_idIndexMarker667"/> that will be applied as a result of the trigger, usually using a PipelineRun object, which, in turn, will run a pipeline.</li>
				<li><strong class="bold">TriggerBinding</strong>: This defines the field data<a id="_idIndexMarker668"/> that will be extracted from the event payload to be used with the associated PipelineRun.</li>
				<li><strong class="bold">ClusterTriggerBinding</strong>: This is the same as the TriggerBinding<a id="_idIndexMarker669"/> but cluster-scoped. It can be reused among different namespaces.</li>
			</ul>
			<p>The following objects will be used in our example:</p>
			<div>
				<div id="_idContainer149" class="IMG---Figure">
					<img src="image/B18015_09_11.jpg" alt="Figure 9.11 – Tekton Trigger objects "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – Tekton Trigger objects</p>
			<p>Now, let’s put this into practice! You<a id="_idIndexMarker670"/> have already created the tasks and pipeline<a id="_idIndexMarker671"/> in your lab, so let’s create the trigger objects that will use the existing pipeline.</p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor195"/>TriggerBinding</h2>
			<p><strong class="bold">TriggerBinding</strong> will parse the data<a id="_idIndexMarker672"/> that’s been extracted from the GitHub payload, as follows:</p>
			<pre class="source-code">apiVersion: triggers.tekton.dev/v1beta1
kind: TriggerBinding
metadata:
  name: clouds-api-tb <strong class="bold">#[1]</strong>
spec:
  params: <strong class="bold">#[2]</strong>
  - name: git-repo-url
    value: $(body.repository.url)
  - name: git-repo-name
    value: $(body.repository.name)
  - name: git-revision
    value: $(body.head_commit.id)</pre>
			<p>Let’s look at this code in more detail:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: The name of the <strong class="source-inline">TriggerBinding</strong> object</li>
				<li><strong class="bold">[2]</strong>: The parameters that will be assigned according to the payload data fields</li>
			</ul>
			<p>Use the following command to create the TriggerBinding:</p>
			<pre class="source-code">$ oc apply -f https://raw.githubusercontent.com/</pre>
			<p>The next object we<a id="_idIndexMarker673"/> need to create is <strong class="source-inline">TriggerTemplate</strong>. Let’s take a look.</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor196"/>TriggerTemplate</h2>
			<p><strong class="source-inline">TriggerTemplate</strong> will create a PipelineRun that executes<a id="_idIndexMarker674"/> our sample pipeline:</p>
			<pre class="source-code">apiVersion: triggers.tekton.dev/v1beta1
kind: TriggerTemplate
metadata:
  name: clouds-api-tt <strong class="bold">#[1]</strong>
spec: 
  params: <strong class="bold">#[2]</strong>
  - name: git-repo-url
    description: The git repository url
  - name: git-revision
    description: The git revision
    default: master
  - name: git-repo-name
    description: The name of the deployment to be created / patched
  resourcetemplates: <strong class="bold">#[3]</strong>
  - apiVersion: tekton.dev/v1beta1
    kind: PipelineRun
    metadata:
      generateName: build-deploy-
    spec:
      serviceAccountName: pipeline
      pipelineRef:
        name: build-and-deploy
      params:
      - name: deployment-name
        value: clouds-api
      - name: git-url
        value: $(tt.params.git-repo-url)
      - name: git-revision
        value: $(tt.params.git-revision)
      - name: IMAGE
        value: image-registry.openshift-image-registry.svc:5000/pipelines-sample/clouds-api
      workspaces:
      - name: shared-workspace
        volumeClaimTemplate:
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 500Mi</pre>
			<p>Let’s look at this code in more detail:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: The name of the <strong class="source-inline">TriggerTemplate</strong> object</li>
				<li><strong class="bold">[2]</strong>: The input parameters that are populated by the <strong class="source-inline">TriggerBinding</strong> object</li>
				<li><strong class="bold">[3]</strong>: The objects that will be created as a result of the trigger</li>
			</ul>
			<p>Use the following command <a id="_idIndexMarker675"/>to create the <strong class="source-inline">TriggerTemplate</strong> object:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Trigger/clouds-api-tt.yaml</pre>
			<p>Finally, we can create the <strong class="source-inline">Trigger</strong> object, which uses all the objects we have created.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor197"/>Trigger</h2>
			<p>The <strong class="source-inline">Trigger</strong> object will be the glue between<a id="_idIndexMarker676"/> the GitHub interceptor, <strong class="source-inline">TriggerBinding</strong>, and <strong class="source-inline">TriggerTemplate</strong>:</p>
			<pre class="source-code">apiVersion: triggers.tekton.dev/v1beta1
kind: Trigger
metadata:
  name: clouds-api-trigger <strong class="bold">#[1]</strong>
spec:
  serviceAccountName: pipeline
  interceptors: <strong class="bold">#[2]</strong>
    - ref:
        name: "github" <strong class="bold">#[3]</strong>
      params:
        - name: "secretRef" <strong class="bold">#[4]</strong>
          value:
            secretName: github-secret
            secretKey: secretToken
        - name: "eventTypes"
          value: ["push"] <strong class="bold">#[5]</strong>
  bindings:
    - ref: clouds-api-tb <strong class="bold">#[6]</strong>
  template:
    ref: clouds-api-tt <strong class="bold">#[7]</strong></pre>
			<p>Let’s look at this code in more detail:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: The name of the <strong class="source-inline">Trigger</strong> object.</li>
				<li><strong class="bold">[2]</strong>: The list of event interceptors to be used to trigger the actions.</li>
				<li><strong class="bold">[3]</strong>: The interceptor from GitHub.</li>
				<li><strong class="bold">[4]</strong>: The secret that’s been configured in the GitHub webhook.</li>
				<li><strong class="bold">[5]</strong>: The trigger event types that Tekton will react to. In this case, it will be GitHub “push” events.</li>
				<li><strong class="bold">[6]</strong>: The <strong class="source-inline">TriggerBinding</strong> object that will be used with this trigger.</li>
				<li><strong class="bold">[7]</strong>: The <strong class="source-inline">TriggerTemplate</strong> object that will be used with this trigger.</li>
			</ul>
			<p>The following code shows<a id="_idIndexMarker677"/> an example of the GitHub secret (<strong class="bold">[4]</strong>):</p>
			<pre class="source-code">apiVersion: v1
kind: Secret
metadata:
  name: github-secret
type: Opaque
stringData:
  secretToken: "tekton"</pre>
			<p>Use the following command to create the secret and trigger:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Trigger/clouds-api-trigger.yaml</pre>
			<p>The last object we need to create to put the trigger into practice is <strong class="source-inline">EventListener</strong>. Let’s take a look.</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor198"/>EventListener</h2>
			<p>Finally, we need to create an <strong class="bold">EventListener</strong> object that will listen<a id="_idIndexMarker678"/> for HTTP requests and be used with the GitHub webhook configuration. We will learn how to configure the GitHub webhook soon:</p>
			<pre class="source-code">apiVersion: triggers.tekton.dev/v1beta1
kind: EventListener
metadata:
  name: clouds-api-el <strong class="bold">#[1]</strong>
spec:
  serviceAccountName: pipeline
  triggers:
    - triggerRef: vote-trigger <strong class="bold">#[2]</strong></pre>
			<p>Let’s look at this code in more detail:</p>
			<ul>
				<li><strong class="bold">[1]</strong>: The name of the <strong class="source-inline">EventListener</strong> object</li>
				<li><strong class="bold">[2]</strong>: The trigger that will be invoked when the <strong class="source-inline">EventListener</strong> object is sensitized</li>
			</ul>
			<p>Run the following command<a id="_idIndexMarker679"/> to create the <strong class="source-inline">EventListener</strong> object:</p>
			<pre class="source-code">$ oc apply -f https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter09/Trigger/clouds-api-el.yaml</pre>
			<p><strong class="source-inline">EventListener</strong> will create a service on OpenShift that you need to expose externally. The route URL that’s generated will be used during the GitHub webhook configuration:</p>
			<pre class="source-code">$ oc expose svc el-clouds-api-el</pre>
			<p>Now, we are ready to configure a new GitHub webhook that will use the <strong class="source-inline">EventListener</strong> object we just created to fire Tekton’s trigger.</p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor199"/>Creating a GitHub webhook</h2>
			<p>To create a webhook, you need<a id="_idIndexMarker680"/> to fork our GitHub repository. If you haven’t forked it yet, do so now in your personal GitHub account: <a href="https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook">https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook</a>.</p>
			<p>Open the GitHub forked repository and go to <strong class="bold">Settings</strong> | <strong class="bold">Webhook</strong>. On the following page, click on the <strong class="bold">Add webhook</strong> button:</p>
			<div>
				<div id="_idContainer150" class="IMG---Figure">
					<img src="image/B18015_09_12.jpg" alt="Figure 9.12 – Adding a webhook on GitHub "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – Adding a webhook on GitHub</p>
			<p>Fill out the form by providing<a id="_idIndexMarker681"/> the following information:</p>
			<ul>
				<li><strong class="bold">Payload URL</strong>: The route URL we created in the previous section. You can get this URL by running the following command:<p class="source-code">$ echo "$(oc  get route el-clouds-api-el --template='http://{{.spec.host}}')"</p></li>
				<li><strong class="bold">Content type</strong>: <strong class="source-inline">application/json</strong>.</li>
				<li><strong class="bold">Secret</strong>: The same value you used with the Tekton trigger’s secret (in our case, this is <strong class="source-inline">tekton</strong>):</li>
			</ul>
			<div>
				<div id="_idContainer151" class="IMG---Figure">
					<img src="image/B18015_09_13.jpg" alt="Figure 9.13 – Adding a webhook on GitHub "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.13 – Adding a webhook on GitHub</p>
			<p>After a few seconds, you should<a id="_idIndexMarker682"/> see a green check mark next to the webhook we created:</p>
			<div>
				<div id="_idContainer152" class="IMG---Figure">
					<img src="image/B18015_09_14.jpg" alt="Figure 9.14 – Webhook added "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.14 – Webhook added</p>
			<p>Now that we have our <strong class="source-inline">Trigger</strong> objects from the Tekton side and the webhook configured on GitHub, let’s test it!</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor200"/>Testing the Tekton trigger</h2>
			<p>Run a <strong class="source-inline">commit</strong> and push<a id="_idIndexMarker683"/> the trigger to the webhook event, like so: </p>
			<pre class="source-code">$ git commit -m "empty-commit" --allow-empty &amp;&amp; git push origin main</pre>
			<p>Access the <strong class="bold">Pipelines</strong> menu. You should <a id="_idIndexMarker684"/>see a new <strong class="bold">PipelineRun</strong> start after the Git <strong class="source-inline">push</strong> command has been run:</p>
			<div>
				<div id="_idContainer153" class="IMG---Figure">
					<img src="image/B18015_09_15.jpg" alt="Figure 9.15 – PipelineRun on Red Hat "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.15 – PipelineRun on Red Hat</p>
			<p>Congratulations – you have successfully created a CI/CD pipeline on Tekton and ran it automatically after a Git push event using a trigger! To wrap up this chapter, we will enhance our pipeline by adding a validation task for YAML files using the YAML linter tool.</p>
			<p>To do so, let’s use Tekton Hub <a id="_idIndexMarker685"/>to find a reusable task. Go to <a href="https://hub.tekton.dev/">https://hub.tekton.dev/</a> and search for YAML using the search box at the top right of the screen:</p>
			<div>
				<div id="_idContainer154" class="IMG---Figure">
					<img src="image/B18015_09_16.jpg" alt="Figure 9.16 – Tekton Hub "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.16 – Tekton Hub</p>
			<p>Click the <strong class="bold">YAML linter</strong> task to find<a id="_idIndexMarker686"/> the instructions on how to install and use it:</p>
			<div>
				<div id="_idContainer155" class="IMG---Figure">
					<img src="image/B18015_09_17.jpg" alt="Figure 9.17 – YAML linter "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.17 – YAML linter</p>
			<p>This time, we will use the <strong class="bold">Pipeline Builder</strong> page to add the YAML linter task. To do so, access the OpenShift UI and select the <strong class="bold">Developer</strong> console:</p>
			<div>
				<div id="_idContainer156" class="IMG---Figure">
					<img src="image/B18015_09_18.jpg" alt="Figure 9.18 – Developer console "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.18 – Developer console</p>
			<p>Now, perform<a id="_idIndexMarker687"/> the following steps:</p>
			<ol>
				<li value="1">Access the <strong class="bold">Pipelines</strong> menu and click on the <strong class="source-inline">build-and-deploy</strong> pipeline:</li>
			</ol>
			<div>
				<div id="_idContainer157" class="IMG---Figure">
					<img src="image/B18015_09_19.jpg" alt="Figure 9.19 – The Pipelines menu "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.19 – The Pipelines menu</p>
			<ol>
				<li value="2">Now, click the <strong class="bold">Actions</strong> button and then <strong class="bold">Edit Pipeline</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer158" class="IMG---Figure">
					<img src="image/B18015_09_20.jpg" alt="Figure 9.20 – The build-and-deploy pipeline "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.20 – The build-and-deploy pipeline</p>
			<ol>
				<li value="3">On the following screen, click on the <strong class="bold">fetch-repository</strong> box and then the <strong class="bold">+</strong> sign next to it:</li>
			</ol>
			<div>
				<div id="_idContainer159" class="IMG---Figure">
					<img src="image/B18015_09_21.jpg" alt="Figure 9.21 – The Pipeline builder feature "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.21 – The Pipeline builder feature</p>
			<ol>
				<li value="4">Select the <strong class="bold">Add task</strong> box, type <strong class="source-inline">yaml lint</strong>, and click<a id="_idIndexMarker688"/> the <strong class="bold">Install and add</strong> button:</li>
			</ol>
			<div>
				<div id="_idContainer160" class="IMG---Figure">
					<img src="image/B18015_09_22.jpg" alt="Figure 9.22 – Adding a new task using the Pipeline builder feature "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.22 – Adding a new task using the Pipeline builder feature</p>
			<ol>
				<li value="5">The new task should have been added. You should see an exclamation mark next to it:</li>
			</ol>
			<div>
				<div id="_idContainer161" class="IMG---Figure">
					<img src="image/B18015_09_23.jpg" alt="Figure 9.23 – Adding a new task using the Pipeline builder feature "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.23 – Adding a new task using the Pipeline builder feature</p>
			<ol>
				<li value="6">Now, click<a id="_idIndexMarker689"/> it and input <strong class="source-inline">./sample-go-app/clouds-api/k8s</strong> as the <strong class="bold">args</strong> parameter and <strong class="source-inline">shared-workspace</strong> as the <strong class="bold">Workspaces</strong> group:</li>
			</ol>
			<div>
				<div id="_idContainer162" class="IMG---Figure">
					<img src="image/B18015_09_24.jpg" alt="Figure 9.24 – Setting the yaml-lint task’s parameters "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.24 – Setting the yaml-lint task’s parameters</p>
			<ol>
				<li value="7">Now, click on <strong class="bold">Save</strong>.</li>
				<li>At this point, our pipeline has a new step that validates the YAML content of our Kubernetes manifest <a id="_idIndexMarker690"/>files. To test our previous change, let’s run it from the same web UI. To do so, click the <strong class="bold">Actions</strong> menu from the <strong class="bold">Pipeline details</strong> screen and select the <strong class="bold">Start</strong> action:</li>
			</ol>
			<div>
				<div id="_idContainer163" class="IMG---Figure">
					<img src="image/B18015_09_25.jpg" alt="Figure 9.25 – Running the pipeline from the Developer console "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.25 – Running the pipeline from the Developer console</p>
			<ol>
				<li value="9">Fill out the form by using the following values and click <strong class="bold">Start</strong>:<ul><li><strong class="bold">deployment-name</strong>: <strong class="source-inline">clouds-api</strong></li>
<li><strong class="bold">git-url</strong>: &lt;Your forked repository&gt;</li>
<li><strong class="bold">git-revision</strong>: <strong class="source-inline">main</strong></li>
<li><strong class="bold">IMAGE</strong>: <strong class="source-inline">image-registry.openshift-image-registry.svc:5000/pipelines-sample/clouds-api</strong></li>
<li><strong class="bold">CONTEXT</strong>: <strong class="source-inline">./sample-go-app/clouds-api/</strong></li>
<li><strong class="bold">shared-workspace</strong>: <strong class="source-inline">VolumeClaimTemplate</strong>:</li>
</ul></li>
			</ol>
			<div>
				<div id="_idContainer164" class="IMG---Figure">
					<img src="image/B18015_09_26.jpg" alt="Figure 9.26 – PipelineRun parameters "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.26 – PipelineRun parameters</p>
			<ol>
				<li value="10">Check the <strong class="source-inline">PipelineRun</strong> object on the following<a id="_idIndexMarker691"/> screen. You will get an error regarding the new <strong class="bold">yaml-lint</strong> task we added:</li>
			</ol>
			<div>
				<div id="_idContainer165" class="IMG---Figure">
					<img src="image/B18015_09_27.jpg" alt="Figure 9.27 – PipelineRun failed due to YAML linter validations "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.27 – PipelineRun failed due to YAML linter validations</p>
			<ol>
				<li value="11">Click the <strong class="bold">yaml-lint</strong> step and check<a id="_idIndexMarker692"/> out the logs to find the issue:</li>
			</ol>
			<div>
				<div id="_idContainer166" class="IMG---Figure">
					<img src="image/B18015_09_28.jpg" alt="Figure 9.28 – PipelineRun failed due to YAML linter validations "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.28 – PipelineRun failed due to YAML linter validations</p>
			<p>As you can see, the YAML linter<a id="_idIndexMarker693"/> detected errors in some YAML files. Those errors are expected and have been prepared especially for you to simulate what a real CI/CD pipeline looks like. Now, practice the skills you’ve just acquired to fix those errors and get the pipeline working again (or look at the solution in the next section)!</p>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor201"/>Fixing the failed PipelineRun due to YAML issues</h1>
			<p>To get your pipeline<a id="_idIndexMarker694"/> working again, follow these steps:</p>
			<ol>
				<li value="1">Add <strong class="source-inline">---</strong> to the first line of all the YAML files in the<strong class="source-inline">./sample-go-app/clouds-api/k8s</strong> folder.</li>
				<li>Fix the indentation of the <strong class="source-inline">kustomization.yaml</strong> file by adding two spaces at the beginning of all the lines after <strong class="source-inline">resources</strong>, like so:<p class="source-code">---</p><p class="source-code">resources:</p><p class="source-code">  - deployment.yaml #add two spaces at the begging of the line</p><p class="source-code">  - service.yaml #add two spaces at the begging of the line</p><p class="source-code">  - route.yaml #add two spaces at the begging of the line</p></li>
				<li>Add a new line at the end of the <strong class="source-inline">service.yaml</strong> file.</li>
				<li>Commit and push the changes:<p class="source-code">$ git add *</p><p class="source-code">$ git commit -m "fixed yaml files"</p><p class="source-code">$ git push</p></li>
			</ol>
			<p>A new PipelineRun should be triggered automatically and complete.</p>
			<h1 id="_idParaDest-194"><a id="_idTextAnchor202"/>Summary</h1>
			<p>In this chapter, we dived into Tekton, from installing it on OpenShift to using it. You learned how to create custom tasks, reuse existing ones, build a pipeline, and then run it. You also learned how to set a trigger to run the pipeline when a push event occurs in your GitHub repository. The objects you have seen in this chapter are the main ones you will use to create most Tekton pipelines. </p>
			<p>In the next chapter, we will bring more power to your CI/CD process by adding <strong class="bold">Argo CD</strong> and <strong class="bold">GitOps</strong> to your pipelines. We will also start looking at ways to deploy applications into multiple clusters at once. Let’s get started and take a deeper dive into OpenShift GitOps!</p>
			<h1 id="_idParaDest-195"><a id="_idTextAnchor203"/>Further reading</h1>
			<p>If you want to learn more about what we covered in this chapter, check out the following references:</p>
			<ul>
				<li><em class="italic">OpenShift Pipelines official documentation:</em> <a href="https://docs.openshift.com/container-platform/4.9/cicd/pipelines/understanding-openshift-pipelines.html">https://docs.openshift.com/container-platform/4.9/cicd/pipelines/understanding-openshift-pipelines.html</a> </li>
				<li><em class="italic">Tekton official documentation:</em> <a href="https://tekton.dev/docs/">https://tekton.dev/docs/</a></li>
				<li><em class="italic">How to create custom interceptors using</em> <strong class="bold">ClusterInterceptor</strong>: <a href="https://tekton.dev/docs/triggers/clusterinterceptors/">https://tekton.dev/docs/triggers/clusterinterceptors/</a></li>
				<li><em class="italic">Tekton Hub (a collection of reusable tasks):</em> <a href="https://hub.tekton.dev/">https://hub.tekton.dev/</a> </li>
			</ul>
		</div>
		<div>
			<div id="_idContainer168">
			</div>
		</div>
</body></html>