- en: Virtual Network Infrastructure Using Linux Bridges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the core functions of OpenStack Networking is to provide end-to-end network
    connectivity to instances running in the cloud. In *[chapter 3](bf508e37-ce8a-4116-89db-e8f8a6abf0f4.xhtml) Installing
    Neutron*, we installed the Neutron API service and the ML2 plugin across all nodes
    in the cloud. Beginning with this chapter, you will be introduced to networking
    concepts and architectures that Neutron relies on to provide connectivity to instances
    and other virtual devices.
  prefs: []
  type: TYPE_NORMAL
- en: The ML2 plugin for Neutron allows an OpenStack cloud to leverage multiple Layer
    2 technologies simultaneously through the use of Mechanism drivers. In the next
    few chapters, we will look at multiple Mechanism drivers that extend the functionality
    of the ML2 network plugin, including the Linux bridge and Open vSwitch drivers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Discover how Linux bridges are used to build a virtual network infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualize traffic flow through virtual bridges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy the Linux bridge Mechanism driver and agent on hosts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Linux bridge driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Linux bridge Mechanism driver supports a range of traditional and overlay
    networking technologies, and has support for the following types of drivers:'
  prefs: []
  type: TYPE_NORMAL
- en: Local
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VLAN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VXLAN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a host is configured to use the ML2 plugin and the Linux bridge Mechanism
    driver, the Neutron agent on the host relies on the `bridge`, `8021q`, and `vxlan`
    kernel modules to properly connect instances and other network resources to virtual
    switches. These connections allow instances to communicate with other network
    resources in and out of the cloud. The Linux bridge Mechanism driver is popular
    for its dependability and ease of troubleshooting but lacks support for some advanced
    Neutron features such as distributed virtual routers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a Linux bridge-based network implementation, there are five types of interfaces
    managed by OpenStack Networking:'
  prefs: []
  type: TYPE_NORMAL
- en: Tap interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Physical interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VLAN interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VXLAN interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux bridges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **tap interface** is created and used by a hypervisor such as QEMU/KVM to
    connect the guest operating system in a virtual machine instance to the underlying
    host. These virtual interfaces on the host correspond to a network interface inside
    the guest instance. An Ethernet frame sent to the tap device on the host is received
    by the guest operating system, and frames received from the guest operating system
    are injected into the host network stack.
  prefs: []
  type: TYPE_NORMAL
- en: A **physical interface** represents an interface on the host that is plugged
    into physical network hardware. Physical interfaces are often labeled `eth0`,
    `eth1`, `em0`, `em1`, and so on, and may vary depending on the host operating
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Linux supports 802.1q VLAN tagging through the use of virtual VLAN interfaces.
    A VLAN interface can be created using `iproute2` commands or the traditional `vlan`
    utility and `8021q` kernel module. A VLAN interface is often labeled `ethX.<vlan>`
    and is associated with its respective physical interface, `ethX`.
  prefs: []
  type: TYPE_NORMAL
- en: A **VXLAN interface** is a virtual interface that is used to encapsulate and
    forward traffic based on parameters configured during interface creation, including
    a VXLAN Network Identifier (**VNI**) and VXLAN Tunnel End Point (VTEP). The function
    of a VTEP is to encapsulate virtual machine instance traffic within an IP header
    across an IP network. Traffic on the same VTEP is segregated from other VXLAN
    traffic using an ID provided by the VNI. The instances themselves are unaware
    of the outer network topology providing connectivity between VTEPs.
  prefs: []
  type: TYPE_NORMAL
- en: A **Linux bridge** is a virtual interface that connects multiple network interfaces.
    In Neutron, a bridge will usually include a physical interface and one or more
    virtual or tap interfaces. Linux bridges are a form of virtual switches.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing traffic flow through Linux bridges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For an Ethernet frame to travel from a virtual machine instance to a device
    on the physical network, it will pass through three or four devices inside the
    host:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Network type** | **Interface type** | **Interface name** |'
  prefs: []
  type: TYPE_TB
- en: '| all | tap | tapN |'
  prefs: []
  type: TYPE_TB
- en: '| all | bridge | brqXXXX |'
  prefs: []
  type: TYPE_TB
- en: '| vxlan | vxlan | vxlan-z (where Z is the VNI) |'
  prefs: []
  type: TYPE_TB
- en: '| vlan | vlan | ethX.Y (where X is the physical interface and Y is the VLAN
    ID) |'
  prefs: []
  type: TYPE_TB
- en: '| flat, vlan | physical | ethX (where X is the interface) |'
  prefs: []
  type: TYPE_TB
- en: To help conceptualize how Neutron uses Linux bridges, a few examples of Linux
    bridge architectures are provided in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: VLAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine an OpenStack cloud that consists of a single `vlan` provider network
    with the segmentation ID 100\. Three instances have been connected to the network.
    As a result, the network architecture within the `compute` node resembles the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4294799-da56-4b93-b330-8f31b59981b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1
  prefs: []
  type: TYPE_NORMAL
- en: In Figure 4.1, three virtual machine instances are connected to a Linux bridge
    named `brqXXXX` via their respective tap interfaces. When the first instance was
    launched and connected to the network, Neutron created the bridge and a virtual
    interface named `eth1.100` and automatically connected the interface to the bridge.
    The `eth1.100` interface is bound to physical interface `eth1`. As traffic from
    instances traverses the Linux bridge and out toward the physical interface, interface `eth1.100`
    tags that traffic as VLAN 100 and drops it on `eth1`. Likewise, ingress traffic
    toward the instances through `eth1` is inversely untagged by `eth1.100` and sent
    to the appropriate instance connected to the bridge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `brctl show` command, the preceding diagram can be realized in the
    Linux CLI as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cdf7dc29-1527-4be3-bfec-e0c576e3fca3.png)'
  prefs: []
  type: TYPE_IMG
- en: The `bridge id` in the output is dynamically generated based on the parent NIC
    of the virtual VLAN interface. In this bridge, the parent interface is `eth1`.
  prefs: []
  type: TYPE_NORMAL
- en: The `bridge name`, beginning with the `brq` prefix, is generated based on the
    ID of the corresponding Neutron network it is associated with. In a Linux bridge
    architecture, every network uses its own bridge. Bridge names should be consistent
    across nodes for the same network.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the physical switch, the necessary configuration to facilitate the networking
    described here will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When configured as a trunk port, the provider interface can support multiple
    VLAN networks. If more than one VLAN network is needed, another Linux bridge will
    be created automatically that contains a separate VLAN interface. The new virtual
    interface, `eth1.101`, is connected to a new bridge, `brqYYYY`, as seen in Figure
    4.2:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c03d0af9-2f3a-4c25-bdfb-62cac609f165.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `compute` node, the preceding diagram can be realized as the following
    `brctl show` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a02f465-940d-4f04-8406-22804f535e5b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On the physical switch, the necessary configuration to facilitate the networking
    described here will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Flat
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A flat network in Neutron describes a network in which *no *VLAN tagging takes
    place. Unlike VLAN networks, flat networks require that the physical interface
    of the host associated with the network be connected directly to the bridge. This
    means that only a *single* flat network can exist per physical interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.3 demonstrates a physical interface connected directly to a Neutron-managed
    bridge in a flat network scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e02072f7-9d5f-423a-97d2-261a40d5d127.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3
  prefs: []
  type: TYPE_NORMAL
- en: In Figure 4.3, `eth1` is connected to the bridge named `brqZZZZ` along with
    three tap interfaces that correspond to guest instances. No VLAN tagging for instance
    traffic takes place in this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `compute` node, the preceding diagram can be realized as the following
    `brctl show` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d198e2a-b0cf-4de2-9052-00c8a3f5fd0b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On the physical switch, the necessary configuration to facilitate the networking
    described here will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, the interface can also be configured as an access port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Only one flat network is supported per provider interface. When configured as
    a trunk port with a native VLAN, the provider interface can support a single flat
    network and multiple VLAN networks. When configured as an access port, the interface
    can only support a single flat network and any attempt to tag traffic will fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'When multiple flat networks are created, a separate physical interface must
    be associated with each flat network. Figure 4.4 demonstrates the use of a second
    physical interface required for the second flat network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89500fd7-b3c8-4da1-b390-4931221d1a70.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `compute` node, the use of two physical interfaces for separate flat
    networks can be realized as the following `brctl show` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/131ff3f7-4c4e-4104-b482-82280715f3a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On the physical switch, the necessary configuration to facilitate the networking
    described here will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With the two flat networks, the host does not perform any VLAN tagging on traffic
    traversing those bridges. Instances connected to the two bridges require a router
    to communicate with one another. Given the requirement for unique interfaces per
    flat network, flat networks do not scale well and are not common in production
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: VXLAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When VXLAN networks are created, the Neutron Linux bridge agent creates a corresponding
    VXLAN interface using `iproute2` user-space utilities and connects it to a Linux
    bridge. The VXLAN interface is programmed with information such as the VNI and
    local VTEP address.
  prefs: []
  type: TYPE_NORMAL
- en: When the L2 population driver is configured, Neutron prepopulates the forwarding
    database with static entries consisting of the MAC addresses of instances and
    their respective host VTEP addresses. As a packet from an instance traverses the
    bridge, the host determines how to forward the packet by consulting the forwarding
    table. If an entry is found, Neutron will forward the packet out of the corresponding
    local interface and encapsulate the traffic accordingly. To view the forwarding
    database table on each host, use the `bridge fdb show` command.
  prefs: []
  type: TYPE_NORMAL
- en: Potential issues when using overlay networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One thing to be aware of when using overlay networking technologies is that
    the additional headers added to the encapsulated packets may cause them to exceed
    the **maximum transmission unit (MTU)** of the switchport or interface. The MTU
    is the largest size of packet or frame that can be sent over the network. Encapsulating
    a packet with VXLAN headers may cause the packet size to exceed the default maximum
    1500-byte MTU. Connection issues caused by exceeding the MTU manifest themselves
    in strange ways, including partial failures in connecting to instances over SSH
    or a failure to transfer large payloads between instances, and more. To avoid
    this, consider lowering the MTU of interfaces within virtual machine instances
    from 1500 bytes to 1450 bytes to account for the overhead of VXLAN encapsulation
    to avoid connectivity issues.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to dropping the MTU is to increase the MTU of the interfaces
    used for the VTEPs. It is common to set a jumbo MTU of 9000 on VTEP interfaces
    and corresponding switchports to avoid having to drop the MTU inside instances.
    Increasing the MTU of the VTEP interfaces has also been shown to provide increases
    in network throughput when using overlay networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The DHCP agent can be configured to push a non-standard MTU to instances within
    the DHCP lease offer by modifying DHCP option `26`. To configure a lower MTU,
    complete the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `controller` node, modify the DHCP configuration file at `/etc/neutron/dhcp_agent.ini`
    and specify a custom `dnsmasq` configuration file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create the custom `dnsmasq` configuration file at `/etc/neutron/dnsmasq-neutron.conf` and
    add the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Save and close the file. Restart the Neutron DHCP agent with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Inside an instance running Linux, the MTU can be observed within the instance
    using the `ip link show <interface>` command.
  prefs: []
  type: TYPE_NORMAL
- en: A change to the `dnsmasq` configuration affects all networks, even instances
    on VLAN networks. Neutron ports can be modified individually to avoid this effect.
  prefs: []
  type: TYPE_NORMAL
- en: Local
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When creating a local network in Neutron, it is not possible to specify a VLAN
    ID or even a physical interface. The Neutron Linux bridge agent will create a
    bridge and connect only the tap interface of the instance to the bridge. Instances
    in the same local network on the same node will be connected to the same bridge
    and are free to communicate with one another. Because the host does not have a
    physical or virtual VLAN interface connected to the bridge, traffic between instances
    is limited to the host on which the instances reside. Traffic between instances
    in the same local network that reside on different hosts will be unable to communicate
    with one another.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.5 demonstrates the lack of physical or virtual VLAN interfaces connected
    to the bridge:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/643d81ea-7e9f-49ec-9fe7-b631bba698fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5
  prefs: []
  type: TYPE_NORMAL
- en: In Figure 4.5, two local networks have been created along with their respective
    bridges, `brqZZZZ` and `brqNNNN`. Instances connected to the same bridge can communicate
    with one another, but nothing else outside of the bridge. There is no mechanism
    to permit traffic between instances on different bridges or hosts when using local
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: Some application architectures may require multiple instances be deployed on
    the same host without the need for cross-host communication. A local network might
    make sense in this scenario and can be used to avoid the consumption of precious
    VLAN IDs or VXLAN overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the ML2 networking plugin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you can build network resources in an OpenStack cloud, a network plugin
    must be defined and configured. The ML2 plugin provides a common framework that
    allows multiple drivers to interoperate with one another. In this section, we
    will look at how to configure the Linux bridge ML2 driver and agent on the `controller01`
    and `compute01` hosts.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Linux bridge and Open vSwitch drivers for simultaneous operation
    will be discussed in this book but may not be appropriate for a production environment.
    To make things simple, I recommend deploying the Linux bridge driver if distributed
    virtual routers are not required. The configuration and architecture of distributed
    virtual routers are outlined in *[Chapter 12](b441728b-4377-43cf-b675-166266fef6c9.xhtml),
    Distributed Virtual Routers*.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the bridge interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this installation, physical network interface `eth2` will be utilized as
    the **provider interface **for VLAN and flat networks. Neutron will be responsible
    for configuring VLAN interfaces off `eth2` once the initial network configuration
    has been completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `controller01` and `compute01` nodes, configure the `eth2` interface
    within the`/etc/network/interfaces` file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Close and save the file, and bring the interface up with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Confirm the interface is in an `UP` state using the `ip link show dev eth2` command.
    If the interface is up, it is ready for use in bridges that Neutron will create
    and manage.
  prefs: []
  type: TYPE_NORMAL
- en: Because the interface will be used in a bridge, an IP address cannot be applied
    directly to the interface. If there is an IP address applied to `eth2`, it will
    become inaccessible once the interface is placed in a bridge. If an IP is required,
    consider moving it to an interface not required for Neutron networking.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the overlay interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this installation, physical network interface `eth1` will be utilized as
    the **overlay interface **for overlay networks using VXLAN. Neutron will be responsible
    for configuring VXLAN interfaces once the initial network configuration has been
    completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `controller01` and `compute01` nodes, configure the `eth1` interface
    within the `/etc/network/interfaces` file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following table for the appropriate address, and substitute for `X`
    where appropriate:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Host** | **Address** |'
  prefs: []
  type: TYPE_TB
- en: '| `controller01` | 10.20.0.100 |'
  prefs: []
  type: TYPE_TB
- en: '| `compute01` | 10.20.0.101 |'
  prefs: []
  type: TYPE_TB
- en: 'Close and save the file, and bring the interface up with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Confirm the interface is in an `UP` state and that the address has been set
    using the `ip addr show dev eth1` command. Ensure both hosts can communicate over
    the newly configured interface by pinging `compute01` from the `controller01`
    node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8b325ed-0688-40b6-89ae-2ed75ac53034.png)'
  prefs: []
  type: TYPE_IMG
- en: If you experience any issues communicating across this interface, you *will*
    experience issues with VXLAN networks created with OpenStack Networking. Any issues
    should be corrected before continuing.
  prefs: []
  type: TYPE_NORMAL
- en: ML2 plugin configuration options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ML2 plugin was installed in the previous chapter and its configuration file
    located at `/etc/neutron/plugins/ml2/ml2_conf.ini` must be configured before OpenStack
    Networking services can be used.The ML2 plugin configuration file is referenced
    by the `neutron-server` service may be referenced by multiple agents, including
    Linux bridge and Open vSwitch agents. Agent-specific changes will be made in their
    respective configuration files on each host.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ml2_conf.ini` file is broken into configuration blocks and contains the
    following commonly used options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Configuration options must remain in the appropriate block, otherwise Neutron
    services may not start or operate properly.
  prefs: []
  type: TYPE_NORMAL
- en: Type drivers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Type drivers describe the type of networks that can be created and implemented
    by Mechanism drivers. Type drivers included with the ML2 plugin include `local`,
    `flat`, `vlan`, `gre`, `vxlan`, and `geneve`. Not all Mechanism drivers can implement
    all types of networks, however. The Linux bridge driver lacks support for GENEVE
    and GRE networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the ML2 configuration file on the controller01 node and add the following `type_drivers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Mechanism drivers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mechanism drivers are responsible for implementing networks described by the
    type driver. Mechanism drivers included with the ML2 plugin include `linuxbridge`,
    `openvswitch`, and `l2population`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the ML2 configuration file on the `controller01` node and add the following
    `mechanism_drivers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The Neutron Linux bridge agent requires specific configuration options that
    will be discussed later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using the L2 population driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The L2 population driver was introduced in the Havana release of OpenStack alongside
    the ML2 plugin. It enables broadcast, multicast, and unicast traffic to scale
    on large overlay networks constructed by OpenStack.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of the L2 population driver is to inhibit costly switch learning behaviors
    by pre-populating bridge forwarding and IP neighbor (ARP) tables on all hosts.
    Because Neutron is seen as a source of truth for the logical layout of networks
    and instances created by users, it can easily pre-populate forwarding tables consisting
    of MAC addresses and destination VTEPs with that information. The L2 population
    driver also implements an ARP proxy on each host, eliminating the need to broadcast
    ARP requests across the overlay network. Each `compute` or `network` node is able
    to intercept an ARP request from an instance or router and proxy the response
    to the requestor. However, the L2 population driver does have limitations that
    will be discussed later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to using the L2 population driver is to rely on the use of multicast
    to propagate forwarding database information between hosts. Each host should be
    configured to subscribe to a multicast group configured outside of OpenStack.
    If not properly configured, broadcast messages may be used in lieu of multicast
    and may cause unnecessary chatter on the network. The configuration of multicast
    is outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Tenant network types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `tenant_network_types` configuration option describes the type of networks
    that a tenant or project can create. When using the Linux bridge Mechanism driver,
    the supported tenant network types are `flat`, `vlan`, `local`, `vxlan`, and `none`.
  prefs: []
  type: TYPE_NORMAL
- en: The configuration option takes values in an ordered list, such as `vlan,vxlan`.
    In this example, when a user creates a network, Neutron will automatically provision
    a VLAN network and ID without any user interaction. When all available VLAN IDs
    have been allocated, Neutron will allocate a network of the next type in the list.
    In this case, a VXLAN network and VNI would be allocated. When all segmentation
    IDs of any listed network type have been allocated, users will no longer be able
    to create networks and an error will be presented to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Users with the `admin` role can override the behavior of `tenant_network_types`
    by specifying provider attributes during the network creation process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the ML2 configuration file on the `controller` node and add the following `tenant_network_types`
    configuration to the `[ml2]` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: If at any time you wish to change the value of `tenant_network_types`, edit
    the plugin configuration file accordingly on all nodes and restart the `neutron-server`
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Flat networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `flat_networks` configuration option defines interfaces that support the
    use of untagged networks, commonly referred to as a native or access VLAN. This
    option requires that a provider label be specified. A **provider label** is an
    arbitrary label or name that is mapped to a physical interface or bridge on the
    host. These mappings will be discussed in further detail later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, the `physnet1` interface has been configured to support
    a flat network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Multiple interfaces can be defined using a comma-separated list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Due to the lack of an identifier to segregate untagged traffic on the same interface,
    an interface can only support a single flat network.
  prefs: []
  type: TYPE_NORMAL
- en: In this environment, the `flat_networks` option can remain *unconfigured*.
  prefs: []
  type: TYPE_NORMAL
- en: Network VLAN ranges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `network_vlan_ranges` configuration option defines a range of VLANs that
    project networks will be associated with upon their creation when `tenant_network_types`
    is `vlan`. When the number of available VLANs reaches zero, tenants will no longer
    be able to create VLAN networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, VLAN IDs `40` through `43` are available for tenant
    network allocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Non-contiguous VLANs can be allocated by using a comma-separated list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: In this specific deployment, the provider label `physnet1` will be used with
    VLANs `40` through `43`. Those VLANs will be automatically assigned to `vlan`
    networks upon creation unless overridden by a user with the `admin` role.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the ML2 configuration file on the `controller01` node and add the following 
     `network_vlan_ranges` to the `[ml2_type_vlan]` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: VNI ranges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When VXLAN networks are created, each network is assigned a unique segmentation
    ID that is used to encapsulate traffic. When the Linux bridge Mechanism driver
    is used, the segmentation ID is used when creating the respective VXLAN interface
    on each host.
  prefs: []
  type: TYPE_NORMAL
- en: The `vni_ranges` configuration option is a comma-separated list of ID ranges
    that are available for project network allocation when `tunnel_type` is set to
    `vxlan`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, segmentation IDs `1` through `1000` are reserved
    for allocation to tenant networks upon creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `vni_ranges` option supports non-contiguous IDs using a comma-separated
    list as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the ML2 configuration file on the `controller01` node and add the following
    `vni_ranges` to the `[ml2_type_vxlan]` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The 24-bit VNI field in the VXLAN header supports up to approximately 16 million
    unique identifiers.
  prefs: []
  type: TYPE_NORMAL
- en: Security groups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `enable_security_group` configuration option instructs Neutron to enable
    or disable security group-related API functions. The option is set to `true` by
    default.
  prefs: []
  type: TYPE_NORMAL
- en: The `enable_ipset` configuration option instructs Neutron to enable or disable
    the `ipset` extension for iptables when the iptables firewall driver is used.
    The use of ipsets allows for the creation of firewall rules that match entire
    sets of addresses at once rather than having individual lines per address, making
    lookups very efficient compared to traditional linear lookups. The option is set
    to `true` by default.
  prefs: []
  type: TYPE_NORMAL
- en: If at any time the ML2 configuration file is updated, you must restart the `neutron-server` service
    and respective Neutron agent for the changes to take effect.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Linux bridge driver and agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Linux bridge Mechanism driver is included with the ML2 plugin, and was installed
    in *[Chapter 3](bf508e37-ce8a-4116-89db-e8f8a6abf0f4.xhtml),* *Installing Neutron*.
    The following sections will walk you through the configuration of OpenStack Networking
    to utilize the Linux bridge driver and agent.
  prefs: []
  type: TYPE_NORMAL
- en: While the Linux bridge and Open vSwitch agents and drivers can coexist in the
    same environment, they should not be installed and configured simultaneously on
    the same host.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Linux bridge agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To install the Neutron Linux bridge agent, issue the following command on `controller01`
    and `compute01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: If prompted to overwrite existing configuration files, type `N` at the `[default=N]`
    prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Updating the Linux bridge agent configuration file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Linux bridge agent uses a configuration file located at `/etc/neutron/plugins/ml2/linuxbridge_agent
    .ini`. The most common options are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Physical interface mappings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `physical_interface_mappings` configuration option describes the mapping
    of an artificial label to a physical interface in the server. When networks are
    created, they are associated with an interface label, such as `physnet1`. The
    label `physnet1` is then mapped to a physical interface, such as `eth2`, by the
    `physical_interface_mappings` option. This mapping can be observed in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The chosen label(s) must be consistent between all nodes in the environment
    that are expected to handle traffic for a given network created with Neutron.
    However, the physical interface mapped to the label may be different. A difference
    in mappings is often observed when one node maps `physnet1` to a gigabit interface
    while another maps `physnet1` to a 10-gigabit interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple interface mappings are allowed, and can be added to the list using
    a comma-separated list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In this installation, the `eth2`interface will be utilized as the physical network
    interface, which means that traffic for any networks associated with `physnet1`
    will traverse `eth2`. The physical switch port connected to `eth2` must support
    802.1q VLAN tagging if VLAN networks are to be created by tenants.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure the Linux bridge agent to use `physnet1` as the physical interface
    label and `eth2` as the physical network interface by updating the ML2 configuration
    file accordingly on `controller01` and `compute01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Enabling VXLAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To enable support for VXLAN networks, the `enable_vxlan` configuration option
    must be set to`true`. Update the `enable_vxlan` configuration option in the `[vxlan]`
    section of the ML2 configuration file accordingly on `Controller01` and `compute01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: L2 population
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To enable support for the L2 population driver, the `l2_population` configuration
    option must be set to `true`. Update the `l2_population` configuration option
    in the `[vxlan]` section of the ML2 configuration file accordingly on `controller01`
    and `compute01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: A useful feature of the L2 population driver is its ARP responder functionality
    that helps avoid the broadcasting of ARP requests across the overlay network.
    Each `compute` node can proxy ARP requests from virtual machines and provide them
    with replies, all without that traffic leaving the host.
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable the ARP responder, update the following configuration option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The ARP responder has known incompatibilities with the `allowed-address-pairs` extension
    on systems using the Linux bridge agent, however. The `vxlan` kernel module utilized
    by the Linux bridge agent does not support dynamic learning when ARP responder
    functionality is enabled. As a result, when an IP address moves between virtual
    machines, the forwarding database may not be updated with the MAC address and
    respective VTEP of the destination host as Neutron is not notified of this change.
    If allowed-address-pairs functionality is required, my recommendation is to disable
    the ARP responder until this behavior is changed.
  prefs: []
  type: TYPE_NORMAL
- en: Local IP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `local_ip` configuration option specifies the local IP address on the node
    that will be used to build the overlay network between hosts. Refer to *[Chapter
    1](961d71d1-9804-4af7-ad1f-8716e6dd5ac6.xhtml), Introduction to OpenStack Networking*,
    for ideas on how the overlay network should be architected. In this installation,
    all guest traffic through overlay networks will traverse a dedicated network over
    the `eth1` interface configured earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the `local_ip` configuration option in the `[vxlan]` section of the
    ML2 configuration file accordingly on the `controller01` and `compute01` hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The following table provides the interfaces and addresses to be configured
    on each host. Substitute for `X` where appropriate:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Hostname** | **Interface** | **IP address** |'
  prefs: []
  type: TYPE_TB
- en: '| `controller01` | eth1 | 10.20.0.100 |'
  prefs: []
  type: TYPE_TB
- en: '| `compute01` | eth1 | 10.20.0.101 |'
  prefs: []
  type: TYPE_TB
- en: Firewall driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `firewall_driver` configuration option instructs Neutron to use a particular
    firewall driver for security group functionality. There may be different firewall
    drivers configured based on the Mechanism driver in use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the ML2 configuration file on `controller01` and `compute01` and define
    the appropriate `firewall_driver` in the `[securitygroup]` section on a single
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: If you do not want to use a firewall, and want to disable the application of
    security group rules, set `firewall_driver` to `noop`.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the DHCP agent to use the Linux bridge driver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For Neutron to properly connect DHCP namespace interfaces to the appropriate
    network bridge, the DHCP agent on the `controller` node must be configured to
    use the Linux bridge interface driver.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `controller` node, update the `interface_driver` configuration option
    in the Neutron DHCP agent configuration file at `/etc/neutron/dhcp_agent.ini` to
    use the Linux bridge interface driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The interface driver will vary based on the plugin agent in use on the node
    hosting the DHCP agent.
  prefs: []
  type: TYPE_NORMAL
- en: Restarting services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some services must be restarted for the changes made to take effect. The following
    services should be restarted on `controller01` and `compute01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The following services should be restarted on the `controller01` node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Verifying Linux bridge agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To verify the Linux bridge network agents have properly checked in, issue the
    `openstack network agent list` command on the `controller` node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a1773ac-d29a-483a-98ec-a2630963e98b.png)'
  prefs: []
  type: TYPE_IMG
- en: The Neutron Linux bridge agents on the `controller01` and `compute01` nodes
    should be visible in the output with a state of `UP`. If an agent is not present,
    or the state is `DOWN`, you will need to troubleshoot agent connectivity issues
    by observing log messages found in `/var/log/neutron/neutron-linuxbridge-agent.log`
    on the respective host.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discovered how Neutron leverages Linux bridges and virtual
    interfaces to provide network connectivity to instances. The Linux bridge driver
    supports many different network types, including tagged, untagged, and overlay
    networks, and I will demonstrate in later chapters how these differ when we launch
    instances on those networks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn the difference between a Linux bridge and
    Open vSwitch implementation and will be guided through the process of installing
    the Open vSwitch driver and agent on two additional `compute` nodes and a network
    node dedicated to distributed virtual routing functions.
  prefs: []
  type: TYPE_NORMAL
