<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Networking with Proxmox VE"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Networking with Proxmox VE</h1></div></div></div><p>In <a class="link" href="ch05.html" title="Chapter 5. Working with Virtual Disks">Chapter 5</a>, <span class="emphasis"><em>Managing Virtual Disks</em></span>, we looked at one of the most flexible, and therefore complex components of virtualization: secondary storage. That flexibility and concomitant complexity is because we were attentive to performance and tuning I/O throughput to do the best we can in the face of the overhead implicit in this kind of virtualization.</p><p>This chapter gives the same attention to another opportunity to optimize I/O throughput: <span class="emphasis"><em>the vNIC configuration of the virtual machine</em></span>.</p><p>Since vNIC optimization involves coordinating fewer moving parts, we're going to use this opportunity to address networking with Proxmox VE in a broader context—beyond just the optimization of the virtual machine, and to the design of networks that include Proxmox VE guests and hosts.</p><p>Throughout, we'll (strive to) maintain coherent focus on the Proxmox VE's networking model and the possibilities that model opens up for us. We'll cover the topic with enough detail to conjure up possibilities for enterprise network deployment. At the same time, we'll walk through configurations that make more sense in a small office context more consistent with our hardware.</p><p>We'll proceed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Proxmox VE network model</li><li class="listitem" style="list-style-type: disc">Configuring virtual machine guests</li></ul></div><div class="section" title="Proxmox VE network model"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec32"/>Proxmox VE network model</h1></div></div></div><p>This section provides a high-level overview of the Proxmox VE network model. It covers subjects relevant to both Proxmox VE guests as well as hosts.</p><p>In Proxmox VE 4.0, two fundamental guest network configurations are supported:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Bridged</li><li class="listitem" style="list-style-type: disc">Masquerading with NAT</li></ul></div><p>The following subsection contrasts these two configuration models and establishes effective, sensible use cases for each.</p><p>The remainder of the subsection addresses Proxmox VE host configuration concerns:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Routed configuration</li><li class="listitem" style="list-style-type: disc">VLAN support</li><li class="listitem" style="list-style-type: disc">NIC bonding</li></ul></div><div class="section" title="Bridged configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec30"/>Bridged configuration</h2></div></div></div><p>Bridged networking connects a Proxmox VE guest to a network using the host's Ethernet adapter.</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_01-1.png" alt="Bridged configuration"/><div class="caption"><p>Visualizing bridged configuration</p></div></div><p>
</p><p>Virtual machines and containers with bridged connections behave precisely as if they're connected to the physical network. Indeed, each virtual server has a virtual NIC (or vNIC) that appears to the network with a discreet and unique MAC (media access control address) and IP address consistent with the physical network.</p><p>This is the default network configuration for Proxmox VE virtual servers.</p><p>As in the preceding illustration, it may be helpful to think of a bridged connection as analogous to attaching a physical machine to a simple network switch.</p><p>In <span class="emphasis"><em>Mastering Proxmox</em></span>, two contrasting diagrams help illustrate how bridged networking works to provide an alternative to a more traditional infrastructure without virtualization. First, let's look at a traditional campus infrastructure:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_02-1.png" alt="Bridged configuration"/><div class="caption"><p>Visualizing a traditional campus infrastructure</p></div></div><p>
</p><p>The next diagram, also from <span class="emphasis"><em>Mastering Proxmox</em></span>, represents a campus with a virtualized network infrastructure:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_03-1.png" alt="Bridged configuration"/><div class="caption"><p>Visualizing the same campus with a Proxmox VE virtualized network infrastructure</p></div></div><p>
</p></div><div class="section" title="NAT configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec31"/>NAT configuration</h2></div></div></div><p>In some cases, you may want to hide a virtual server behind the PVE host's true IP address and masquerade traffic using <span class="strong"><strong>network address translation</strong></span> (<span class="strong"><strong>NAT</strong></span>).</p><p>In this scenario, the virtual machine or container has full access to network resources, but is not directly accessible from outside nodes. If a bridged connection is thought of as a kind of switch, NAT virtual servers may be thought of as being behind a router that partitions a public network from a private network.</p><p>With virtualization solutions and applications for workstations, such as Oracle's VirtualBox or VMware Workstation, NAT virtual machines make so much sense; they're fantastic for creating development and testing environments. They have full access to the LAN but, unless ports are forwarded, they cannot be accessed by the other nodes on the LAN. This is precisely what we want in the development and testing environments.</p><p>However, it may be hard at first to come up with a use case for virtual servers hosted by Proxmox VE, since the services wouldn't be available to users on the physical network.</p><p>Here's an example where NATing virtual servers is an ideal solution: several web servers are working together to provide optimal service availability. Each is listening on ports 80 and 443 (conventionally, HTTP and HTTPS respectively). For efficiency and efficacy, traffic is proxied through a load balancer.</p><p>As illustrated here, both bridging and NATing are used for the scenario described previously:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_04-1024x930.png" alt="NAT configuration"/><div class="caption"><p>An example use case of using NAT and bridged configurations with virtual servers and Proxmox VE</p></div></div><p>
</p></div><div class="section" title="Routed configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec32"/>Routed configuration</h2></div></div></div><p>If your Proxmox VE instance is hosted by a cloud service, the bridged configuration described previously should not work. With an eye toward security, most hosting providers disable networking when they detect multiple MAC addresses on a single interface (<a class="ulink" href="https://pve.proxmox.com/wiki/Network_Model">https://pve.proxmox.com/wiki/Network_Model</a>).</p><p>As a result, the bridged configuration provided here would likely not be functional:</p><pre class="programlisting">auto lo
iface lo inet loopback
iface eth0 inet manual
auto vmbr0
iface vmbr0 inet static
address 192.168.10.2
netmask 255.255.255.0
gateway 192.168.10.1
bridge_ports eth0
bridge_stp off
bridge_fd 0</pre><p>A common solution is having a single interface configured with a public, static IP (<code class="literal">192.168.10.2</code> for this example). Using a bridge, additional IP blocks are provided for the Proxmox VE guests (assume <code class="literal">10.10.10.1</code> with a subnet mask of <code class="literal">255.255.255.0</code> for this example).</p><p>The configuration for a routed solution scenario might look something like this:</p><pre class="programlisting">auto lo
iface lo inet loopback
auto eth0
iface eth0 inet static
address 192.168.10.2
netmask 255.255.255.0
gateway 192.168.10.1
post-up echo 1 &gt; /proc/sys/net/ipv4/conf/eth0/proxy_arp
auto vmbr0
iface vmbr0 inet static
address 10.10.10.1
netmask 255.255.255.0
bridge_ports none
bridge_stp off
bridge_fd 0</pre><p>The configurations offered are published on the Proxmox VE wiki page at <a class="ulink" href="https://pve.proxmox.com/wiki/Network_Model#Routed_Configuration">https://pve.proxmox.com/wiki/Network_Model#Routed_Configuration</a>.</p><p>In addition, helpful information is incidentally provided in the Proxmox forum thread at <a class="ulink" href="http://forum.proxmox.com/threads/2034-Routed-setup">http://forum.proxmox.com/threads/2034-Routed-setup</a>.</p></div><div class="section" title="VLAN support"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec33"/>VLAN support</h2></div></div></div><p>Proxmox VE supports VLANs in the network infrastructure.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note61"/>Note</h3><p>A VLAN (or virtual LAN) is now understood as a group of network devices that are configured to communicate as if they were attached to the same physical network, when they are, in fact, located on any number of different LAN segments. In other words, on a campus where physical media intended for a single LAN are available, VLANs logically partition that monolithic physical network into a number of logical, or virtual LANs. Thus, based on logical connections rather than physical ones, VLANs provide an opportunity for enormous flexibility.</p></div></div><p>The procedure for joining a Proxmox VE host is outlined here; this process requires editing the text file at <code class="literal">/etc/network/interfaces</code>. Have the VLANs already set up in your infrastructure:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create the bonded interfaces for each of the VLANs.</li><li class="listitem">Edit your <code class="literal">bridge_ports</code> interfaces to match the VLANs you are using for management.</li><li class="listitem">Rename your <code class="literal">vmbr</code> devices so that they reflect your VLAN.</li><li class="listitem">After ensuring that the switch port that is plugged into the PVE machine is trunked using the dot1q encapsulation, restart the interface: <code class="literal">/etc/init.d/networking restart</code>.</li><li class="listitem">Check your work using the <code class="literal">ifconfig</code> command.</li></ol></div><p>The details are extremely contingent on the logical organization of the network; however, the Proxmox VE wiki has a guide with detailed examples at <a class="ulink" href="https://pve.proxmox.com/wiki/Vlans">https://pve.proxmox.com/wiki/Vlans</a>.</p></div><div class="section" title="NIC bonding"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec34"/>NIC bonding</h2></div></div></div><p>Proxmox VE supports NIC bonding (or NIC teaming) out of the box, and it's configured very much as it would be on any Debian-based host.</p><p>NIC bonding is a strategy used primarily to increase fault tolerance on a PVE server. Bonded NICs that appear to have the same physical device have the same MAC address. Linux includes a kernel module called bonding to allow users to bond multiple network interfaces into a single channel.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip62"/>Tip</h3><p>To learn more about NIC bonding with GNU/Linux and the pitfalls to avoid, please visit Charlie Schulting's article <span class="emphasis"><em>Understanding NIC Bonding with Linux</em></span> at <a class="ulink" href="http://www.enterprisenetworkingplanet.com/linux_unix/article.php/3850636/Understanding-NIC-Bonding-with-Linux.htm">http://www.enterprisenetworkingplanet.com/linux_unix/article.php/3850636/Understanding-NIC-Bonding-with-Linux.htm</a> (posted November 2, 2009). Linux Journal published another great resource called "Bond, Ethernet Bond" in 2011: <a class="ulink" href="http://www.linuxjournal.com/article/10931">http://www.linuxjournal.com/article/10931</a>.</p><p>To learn more about bonding with Debian, the GNU/Linux distribution upon which Proxmox VE is built, visit the Debian wiki at <a class="ulink" href="https://wiki.debian.org/Bonding">https://wiki.debian.org/Bonding</a>.</p></div></div><p>The Proxmox VE wiki has an article on making the best use of bonding at <a class="ulink" href="https://pve.proxmox.com/wiki/Bonding">https://pve.proxmox.com/wiki/Bonding</a>.</p><p>The simplest resource for configuring a Proxmox VE host to take advantage of bonding is an official Proxmox tutorial on YouTube at <a class="ulink" href="https://www.youtube.com/watch?v=-8SwpgaxFuk">https://www.youtube.com/watch?v=-8SwpgaxFuk</a>. You'll find that, unlike VLAN configuration, bonding can be configured from the management interface alone; there's no immediate need to edit files from the command line.</p></div></div></div>
<div class="section" title="Network configuration for virtual servers"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec33"/>Network configuration for virtual servers</h1></div></div></div><p>Equipping a virtual machine or container with a vNIC can be a simple matter handled completely through the management interface during the initial configuration or subsequently as circumstances demand.</p><p>However, it can also be a fairly complex matter that requires modification of configuration files from the command line on the host, in the VM or container, or both.</p><p>In this section, we'll explore the simplest scenario: providing connectivity to VMs through the web-based management interface.</p><div class="section" title="Providing basic connectivity"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec35"/>Providing basic connectivity</h2></div></div></div><p>Here, we will focus on providing our virtual machines with basic connectivity  and incorporate them into a flat network. We'll work first with VMs and then with containers.</p><div class="section" title="Of VMs and vNICs"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec7"/>Of VMs and vNICs</h3></div></div></div><p>In <a class="link" href="ch04.html" title="Chapter 4. Creating Virtual Machines">Chapter 4</a>, <span class="emphasis"><em>Creating Virtual Machines</em></span>, we glossed over the configuration of the virtual network interface in the name of efficiency. Here, we'll discuss options provided by the VM creation wizard in the administrative interface.</p><div class="section" title="Bridge configuration"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec11"/>Bridge configuration</h4></div></div></div><p>First, let's configure a VM intended to be used with Debian 8 that's using a bridged connection. As previously described, a bridge configuration will integrate the VM into the LAN, making it fully available to other nodes, addressable with a unique IP, and identifiable by its MAC address. It's analogous to plugging a new physical machine into a network switch on the physical network.</p><p>Recall from <a class="link" href="ch04.html" title="Chapter 4. Creating Virtual Machines">Chapter 4</a>, <span class="emphasis"><em>Creating Virtual Machines</em></span>, that the <span class="strong"><strong>Create: Virtual Machine</strong></span> dialog has eight tabs in total and that the <span class="strong"><strong>Network</strong></span> tab is the seventh—the final tab before reviewing and committing your configuration for the new VM.</p><p>Here are the steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Download the Debian 8 netinst image and upload it to the Proxmox VE host using any of the methods described in <a class="link" href="ch04.html" title="Chapter 4. Creating Virtual Machines">Chapter 4</a>, <span class="emphasis"><em>Creating Virtual Machines</em></span>.</li><li class="listitem">Access the Proxmox VE administrative interface at <code class="literal">https://&lt;my-ip-addr&gt;:8006</code> and create a new VM, specifying the netinst image in the CD/DVD tab of the <span class="strong"><strong>Create: Virtual Machine</strong></span> wizard.</li><li class="listitem">For this VM, the defaults on most tabs will be fine. On the <span class="strong"><strong>OS</strong></span> tab, choose the <span class="strong"><strong>Linux 3.x/2.6 Kernel</strong></span> option at the top right of the tab; on the <span class="strong"><strong>CPU</strong></span> tab, ensure <span class="strong"><strong>Type</strong></span> is set to <span class="strong"><strong>Default (kvm64)</strong></span>. As discussed in the previous chapter, we'll choose <span class="strong"><strong>VIRTIO</strong></span> as our <span class="strong"><strong>Bus/Device</strong></span> on the <span class="strong"><strong>Hard Disk</strong></span> tab with the <span class="strong"><strong>Cache</strong></span> option set to <span class="strong"><strong>No cache</strong></span>.<p>
</p><div class="mediaobject"><img src="graphics/B01784_06_05.png" alt="Bridge configuration"/><div class="caption"><p>Configuring the hard disk</p></div></div><p>
</p></li><li class="listitem">On the <span class="strong"><strong>Network</strong></span> tab, we'll choose <span class="strong"><strong>Bridged mode</strong></span> in the left column. The virtio paravirtualization driver increases performances not only for storage IO, but also for network IO. Since virtio drivers are incorporated into GNU/Linux, we're going to take advantage of this support by choosing virtio (paravirtualized) as the NIC model in the right column of the <span class="strong"><strong>Network</strong></span> tab.</li><li class="listitem">When you're all set, review your configuration on the <span class="strong"><strong>Confirm</strong></span> tab and click on <span class="strong"><strong>Finish</strong></span> to commit to the VM's creation.</li><li class="listitem">Remember, you're not stuck with VNC options through the <span class="strong"><strong>Console</strong></span> tab. Select the VM, select the <span class="strong"><strong>Hardware</strong></span> tab, and double-click on <span class="strong"><strong>Display</strong></span> to select <span class="strong"><strong>SPICE</strong></span>.</li></ol></div><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_06.png" alt="Bridge configuration"/><div class="caption"><p>Configuring the display for use with SPICE console option</p></div></div><p>
</p><p>Note that the <span class="strong"><strong>Hardware</strong></span> tab also indicates that the configured vNIC for the VM has now been assigned a MAC. If you select <span class="strong"><strong>Network Device</strong></span> and click on the <span class="strong"><strong>Edit</strong></span> button, you should see a similar dialog to the one illustrated here:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_07.png" alt="Bridge configuration"/><div class="caption"><p>Configuring the Network Device</p></div></div><p>
</p><p>Now, get ready to start the installation, select the VM, click on <span class="strong"><strong>Start</strong></span>, and drop the <span class="strong"><strong>Console</strong></span> menu down to select <span class="strong"><strong>SPICE</strong></span>.</p><p>At this point, follow the on-screen instructions to install Debian 8 to suit your taste. You'll have the option to use graphical installation—the screenshots shared in this section will be from that installation mode.</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_08.png" alt="Bridge configuration"/><div class="caption"><p>Networking works</p></div></div><p>
</p><p>At this stage, you have confirmation that your virtual machine has connectivity: if you glance at the management interface, you'll also see network activity:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_09.png" alt="Bridge configuration"/><div class="caption"><p>Network confirmed as working</p></div></div><p>
</p><p>Proceed through the installation until you are asked to specify packages to install. At that point, let's select just enough for a proof-of-concept of bridge configuration. Select <span class="strong"><strong>web server</strong></span>, <span class="strong"><strong>SSH server</strong></span>, and <span class="strong"><strong>standard system utilities</strong></span>; click on <span class="strong"><strong>Continue</strong></span> to complete the installation.</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_10.png" alt="Bridge configuration"/><div class="caption"><p>Selecting packages to install</p></div></div><p>
</p><p>With all the virtual pieces in place, when you click on <span class="strong"><strong>Continue</strong></span>, you should be able to watch the progress as it downloads packages from the Internet and gives them a default installation and configuration:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_11.png" alt="Bridge configuration"/></div><p>
</p><p>Given a bridge configuration, when the installation is complete and the machine reboots, it'll be available at a dynamically assigned IP. You should be able to confirm this by accessing the machine via SSH or accessing Apache's default web page using your browser and pointing to port 80 on the machine.</p><p>On the other hand, nothing is confirmed without the IP address.</p><p>Unfortunately, the dynamically assigned IP isn't immediately available through the administration interface; we can find it through a scan, or we can simply use the console and ask in a terminal session.</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_12.png" alt="Bridge configuration"/><div class="caption"><p>Using ifconfig to discover the dynamically assigned IP address of the guest</p></div></div><p>
</p><p>The preceding illustration shows the results of <code class="literal">ifconfig</code> in the new virtual machine: <code class="literal">inet addr</code>, the IPv4 address is 192.168.1.50. Users can now use any machine with a browser or SSH client to control the new web server, for example <code class="literal">ssh rik@192.168.1.50</code>, or <code class="literal">http://192.168.1.50</code> in this case:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_13.png" alt="Bridge configuration"/><div class="caption"><p>Successful Apache2 access from the LAN</p></div></div><p>
</p><p>We've successfully created a virtual web server available everywhere on our flat LANs.</p><p>As long as we keep using a dynamic IP, the address will not be reliable. Configuring a static IP address in a VM is not different from doing so on a physical machine. It depends on privileged access and knowing the routine and your network configuration; you'll need to have an available IP address in mind, and know your subnetwork mask, preferred DNS servers, and gateway. You'll also want your root credentials on hand.</p><p>Before you make changes, <code class="literal">/etc/network/interfaces</code> will look like this:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_14.png" alt="Bridge configuration"/><div class="caption"><p>Interfaces configuration from the CLI</p></div></div><p>
</p><p>With my target configuration in mind, I can use <code class="literal">nano /etc/network/interfaces</code> to edit the configuration file to match it, as illustrated here:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_15.png" alt="Bridge configuration"/><div class="caption"><p>Editing /etc/network/interfaces in the guest</p></div></div><p>
</p><p>After writing out and rebooting, the web page should be available at the specified address, in this case <code class="literal">http://192.168.1.250</code>:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_16.png" alt="Bridge configuration"/><div class="caption"><p>The Apache 2 default page</p></div></div><p>
</p><p>Use the <code class="literal">ifconfig</code> command to review the configuration of the network interfaces:</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_17.png" alt="Bridge configuration"/></div><p>
</p><p>In a home or small office setting, we simply forward a port on the WAN side to port 80 on the VM, and it will be accessible to the world.</p><p>In this subsection, we worked through an example of bridge configuration by creating a disposable Debian web and SSH server. We saw that using a bridge configuration, our virtual server is available to any node on the LAN, and potentially to the world.</p><p>In the following subsection, we'll quickly demonstrate NAT configuration with a pretty narrow use case.</p></div><div class="section" title="Using NAT configuration"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl4sec12"/>Using NAT configuration</h4></div></div></div><p>Let's adapt our Debian 8 guest. Instead of a virtual server, let's turn it into a desktop machine that's hidden from the rest of the LAN but accessible to users with access rights via PVE's web-administration console.</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Log in to the administrative interface, select the Debian VM we created in the preceding subsection, shut it down, and select its <span class="strong"><strong>Hardware</strong></span> tab.</li><li class="listitem">Select the <span class="strong"><strong>Network Device</strong></span> line and click on the <span class="strong"><strong>Delete</strong></span> button to remove the interface.</li><li class="listitem">Click on the <span class="strong"><strong>Add</strong></span> button and select <span class="strong"><strong>Network device</strong></span>, as illustrated here.</li><li class="listitem">In the <span class="strong"><strong>Add: Network Device</strong></span> dialog, select <span class="strong"><strong>NAT mode</strong></span> in the left column and choose <span class="strong"><strong>VirtIO (paravirtualized)</strong></span> from the <span class="strong"><strong>Model</strong></span> drop-down menu.<p>
</p><div class="mediaobject"><img src="graphics/B01784_06_18.png" alt="Using NAT configuration"/><div class="caption"><p>Setting up a network device with NAT configuration</p></div></div><p>
</p></li><li class="listitem">Enter the VM with the console, and return the interface's configuration to its prior state by entering <code class="literal">nano /etc/network/interfaces</code> and editing the file as it appears here:<p>
</p><div class="mediaobject"><img src="graphics/B01784_06_19.png" alt="Using NAT configuration"/><div class="caption"><p>Setting up a network device with NAT configuration</p></div></div><p>
</p></li><li class="listitem">Restart networking with <code class="literal">/etc/init.d/networking restart</code>.</li><li class="listitem">Confirm your new address by entering <code class="literal">ifconfig</code> to see results similar to those illustrated here:</li></ol></div><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_20.png" alt="Using NAT configuration"/><div class="caption"><p>Results of ifconfig</p></div></div><p>
</p><p>At this point, the VM is accessible only to the Proxmox VE host and cunningly masqueraded behind its IP address.</p><p>Let's access it and configure the VM for virtual desktop access through <span class="strong"><strong>SPICE</strong></span>.</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Make sure the Debian 8 VM machine is selected.</li><li class="listitem">Drop down the <span class="strong"><strong>Console</strong></span> menu and select <span class="strong"><strong>SPICE</strong></span>. You should be prompted to log in to a terminal session. Login with the root credentials.</li><li class="listitem">At the prompt, enter <code class="literal">tasksel</code> and press 
<span class="strong"><strong>Enter
</strong></span> to launch the package configuration tool.</li><li class="listitem">In the menu, select the <span class="strong"><strong>GNU/Linux Desktop</strong></span> you'd like to try; in the following screenshot, <span class="strong"><strong>LXDE</strong></span> is selected specifically because it is lightweight and our drive space is minimal.<p>
</p><div class="mediaobject"><img src="graphics/B01784_06_21.png" alt="Using NAT configuration"/><div class="caption"><p>The package configuration before adding the desktop environment</p></div></div><p>
</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_22-1024x559.png" alt="Using NAT configuration"/><div class="caption"><p>The package configuration after choosing LXDE desktop environment</p></div></div><p>
</p></li><li class="listitem">After the package installation completes, restart the VM with <code class="literal">reboot</code> or <code class="literal">shutdown -r now</code>.</li></ol></div><p>Welcome to the LXDE desktop environment; log in with the credentials you created for the first user during the installation of Debian earlier in the chapter.</p><p>Going immediately to a browser, we can determine that we have access to services on the LAN as well as the Internet:</p><p>
</p><div class="mediaobject"><img src="graphics/image_06_023.png" alt="Using NAT configuration"/><div class="caption"><p>Accessing LAN from the VM with NAT configuration</p></div></div><p>
</p><p>
</p><div class="mediaobject"><img src="graphics/B01784_06_24-1024x766.png" alt="Using NAT configuration"/><div class="caption"><p>Accessing the Internet from a NAT-configured VM</p></div></div><p>
</p><p>However, returning to the physical workstation, we find that we have no access to the VM without going first through the Proxmox host.</p><p>Instead, we can access the new desktop through the console, and manage permissions with the feature-rich rights-management system Proxmox VE provides to restrict or permit access to VMs by specific users or groups (see <a class="ulink" href="https://pve.proxmox.com/wiki/User_Management">https://pve.proxmox.com/wiki/User_Management</a> to explore the rich rights management system in PVE).</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec34"/>Summary</h1></div></div></div><p>We conclude having explored the Proxmox VE network model and worked through some configurations for virtual machines.</p><p>Along the way, our attention turned once more to virtio paravirtualization drivers—not for storage, as in the prior chapter, but rather for network IO. To briefly reiterate, virtio paravirtualization drivers for KVM-QEMU virtual machines help optimize efficiency by taking some of the sting out of the resource overhead associated with virtualization. Proxmox VE doesn't default to virtio, however; it defaults instead to the option with the greatest compatibility. In the case of vNICs, that default is Intel's E1000 NIC.</p><p>In the next chapter, we'll take a somewhat abstracted look at security threats and countermeasures specific to virtual machines, containers, and their hosts. We'll take our first look at the firewall features built in to the Proxmox VE administrative interfaces, and we'll work to realize some of the countermeasures proposed.</p><p>That being said, let's harden our Proxmox VE hosts and guests!</p></div></body></html>