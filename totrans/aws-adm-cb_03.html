<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Storage and Content Delivery</h1>
            </header>

            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Hosting a static website</li>
<li>Caching a website</li>
<li>Working with network storage</li>
<li>Backing up data for compliance</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Introduction</h1>
            </header>

            <article>
                
<p>Each of these recipes is backed by a CloudFormation template that makes them quick and easy to reproduce and modify.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Storage</h1>
            </header>

            <article>
                
<p>Storage is an integral part of any organization's cloud usage. When used correctly, servers are short-lived and replaceable. This means that having a durable, available storage service is critical to persisting and sharing state.</p>
<p>Here is a high-level summary of the storage services AWS offers:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="image-border" height="424" src="assets/B06236_03_01.png" width="391"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Storage services from AWS</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Elastic Block Store</h1>
            </header>

            <article>
                
<p><strong>Elastic Block Store</strong> (<strong>EBS</strong>) provides block-device storage as volumes to EC2 instances. It behaves similarly to a <strong>storage area network</strong> (<strong>SAN</strong>) and offers the lowest-latency access of the various storage services offered. EBS volumes can only be accessed by one instance at a time. The size of a volume must be specified when they are provisioned, and cannot be changed after.</p>
<p>Volumes are hosted on redundant hardware in a specific AZ, but they do not offer redundancy across AZs.</p>
<p>Some recommended use cases for EBS are:</p>
<ul>
<li>Instance boot volumes</li>
<li>Intensive data processing</li>
<li>Transactional writes</li>
</ul>
<p>We will cover EBS in more detail in the <a href="beece917-78ff-43b8-934b-706eca5968f9.xhtml"><span class="ChapterrefPACKT">Chapter 4</span></a>, <em>Using AWS Compute</em>, as its primary use is as the underlying storage for EC2 instances.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Elastic File System</h1>
            </header>

            <article>
                
<p><strong>Elastic File System</strong> (<strong>EFS</strong>) provides a file-storage service that can be accessed simultaneously by many instances, similar to <strong>Network Attached Storage</strong> (<strong>NAS</strong>). While not as fast as EBS, it still provides low-latency access. As it may be accessed by multiple clients at a time, it can reach much higher levels of throughput than EBS. EFS filesystems also in size scale dynamically and so do not need to be preallocated or modified during use. Filesystems are stored redundantly across AZs.</p>
<p>Some recommended use cases for EFS are:</p>
<ul>
<li>Home directories</li>
<li>Serving shared web content</li>
<li>Content management</li>
</ul>
<div class="packt_tip">EFS performance scales according to the filesystem size. As the filesystem size is not preallocated, the only way to increase your performance is to add more data to it.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Simple Storage Service</h1>
            </header>

            <article>
                
<p><strong>Simple Storage Service</strong> (<strong>S3</strong>) provides a web-based service for hosting files. Files are referred to as <strong>objects</strong> and grouped in <strong>buckets</strong>. Objects are effectively a key-value pair, similar to a document database. Keys are used like file paths, with <em>/</em> used as a separator and grouping character. Buckets can be easily accessed like a website via an automatically generated domain name.</p>
<div class="packt_infobox">Due to being associated with a domain name, bucket names must be <em>globally</em> unique.</div>
<p>Some recommended usecases for S3 are:</p>
<ul>
<li>Static website assets</li>
<li>Sharing large files</li>
<li>Short-term (a.k.a. <em>warm</em>) backups</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Glacier</h1>
            </header>

            <article>
                
<p><strong>Glacier</strong> is a companion service to S3, but is the <strong>cold</strong> storage option. Cold storage is a service where you are not able to directly access your data; you must lodge a request for data to be restored (to S3), and you are notified when it is ready. A physical example of cold storage might be backup tapes that are stored in a secure location. Similar to S3, files are referred to as <em>objects</em>. Files are grouped together and stored in <strong>archives</strong>. Archives can be created and deleted, but never modified. Archives are grouped together in to <strong>vaults</strong>, which allow you to control access.</p>
<p>The shortest restoration time is 1-5 minutes (with limitations). Standard restoration times take 3-5 hours, with some other options available.</p>
<p>Some recommended usecases for Glacier are:</p>
<ul>
<li>Long-term (a.k.a. <em>cold</em>) backups</li>
<li>Compliance backups</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Content delivery</h1>
            </header>

            <article>
                
<p>Content delivery is aimed at quickly and efficiently distributing your content to users. The best practice way to do this is to leverage a <strong>Content Delivery Network</strong> (<strong>CDN</strong>). Amazon's CDN service is <strong>Amazon CloudFront</strong>.</p>
<p>While AWS currently has 14 regions, it has an additional 68 edge locations that can be used as part of CloudFront. This gives you a massive global network of resources you can use to improve your users' experience of your application.</p>
<p>CloudFront works closely with S3 to serve static assets. In addition to this, it can be configured to cache dynamic content. This gives you an easy way to improve the performance of applications that are not even aware of CloudFront.</p>
<p>CloudFront websites are referred to as <strong>distributions</strong> which speaks to their CDN role.</p>
<div class="packt_tip">Distributions can also be used to provide a common frontend for multiple, disparate, sources of content.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Hosting a static website</h1>
            </header>

            <article>
                
<p>It's really easy to host a static website on AWS. It turns out it's also dirt cheap, fast, reliable, and massively scalable too.</p>
<p>You do this by storing your content in an S3 bucket and configuring that bucket to behave like a website.</p>
<p>It's important to note that we're talking about static content only. This method doesn't work for websites requiring server-side processing or some other backend functionality. WordPress, for example, requires PHP which means you need a fully functional web server to run it. S3 won't interpret PHP pages for you, it will just serve files straight to the browser.</p>
<p>So, why would you want to host a static website in S3? Common scenarios we see are:</p>
<ul>
<li>Simply, your website is completely static and you don't change it very often.</li>
<li>Your company is launching a new product or service. You're expecting very large numbers of customers to visit a mini-site within a short time period; likely more traffic than your existing web hosting environment can handle.</li>
<li>You need somewhere to host a failover or <em>down for maintenance</em> style page which is separate from your existing web hosting environment.</li>
</ul>
<div class="packt_infobox">HTTPS is not supported by S3 when it is used to serve static content.</div>
<div class="CDPAlignCenter CDPAlign"><br/>
<img class="image-border" src="assets/B06236_03_02-1.png"/></div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>This recipe provides you with the CloudFormation necessary to create:</p>
<ul>
<li>An S3 bucket for hosting your content</li>
<li>A Route 53 hosted zone and necessary DNS records</li>
<li>A redirection from <kbd>www</kbd> to <kbd>root/apex</kbd> for your domain</li>
</ul>
<p>After running this CloudFormation you will of course need to upload your content to the buckets which CloudFormation created for you.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Creating S3 buckets and hosting content</h1>
            </header>

            <article>
                
<p>In this example, we're actually going to create two S3 buckets for our site <a href="http://www.example.org/"><span class="URLPACKT">http://www.example.org/</span></a>. They correspond to the hostnames:</p>
<ul>
<li><kbd>www.example.org</kbd></li>
<li><kbd><span class="URLPACKT">example.org</span></kbd></li>
</ul>
<div class="packt_infobox">It might be a good time to remind you that S3 bucket names are globally unique. You'll also need to substitute <kbd><span class="URLPACKT">example.org</span></kbd> for a domain which you own.</div>
<ol>
<li>We're going to put all our content in our <kbd><span class="URLPACKT">example.org</span></kbd> bucket and tell S3 that requests to <kbd><span class="URLPACKT">www.example.org</span></kbd> should be redirected to the other bucket. Here's what the relevant parts of the CloudFormation would look like for creating these buckets (note that we'll be expanding on this example as we proceed through this recipe):</li>
</ol>
<pre>
      Resources: <br/>        ApexBucket: <br/>          Type: AWS::S3::Bucket <br/>          Properties: <br/>            BucketName: !Ref DomainName <br/>        WWWBucket: <br/>          Type: AWS::S3::Bucket <br/>          Properties: <br/>            BucketName: !Sub <br/>              - www.${Domain} <br/>              - Domain: !Ref DomainName
</pre>
<ol start="2">
<li>We won't be hardcoding our domain name into the bucket names. Instead we're going to supply our domain as a parameter to the CloudFormation template in order to maximize its reusability, then reference it via <kbd>!Ref DomainName</kbd>. To keep this recipe as simple as possible we're going to set up a single page website. In the real world, your website will of course consist of multiple files but the process you need to follow is exactly the same.</li>
</ol>
<ol start="3">
<li>Configuring the index document:
<ul>
<li>The <strong>index</strong> document is the file which S3 will serve by default when someone types your domain name into the address bar in their browser. This precludes the user from having to type the full path to a file, that is, <kbd>example.org/index.html</kbd>.</li>
<li>Typically, your index document will be called <kbd>index.html</kbd>. We'll provide a code snippet for this file towards the end of this chapter.</li>
</ul>
</li>
</ol>
<ol start="4">
<li>Configuring the error document:
<ul>
<li>The <strong>error</strong> document is the file S3 will serve if something goes wrong (missing files, forbidden access, bad requests, and so on). To keep things consistent we're going to call ours <kbd>error.html</kbd>. Again, we'll provide a code snippet for this later in the chapter.</li>
</ul>
</li>
<li>Enabling website hosting on your bucket:
<ul>
<li>As mentioned previously, we're going to need to tell S3 that it should serve static website content from our <kbd><span class="URLPACKT">example.org</span></kbd> bucket. Often users will perform this configuration through the S3 web console. We're going to do it in CloudFormation however. The CLI also offers a nice one-liner for doing this. You're not going to need to run this command, we're just adding it here for reference:</li>
</ul>
</li>
</ol>
<pre>
<strong>                aws s3 website s3://example.org/ <br/>                  --index-document index.html --error-document error.html</strong>
</pre>
<ol start="6">
<li>Setting up redirection from the <kbd>www</kbd> hostname:
<ul>
<li>When performing this task manually one has little option but to fire up the web console and configure the <kbd><span class="URLPACKT">www.example.org</span></kbd> bucket to redirect to the <kbd><span class="URLPACKT">example.org</span></kbd> bucket. There's no handy one-line CLI command for this one. Fortunately, it's easy in CloudFormation as you'll soon see in the upcoming CloudFormation snippet.</li>
</ul>
</li>
</ol>
<ol start="7">
<li>Configuring permissions:
<ul>
<li>The last bucket setup task is to configure permissions. By default S3 buckets are private and only the bucket owner can see its contents. This is not much use to us in this scenario because we need <em>everyone</em> to be able to see our bucket contents. This is a public website after all.</li>
</ul>
</li>
</ol>
<ol start="8">
<li>If we were configuring our bucket manually we would apply a bucket policy which looks something like this:</li>
</ol>
<pre>
      { <br/>        "Version":"2012-10-17", <br/>        "Statement": [{ <br/>          "Sid": "Allow Public Access to everything in our bucket", <br/>          "Effect": "Allow", <br/>          "Principal": "*", <br/>          "Action": "s3:GetObject", <br/>          "Resource": "arn:aws:s3:::example.org/*" <br/>        } <br/>       ] <br/>      }
</pre>
<ol start="9">
<li>Fortunately, in CloudFormation the task is much simpler. Building on the previous example, the <kbd>Resources</kbd> section of our CloudFormation template now looks like this:</li>
</ol>
<pre>
        ApexBucket: <br/>          Type: AWS::S3::Bucket <br/>          Properties: <br/>            BucketName: <br/>              Ref: DomainName <br/>            AccessControl: PublicRead <br/>            WebsiteConfiguration: <br/>              IndexDocument: index.html <br/>              ErrorDocument: error.html <br/>        WWWBucket: <br/>          Type: AWS::S3::Bucket <br/>          Properties: <br/>            BucketName: <br/>              Fn::Join: [ ., [ www, Ref: DomainName ] ]<br/>            AccessControl: BucketOwnerFullControl <br/>            WebsiteConfiguration: <br/>              RedirectAllRequestsTo: <br/>                HostName: <br/>                  Ref: ApexBucket
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Creating a hosted zone</h1>
            </header>

            <article>
                
<p>In order to start adding DNS records we first need to add a hosted zone to Route 53. As you can see in the following code, this is reasonably simple to do. The <kbd>Name</kbd> we are going to supply will be provided as a parameter to our CloudFormation template:</p>
<pre>
DNSHostedZone: <br/>  Type: "AWS::Route53::HostedZone" <br/>  Properties: <br/>    Name: <br/>      Ref: DomainName
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Creating DNS records</h1>
            </header>

            <article>
                
<ol>
<li>Now that we have a hosted zone we can go ahead and create DNS records for it. For this we use the AWS resource type <kbd>AWS::Route53::RecordSetGroup</kbd>.</li>
<li>We're going to create an A record for our domain's <kbd>root/apex</kbd> entry and we'll make it an alias. This alias will be configured to point to the AWS endpoint for S3-hosted websites in the particular region we choose to run this CloudFormation in.</li>
<li>In order to archive region portability in our template, we'll use a <em>mapping</em> to provide all the endpoints. The values in this map are published by AWS in their API endpoints documentation. You won't need to look these up, however, because our code sample provides the most up-to-date endpoints (as of the time of writing this). The endpoints tend not to change, but the list obviously grows when AWS adds more regions.</li>
<li>The mapping will look like this:</li>
</ol>
<pre>
        us-east-1: <br/>          S3HostedZoneID: Z3AQBSTGFYJSTF <br/>          S3AliasTarget: s3-website-us-east-1.amazonaws.com <br/>        us-east-2: <br/>          S3HostedZoneID: Z2O1EMRO9K5GLX <br/>          S3AliasTarget: s3-website.us-east-2.amazonaws.com
</pre>
<p style="padding-left: 60px">We'll also need a <kbd>CNAME</kbd> for <kbd>www</kbd> which will point at our <kbd>WWWBucket</kbd> so that redirection can take place. The final resource for our DNS records will look like this:</p>
<pre>
        DNSRecords: <br/>          Type: "AWS::Route53::RecordSetGroup" <br/>          Properties: <br/>            HostedZoneId: <br/>              Ref: DNSHostedZone <br/>            RecordSets: <br/>              - Name: <br/>                  Ref: DomainName <br/>                Type: A <br/>                AliasTarget: <br/>                  HostedZoneId: <br/>                    Fn::FindInMap: [ RegionMap, Ref: "AWS::Region",<br/>                      S3HostedZoneID ]<br/>                  DNSName: <br/>                    Fn::FindInMap: [ RegionMap, Ref: "AWS::Region",<br/>                      S3AliasTarget ]<br/>              - Name: <br/>                  Fn::Join: [ ., [ www, Ref: DomainName ] ] <br/>                Type: CNAME <br/>                TTL: 300 <br/>                ResourceRecords: <br/>                  - Fn::GetAtt: WWWBucket.DomainName
</pre>
<ol start="5">
<li>We're ready for launch. It's time to create our CloudFormation stack. You can do so using the following CLI command:</li>
</ol>
<pre>
<strong>      aws cloudformation create-stack \ </strong><br/><strong>        --stack-name static-website-1 \ </strong><br/><strong>        --template-body file://03-hosting-a-static-website.yaml \ </strong><br/><strong>        --parameters \</strong><br/><strong>        ParameterKey=DomainName,ParameterValue=&lt;your-domain-name&gt;</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Uploading website content</h1>
            </header>

            <article>
                
<p>It's now time to upload some content to our S3 buckets. Here are the snippets we promised you earlier. There's nothing fancy here. Once you've got these examples working, you can try replacing them with your real website content:</p>
<ul>
<li><kbd>index.html</kbd></li>
</ul>
<pre>
      &lt;html&gt; <br/>        &lt;head&gt; <br/>          &lt;title&gt;Welcome to exmaple.org&lt;/title&gt; <br/>        &lt;/head&gt; <br/>        &lt;body&gt; <br/>          &lt;h1&gt;example.org&lt;/h1&gt; <br/>          &lt;p&gt;Hello World!&lt;/p&gt; <br/>        &lt;/body&gt; <br/>      &lt;/html&gt;
</pre>
<ul>
<li><kbd>error.html</kbd></li>
</ul>
<pre>
      &lt;html&gt; <br/>        &lt;head&gt; <br/>          &lt;title&gt;Error&lt;/title&gt; <br/>        &lt;/head&gt; <br/>        &lt;body&gt; <br/>          &lt;h1&gt;example.org&lt;/h1&gt; <br/>          &lt;p&gt;Something went wrong!&lt;/p&gt; <br/>        &lt;/body&gt; <br/>      &lt;/html&gt;
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>That's it! As soon as S3 has an <kbd>index.html</kbd> file to serve up, you will be hosting a single-page website on S3. Go ahead and test it out. The supplied CloudFormation example will output a URL you can use to see your new website. After you've verified it's working, you can go ahead and upload your real static website and enjoy fast, cheap, and server-free hosting.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>Let's look at some additional things to consider.<br/></p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Delegating your domain to AWS</h1>
            </header>

            <article>
                
<p>While we've created a hosted zone and some DNS records in Route 53, no one can actually see them yet. In order to send your website visitors to your new S3 static website, you'll need to delegate your domain to Route 53. This is left to you as an exercise; however, there are some important things to remember:</p>
<ul>
<li>The DNS servers to delegate your domain to can be found in the NS record for your hosted zone.</li>
<li>If your domain is already live and production-like, you'll need to make sure all your DNS records for your zone are recreated in Route 53, including things such as MX records, which are critical for the continuity of your e-mail service.</li>
<li>Before delegating to AWS, you may consider reducing the TTL values on your DNS records. This will be useful if for some reason you need to re-delegate or make changes to them. Once your DNS setup is stable, you can increase TTLs.</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Cross-origin resource sharing </h1>
            </header>

            <article>
                
<p>It's worth discussing <strong>cross-origin resource sharing</strong> (<strong>CORS</strong>) here because the more static web content hosting you do in S3, the higher your chances are of needing to know about this, particularly where web fonts are concerned.</p>
<p>Some browsers implement a <em>same origin</em> policy restriction. This prevents the browser from loading certain kinds of assets from hostnames that are different from the page being displayed to the user. Web fonts fall under this restriction and are an often-cited example because when they don't load correctly, your website will usually look a lot different to how you intended. The solution to this is to add a CORS configuration to your bucket to allow its content to be loaded by the particular origin or hostname that requested it.</p>
<p>We'll leave the CORS configuration out of our full example, but if you need to add one to your bucket, here's how you can do it. Update your <kbd>AllowedOrigins</kbd> property to look similar to the following CloudFormation and you should be all set:</p>
<pre>
  ApexBucket: <br/>    Type: AWS::S3::Bucket <br/>    Properties: <br/>      BucketName: !Ref DomainName <br/>      AccessControl: PublicRead <br/>      WebsiteConfiguration: <br/>        IndexDocument: index.html <br/>        ErrorDocument: error.html <br/>      CorsConfiguration: <br/>        CorsRules: <br/>        - AllowedOrigins: <br/>            - example.net <br/>            - www.example.net <br/>            - example.com <br/>            - www.example.com <br/>          AllowedMethods: <br/>            - GET <br/>          MaxAge: 3000 <br/>          AllowedHeaders: <br/>            - Content-* <br/>            - Host
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Caching a website</h1>
            </header>

            <article>
                
<p>In this recipe, we'll show you how to use AWS CloudFront to cache your website.</p>
<p>The primary reasons you'll want to consider doing this are as follows:</p>
<ul>
<li>Copies of your content will be geographically located closer to your end users, thus improving their experience and delivering content to them faster.</li>
<li>The burden for serving content will be removed from your fleet of servers. This could potentially result in a large cost saving if you're able to turn off some servers or reduce your bandwidth bill.</li>
<li>You may need to be shielded from large and unexpected spikes in traffic.</li>
<li>While not the focus of this chapter, CloudFront gives you the ability to implement <strong>Web Application Firewall</strong> (<strong>WAF</strong>) as an added layer of protection from the bad guys.</li>
</ul>
<div class="packt_infobox">Unlike most AWS services, which are region specific, CloudFront is a <em>global</em> service.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>First of all, you're going to need a publicly accessible website. This could be a static website hosted in S3, or it could be a dynamically generated website hosted in EC2. In fact, your website doesn't even need to be hosted in AWS in order to use CloudFront. As long as your website is publicly accessible, you should be good to go.</p>
<p>You'll also need to have the ability to modify the DNS records for your website. Instead of pointing to your web server (or S3 bucket), we'll eventually point them to CloudFront.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">About dynamic content</h1>
            </header>

            <article>
                
<p>If your website consists of mostly dynamic content, you can still benefit from implementing CloudFront.</p>
<p>First of all, CloudFront will maintain a pool of persistent connections with your origin servers. This lessens the time it takes for files to be served to your users because the number of three-way handshakes they'll need to perform is reduced.</p>
<p>Second, CloudFront implements some additional optimizations around TCP connections for high performance. More data is able to initially be transferred over the wire because CloudFront uses a wider initial TCP window.</p>
<p>Finally, implementing a CDN such as CloudFront <em>does</em> give you the opportunity to review your caching strategy and how you use cache-control headers. If your home page is dynamically generated, you'll get some benefit straight away by serving it via CloudFront, but the benefits will be much greater if you were to let CloudFront cache it for a few minutes. Again, cost, end user, and backend performance are all things you should take into consideration.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Configuring CloudFront distributions</h1>
            </header>

            <article>
                
<p>Distributions can be configured with a fairly wide array of options. Our recipe is going to be quite simple so that you can get up and running as quickly as possible. But we will talk through some of the more common configuration options:</p>
<ul>
<li><span class="packt_screen">Origins</span>: A distribution needs to have at least one origin. An origin, as the name indicates, is where your website content originates from your public-facing website. The properties you'll most likely be concerned with are:
<ul>
<li><span class="packt_screen">Origin Domain Name</span>: This is the hostname of your public-facing website. The CloudFormation template we supply accepts this hostname as a parameter.</li>
<li><span class="packt_screen">Origin Path</span>: It's possible to configure the distribution to fetch content from a directory or subfolder at the origin, for example, <kbd>/content/images</kbd> if you were using CloudFront to cache images only. In our case, we are caching our entire website, so we don't specify an <span class="packt_screen">Origin Path</span> at all.</li>
</ul>
</li>
<li style="list-style-type: none">
<ul>
<li><span class="packt_screen">Origin ID</span>: This is particularly important when you are using nondefault cache behavior settings and therefore have configured multiple origins. You need to assign a unique ID to the origins so that the cache behaviors know which origin to target. There'll be more discussion on cache behaviors later.</li>
<li><span class="packt_screen">HTTP Port, HTTPS Port</span>: If your origin is listening on nonstandard ports for HTTP or HTTPS, you would use these parameters to define those ports.</li>
<li><span class="packt_screen">Origin Protocol Policy</span>: You are able to configure the distribution to talk to your origin via:
<ul>
<li><span class="packt_screen">HTTP Only</span></li>
<li><span class="packt_screen">HTTPS Only</span></li>
<li><span class="packt_screen">Match Viewer</span></li>
</ul>
</li>
</ul>
</li>
</ul>
<p style="padding-left: 150px">The <span class="packt_screen">Match Viewer</span> option forwards requests to the origin based on which protocol the user requested with in their browser. Again, we are keeping things quite simple in this recipe, so we'll be opting for <span class="packt_screen">HTTP Only</span>.</p>
<ul>
<li><span class="packt_screen">Logging</span>: Keep in mind that because less traffic will be hitting your origin, fewer access logs will also be captured. It makes sense to have CloudFront keep these logs for us in an S3 bucket. This is included in the CloudFormation provided with this recipe:
<ul>
<li><strong>Cache behaviors</strong>: In this recipe, we'll configure a single (default) cache behavior, which will forward all requests to our origin.</li>
<li><strong>CloudFront</strong>: It allows you to get quite fine grained with the behaviors you configure. You might, for example, want to apply a rule to all the <kbd>.js</kbd> and <kbd>.css</kbd> files on your origin. Perhaps you want to forward query strings to the origin for these file types. Similarly, you might want to ignore the TTL the origin is trying to set for image files, instead telling CloudFront to cache for a minimum of 24 hours.</li>
</ul>
</li>
<li><span class="packt_screen">Aliases</span>: These are additional hostnames you want the distribution to serve traffic for. For example, if your <span class="packt_screen">Origin Domain Name</span> is configured to <kbd>loadbalancer.example.org</kbd>, then you probably want aliases that look something like this:
<ul>
<li><kbd><span class="URLPACKT">example.org</span></kbd></li>
<li><kbd>www.example.org</kbd></li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">  The CloudFormation template provided with this recipe expects one or more<br/>
  aliases to be provided in the form of a comma-delimited list of strings.</p>
<ul>
<li><span class="packt_screen">Allowed HTTP Methods</span>: By default, CloudFront will only forward <span class="packt_screen">GET</span> and <span class="packt_screen">HEAD</span> requests to your origin. This recipe doesn't change those defaults, so we don't declare this parameter in the provided template. If your origin is serving dynamically generated content, then you will likely want to declare this parameter and set its values to <span class="packt_screen">GET</span>, <span class="packt_screen">HEAD</span>, <span class="packt_screen">OPTIONS</span>, <span class="packt_screen">PUT</span>, <span class="packt_screen">POST</span>, <span class="packt_screen">PATCH</span>, and <span class="packt_screen">DELETE</span>.</li>
<li>TTLs (minimum/maximum/default): You can optionally define how long you'd like objects to stay in CloudFront's caches before expiring and being refetched from the origin. Again, we've opted to stick to CloudFront's default values to keep this recipe simple, so we've omitted this parameter from our template. The defaults are as follows:
<ul>
<li><span class="packt_screen">Minimum TTL</span>: 0 seconds</li>
<li><span class="packt_screen">Default TTL</span>: 1 day</li>
<li><span class="packt_screen">Maximum TTL</span>: 1 year</li>
</ul>
</li>
<li><span class="packt_screen">Price Class</span>: By default, CloudFront will serve your content from all of its edge locations, giving you the maximum performance possible. We're going to deploy our distribution using the lowest possible price class, <span class="packt_screen">Price Class </span><em>100</em>. This corresponds to edge locations in the United States, Canada, and Europe. Users from Australia would not benefit too much from this <span class="packt_screen">Price Class</span>, but you're also paying less for it. <span class="packt_screen">Price Class </span><em>200</em> adds Asian regions, and <span class="packt_screen">Price Class </span><em>All</em> adds South America and Australia.</li>
</ul>
<div class="packt_infobox">A comprehensive list and detailed explanation on which values can be specified when creating a CloudFront distribution can be found here at <span class="URLPACKT"><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html</a>.</span></div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The first (and only) thing we need to do is configure a CloudFront distribution as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" height="363" src="assets/image_03_003.png" width="440"/></div>
<ol>
<li>Create a new CloudFormation template and add the following code:</li>
</ol>
<pre>
      AWSTemplateFormatVersion: '2010-09-09'<br/>      Parameters:<br/>        OriginDomainName:<br/>          Description: The hostname of your origin<br/>           (i.e. www.example.org.s3-website-ap-southeast-2.amazonaws.com)<br/>          Type: String<br/>        Aliases:<br/>          Description: Comma delimited list of aliases<br/>           (i.e. example.org,www.example.org)<br/>          Type: CommaDelimitedList<br/>      Resources:<br/>        DistributionALogBucket:<br/>          Type: AWS::S3::Bucket<br/>        DistributionA:<br/>          Type: AWS::CloudFront::Distribution    <br/>          Properties:<br/>            DistributionConfig:<br/>              Origins:<br/>              - DomainName:<br/>                  Ref: OriginDomainName<br/>                Id: OriginA<br/>                CustomOriginConfig:<br/>                  OriginProtocolPolicy: http-only<br/>              Enabled: true<br/>              Logging:<br/>                IncludeCookies: false<br/>                Bucket:<br/>                  Fn::GetAtt: DistributionALogBucket.DomainName<br/>                Prefix: cf-distribution-a<br/>              Aliases:<br/>                Ref: Aliases<br/>              DefaultCacheBehavior:<br/>                TargetOriginId: OriginA<br/>                ForwardedValues:<br/>                  QueryString: false<br/>                ViewerProtocolPolicy: allow-all<br/>              PriceClass: PriceClass_100<br/>      Outputs:<br/>        DistributionDomainName:<br/>          Description: The domain name of the CloudFront Distribution<br/>          Value:<br/>            Fn::GetAtt: DistributionA.DomainName<br/>        LogBucket:<br/>          Description: Bucket where CloudFront logs will be stored<br/>          Value:<br/>            Ref: DistributionALogBucket
</pre>
<ol start="2">
<li>Using the template we created above, go ahead and create your CloudFront distribution. Expect to wait around 20-25 minutes for this stack to finish creating. It takes a while for your distribution configuration to be pushed out to all the AWS CloudFront locations:</li>
</ol>
<pre>
<strong>        aws cloudformation create-stack \ </strong><br/><strong>          --stack-name cloudfont-cache-1 \ </strong><br/><strong>          --template-body file://03-caching-a-website.yaml \  </strong><br/><strong>          --parameters \ </strong><br/><strong>          ParameterKey=OriginDomainName,ParameterValue=&lt;your-domain-name&gt; \ </strong><br/><strong>          ParameterKey=Aliases,ParameterValue='&lt;alias-1&gt;\,&lt;alias-2&gt;'</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Working with network storage</h1>
            </header>

            <article>
                
<p>In this recipe, we will use the Amazon EFS to provide network-based storage to instances.</p>
<p>Some of the benefits of using EFS compared to other AWS services are as follows:</p>
<ul>
<li>Guaranteed write order between distributed clients</li>
<li>Automatic resizing—no need to preallocate and no need to downsize</li>
<li>You only pay for the space you use (per GB)—no transfer or extra costs</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>This example works with the default VPC and subnets, present in all AWS accounts when they are created. Even if you have changed you network configuration, all you need is a working VPC with two or more subnets in different AZs for this recipe.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>Open your favorite text editor, and start a new CloudFormation template by defining the <kbd>AWSTemplateFormatVersion</kbd> and <kbd>Description</kbd>:</li>
</ol>
<pre>
        AWSTemplateFormatVersion: "2010-09-09" <br/>        Description: Create an EFS file system and endpoints.
</pre>
<ol start="2">
<li>Create a top-level <kbd>Parameters</kbd> section, and define the required parameters, <kbd>VpcId</kbd> and <kbd>SubnetIds</kbd>, inside it:</li>
</ol>
<pre>
        VpcId: <br/>          Description: VPC ID that contains the subnets that will <br/>            access the file system <br/>          Type: AWS::EC2::VPC::Id <br/>        SubnetIds: <br/>          Description: Subnet IDs allowed to access the EFS file system <br/>          Type: List&lt;AWS::EC2::Subnet::Id&gt;
</pre>
<ol start="3">
<li>Create a top-level <kbd>Resources</kbd> property, which will contain all the resources defined.</li>
</ol>
<ol start="4">
<li>Under the <kbd>Resources</kbd> property, add the <kbd>EFS</kbd> filesystem resource:</li>
</ol>
<pre>
        FileSystem: <br/>          Type: AWS::EFS::FileSystem <br/>          Properties: <br/>            FileSystemTags: <br/>              - Key: Name <br/>                Value: <br/>                  Fn::Sub: "${AWS::StackName} EFS File System" <br/>            PerformanceMode: generalPurpose
</pre>
<ol start="5">
<li>Add mount target resources for connecting to the filesystem you just created:</li>
</ol>
<pre>
      MountTargetA: <br/>        Type: AWS::EFS::MountTarget <br/>        Properties: <br/>          FileSystemId: <br/>            Ref: FileSystem <br/>          SecurityGroups: <br/>            - Fn::GetAtt: MountTargetSecurityGroup.GroupId <br/>          SubnetId: <br/>            Fn::Select: [ 0, Ref: SubnetIds  ] <br/>      MountTargetB: <br/>        Type: AWS::EFS::MountTarget <br/>        Properties: <br/>          FileSystemId: <br/>            Ref: FileSystem <br/>          SecurityGroups: <br/>            - Fn::GetAtt: MountTargetSecurityGroup.GroupId <br/>          SubnetId: <br/>            Fn::Select: [ 1, Ref: SubnetIds  ]           
</pre>
<ol start="6">
<li>Create a security group to control access to the mount targets:</li>
</ol>
<pre>
      MountTargetSecurityGroup: <br/>        Type: AWS::EC2::SecurityGroup <br/>        Properties: <br/>          GroupDescription: EFS endpoint security group <br/>          Tags: <br/>            - Key: Name <br/>              Value: MountTargetSecurityGroup <br/>          VpcId: <br/>            Ref: VpcId
</pre>
<ol start="7">
<li>Create a security group to access the mount target security group you created in the previous step:</li>
</ol>
<pre>
      MountTargetAccessSecurityGroup: <br/>        Type: AWS::EC2::SecurityGroup <br/>        Properties: <br/>          GroupDescription: EFS endpoint access security group <br/>        Tags: <br/>          - Key: Name <br/>            Value: MountTargetAccessSecurityGroup <br/>        VpcId: <br/>          Ref: VpcId
</pre>
<ol start="8">
<li>Define the ingress and egress rules for the mount target security group:</li>
</ol>
<pre>
      MountTargetIngress: <br/>        Type: AWS::EC2::SecurityGroupIngress <br/>        Properties: <br/>          FromPort: 2049 <br/>          GroupId: <br/>            Fn::GetAtt: MountTargetSecurityGroup.GroupId <br/>          IpProtocol: tcp <br/>          SourceSecurityGroupId: <br/>            Fn::GetAtt: MountTargetAccessSecurityGroup.GroupId <br/>          ToPort: 2049 <br/>      MountTargetEgress: <br/>        Type: AWS::EC2::SecurityGroupEgress <br/>        Properties: <br/>          DestinationSecurityGroupId: <br/>            Fn::GetAtt: MountTargetAccessSecurityGroup.GroupId <br/>          FromPort: 2049 <br/>          GroupId: <br/>            Fn::GetAtt: MountTargetSecurityGroup.GroupId <br/>          IpProtocol: tcp <br/>          ToPort: 2049
</pre>
<ol start="9">
<li>Define the ingress and egress rules for the mount target access security group:</li>
</ol>
<pre>
      MountTargetAccessIngress: <br/>        Type: AWS::EC2::SecurityGroupIngress <br/>        Properties: <br/>          FromPort: 22 <br/>          GroupId: <br/>            Fn::GetAtt: MountTargetAccessSecurityGroup.GroupId <br/>          IpProtocol: tcp <br/>          CidrIp: 0.0.0.0/0 <br/>          ToPort: 22 <br/>      MountTargetAccessEgress: <br/>        Type: AWS::EC2::SecurityGroupEgress <br/>        Properties: <br/>          DestinationSecurityGroupId: <br/>            Fn::GetAtt: MountTargetSecurityGroup.GroupId <br/>          FromPort: 2049 <br/>          GroupId: <br/>            Fn::GetAtt: MountTargetAccessSecurityGroup.GroupId <br/>          IpProtocol: tcp <br/>          ToPort: 2049
</pre>
<ol start="10">
<li>Save your template with the name <kbd>03-working-with-network-storage.yaml</kbd>.</li>
<li>Launch the CloudFormation stack with the following AWS CLI command, substituting your own VPC ID and subnet IDs:</li>
</ol>
<pre>
<strong>      aws cloudformation create-stack \</strong><br/><strong>        --stack-name wwns1 \</strong><br/><strong>        --template-body file://03-working-with-network-storage.yaml \</strong><br/><strong>        --parameters \</strong><br/><strong>        ParameterKey=VpcId,ParameterValue=&lt;your-vpc-id&gt; \  </strong><br/><strong>        ParameterKey=SubnetIds,ParameterValue="&lt;subnet-id-1&gt;\, \<br/>          &lt;subnet-id-2&gt;"</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Here is what the created resources will look like at the end of the recipe:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="328" src="assets/image_03_004.png" width="520"/></div>
<div class="packt_figure CDPAlignCenter CDPAlign packt_figref">Working with network storage</div>
<p>We start by creating the standard CloudFormation template properties in step 1.</p>
<p>In step 2, you define the template's parameters that will be used when configuring the resources.</p>
<p>Steps 3 and 4 are where the EFS resources are specified. They consist of an EFS filesystem and mount targets in each of the AZs that will access it.</p>
<p>We then create the security groups in steps 5 and 6: one for the mount targets and one for the instances that are allowed to connect to the mount targets.</p>
<p>As these two security groups contain two-way (or circular) references to each other, we must define the rules between them in separate resources in steps 7 and 8.</p>
<p>In step 9, you save the template with a specific filename so that it can be referenced in the command to launch the stack in step 10.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>To confirm that your EFS filesystem, mount targets, and security groups are working, you can also provision some client instances to connect to them. Add the following resources and parameters to the template you have already created:</p>
<ol>
<li>Add the following parameters to your top-level <kbd>Parameters</kbd> section to configure your instances:</li>
</ol>
<pre>
      MountPoint: <br/>        Description: The path on disk to mount the EFS file system <br/>        Type: String <br/>        Default: /mnt/efs <br/>      KeyName: <br/>        Description: The SSH key pair allowed to connect to the client <br/>          instance <br/>        Type: AWS::EC2::KeyPair::KeyName
</pre>
<ol start="2">
<li>Add an <kbd>AutoScalingGroup</kbd> under the <kbd>Resources</kbd> section; regardless of which AZ your servers are provisioned to, they will have access to the <kbd>EFS</kbd> filesystem via the local mount point:</li>
</ol>
<pre>
      AutoScalingGroup: <br/>        Type: AWS::AutoScaling::AutoScalingGroup <br/>        DependsOn: MountTargetA <br/>        Properties: <br/>          MinSize: 2 <br/>          MaxSize: 2 <br/>          LaunchConfigurationName: <br/>            Ref: LaunchConfiguration <br/>          Tags: <br/>            - Key: Name <br/>              Value: <br/>                Fn::Sub: "${AWS::StackName} EFS Client" <br/>              PropagateAtLaunch: true <br/>          VPCZoneIdentifier: <br/>            Ref: SubnetIds
</pre>
<ol start="3">
<li>Still in the <kbd>Resources</kbd> section, add a launch configuration:</li>
</ol>
<pre>
      LaunchConfiguration: <br/>        Type: AWS::AutoScaling::LaunchConfiguration <br/>        DependsOn: FileSystem <br/>        Properties: <br/>          ImageId: ami-1e299d7e <br/>        SecurityGroups: <br/>          - Ref: MountTargetAccessSecurityGroup <br/>        InstanceType: t2.micro <br/>        KeyName: <br/>          Ref: KeyName <br/>        UserData: <br/>          Fn::Base64: <br/>          Fn::Sub: |<br/>            #!/bin/bash -xe<br/>            mkdir -p ${MountPoint}<br/>            echo 'Waiting for mount target DNS to propagate'<br/>            sleep 90<br/>            echo '${FileSystem}.efs.${AWS::Region}.amazonaws.com:/<br/>            ${MountPoint} nfs4<br/>            nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,<br/>            retrans=2 0 0' &gt;&gt; <br/>            /etc/fstab<br/>            mount -a\nchown ec2-user: ${MountPoint}\n"
</pre>
<ol start="4">
<li>Launch the CloudFormation stack with the following AWS CLI command, substituting your own parameter values:</li>
</ol>
<pre>
<strong>      aws cloudformation create-stack \ </strong><br/><strong>        --stack-name wwns1 \</strong><br/><strong>        --template-body file://03-working-with-network-storage.yaml \</strong><br/><strong>        --parameters \</strong><br/><strong>        ParameterKey=VpcId,ParameterValue=&lt;vpc-id&gt; \</strong><br/><strong>        ParameterKey=SubnetIds,ParameterValue='&lt;subnet-id-1&gt;\, \<br/>          &lt;subnet-id-1&gt;' \  </strong><br/><strong>        ParameterKey=MountPoint,ParameterValue=&lt;local-path-to-mount-efs&gt; \</strong><br/><strong>        ParameterKey=KeyName,ParameterValue=&lt;existing-key-pair-name&gt;</strong>
</pre>
<p>             Once the new stack is ready, you will be able to SSH to your instances and verify  <br/>
             that they have mounted the EFS filesystem.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Backing up data for compliance</h1>
            </header>

            <article>
                
<p>We work with a lot of companies (especially in the finance industry) that have strict rules around the minimum time data needs to be kept for. This can become quite onerous and expensive if you need to keep customer records for a minimum of 7 years, for example.</p>
<p>Using S3, Glacier, and life cycle rules, we can create a flexible long-term backup solution while also automating the archiving and purging of backups and reducing costs.</p>
<p>We are also going to utilize <em>versioning</em> in order to mitigate the damaged caused by a file being accidentally deleted or overwritten in our backup bucket.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>First, we need to define a few parameters:
<ul>
<li><kbd>ExpirationInDays</kbd>: This is the maximum amount of time we want to have our files kept in backup for. We've set a default for this value of 2,555 days (7 years).</li>
<li><kbd>TransitionToInfrequentAccessInDays</kbd>: After a backup has been copied to S3, we want to move it to the <em>infrequently accessed</em> class to reduce our costs. This doesn't affect the durability of the backup, but it does have a small impact on its availability. We'll set this to 30 days.</li>
<li><kbd>TransitionToGlacierInDays</kbd>: After the backup has been kept in the infrequently accessed class for a while, we want to move it to Glacier. This again helps us reduce our costs at the expense of retrieval times. If we need to fetch a backup from Glacier, the wait time will be approximately 3-5 hours. We'll set the default for this to 60 days.</li>
<li><kbd>PreviousVersionsExpirationInDays</kbd>: Given that we will have versioning enabled on our bucket, we want to make sure old versions of files aren't kept forever—we're using this feature only to mitigate accidents. We'll set this value to 60 days, which gives us more than enough time to identify and recover from an accidental deletion or overwrite.</li>
<li><kbd>PreviousVersionsToInfrequentAccessInDays</kbd>: Just like our other backup files, we want to move our old versions to the infrequently accessed class after a period of time in order to minimize costs. We'll set this to 30 days:</li>
</ul>
</li>
</ol>
<pre>
               AWSTemplateFormatVersion: '2010-09-09'<br/>               Parameters:<br/>                 ExpirationInDays:<br/>                   Description: The maximum amount of time to keep files<br/>                     for<br/>                   Type: Number<br/>                   Default: 2555<br/>                 TransitionToInfrequentAccessInDays:<br/>                   Description: How many days until files are moved to<br/>                     the Infrequent Access class<br/>                   Type: Number<br/>                   Default: 30<br/>                 TransitionToGlacierInDays:<br/>                   Description: How many days until files are moved<br/>                     to Glacier<br/>                   Type: Number<br/>                   Default: 60<br/>                 PreviousVersionsExpirationInDays:<br/>                   Description: The maximum amount of time to keep previous<br/>                     versions of files for<br/>                   Type: Number<br/>                   Default: 60<br/>                 PreviousVersionsToInfrequentAccessInDays:<br/>                   Description: How many days until previous versions<br/>                     of files are moved to the Infrequent Access class<br/>                   Type: Number<br/>                   Default: 30
</pre>
<ol start="2">
<li>Next, we'll need to create the S3 bucket to store our backups in. Note that we're omitting the <kbd>name</kbd> property for this bucket in order to avoid bucket name conflicts and maximize region portability. We're also enabling versioning and adding our life cycle rules from our previous <kbd>Parameters</kbd>:</li>
</ol>
<pre>
      Resources: <br/>        BackupBucket: <br/>          Type: AWS::S3::Bucket <br/>          Properties: <br/>            VersioningConfiguration: <br/>              Status: Enabled <br/>            LifecycleConfiguration: <br/>              Rules: <br/>                - Status: Enabled <br/>                  ExpirationInDays: <br/>                    Ref: ExpirationInDays <br/>                  Transitions: <br/>                    - StorageClass: STANDARD_IA <br/>                      TransitionInDays: <br/>                        Ref: TransitionToInfrequentAccessInDays <br/>                    - StorageClass: GLACIER <br/>                      TransitionInDays: <br/>                        Ref: TransitionToGlacierInDays <br/>                    NoncurrentVersionExpirationInDays: <br/>                      Ref: PreviousVersionsExpirationInDays <br/>                    NoncurrentVersionTransitions: <br/>                    - StorageClass: STANDARD_IA <br/>                      TransitionInDays: <br/>                        Ref: PreviousVersionsToInfrequentAccessInDays
</pre>
<ol start="3">
<li>Finally, let's add an output so we know which bucket to store our backups in:</li>
</ol>
<pre>
      Outputs: <br/>        BackupBucket: <br/>          Description: Bucket where backups are stored <br/>          Value: <br/>            Ref: BackupBucket
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Go ahead and launch this CloudFormation stack. If you're happy with the default values for the parameters, you don't need to provide them with the CLI command:</p>
<pre>
<strong>aws cloudformation create-stack \</strong><br/><strong>  --stack-name backup-s3-glacier-1 \</strong><br/><strong>  --template-body file://03-backing-up-data-for-compliance.yaml</strong>
</pre>
<p>Once the stack has been created, you'll be all set to start copying backups to the S3 bucket and to start worrying less about your backups' life cycle and management. If you decide that the expiry or transition times need to change after you've created the bucket, you can do this by simply updating the parameters for the stack.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>