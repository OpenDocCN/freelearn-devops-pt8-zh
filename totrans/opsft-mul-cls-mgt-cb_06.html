<html><head></head><body>
		<div id="_idContainer106">
			<h1 id="_idParaDest-105" class="chapter-number"><a id="_idTextAnchor113"/>6</h1>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor114"/>OpenShift Troubleshooting, Performance, and Best Practices</h1>
			<p>The concepts explained in <a href="B18015_05.xhtml#_idTextAnchor090"><em class="italic">Chapter 5</em></a>, <em class="italic">OpenShift Deployment</em>, provided the foundation for you to initiate your first contact with an OpenShift cluster. In this chapter, we will give some tips on how to perform a health check on a cluster, dive into some <strong class="bold">root cause analysis</strong> (<strong class="bold">RCA</strong>), and also provide details on how to make a cluster run according to some best practices. Our intention with this chapter is to give you some general guidance about troubleshooting, however, it is important you always open a support ticket with Red Hat before making any changes in the platform due to troubleshooting attempts.</p>
			<p>This chapter covers the following topics:</p>
			<ul>
				<li>Things that can crash a cluster</li>
				<li>Troubleshooting reference guide—how to start</li>
				<li>Understanding misleading error messages</li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">The source code used in this chapter is available at <a href="https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter06">https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter06</a>.</p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor115"/>Things that can crash a cluster</h1>
			<p>Every time we start learning about some technology, it is common to be twice as careful with the installation, configuration, or adjustment to be as thorough as possible. Sometimes, to achieve these goals related to troubleshooting, performance, and best practices, the reader would turn to multiple expert readings on each of the related topics, or go through the pain of trial and error, which takes a lot of effort to succeed.</p>
			<p>OpenShift is a great and disruptive technology, but you will navigate through a puzzle of different aspects related to storage, compute, network, and others. Obviously, in the official documentation—or even in quick internet searches—you will find commands to start from scratch, but in many situations, even with the necessary commands and parameters, it is difficult to navigate from troubleshooting to a solution.</p>
			<p>Currently, OpenShift has an automatic<a id="_idIndexMarker391"/> recovery system, but this is usually not enough to ensure a stable environment. For this self-healing to take place successfully, many prerequisites need to be checked on the cluster first. So, before we understand what can potentially crash, let’s understand how this self-adjustment mechanism works.</p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor116"/>Operators</h2>
			<p>In the world of technology, there are <a id="_idIndexMarker392"/>many roles played, and some of them are linked to<a id="_idIndexMarker393"/> the administration of the infrastructure. There are several names for this role, the most common still being the <strong class="bold">system administrator</strong>, or <strong class="bold">sysadmin</strong>, who operates the servers and services of an <strong class="bold">information technology</strong> (<strong class="bold">IT</strong>) infrastructure. Likewise, OpenShift has <em class="italic">operators</em> that are nothing more than <strong class="bold">applications designed to monitor platform behavior and maintain an operation</strong>.</p>
			<p>How do operators work? Operators are assigned to fulfill a single task of maintaining the application and all its components according to a standard. Understand that operators are not the same for all applications—that is, operators are unique, each with its own parameter definitions, configurations that are required and optional, and others.</p>
			<p>The operator parameters’ contract is <a id="_idIndexMarker394"/>described in the <strong class="bold">Custom Resource Definition </strong>(<strong class="bold">CRD</strong>). A CRD is a definition that extends a Kubernetes <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) functionality, giving more flexibility to the cluster to store a collection of objects of a certain type. Once a CRD is defined, you can<a id="_idIndexMarker395"/> create a <strong class="bold">Custom Resource</strong> (<strong class="bold">CR</strong>) that will allow you to add a Kubernetes’ custom API to the cluster.</p>
			<p>Operators are a tool for keeping a cluster or application healthy, so why should we care about learning about OpenShift troubleshooting if it fixes itself? Indeed, operators are a powerful tool, but as we mentioned earlier, OpenShift is a big puzzle, and the pieces need to fit together perfectly for it to work properly. Although it is reigned by operators that are somehow prepared to maintain its integrity, failures can occur, and the role of the cluster administrator and their experience in solving problems will help keep all these operators healthy.</p>
			<p>In the next sections, we’ll go deeper into the main components of OpenShift and which aspects to be concerned about.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor117"/>etcd</h2>
			<p>In the case of <a id="_idIndexMarker396"/>OpenShift clusters, etcd is a distributed key-value service responsible for storing<a id="_idIndexMarker397"/> the state of the cluster. Through it, all objects contained in the cluster are shown in a key-value format, so it is important to consider at least three important factors in this service, which is the heart of the control plane’s operation. Note the following:</p>
			<ul>
				<li>etcd is <em class="italic">highly sensitive</em> to an infrastructure’s <strong class="bold">latency</strong> and <strong class="bold">bandwidth</strong>.</li>
				<li>etcd needs to be distributed on all master nodes—that is, to be highly available, an OpenShift cluster infrastructure demands this service be distributed on three master nodes.</li>
				<li>Unlike many <strong class="bold">high-availability</strong> (<strong class="bold">HA</strong>) services, in <a id="_idIndexMarker398"/>which you have a main and a secondary server, with etcd, this concept is based on <strong class="bold">quorum</strong>  members <a id="_idIndexMarker399"/>and <strong class="bold">leadership</strong>.</li>
			</ul>
			<p>Red Hat made the etcd complexity easier by establishing the number of master nodes to be <strong class="source-inline">3</strong> as default and also by using a cluster operator that manages etcd and reports any issue in it; however, you must still understand how etcd works to be able to troubleshoot if any complex issue occurs. Go ahead to learn how the quorum and leader-based etcd algorithm works.</p>
			<h3>How do the quorum and leader-based schemes work?</h3>
			<p>An etcd cluster works on the concept of <strong class="bold">leader</strong> and <strong class="bold">followers</strong>, which is known as the <strong class="bold">Raft Distributed Consensus</strong> protocol. This<a id="_idIndexMarker400"/> protocol implements an algorithm based on a <em class="italic">leader election</em> to establish a distributed consensus among all members of an etcd cluster. Once members are added to<a id="_idIndexMarker401"/> an etcd cluster and a leader is elected, the process only requires sending periodic heartbeats to confirm that the leader still responds within a suitable latency time.</p>
			<p>In case of an unanswered heartbeat time frame, the members start a new election to guarantee cluster resilience, self-healing, and continuity of service.</p>
			<p>It is recommended that an etcd cluster has an odd number of nodes so that the following formula guarantees the tolerance of a given number of failing members. To this we give the name of <strong class="bold">quorum</strong>:</p>
			<p><em class="italic">Quorum = (n/2)+1, where “n” represents the number of members.</em></p>
			<p>A cluster must always have at least the <em class="italic">quorum</em> number of members working to be functioning properly. For the <a id="_idIndexMarker402"/>sake of clarity, let’s check out some scenarios, as follows:</p>
			<ul>
				<li><strong class="bold">Scenario 1</strong>: Three-member cluster, all up and running, as illustrated in the following diagram:</li>
			</ul>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/B18015_06_01.jpg" alt="Figure 6.1 – Healthy etcd cluster (three-node member health) "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Healthy etcd cluster (three-node member health)</p>
			<p><em class="italic">Analysis</em>: Quorum is OK as there are a majority of working members and leadership is assured, so the cluster is healthy.</p>
			<ul>
				<li><strong class="bold">Scenario 2</strong>: Three-member cluster with two members working, as illustrated in the following diagram:</li>
			</ul>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/B18015_06_02.jpg" alt="Figure 6.2 – Healthy etcd cluster (two-node member health; risk of outage) "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Healthy etcd cluster (two-node member health; risk of outage)</p>
			<p><em class="italic">Analysis</em>: Quorum is OK as there are a majority of working members and leadership is assured. There is a degradation risk in case of disruption of one more node, but the<a id="_idIndexMarker403"/> cluster is healthy.</p>
			<ul>
				<li><strong class="bold">Scenario 3</strong>: Three-member cluster with one member working, as illustrated in the following diagram:</li>
			</ul>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="image/B18015_06_03.jpg" alt="Figure 6.3 – Degraded etcd cluster (one-node member health; unhealthy cluster) "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Degraded etcd cluster (one-node member health; unhealthy cluster)</p>
			<p><em class="italic">Analysis</em>: There is no quorum as the majority of members are down, so it is no longer possible to elect a <a id="_idIndexMarker404"/>new leader, and the cluster is degraded.</p>
			<h3>Troubleshooting etcd</h3>
			<p>As mentioned earlier, OpenShift is <a id="_idIndexMarker405"/>managed by its operators, which can provide standardization, self-healing, and activities metrics, but this is not always enough to keep the cluster fully functional.</p>
			<p>Situations such as scenarios <em class="italic">2</em> and <em class="italic">3</em> can occur due to different factors related to any infrastructure layer. It is important to carry out an in-depth analysis to restore the cluster to a functional state. Here’s an approach to troubleshooting etcd.</p>
			<p>For troubleshooting, it is important to consider what kind of disruption the cluster has been hit with. If we are still able to use the OpenShift API to access the nodes, you can use the first approach. Otherwise, if the API is unavailable, you must refer to the second scenario.</p>
			<h4>Scenario 1 – etcd member is degraded</h4>
			<p>In cases where it is still<a id="_idIndexMarker406"/> possible to execute <strong class="source-inline">oc</strong> or <strong class="source-inline">kubectl</strong> commands, use the <strong class="source-inline">rsh</strong> command to the etcd pod, and performing the following steps through <strong class="source-inline">etcdctl</strong> is the quickest approach.</p>
			<p>An etcd degradation can occur for many different reasons, such as storage or network failures, live migration of the master nodes, or even manipulations in the <strong class="bold">operating system</strong> (<strong class="bold">OS</strong>), which may cause immediate disruption of the cluster.</p>
			<p>As mentioned before, run the following commands to open a terminal in an etcd pod and identify the failure:</p>
			<pre class="source-code">$ oc project openshift-etcd
$ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd
etcd-ocp-master-0 3/3 Pending 0 14m
etcd-ocp-master-1 3/3 CrashLoopBackOff 6 17m
etcd-ocp-master-3 2/3 Running 0 9m11s</pre>
			<p>Notice that in the previous output, two out of three masters are getting issues, so let’s <strong class="source-inline">rsh</strong> to <strong class="source-inline">master-3</strong>, perform a<a id="_idIndexMarker407"/> backup, and recreate the etcd nodes, as follows:</p>
			<pre class="source-code">oc rsh etcd-ocp-master-3
Defaulting container name to etcdctl.
Use 'oc describe pod/etcd-ocp-master-3 -n openshift-etcd' to see all of the containers in this pod.
sh-4.4# etcdctl member list -w table
+------+------+------+------+------+------+
| ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER +------+------+------+------+------+------+
| <strong class="bold">5bdacda4e0f48d91</strong> | <strong class="bold">failed</strong> | ocp-master-1 | https://192.168.200.235:2380 | https://192.168.200.235:2379 | false |
| <strong class="bold">b50b656cba1b0122</strong> | <strong class="bold">started</strong> | ocp-master-3 | https://192.168.200.14:2380 | https://192.168.200.14:2379 | false |
| <strong class="bold">cdc9d2f71033600a</strong> | <strong class="bold">failed</strong> | ocp-master-0 | https://192.168.200.234:2380 | https://192.168.200.234:2379 | false |
+------+------+------+------+------+------+
sh-4.4# etcdctl endpoint status -w table
+------+------+------+------+------+------+
| ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+------+------+------+------+------+------+
| https://192.168.200.14:2379 | <strong class="bold">b50b656cba1b0122</strong> | 3.4.9 | 136 MB | true | false | 281 | 133213554 | 133213554 | |
| https://192.168.200.234:2379 | <strong class="bold">cdc9d2f71033600a</strong> | 3.4.9 | 137 MB | false | false | 281 | 133213554 | 133213554 | |
| https://192.168.200.235:2379 | <strong class="bold">5bdacda4e0f48d91</strong> | 3.4.9 | 136 MB | false | false | 281 | 133213554 | 133213554 | |
+------+------+------+------+------+------+</pre>
			<p>Once the <strong class="bold">identifiers</strong> (<strong class="bold">IDs</strong>) of the failed members are determined, the next step is to remove the etcd members, leaving<a id="_idIndexMarker408"/> only the one that is running as part of the cluster. To do so, first run the backup of etcd, like so:</p>
			<pre class="source-code">/usr/local/bin/cluster-backup.sh /home/core/assets/backup</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The etcd backup will be saved in the <strong class="source-inline">home</strong> directory of the <strong class="source-inline">core</strong> user in the same node as the one where the etcd pod is running. It is highly recommended you copy it to an off-node location as this will avoid the risk of losing access to the node and, as such, losing the etcd backup file and putting the cluster recovery at risk.</p>
			<p>Now that you have already identified the problem with the etcd cluster, see next the suggested steps to recover your cluster.</p>
			<h4>How to solve it? </h4>
			<p>Formerly, on<a id="_idIndexMarker409"/> OpenShift version 3, the usual solution for both cases was reestablishing the etcd cluster using a backup. Now, with OpenShift 4, it is easier to provision new master nodes in your infrastructure. That said, if your issue is the first scenario (API is still available) and your installation is the <strong class="bold">installer-provisioned infrastructure</strong> (<strong class="bold">IPI</strong>) method, we <a id="_idIndexMarker410"/>suggest you take the following steps to recreate the problematic master node, using a new node name:</p>
			<ol>
				<li>Get the <strong class="bold">YAML Ain’t Markup Language</strong> (<strong class="bold">YAML</strong>) machine descriptor for any current master node by running the <a id="_idIndexMarker411"/>following command:<p class="source-code">oc get machine &lt;master-node&gt; \</p><p class="source-code">    -n openshift-machine-api \</p><p class="source-code">    -o yaml \</p><p class="source-code">    &gt; new-master-machine.yaml</p></li>
				<li>The YAML file <a id="_idIndexMarker412"/>should look like this:<p class="source-code"><strong class="bold">new-master-machine.yaml</strong></p><p class="source-code">apiVersion: machine.openshift.io/v1beta1</p><p class="source-code">kind: Machine</p><p class="source-code">metadata:</p><p class="source-code">  finalizers:</p><p class="source-code">  - machine.machine.openshift.io</p><p class="source-code">  labels:</p><p class="source-code">    machine.openshift.io/cluster-api-cluster: ocp-sgw5f</p><p class="source-code">(.. omitted ..)</p><p class="source-code">  name: ocp-master-4</p><p class="source-code">  namespace: openshift-machine-api</p><p class="source-code">  selfLink: /apis/machine.openshift.io/v1beta1/namespaces/openshift-machine-api/machines/ocp-master-4</p><p class="source-code">spec:</p><p class="source-code">  metadata: {}</p><p class="source-code">  providerSpec:</p><p class="source-code">    value:</p><p class="source-code">      apiVersion: vsphereprovider.openshift.io/v1beta1</p><p class="source-code">      credentialsSecret:</p><p class="source-code">        name: vsphere-cloud-credentials</p><p class="source-code">      diskGiB: 120</p><p class="source-code">      kind: VSphereMachineProviderSpec</p><p class="source-code">(.. omitted ..)</p></li>
				<li>Make the required changes in the YAML file to provision the new master, as follows:<ol><li>Remove the<a id="_idIndexMarker413"/> following sections or fields:</li>
</ol><ol><li value="1">Entire <strong class="source-inline">status</strong>, <strong class="source-inline">metadata.annotations</strong>, and <strong class="source-inline">metadata.generation</strong> sections.</li>
<li>Delete <strong class="source-inline">metadata.resourceVersion</strong>, <strong class="source-inline">metadata.uid</strong>, and <strong class="source-inline">spec.providerId</strong> fields.</li>
</ol><p>II.	Change the <strong class="source-inline">metadata.name</strong> field to a new name (for example, <strong class="source-inline">&lt;clustername&gt;-&lt;clusterid&gt;-master-3</strong>).</p><ol><li value="3">Also update the node name in the <strong class="source-inline">metadata.selfLink</strong> field.</li>
</ol></li>
				<li>Delete the problematic master node using the following command:<p class="source-code">$ oc delete machine &lt;problematic-master-node-name&gt; -n openshift-machine-api</p></li>
				<li>Use the following command to monitor the deletion process and certify it has been deleted:<p class="source-code">$ oc get machines -n openshift-machine-api -o wide</p></li>
				<li>As soon as the problematic master has been deleted, you can now provision a new one using the YAML we prepared previously. To do so, run the following command:<p class="source-code">oc apply –f new-master-machine.yaml</p></li>
			</ol>
			<p class="callout-heading">Note</p>
			<p class="callout">Repeat this procedure if necessary, changing only the <strong class="source-inline">metadata.name</strong> and <strong class="source-inline">metadata.selfLink</strong> fields for each problematic master node in your cluster.</p>
			<p>After the new master nodes have been provisioned, observe the following steps to verify whether the etcd cluster<a id="_idIndexMarker414"/> is healthy:</p>
			<ol>
				<li value="1">Check if all etcd pods are running, as follows. You must see three pods running:<p class="source-code">$ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd</p></li>
				<li>There are some cases in which the etcd pod is not deployed automatically with the master provisioning. If you don’t see three pods running, you may run the following command to force the etcd operator to deploy the etcd pod in the new node:<p class="source-code">$ oc patch etcd cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge</p></li>
				<li>Now, let’s check from inside the etcd cluster whether it is working as expected. To do so, run the following command to open a terminal inside one of the etcd pods:<p class="source-code"># Get the name of one etcd pod</p><p class="source-code">$ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd</p><p class="source-code">$ oc rsh &lt;etcd-pod-name&gt; -n openshift-etcd</p></li>
				<li>Now, check the cluster member list, like so:<p class="source-code">etcdctl member list -w table</p></li>
				<li>In some cases, you will still see the problematic etcd node that we already removed as part of the cluster members. Therefore, if the previous command shows more than three members, use the following command to remove the nonfunctional etcd members:<p class="source-code">$ etcdctl remove &lt;member-id&gt;</p></li>
			</ol>
			<h4>Scenario 2 – cluster API down</h4>
			<p>If the OpenShift API is down, it is<a id="_idIndexMarker415"/> important to perform any steps with much more caution to avoid an irreversible loss to the cluster. In such a scenario, you can’t use the <strong class="source-inline">rsh</strong> command, get logs using <strong class="source-inline">oc logs</strong>, OR use any <strong class="source-inline">oc</strong> or <strong class="source-inline">kubectl</strong> command, as all of them use the OpenShift API, which makes troubleshooting and finding a solution much more difficult and complex.</p>
			<p>Due to that, there must be regular etcd backups in place before the cluster malfunctions. If there is no previous backup, the first step is to perform a direct backup on the node that is in operation. To do so, proceed as follows:</p>
			<ul>
				<li>Run the following command:<p class="source-code">$ ssh -i ~/.ssh/id_rsa core@ocp-master-3</p></li>
				<li>Check out the etcd state by running the <strong class="source-inline">crictl</strong> command, like so:<p class="source-code">$ sudo crictl | grep –i etcd</p></li>
				<li>Get the etcd pod ID and run the <strong class="source-inline">crictl exec</strong> statement to identify the cluster’s node state, as follows:<p class="source-code">$ crictl exec <strong class="bold">bd077a3f1b211</strong> etcdctl member list -w table</p><p class="source-code">+---+---+---+---+---+---+</p><p class="source-code">| ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER |</p><p class="source-code">+---+---+---+---+---+---+</p><p class="source-code">| 9e715067705c0f7c | <strong class="bold">unknown</strong> | ocp-master-4 | https://192.168.200.15:2380 | https://192.168.200.15:2379 | false |</p><p class="source-code">| b50b656cba1b0122 | <strong class="bold">started</strong> | ocp-master-3 | https://192.168.200.14:2380 | https://192.168.200.14:2379 | false |</p><p class="source-code">| cdc9d2f71033600a | <strong class="bold">failed</strong>  | ocp-master-0 | https://192.168.200.234:2380 | https://192.168.200.234:2379 | false |</p><p class="source-code">+---+---+---+---+---+---+</p></li>
				<li>Note that the etcd <a id="_idIndexMarker416"/>members are unreachable except for one that is in the started state. Run a backup by going to the node and running the backup command, as follows:<p class="source-code">sudo /usr/local/bin/cluster-backup.sh /home/core/assets/backup</p></li>
				<li>With the pod ID of etcd, obtained by <strong class="source-inline">crictl</strong>, run the following command to identify the cluster nodes and their state:<p class="source-code">$ crictl exec <strong class="bold">bd077a3f1b211 </strong>etcdctl endpoint status -w table</p><p class="source-code">+-------+-------+-------+-------+-------+-------+</p><p class="source-code">| ENDPOINT | ID | VERSION | DB SIZE | <strong class="bold">IS LEADER</strong> | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</p><p class="source-code">+-------+-------+-------+-------+-------+-------+</p><p class="source-code">| https://192.168.200.14:2379 | b50b656cba1b0122 | 3.4.9 | 136 MB | <strong class="bold">true </strong>| false | 491 | 133275501 | 133275501 | |</p><p class="source-code">| https://192.168.200.15:2379 | 9e715067705c0f7c | 3.4.9 | 137 MB | <strong class="bold">false</strong>| false | 491 | 133275501 | 133275501 | |</p><p class="source-code">+-------+-------+-------+-------+-------+-------+</p></li>
			</ul>
			<p>At this stage, it is possible<a id="_idIndexMarker417"/> to draw some conclusions. We understand that there is no minimum quorum to keep the cluster up, so the API became unavailable. Continue next for a suggestion on how to proceed in this scenario.</p>
			<h4>How to solve it?</h4>
			<p>In general, to restore a cluster in this scenario you will use the command <strong class="source-inline">etcdctl member remove</strong> to remove all problematic etcd members and then use the procedure we described in the previous <em class="italic">How to solve it?</em> section to remove problematic master nodes and provision new ones. However, troubleshooting a cluster in this scenario is much more challenging, work with Red Hat support to find the best way to restore it.</p>
			<p>Now that we have already gone through etcd troubleshooting, let’s discuss another important aspect of it: performance analysis.</p>
			<h3>etcd performance analysis</h3>
			<p>Kubernetes clusters are highly sensitive to latency and throughput. Due to this, some precautions are necessary <a id="_idIndexMarker418"/>to have a stable cluster and also great performance. OpenShift is<a id="_idIndexMarker419"/> a platform designed for HA, and, as such, the expected etcd use and consumption are traffic-intensive. It is important, then, to follow some best practices to have a stable cluster. Let’s look at some recommended configurations.</p>
			<h4>Storage</h4>
			<p>etcd’s disk <a id="_idIndexMarker420"/>usage is intensive, so it is recommended to use <strong class="bold">solid-state drive</strong> (<strong class="bold">SSD</strong>) disks <a id="_idIndexMarker421"/>for a fast write/read response time. Regarding response times, we could say that 50 sequential <strong class="bold">input/output operations per second</strong> (<strong class="bold">IOPS</strong>) would be a minimum requirement, but from our <a id="_idIndexMarker422"/>experience, the OpenShift usage grows really fast, so we recommend you consider disks that can deliver at least 500 concurrent IOPS, to maintain the cluster’s health and stability. However, note that some providers do not publish the sequential IOPS but only the shared IOPS. In such cases, consider that concurrent IOPS is equivalent to 10 times the sequential IOPS value.</p>
			<p>Here is an example of how to measure the performance of the etcd disks using a customized version of the <strong class="source-inline">fio</strong> tool. In the OpenShift cluster, run the <strong class="source-inline">debug</strong> command to get access to a master node, like so:</p>
			<pre class="source-code">$ oc debug node/master1.ocp.hybridcloud.com</pre>
			<p>As soon as the command is executed, the following message will be displayed. Execute the <strong class="source-inline">chroot</strong> command after the shell to be able to execute commands in privileged mode:</p>
			<pre class="source-code">Starting pod/ocp-master1hybridcloud-debug ...
 To use host binaries, run `chroot /host`
 chroot /host
Pod IP: 172.19.10.4
 If you don't see a command prompt, try pressing enter.
 sh-4.4# chroot /host
 sh-4.4#</pre>
			<p>Create a container, as indicated in the following code snippet. After the <strong class="source-inline">etcd-perf</strong> container starts, it will <a id="_idIndexMarker423"/>automatically run performance checks:</p>
			<pre class="source-code">sh-4.4# <strong class="bold">podman run --volume /var/lib/etcd:/var/lib/etcd:Z </strong>quay.io/openshift-scale/etcd-perf Trying to pull quay.io/openshift-scale/etcd-perf:latest...
Getting image source signatures
(.. omitted ..)
------- Running fio ------{
"fio version" : "fio-3.7",
"timestamp" : 1631814461,
"timestamp_ms" : 1631814461780,
"time" : "Thu Sep 16 17:47:41 2021",
"global options" : {
"rw" : "write",
 "ioengine" : "sync",
"fdatasync" : "1",
 "directory" : "/var/lib/etcd",
"size" : "22m", <strong class="bold">[1]</strong>
"bs" : "2300" }, <strong class="bold">[2]</strong>
(.. omitted ..)
"write" : {
"io_bytes" : 23066700,
"io_kbytes" : 22526,
"bw_bytes" : 1319077,
"bw" : 1288, <strong class="bold">[3]</strong>
"iops" : 573.511752, <strong class="bold">[4]</strong>
(.. omitted ..)
"read_ticks" : 3309,
"write_ticks" : 29285,
"in_queue" : 32594,
"util" : 98.318751
} ]
}
---------
99th percentile of fsync is <strong class="bold">5406720</strong> ns
99th percentile of the fsync is <strong class="bold">within</strong> the recommended threshold - 10 ms, the disk can be used to host etcd <strong class="bold">[5]</strong></pre>
			<p>In the preceding <a id="_idIndexMarker424"/>code snippet, we have used the following annotations:</p>
			<p><strong class="bold">[1]</strong>: A chunk size of 22 <strong class="bold">megabytes</strong> (<strong class="bold">MB</strong>) is usually enough to analyze performance results.</p>
			<p><strong class="bold">[2]</strong>: Instead of using 4k block size, etcd uses small chunks of 2.3k block size, so it guarantees performance, including with small writing fragmentations.</p>
			<p><strong class="bold">[3]</strong>: Bandwidth required considering traffic between the node and underlying storage. It is recommended you use at least a network interface of 1 <strong class="bold">gigabyte</strong> (<strong class="bold">GB</strong>). For medium and large clusters, the recommendation is a 10 GB interface.</p>
			<p><strong class="bold">[4]</strong>: The recommendation is at least 500 concurrent IOPS, as explained previously.</p>
			<p><strong class="bold">[5]</strong>: The report of the etcd IO check. In the example, 5.40 <strong class="bold">milliseconds</strong> (<strong class="bold">ms</strong>) demonstrates a reliable performance—for it to be so, it must be under 10 ms.</p>
			<p>Besides using <strong class="source-inline">etcd-perf</strong> to check the disk performance, you could also perfectly use custom parameters as you need, such as block size, chunk size, and so on, using the <strong class="source-inline">fio</strong> binary tool, which<a id="_idIndexMarker425"/> is available using the standard Red Hat package manager (for example, by executing <strong class="source-inline">yum/dnf install fio</strong>).</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For didactic reasons, we suppressed some results, leaving only items that are pertinent to our analysis.</p>
			<h4>etcd sizing</h4>
			<p>To avoid any<a id="_idIndexMarker426"/> problems related to the <strong class="bold">central processing unit</strong> (<strong class="bold">CPU</strong>), you must understand whether your cluster is well-sized. You must consider some factors to check the cluster <a id="_idIndexMarker427"/>sizing, such as the number of customers using the platform, the expected number of requests per second, and the amount of storage available for etcd.</p>
			<p>First, let’s give you some parameters to consider for your cluster size:</p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/B18015_06_Table_01.jpg" alt=""/>
				</div>
			</div>
			<p>The following table demonstrates some use cases using public clouds and on-premises infrastructures according to the amount of CPU, memory, disk IOPS, and bandwidth linked to the cluster size:</p>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/B18015_06_Table_02.jpg" alt=""/>
				</div>
			</div>
			<p>In a nutshell, when you size a cluster, you should consider these thresholds because this is already benchmarked by the etcd community, and their performance will likely be acceptable if these recommendations are followed. Further information regarding sizing the etcd cluster can be<a id="_idIndexMarker428"/> found at the link we have provided in the <em class="italic">Further reading</em> session of this chapter.</p>
			<p>In this section, you have seen some ways to check etcd performance and troubleshoot, and you also got some important information regarding sizing best practices. We hope you enjoyed the approach and take a close look at the next section about authentication, which will be another interesting theme.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor118"/>Authentication</h2>
			<p>Another important aspect<a id="_idIndexMarker429"/> of an OpenShift cluster is user authentication and authorization flow. OpenShift’s flexibility and easy-to-use authentication plugins are a smart way of setting up users and groups. Instead of simply having a vault of usernames and passwords, OpenShift’s authentication service can authenticate a user in a variety of <a id="_idIndexMarker430"/>ways—we call it an <strong class="bold">identity provider</strong> (<strong class="bold">IdP</strong>). In this way, OpenShift is responsible for trusting the IdP and allowing or denying authentication according to the provider. In the following diagram, you can see how the process of authenticating a user works:</p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B18015_06_04.jpg" alt="Figure 6.4 – Authentication and authorization flow "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Authentication and authorization flow</p>
			<p>The IdP is responsible<a id="_idIndexMarker431"/> for notifying OpenShift if the username and password are valid and returning to OpenShift the <strong class="source-inline">success</strong> or <strong class="source-inline">failure</strong> authentication status. This process is <a id="_idIndexMarker432"/>known as <strong class="bold">authentication</strong> (<strong class="bold">AuthN</strong> in some literature).</p>
			<p>We mentioned that the authentication process uses IdPs to validate the user against an authentication provider, but, more importantly, you need to understand how <strong class="bold">authorization</strong> (aka as <strong class="bold">AuthZ</strong>) occurs. Initially, a<a id="_idIndexMarker433"/> user on OpenShift doesn’t have any permissions in any project; however, they can log on. They will not have rights to perform any tasks except creating their own new projects if the cluster has the self-provisioner role enabled (self-provisioner is a role that allows any logged user to create their own projects). To add permissions to a user, it is necessary to inform the appropriate role. This can be accomplished through the inclusion of a user group or by directly assigning it to the<a id="_idIndexMarker434"/> user. This process of adding roles to users or groups is named <strong class="bold">RoleBindings</strong>.</p>
			<p>To better understand which role best fits a user or group, consider looking at the default roles that already exist in an OpenShift cluster, as set out here:</p>
			<ul>
				<li><strong class="source-inline">admin</strong>—This is a project admin. It allows changes with all project-scoped resources, including the ability to create RoleBindings using ClusterRoles. It does not allow the modification <a id="_idIndexMarker435"/>of quotas, limits, or cluster resources.</li>
				<li><strong class="source-inline">edit</strong>—This is a project editor. It allows usage and manipulation of all project-scoped resources, but cannot change authorization objects.</li>
				<li><strong class="source-inline">view</strong>—This is a project viewer. It allows the inspection of project-scoped resources and works like a read-only RoleBinding. Secrets inspections are not allowed.</li>
				<li><strong class="source-inline">cluster-admin</strong>—This is the equivalent of a root user on a *nix-like OS. It allows total control of any resource in the entire cluster.</li>
				<li><strong class="source-inline">cluster-reader</strong>—This is useful for allowing special users permissions, especially those that work with cluster monitoring. This RoleBinding is read-only and does not allow users to escalate or manipulate objects on the cluster.</li>
			</ul>
			<p>You must also understand the scope of the RoleBinding, which can be one of the following:</p>
			<ul>
				<li><strong class="bold">Local RoleBinding</strong>—Permissions<a id="_idIndexMarker436"/> that are given in a specific project; for example, adding the <strong class="source-inline">edit</strong> role to user <em class="italic">X</em> in project <em class="italic">Z</em>. Creating local RoleBindings is as simple as running the following command:<p class="source-code">$ oc adm policy add-role-to-user &lt;role&gt; &lt;user&gt; -n &lt;project&gt;</p></li>
				<li><strong class="bold">Cluster RoleBinding</strong>—Permissions that are given for the entire cluster; for example, adding the <strong class="source-inline">cluster-admin</strong> role to user <em class="italic">X</em>. To create a cluster RoleBinding, run the <a id="_idIndexMarker437"/>following command:<p class="source-code">$ oc adm policy add-cluster-role-to-user &lt;role&gt; &lt;user&gt;</p></li>
			</ul>
			<p>Similar commands can be applied to groups, just replacing <strong class="source-inline">user</strong> with <strong class="source-inline">group</strong> (for example, <strong class="source-inline">add-role-to-group</strong> and <strong class="source-inline">add-cluster-role-to-group</strong>). Similarly, to remove a role from a user or group, use <strong class="source-inline">remove-role-from-user/group</strong>, as in the following example:</p>
			<pre class="source-code">$ oc adm policy remove-role-from-user &lt;role&gt; &lt;user&gt; -n &lt;project&gt;
$ oc adm policy remove-role-from-group &lt;role&gt; &lt;group&gt; -n &lt;project&gt;
$ oc adm policy remove-cluster-role-from-user &lt;role&gt; &lt;user&gt;
$ oc adm policy remove-cluster-role-from-group &lt;role&gt; &lt;group&gt;</pre>
			<p>These are some of the most<a id="_idIndexMarker438"/> popular default roles that are used with OpenShift, but you can create custom ones if needed. To create a custom role, you need to first understand what are <strong class="bold">verbs</strong> and <strong class="bold">resources</strong>, so here are definitions of these:</p>
			<ul>
				<li>A <strong class="bold">verb</strong> is an action the user runs against the OpenShift API—for instance, <strong class="source-inline">get</strong>, <strong class="source-inline">list</strong>, <strong class="source-inline">create</strong>, <strong class="source-inline">update</strong>, and so on.</li>
				<li>A <strong class="bold">resource</strong> is an entity in which the verb will be performed—for example, <strong class="source-inline">pod</strong>, <strong class="source-inline">deployment</strong>, <strong class="source-inline">service</strong>, <strong class="source-inline">secret</strong>, and so on.</li>
			</ul>
			<p>That said, to define a custom role, you need to know which verbs for the user or group will be allowed to run over which objects. As soon as you have defined verbs and resources, a role can be created using the following command:</p>
			<pre class="source-code">$ oc create role &lt;role-name&gt; --verb=&lt;verbs-list&gt; --resource=&lt;resources-list&gt;</pre>
			<p>Have a look at the following example:</p>
			<pre class="source-code">$ oc create role sample --verb=get,list,watch --resource=pods,pods/status</pre>
			<p>There are more things about authentication and authorization with OpenShift that it's not our intention to bring to light here. We tried to highlight some of the important aspects you need to know about it, and we left a set of links in the <em class="italic">Further reading</em> section of this chapter if you want to go even deeper into this subject.</p>
			<p>With that, we have demystified the authentication process a bit, and you can now perform the process of <strong class="bold">AuthN</strong> and <strong class="bold">AuthZ</strong>. The previous diagram showed a quick point of view about the steps of an authentication process. It is important to give proper permissions to each user or group, and—more importantly—to plan the roles you will need to have in place<a id="_idIndexMarker439"/> to give your users and groups the proper permissions to perform their job. In the following section, we will cover another important aspect that an OpenShift operator needs to know about: troubleshooting.</p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor119"/>Troubleshooting reference guide – how to start</h1>
			<p>In this section, you <a id="_idIndexMarker440"/>will see some approaches to troubleshooting your OpenShift cluster if you face any issues. Due to the power of the <strong class="source-inline">oc</strong> <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>), you <a id="_idIndexMarker441"/>will have different ways to succeed in almost any troubleshooting scenario of your OpenShift cluster. Along with your training, you will gain the experience you need to take a step further in using and troubleshooting your OpenShift/Kubernetes cluster.</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor120"/>Describing objects</h2>
			<p>As we have mentioned, the <strong class="source-inline">oc</strong> CLI is a powerful tool to help OpenShift users to do a lot of operations and also do<a id="_idIndexMarker442"/> some troubleshooting. One of the first steps of troubleshooting is to get some details and descriptions of the objects. Suppose, for instance, you have an issue related to a pod that is not coming up, for some reason. Let’s start our troubleshooting by checking the pod details, as follows:</p>
			<pre class="source-code">$ oc describe pod sso-10-qm2hc</pre>
			<p>Check the output in the <strong class="source-inline">Events</strong> section of the object to see what is preventing the pod from spinning up, as illustrated in the following code snippet:</p>
			<pre class="source-code">Events:
  Type     Reason          Age                From               Message
  ----     ------          ----               ----               -------
  Normal   Scheduled       90s                default-scheduler  Successfully assigned rhsso/sso-10-qm2hc to ocp-hml4.hybridcloud.com
  Normal   AddedInterface  89s                multus             Add eth0 [10.242.22.12/23] from openshift-sdn
  Normal   Pulling         39s (x3 over 89s)  kubelet            Pulling image "image-registry.openshift-image-registry.svc:5000/rhsso/sso74-custom"
<strong class="bold">  Warning  Failed          33s (x3 over 83s)  kubelet            Failed to pull image "image-registry.openshift-image-registry.svc:5000/rhsso/sso74-custom": rpc error: code = Unknown desc = pinging container registry image-registry.openshift-image-registry.svc:5000: Get "https://image-registry.openshift-image-registry.svc:5000/v2/": dial tcp 10.244.109.169:5000: connect: no route to host</strong>
  Warning  Failed          33s (x3 over 83s)  kubelet            Error: ErrImagePull
  Normal   BackOff         8s (x4 over 83s)   kubelet            <strong class="bold">Back-off pulling image "image-registry.openshift-image-registry.svc:5000/rhsso/sso74-custom"</strong>
  Warning  Failed          8s (x4 over 83s)   kubelet            Error: ImagePullBackOff</pre>
			<p>In this case, you were <a id="_idIndexMarker443"/>able to see quickly in the <strong class="source-inline">oc describe</strong> command that the error is related to the connection between the node and the image registry (<strong class="source-inline">no route to host</strong>). You can act accordingly to fix the connectivity issue and get the pod up and running. You can also use the <strong class="source-inline">Events</strong> log to see other meaningful information, as you can see in the following section.</p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor121"/>Events</h2>
			<p>Another parameter on the <strong class="source-inline">oc</strong> CLI that helps with problem investigation is the <strong class="source-inline">oc get events</strong> command. This is very<a id="_idIndexMarker444"/> useful for showing a log of tasks recently executed, along with presenting <em class="italic">success</em> or <em class="italic">error</em> messages. Events can be executed cluster-wide or project scoped. Check out the following sample of event logs:</p>
			<pre class="source-code">$ oc get events -n openshift-image-registry
LAST SEEN   TYPE      REASON              OBJECT                                                  MESSAGE
35m         Normal    Scheduled           pod/cluster-image-registry-operator-7456697c64-88hxc    Successfully assigned openshift-image-registry/cluster-image-registry-operator-7456697c64-88hxc to ocp-master2.hybridcloud.com
35m         Normal    AddedInterface      pod/cluster-image-registry-operator-7456697c64-88hxc    Add eth0 [10.242.0.37/23] from openshift-sdn
35m         Normal    Pulled              pod/cluster-image-registry-operator-7456697c64-88hxc    Container image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6a78c524aab5bc95c671811b2c76d59a6c2d394c8f9ba3f2a92bc05a780c783a" already present on machine
(...omitted...)</pre>
			<p>If the pod is up and running but you still have some issues in an application, you can also use OpenShift to check the application logs, as you will see next.</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor122"/>Pod logs</h2>
			<p>Regularly, pod logs bring<a id="_idIndexMarker445"/> important information related to the <a id="_idIndexMarker446"/>scheduler, pod affinity/anti-affinity, container images, and persistent volumes. There are several ways to check the pod logs, as outlined here:</p>
			<ul>
				<li>The common way—inside the namespace—is shown here:<p class="source-code">$ oc project mynamespace</p><p class="source-code">$ oc logs mypod</p></li>
				<li>Here’s how to check them from any namespace:<p class="source-code">$ oc –n mynamespace logs mypod</p></li>
				<li>Here’s how to check<a id="_idIndexMarker447"/> the logs of a specific container inside a pod:<p class="source-code">$ oc -n mynamespace logs mypod -c kube_proxy</p></li>
				<li>You can also check the<a id="_idIndexMarker448"/> logs using the OpenShift console <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>). To do so, access the <strong class="source-inline">Logs</strong> tab of the desired namespace and pod, as illustrated in the following screenshot:</li>
			</ul>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/B18015_06_05.jpg" alt="Figure 6.5 – Pod logs example (OpenShift console graphical UI (GUI)) "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Pod logs example (OpenShift console graphical UI (GUI))</p>
			<p>You may also have issues during the application deployment. See next what you can check to find evidence of deployment problems.</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor123"/>Deployment logs</h2>
			<p>In some cases, a pod does not <a id="_idIndexMarker449"/>start and remains in a<a id="_idIndexMarker450"/> constant crashing state, which makes it difficult to get any logs. In such cases, you can check the <strong class="source-inline">deployment</strong> or <strong class="source-inline">deploymentconfig</strong> logs, which can help you to identify deployment misconfigurations.</p>
			<p>Similar to pod logs, <strong class="source-inline">deployment</strong> logs are accessible by running the <strong class="source-inline">oc logs</strong> command. For <strong class="source-inline">deployment</strong> logs, run the following command:</p>
			<pre class="source-code">$ oc –n mynamespace logs deployment/mydeploypods</pre>
			<p>For <strong class="source-inline">deploymentconfigs</strong> logs, use this one:</p>
			<pre class="source-code">$ oc –n  mynamespace logs dc/mydeploypods</pre>
			<p>Usually, you will not find the <a id="_idIndexMarker451"/>exact issue or the root cause and the solution to be applied, but it will give you a good indication of why it is<a id="_idIndexMarker452"/> failing—for example, dependent components that are missing in the solution, such as images not available; security context constraint with incorrect permissions; configmaps, secrets, and serviceaccounts missing; and so on.</p>
			<p>Another useful way you may use to troubleshoot an issue is to use the <strong class="source-inline">debug</strong> command with temporary root privileges. Learn more on this in the following section.</p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor124"/>Debugging pods</h2>
			<p>Another interesting tool to<a id="_idIndexMarker453"/> troubleshoot a pod that is constantly crashing can be used by executing the <strong class="source-inline">oc debug deployment</strong> or <strong class="source-inline">oc debug deploymentconfig</strong> command. Through this, you can instruct OpenShift to not fail and restart the pod as it crashes. The pod will still be alive, so you can check the logs, access it, and troubleshoot it from inside the container. To use the tool, run the following command:</p>
			<pre class="source-code">$ oc debug deployment/&lt;deployment-name&gt;</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The <strong class="source-inline">oc debug</strong> command allows some interesting options, such as <strong class="source-inline">--as-user</strong> to run the pod with a defined user. To see a comprehensive list of allowed parameters and examples, run the <strong class="source-inline">oc debug -h</strong> command.</p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor125"/>Operator logs</h2>
			<p>As we already<a id="_idIndexMarker454"/> covered in this book, OpenShift uses several operators to deploy and monitor critical features for the platform. That said, operators bring helpful logs to identify some configuration issues and instability with the platform. Those<a id="_idIndexMarker455"/> logs are stored in namespaces starting with the name <strong class="source-inline">openshift-*</strong>, which is a standard for most tools included with OpenShift.</p>
			<p>The reason to maintain several operator pods as a part of project pods is related to some affinity/anti-affinity rules and taints/toleration strategies that a user can apply to the cluster. Operator pods are the watchdog to maintain namespaces’ health, watching the CRD, its standards, liveness, and readiness, and preventing OpenShift’s critical namespaces from suffering undesirable changes.</p>
			<p>One of the main benefits of operators for the cluster’s stability is the ability to maintain the desired state of the operator namespace’s objects. In other words, if any unwanted changes are made by mistake directly into the namespace’s objects, they will be reverted by the operator itself. Every change in the operator’s objects needs to be done through the operator itself, by editing ConfigMaps or CR objects, according to the operator’s specification. That also means that any changes are checked and confirmed by operators before they are effectively applied.</p>
			<p>To check the cluster operators’ functions, you must do the following:</p>
			<ol>
				<li value="1">List the cluster operators, like so:<p class="source-code">$ oc get co</p></li>
				<li>Describe the details of the cluster operator, as follows:<p class="source-code">$ oc describe co &lt;clusteroperatorName&gt;</p></li>
			</ol>
			<p>Here’s an example:</p>
			<p class="source-code">$ oc describe co storage</p>
			<ol>
				<li value="3">Check the status output for error messages, if they exist, like so:<p class="source-code">(...omitted...)</p><p class="source-code">Status:</p><p class="source-code">  Conditions:</p><p class="source-code">    Last Transition Time:  2021-08-26T14:51:59Z</p><p class="source-code">    Message:               All is well</p><p class="source-code">    Reason:                AsExpected</p><p class="source-code">    Status:                False</p><p class="source-code">    Type:                  Degraded</p><p class="source-code">    Last Transition Time:  2021-08-26T14:51:59Z</p><p class="source-code">    Message:               All is well</p><p class="source-code">    Reason:                AsExpected</p><p class="source-code">    Status:                False</p><p class="source-code">    Type:                  Progressing</p><p class="source-code">    Last Transition Time:  2021-08-26T14:51:59Z</p><p class="source-code">    Message:               <strong class="bold">DefaultStorageClassControllerAvailable: No default StorageClass for this platform</strong></p><p class="source-code">    Reason:                AsExpected</p><p class="source-code">    Status:                True</p><p class="source-code">    Type:                  Available</p><p class="source-code">    Last Transition Time:  2021-08-26T14:52:00Z</p><p class="source-code">    Message:               All is well</p><p class="source-code">    Reason:                AsExpected</p><p class="source-code">    Status:                True</p><p class="source-code">    Type:                  Upgradeable</p><p class="source-code">(...ommitted...)</p></li>
			</ol>
			<p>In the previous example, only <a id="_idIndexMarker456"/>a warning message about setting up a default storage class for a cluster is shown. No critical issues were found at storage. In case of any issue, look at the events and pod logs in the operator’s namespace.</p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor126"/>Other oc CLI commands and options</h2>
			<p>The <strong class="source-inline">oc</strong> CLI has some <a id="_idIndexMarker457"/>other powerful commands for troubleshooting. Some useful and powerful commands for troubleshooting are listed here:</p>
			<ul>
				<li>Here’s an example command for high-verbosity logs:<p class="source-code">$ oc –n &lt;namespaceName&gt; logs &lt;podName&gt; <strong class="bold">-v 8</strong></p></li>
				<li>And here’s one for cluster events:<p class="source-code">$ oc <strong class="bold">get events</strong></p></li>
				<li>Here, you can see an example command for namespaced events:<p class="source-code">$ oc –n &lt;namespaceName&gt; <strong class="bold">get events</strong></p></li>
				<li>Here’s how to execute a single command inside the pod (double dash required):<p class="source-code">$ oc exec mypod <strong class="bold">-- date</strong></p></li>
				<li>Here’s how to execute a single command inside a pod in a specific container (double dash required):<p class="source-code">$ oc exec mypod <strong class="bold">-c httpd-container</strong> <strong class="bold">-- date</strong></p></li>
				<li>Create iterative commands spawning a pseudo-terminal, like so:<p class="source-code">$ oc exec mypod <strong class="bold">-i -t -- ls -t /usr</strong></p></li>
				<li>Similar to the <strong class="source-inline">exec</strong> command, <strong class="source-inline">rsh</strong>—shown here—opens a terminal inside the pod:<p class="source-code">$ oc -n &lt;namespaceName&gt; <strong class="bold">rsh</strong>  &lt;podName&gt;</p></li>
			</ul>
			<p>All of the previous commands help you to identify problems in a cluster or even an application. Furthermore, you can investigate the node directly using the <strong class="source-inline">oc debug</strong> command, like so:</p>
			<pre class="source-code">$ oc debug node/&lt;nodeName&gt;</pre>
			<p>The <strong class="source-inline">oc debug</strong> command gives you non-root privilege access, and you cannot run many OS commands without escalation. To do so, we recommend you run the <strong class="source-inline">chroot</strong> command, like so. After that, you can regularly use OS shell commands:</p>
			<pre class="source-code">$ chroot /host /bin/bash</pre>
			<p>As you can see, OpenShift has a lot of useful debugging commands to help you identify cluster-wide or scoped issues. It is not recommended, but it is possible to also directly <strong class="source-inline">ssh</strong> on nodes. This kind of approach requires good knowledge of the <em class="italic">Red Hat CoreOS</em> OS, <strong class="source-inline">podman</strong>, and <strong class="source-inline">crio</strong> to avoid node disruption.</p>
			<p>In any situation, we<a id="_idIndexMarker458"/> also recommend you open a support ticket with Red Hat, which will assist and give you the right guidance to solve your problem. The Red Hat support team often asks for the result of the <strong class="source-inline">must-gather</strong> command, which generates a temporary pod and concatenates meaningful logs and configurations that are useful for the Red Hat engineering team to analyze and correlate events and find the issue or root cause.</p>
			<p>The most common way to run <strong class="source-inline">must-gather</strong> is shown here:</p>
			<pre class="source-code">$ oc adm must-gather --dest-dir=/local/directory</pre>
			<p>This will create a <strong class="source-inline">tar</strong> file under the chosen directory with all logs collected, which can be very useful to identify problems. We suggest you always run this command and upload it when you are opening the support ticket to speed up the process of analyzing the issue.</p>
			<p>In this section, you saw different debug approaches that will certainly help you in everyday life. In the next section, you will see the most common error messages that occur at pod startup, and in this way, you will be able to draw your own line of reasoning that will help you in the problem solution.</p>
			<h1 id="_idParaDest-119"><a id="_idTextAnchor127"/>Understanding misleading error messages</h1>
			<p>Even if you have learned the <a id="_idIndexMarker459"/>different ways to identify a problem, it is not unusual that the error shown does not provide enough information to help you to detect the issue and fix it. Having that in mind, we decided to highlight some very common error messages in this section and also some suggestions to solve the problem.</p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor128"/>ImagePullBackOff</h2>
			<p>This is a common error<a id="_idIndexMarker460"/> related to a missing container image. Check out the following lines of code to become familiarized with this kind of issue when you face it:</p>
			<pre class="source-code">NAMESPACE   NAME READY STATUS RESTARTS AGE
namespace1  backend-tfmqm 0/1 ImagePullBackOff 0 17h</pre>
			<p>Here’s a message that may come up when investigating the pod log:</p>
			<pre class="source-code">$ oc -n namespace1 logs backend-tfmqm
Error from server (BadRequest): container " backend" in pod " backend-tfmqm" is waiting to start: trying and failing to pull image</pre>
			<p>Looking at the error message, it is typically linked to the absence of the image in the registry. This can occur due to some problems, such as the image and its tags not being available in the registry, or incorrect pointing in the <strong class="bold">deployment/deployment config</strong>. Another correlation would be the node where the pod is running is not able to reach the image registry.</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor129"/>CrashLoopBackOff</h2>
			<p>This is an error that<a id="_idIndexMarker461"/> requires some knowledge before acting on solving it effectively. It occurs because the application crashes constantly, so the root cause issue can be due to several different reasons. You can see an example of this here:</p>
			<pre class="source-code">NAMESPACE NAME READY STATUS RESTARTS AGE
3scale backend-redis-1-9qs2q 0/1 CrashLoopBackOff 211 17h</pre>
			<p>Here’s a message you may see when investigating the pod log:</p>
			<pre class="source-code">$ oc logs backend-redis-1-9qs2q
1:M 11 Jan 13:02:19.042 # Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix &lt;filename&gt;</pre>
			<p>The log usually gives you some hints about the issue’s root cause, but it can also be a trap to conduct you to a wrong conclusion. It is important to take into account when a pod has a persistent volume or it has a precedence order that depends on another application to start first and<a id="_idIndexMarker462"/> prepare a persistent volume, as well as many other different scenarios that can lead to this error.</p>
			<h2 id="_idParaDest-122"><a id="_idTextAnchor130"/>Init:0/1</h2>
			<p>When you get an <strong class="source-inline">Init:0/1</strong> error message, it<a id="_idIndexMarker463"/> typically means the pod is waiting for another pod or a condition that hasn’t been satisfied yet. The following lines of code demonstrate what kinds of conditions can result from this message and how to solve this:</p>
			<pre class="source-code">NAMESPACE NAME READY STATUS RESTARTS AGE
3scale backend-cron-1-zmnpj 0/1 Init:0/1 0 17h</pre>
			<p>Here’s a message you may see when investigating the pod log:</p>
			<pre class="source-code">$ oc logs backend-cron-1-zmnpj
Error from server (BadRequest): container "backend-cron" in pod "backend-cron-1-zmnpj" is waiting to start: PodInitializing</pre>
			<p>This, perhaps, can be a confusing status when you are troubleshooting error messages. Certainly, it can be anything wrong in the namespace, so the error message only shows <strong class="source-inline">PodInitializing</strong>. You could interpret it as a condition when a pod is waiting to start; meanwhile, this message means that a condition isn’t satisfied.</p>
			<p>To help you, we have listed here some items that must be checked that may be preventing the pod from starting:</p>
			<ul>
				<li>Check whether the service account used in the pod exists in the namespace, as some containers need a specific service account name and policy applied to start.</li>
				<li>Check the <strong class="bold">security context constraints</strong> (<strong class="bold">SCCs</strong>) and make sure that these are properly set <a id="_idIndexMarker464"/>according to the required permissions for the pod.</li>
				<li>Check other containers and pods in the namespace: depending on the build strategy, it is possible to define pod dependencies.</li>
			</ul>
			<p>If you are not familiar with SCC yet, don’t freak out. We will be covering it in depth in <a href="B18015_08.xhtml#_idTextAnchor153"><em class="italic">Chapter 8</em></a>, <em class="italic">OpenShift Security</em>.</p>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor131"/>Summary</h1>
			<p>In this chapter, we focused on important components of OpenShift, such as operators and their role in maintaining the resilience of a cluster, and we also talked about situations that can cause damage to the cluster.</p>
			<p>We have dived into the heart of OpenShift, which is its distributed database (known as etcd), understanding its importance in the cluster and how to prepare it to receive a high volume of traffic, as well as verifying its sizing and performance, and understanding how to perform troubleshooting in some cases.</p>
			<p>We have also discussed a bit about the AuthN and AuthZ process, so you now know the power and flexibility of the Openshift IDPs. We finally have seen some important troubleshooting tips and tools that will certainly help you in your daily job, operating OpenShift clusters and applications.</p>
			<p>In the next chapter, we will present some other important information about the network on OpenShift. We will discuss and give examples to understand the main differences between a pod network and a service network, as well as understand the difference between North-South and East-West traffic. Keep up with us in this interesting reading and learn more in <a href="B18015_07.xhtml#_idTextAnchor133"><em class="italic">Chapter 7</em></a>, <em class="italic">OpenShift Network</em>.</p>
			<h1 id="_idParaDest-124"><a id="_idTextAnchor132"/>Further reading</h1>
			<p>If you want to look at more information on what we covered in this chapter, check out the following references:</p>
			<ul>
				<li><em class="italic">Red Hat Knowledgebase—etcd recommendation</em>: <a href="https://access.redhat.com/solutions/4770281">https://access.redhat.com/solutions/4770281</a></li>
				<li><em class="italic">etcd quorum model</em>: <a href="https://etcd.io/docs/v3.5/faq/">https://etcd.io/docs/v3.5/faq/</a></li>
				<li><em class="italic">Understanding etcd quorum</em>: <a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></li>
				<li><em class="italic">etcd hardware sizing recommendations</em>: <a href="https://etcd.io/docs/v3.5/op-guide/hardware/">https://etcd.io/docs/v3.5/op-guide/hardware/</a></li>
				<li><em class="italic">etcd tuning options</em>: <a href="https://etcd.io/docs/v3.5/tuning/">https://etcd.io/docs/v3.5/tuning/</a></li>
				<li><em class="italic">etcd benchmarking thresholds</em>: <a href="https://etcd.io/docs/v3.5/benchmarks/">https://etcd.io/docs/v3.5/benchmarks/</a></li>
				<li><em class="italic">etcd benchmark CLI tool</em>: <a href="https://etcd.io/docs/v3.5/op-guide/performance/#benchmarks">https://etcd.io/docs/v3.5/op-guide/performance/#benchmarks</a></li>
				<li><em class="italic">Kubernetes authentication flow</em>: <a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/">https://kubernetes.io/docs/reference/access-authn-authz/authentication/</a></li>
				<li><em class="italic">Openshift IDPs</em>: <a href="https://docs.openshift.com/container-platform/4.7/authentication/understanding-identity-provider.html">https://docs.openshift.com/container-platform/4.7/authentication/understanding-identity-provider.html</a></li>
				<li><em class="italic">Learn more about SCCs</em>: <a href="https://docs.openshift.com/container-platform/4.8/authentication/managing-security-context-constraints.html">https://docs.openshift.com/container-platform/4.8/authentication/managing-security-context-constraints.html</a></li>
				<li><em class="italic">More information about troubleshooting</em>: <a href="https://docs.openshift.com/container-platform/4.7/support/troubleshooting/investigating-pod-issues.html">https://docs.openshift.com/container-platform/4.7/support/troubleshooting/investigating-pod-issues.html</a></li>
				<li><em class="italic">Recommended etcd practices</em>: <a href="https://docs.openshift.com/container-platform/4.10/scalability_and_performance/recommended-host-practices.html#recommended-etcd-practices_recommended-host-practices">https://docs.openshift.com/container-platform/4.10/scalability_and_performance/recommended-host-practices.html#recommended-etcd-practices_recommended-host-practices</a></li>
				<li><em class="italic">How to calculate IOPS in a storage array (blog article)</em>: <a href="https://www.techrepublic.com/article/calculate-iops-in-a-storage-array/">https://www.techrepublic.com/article/calculate-iops-in-a-storage-array/</a></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer107">
			</div>
		</div>
</body></html>