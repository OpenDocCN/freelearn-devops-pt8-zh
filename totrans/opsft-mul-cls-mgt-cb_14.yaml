- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building a Cloud-Native Use Case on a Hybrid Cloud Environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It has been a wonderful journey so far! We walked through so much content in
    this book already, from OpenShift architecture to Pipelines, GitOps, and multi-cloud
    tools! We are now reaching our main goal with this book, which is helping you
    to make the best decisions and implement a good hybrid/multi-cloud strategy for
    your OpenShift footprint. To wrap up this book with helpful content, we will make
    a comprehensive review using a practical approach to building and deploying an
    application using most features we covered during this book: OpenShift Pipelines
    (Tekton), OpenShift GitOps (ArgoCD), Advanced Cluster Management, Quay, and Advanced
    Cluster Security.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, you will find the following in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Use case description
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application build using OpenShift Pipelines and S2I
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application deployment using OpenShift Pipelines and GitOps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding security checks in the building and deployment process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioning and managing multiple clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an application into multiple clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, what are we waiting for? Let’s play now!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The source code used in this chapter is available at [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter14](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter14).
  prefs: []
  type: TYPE_NORMAL
- en: Use case description
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be a bit closer to what you see in the real world, this time we are going
    to use a Java application, using **Quarkus**, which is a great option to build
    modern, cloud-native applications with Java. Look at the references in the *Further
    reading* section of this chapter for more information about **Quarkus**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our application source code was extracted from the *Getting started with Quarkus*
    sample; see reference for it in the *Further reading* section of this chapter.
    During this chapter, we will create a CI/CD pipeline that will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Build the application using s2i to generate Java binaries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the container image to Quay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run a security scan on the image using Advanced Cluster Security.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the application on the local cluster using ArgoCD.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the application on multiple remote clusters using ArgoCD and Advanced
    Cluster Management.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are going to use Advanced Cluster Management to make all OpenShift clusters
    compliant with a standard policy we defined for them as well. For the sake of
    learning and simplicity, we are going to build the pipeline and other objects
    in sequential phases, like building blocks that are added to build a house.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Comprehensive review - Building blocks ](img/B18015_14_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – Comprehensive review - Building blocks
  prefs: []
  type: TYPE_NORMAL
- en: 'We assume that you have access to an OpenShift cluster, which we will call
    the Hub cluster, with enough resources and with the following tools already installed:'
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenShift GitOps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced Cluster Management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced Cluster Security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quay
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `oc` command line installed and connected to the Hub cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will also deploy additional single node clusters on AWS to be used as managed
    remote clusters, to exercise the application deployment into multiple clusters.
    If you haven’t installed these tools yet, refer to the installation process of
    each from *Chapters 9* to *13* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The source code used in this chapter is available at our GitHub repository:
    [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter14](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter14).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by digging into the first building block: the application build.'
  prefs: []
  type: TYPE_NORMAL
- en: Application build using OpenShift Pipelines and S2I
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this step, we are going to use the `quarkus-build` pipeline that you can
    find in the `chapter14/Build/Pipeline/quarkus-build.yaml` file. This pipeline
    is very straightforward and explained in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Pipeline to build a Java Quarkus application ](img/B18015_14_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Pipeline to build a Java Quarkus application
  prefs: []
  type: TYPE_NORMAL
- en: 'In this pipeline we are using pre-existing ClusterTasks to do all the work:'
  prefs: []
  type: TYPE_NORMAL
- en: '`git-clone`: Used to clone the Git repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s2i-java`: Build the Java source code using S2I and Buildah to generate the
    image and push it to the Quay registry. S2I is a very convenient way to build
    code from many different languages, such as Java, Python, Node.js, and others.
    See the *Further reading* section of this chapter for more information about S2I.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`openshift-client`: Used to run the manifests that deploy the application.
    Application manifests use **Kustomize** to declare the Kubernetes manifest. We
    covered **Kustomize** in [*Chapter 10*](B18015_10.xhtml#_idTextAnchor204), *OpenShift
    GitOps – ArgoCD*, of this book; if you didn’t read it yet, we strongly recommend
    you to do so now and then get back here to perform the steps in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now let’s create and run this pipeline. If you haven’t done it yet, fork this
    repository to your GitHub account: [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook).
    After you forked it, follow the instructions in this section to create and run
    this pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the repository in your machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following script and follow the instructions to change the references
    from the original repository (`PacktPublishing`) to your forked repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following commands to create the namespace and the pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should be able to see the pipeline in the OpenShift console, in **Pipelines**
    | **Pipelines** | **Project: chap14-review-cicd**, as you can see in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Build pipeline created ](img/B18015_14_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Build pipeline created
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now run the pipeline either using the web interface or through the
    terminal. To do so from your terminal, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note about Image Registry
  prefs: []
  type: TYPE_NORMAL
- en: This pipeline uses an external registry to push the resulting image. To be able
    to push an image to the registry, you need to link a secret that contains the
    registry credentials with the `pipeline` ServiceAccount. If you don’t do it before
    running the pipeline, you will notice that it will fail in the `build` task. We
    are using Quay in this chapter, but you can use any external image registry, such
    as Nexus, Amazon Elastic Container Registry, Docker Hub, or any other. If you
    decide to use Quay, you need to create a robot account, give it write permissions
    in the image repository, and import the secret to the namespace. Next, you will
    find out how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: See next how to configure your Quay repository and link the credentials to the
    `pipeline` ServiceAccount.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the image registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After you have created a new repository on Quay, follow these steps to configure
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Access the **Settings** tab of the repository and access the **Create robot
    account** link in the **User and Robot Permissions** section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.4 – Create a robot account ](img/B18015_14_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – Create a robot account
  prefs: []
  type: TYPE_NORMAL
- en: 'Give it any name and click on the **Create robot account** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.5 – Create a robot account ](img/B18015_14_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Create a robot account
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, change the permission to **Write** and click on **Add Permission**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.6 – Set Write permissions ](img/B18015_14_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.6 – Set Write permissions
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the robot account link to download the secret that we will use to
    link with the pipeline ServiceAccount:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.7 – Robot account ](img/B18015_14_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.7 – Robot account
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the secret by clicking on the **Download <robot-name>-secret.yml**
    link in the **Kubernetes Secret** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.8 – Download Quay credentials ](img/B18015_14_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.8 – Download Quay credentials
  prefs: []
  type: TYPE_NORMAL
- en: With the secret YAML file in hand, you can proceed with its creation on OpenShift.
    See next how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Linking image registry credentials
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we already have the secret file in our workspace, run the following
    commands to create the secret and link it to the pipeline ServiceAccount. Alternatively,
    you can just run the `link-image-registry-secret.sh` script from the GitHub repository
    that we prepared for you, which will do this same process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you faced the error mentioned in the build task of the pipeline, you can
    now run it again by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you should see the pipeline finishing successfully, as you can see in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.9 – Build pipeline run successfully ](img/B18015_14_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.9 – Build pipeline run successfully
  prefs: []
  type: TYPE_NORMAL
- en: After the pipeline runs successfully, you may want to see what the image looks
    like on Quay.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the image on Quay
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are using Quay, at this stage, you should be able to see and inspect
    the image there:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.10 – Image on Quay, known vulnerabilities detected automatically
    ](img/B18015_14_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.10 – Image on Quay, known vulnerabilities detected automatically
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, Quay detected automatically that this image has some known vulnerabilities.
    We are going to fix these vulnerabilities further in this chapter, but it is important
    now that you observe and understand how easy it is to push images and start checking
    them automatically against known vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we already have the building pipeline of our application working, let’s
    evolve it to use ArgoCD as the deployment tool, leveraging GitOps practices.
  prefs: []
  type: TYPE_NORMAL
- en: Application deployment using OpenShift Pipelines and GitOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This time, we are going to use ArgoCD to deploy the application instead of directly
    running the Kubernetes manifests. The pipeline is basically the same, but now
    the deploy task will run a YAML file that creates an ArgoCD application and wait
    until the application becomes healthy.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.11 – Pipeline to build a Java Quarkus application and deploy it
    using ArgoCD ](img/B18015_14_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.11 – Pipeline to build a Java Quarkus application and deploy it using
    ArgoCD
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to create and run the pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'A new `PipelineRun` will be created to build the container image and create
    the ArgoCD application that will deploy the application. You will see the following
    if everything works well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.12 – Task deployment using ArgoCD ](img/B18015_14_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.12 – Task deployment using ArgoCD
  prefs: []
  type: TYPE_NORMAL
- en: 'Access the ArgoCD console to check the application deployment from there; you
    should see something similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.13 – Application in ArgoCD ](img/B18015_14_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.13 – Application in ArgoCD
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find instructions about how to access the ArgoCD console in [*Chapter
    10*](B18015_10.xhtml#_idTextAnchor204), *OpenShift GitOps – ArgoCD*. As a reminder,
    see next the commands to get the ArgoCD URL and admin password:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now our pipeline already builds the application, pushes it to Quay, and deploys
    it using ArgoCD. The next step is to bring Advanced Cluster Security to add a
    security check step in our pipeline. See next how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding security checks in the building and deployment process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This time, we will add a new step to perform a security check in the image that
    has been built. We are going to use Advanced Cluster Security for that. To successfully
    use it, you should have Advanced Cluster Security installed and the local cluster
    configured as a secured cluster. Check [*Chapter 12*](B18015_12.xhtml#_idTextAnchor251),
    *OpenShift Multi-Cluster Security*, to see how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'See next what our pipeline looks like now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.14 – Pipeline with security checks ](img/B18015_14_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.14 – Pipeline with security checks
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the following task has been added to the pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '`security-check`: Uses ACS APIs to check the image against existing security
    policies defined in ACS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To simulate security issues, we will also use a custom `s2i-java` task that
    uses an old `ubi-openjdk` version, which contains many known vulnerabilities.
    To fix the issues, we will change the build strategy to use a Dockerfile that
    uses the latest version of the RHEL UBI image and additional security fixes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow the instructions in this section to create and run this pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get into the pipeline, we need to configure the integration between
    the pipeline and ACS. To do so, access the **Advanced Cluster Security** dashboard
    and navigate to **Platform Configuration** | **Integrations** | **Authentication
    Tokens**, and click on **API Token**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.15 – Creating ACS API Token](img/B18015_14_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.15 – Creating ACS API Token
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Generate token** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.16 – Generate token ](img/B18015_14_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.16 – Generate token
  prefs: []
  type: TYPE_NORMAL
- en: 'Fill out a name and select **Continuous Integration** in the **Role** field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.17 – Generate token for CI ](img/B18015_14_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.17 – Generate token for CI
  prefs: []
  type: TYPE_NORMAL
- en: 'Copy the token that has been generated. We are going to use it in a secret
    that will be used by the pipeline task to authenticate on ACS APIs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.18 – Copy API Token ](img/B18015_14_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.18 – Copy API Token
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s create the secret. Run the following command using the token from
    the previous step and the ACS central endpoint. Do *not* use `http(s)` in the
    `rox_central_endpoint` host:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we are all set to create and run our pipeline. Run the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see failures in the `security-check` task as we are intentionally
    using an old base image that contains many known vulnerabilities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.19 – Security checks failure ](img/B18015_14_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.19 – Security checks failure
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look briefly at the errors we have as a result of this task. The
    policies that have failed are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fixable Severity at least Important**: As expected (remember that we are
    using now an old base image version), there are several components in the image
    that have important and critical known CVEs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ubi-minimal`, which includes `microdnf` as a package manager.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are going to demonstrate now how to fix these security issues using a Dockerfile
    that addresses all of them.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing security issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To fix the issues, we are going to change our pipeline to use a Dockerfile
    instead of the S2I. To do so we changed the `build` task to use the `buildah`
    ClusterTask instead of `s2i-java`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at what the highlighted numbers mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[1]**: The path where the Dockerfile with security fixes is located'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`buildah` ClusterTasks that will build the application using the given Dockerfile'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s also take a look at the Dockerfile to understand the security fixes.
    This file is located at `quarkus-getting-started/src/main/docker/Dockerfile.multistage`
    in our GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at what the highlighted numbers mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ubi-minimal` as the base image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[2]**: Update OS packages to the latest versions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[3]**: Remove the package manager from the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The lines highlighted will make sure the most up-to-date components, which contain
    the most recent security fixes, are in use, and also the package manager is removed
    from the image before it is packaged.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create this new pipeline version and runs it to check whether the
    security issues have been resolved. To do so, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the pipeline should be finished successfully, as there are no security
    issues detected anymore in our container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.20 – Security issues fixed ](img/B18015_14_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.20 – Security issues fixed
  prefs: []
  type: TYPE_NORMAL
- en: 'You can optionally check ACS now to investigate whether there are still other
    violations that may be fixed later. If you want to do so, navigate to the `Namespace:
    chap14-review-cicd` and `Deployment: quarkus-quickstarts`. You should still see
    some minor violations, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.21 – ACS Violations ](img/B18015_14_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.21 – ACS Violations
  prefs: []
  type: TYPE_NORMAL
- en: 'Do you remember that Quay reported some vulnerabilities in our image before?
    Look at it now to see our new image version:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.22 – Quay security scan ](img/B18015_14_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.22 – Quay security scan
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the newer image has no security issues detected. In this section,
    we added a security check in our pipeline and fixed some vulnerabilities detected
    by this pipeline. In the next section, our pipeline will be able to deploy our
    application against multiple clusters, using ArgoCD and Advanced Cluster Management.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning and managing multiple clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We haven’t touched so far on the hybrid or multi-cluster side of the house.
    This is what we are going to add now: *deployment into multiple remote clusters*.
    To do so, we are going to use Advanced Cluster Management to provision new clusters
    and also help us to deploy the application in them.'
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning new clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to use AWS to host two new clusters that will be used as remote
    clusters to exercise our pipeline. For the sake of saving resources, we are going
    to use single node clusters, so we don’t need to get the cost of many servers
    for this exercise. If you already have clusters available, you can alternatively
    import the existing clusters, instead of provisioning new ones. You can find,
    in the *Further reading* section of this chapter, a link that contains instructions
    about how to import a cluster on Advanced Cluster Management.
  prefs: []
  type: TYPE_NORMAL
- en: 'To provision a single node cluster using ACM, you need to add the AWS credentials,
    navigate to the **Credentials** menu, and click on the **Add credential** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.23 – Adding AWS credentials ](img/B18015_14_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.23 – Adding AWS credentials
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow the wizard and fill out all required fields. You need to provide your
    pull secret, which is available at [https://console.redhat.com/openshift/downloads](https://console.redhat.com/openshift/downloads):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.24 – Adding a new credential ](img/B18015_14_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.24 – Adding a new credential
  prefs: []
  type: TYPE_NORMAL
- en: 'After you have created the AWS credential, access the **Infrastructure** |
    **Clusters** feature and click on the **Create cluster** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.25 – Provisioning a new cluster ](img/B18015_14_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.25 – Provisioning a new cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Select AWS as the infrastructure provider and fill out the wizard with the
    following data but do *not* hit the **Create** button in the last step of the
    wizard:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Infrastructure** provider: **Amazon Web Services**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Infrastructure provider credential**: **aws** (name of the credential that
    you created in the previous step)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ocp-prd1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster set**: **default**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Base DNS domain**: Your public domain on AWS (for example, example.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Release image**: Select the most recent'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`env=prod`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`m5.2xlarge`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Networking**: Leave as-is'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Proxy**: Leave unselected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation**: Leave blank'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the **Review** page, select the **YAML: On** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.26 – Edit YAML ](img/B18015_14_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.26 – Edit YAML
  prefs: []
  type: TYPE_NORMAL
- en: 'In the YAML file, edit `MachinePool` and add the statement `skipMachinePool:
    true`, as you can see in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.27 – Editing MachinePool ](img/B18015_14_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.27 – Editing MachinePool
  prefs: []
  type: TYPE_NORMAL
- en: 'Click in the `install-config` tab and change master replicas to `1` and compute
    replicas to `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.28 – Editing install-config ](img/B18015_14_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.28 – Editing install-config
  prefs: []
  type: TYPE_NORMAL
- en: 'Now hit the `ocp-prd2` with the same parameters used previously. In the end,
    you should see two clusters being provisioned, as you can see in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18015_14_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.29 – Clusters being created
  prefs: []
  type: TYPE_NORMAL
- en: The provisioning will take about 40 minutes. Continue next when you see both
    clusters marked as **Ready**.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One helpful feature that ACM provides is cluster governance using policies.
    We already covered this feature in [*Chapter 11*](B18015_11.xhtml#_idTextAnchor229),
    *OpenShift Multi-Cluster GitOps and Management*. If you didn’t read it yet, we
    strongly recommend you check that chapter. We are going to deploy the policy that
    is in the `Governance` folder of our GitHub repository to inform if the etcd keystores
    of managed clusters are encrypted or not. To do so, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait a few seconds and access the **Governance** feature on ACM to check the
    compliance of the clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.30 – Cluster compliance ](img/B18015_14_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.30 – Cluster compliance
  prefs: []
  type: TYPE_NORMAL
- en: Move to the next section to see how to deploy our sample application into multiple
    remote clusters at once.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an application into multiple clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we already have multiple remote clusters, we can go ahead and use ACM
    and ArgoCD to make our pipeline able to deploy into all of them at once. We are
    going to change the deploy task to use an `ApplicationSet` object that will be
    responsible for deploying our application into both OpenShift remote clusters
    at once.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.31 – Pipeline with deployment into multiple clusters ](img/B18015_14_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.31 – Pipeline with deployment into multiple clusters
  prefs: []
  type: TYPE_NORMAL
- en: 'To make ArgoCD aware of the clusters managed by ACM, we first need to create
    a few objects, such as the `GitOpsCluster` Custom Resource. We covered a detailed
    explanation of these objects in [*Chapter 11*](B18015_11.xhtml#_idTextAnchor229),
    *OpenShift Multi-Cluster GitOps and Management*. Run the following commands to
    create these objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s create and run the pipeline, which uses an `ApplicationSet` object
    to deploy the application into the managed clusters that have the `env=prod` label.
    Remember that we used this label in the clusters we provisioned using ACM. If
    you imported the clusters on ACM, make sure to add the `env=prod` label to them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'When the pipeline finishes, you should now have two new ArgoCD applications
    automatically created by the `ApplicationSet` mechanism:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.32 – ArgoCD and ApplicationSet ](img/B18015_14_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.32 – ArgoCD and ApplicationSet
  prefs: []
  type: TYPE_NORMAL
- en: That’s it, we did it! We started with a simple build pipeline that now performs
    security checks and deploys into multiple remote clusters at once!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thank you for being our partner in this journey! We hope the content of this
    book was helpful for you and now you have a good understanding of the topics covered
    in this book. We went through architecture, people, deployment, troubleshooting,
    multi-cluster administration, usage, and security. So much content that we thought
    we wouldn’t have the ability to write it! And if you are still here, we feel that
    my mission with this book is accomplished!
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a quote from *Johann Wolfgang von Goethe* that says the following:
    “*Knowing is not enough; we must apply. Willing is not enough; we must do*.” After
    reading this book, we hope you not only learned new things but were also able
    to put them into practice. Following this hybrid cloud journey, you have the opportunity
    to leap in knowledge with didactic examples and content made with great dedication
    from us.'
  prefs: []
  type: TYPE_NORMAL
- en: We hope that this book becomes one of your handbooks and will be useful to you
    for planning and executing models suitable for the enterprise, bringing multiple
    options to use, implementations, and good insights to leverage your knowledge
    and your career.
  prefs: []
  type: TYPE_NORMAL
- en: 'To wrap up the content of this chapter, we designed the following diagram to
    serve as a shortcut to the central themes of each chapter and see the entire journey
    we have gone through together:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.33 – The book journey ](img/B18015_14_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.33 – The book journey
  prefs: []
  type: TYPE_NORMAL
- en: We have almost reached the end of this book, but we are not completely done
    yet. We have prepared for you the last chapter with some suggestions as to where
    you can go next after this book, to keep learning and growing your OpenShift and
    Kubernetes skills.
  prefs: []
  type: TYPE_NORMAL
- en: We encourage you to move to the next chapter and look at the training and other
    content we suggest there.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Looking for more information? Check the following references to get more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Quarkus*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Main page:* [https://quarkus.io/](https://quarkus.io/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Quarkus getting started sample*: [https://github.com/quarkusio/quarkus-quickstarts/tree/main/getting-started](https://github.com/quarkusio/quarkus-quickstarts/tree/main/getting-started)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*S2i:*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*GitHub* page: [https://github.com/openshift/source-to-image](https://github.com/openshift/source-to-image)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*How to Create an S2I Builder Image* (blog article): [https://cloud.redhat.com/blog/create-s2i-builder-image](https://cloud.redhat.com/blog/create-s2i-builder-image)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Using Source 2 Image build in Tekton* (blog article): [https://cloud.redhat.com/blog/guide-to-openshift-pipelines-part-2-using-source-2-image-build-in-tekton](https://cloud.redhat.com/blog/guide-to-openshift-pipelines-part-2-using-source-2-image-build-in-tekton)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tekton Hub - S2I*: [https://hub.tekton.dev/tekton/task/s2i](https://hub.tekton.dev/tekton/task/s2i)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Advanced Cluster Management – Importing clusters*: [https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.5/html/clusters/managing-your-clusters#importing-a-target-managed-cluster-to-the-hub-cluster](https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.5/html/clusters/managing-your-clusters#importing-a-target-managed-cluster-to-the-hub-cluster)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Advanced Cluster Security – Image check from Tekton Hub*: [https://hub.tekton.dev/tekton/task/stackrox-image-check](https://hub.tekton.dev/tekton/task/stackrox-image-check)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part 5 – Continuous Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will have some additional content to continue the journey
    to becoming a subject matter expert on OpenShift. Here, you will see a summary
    of the training available on the market to help you with OpenShift’s in-depth
    enablement.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part of the book comprises the following chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 15*](B18015_15.xhtml#_idTextAnchor308), *What’s Next?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
