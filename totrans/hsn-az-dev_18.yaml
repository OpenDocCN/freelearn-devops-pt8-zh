- en: Scaling Azure Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot talk about reliable and stable applications in the cloud without scaling.
    While this process may have seemed a bit complicated and cumbersome in models
    like **Infrastructure as a service** (**IaaS**) or on-premises, Azure gives many
    different ways to multiply our applications quickly, and without downtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling, scaling up, scaling out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling Azure App Services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling Azure Functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling Azure Service Fabric
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To perform exercises from this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Access to an Azure subscription
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoscaling, scaling up, scaling out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The cloud is all about scaling—it is one of the most important advantages of
    such a setup over an on-premises setup. The ability to rapidly adapt to new demands
    when it comes to incoming traffic, and the flexibility a cloud offers, enables
    you to create more stable services, which are less prone to unexpected load spikes
    and insufficient hardware performance. In this chapter, we will focus a little
    bit on diving deeper into the scaling topic, in order to build a deep understanding
    of how different services behave in Azure, and how you can ensure that the scaling
    feature is automated and requires as little attention as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can define the autoscaling feature of many services as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling is a feature that allows a service, a machine, or an application
    to automatically scale up or out based on predefined parameters, like CPU utilization,
    memory used, or artificial factors, like throughput units, or worker utilization.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, you can describe autoscaling as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fa77e25e-3e0c-4897-8cc8-d8528d641cb5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding diagram can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A resource accepts incoming requests as normal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simultaneously there is an entity that monitors a resource—it checks it against
    the scaling rules and decides whether a scaling operation is required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An entity takes a decision regarding scaling—it can scale a resource up/down
    or out, depending on the settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Of course, besides pros, scaling has its downsides:'
  prefs: []
  type: TYPE_NORMAL
- en: It may render your application unresponsive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It requires additional resources for load balancing (if scaling out).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It takes time, depending on the scaling characteristics. It is, therefore, crucial
    to plan such action at the design stage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In many cases, it causes your solution to be many times more expensive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How a service scales depends solely on the service itself. Let us look at some
    examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Event Hub can be scaled manually/automatically (using the auto-inflate
    feature). You can assign more **Throughput Units** (**TUs**) to an instance to
    enable it to accept more messages. Automatic scaling down is not implemented.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure App Services can be scaled both manually and automatically (it depends
    on the tier you have chosen). You have multiple different parameters available,
    and scaling down is also performed automatically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Cosmos DB relies on the **Request Unit** (**RU**) units assigned to an
    instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure SQL has different models for scaling—you can either use **Database Transaction
    Units** (**DTUs**) or vCores.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Functions scale automatically using an internal mechanism of workers and
    the scale controller.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Storage does not support scaling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you can see, there is no single solution for scaling your services in Azure—you
    have to implement the working solution for each component individually. The rule
    of thumb is, that the less control over a resource you have, the more automated
    the scaling will be. While for IaaS scenarios, you have to operate the number
    of VMs, in **PaaS**, you will end up with virtual cores or other units. Here you
    can find different cloud models ordered from the left to right in terms of the
    scaling complexity (where **IaaS **has the most complex model):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d912af6-3636-4479-9bdb-161a28786647.png)'
  prefs: []
  type: TYPE_IMG
- en: Scaling up and scaling out
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two different types of scaling (at least when it comes to Azure):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaling up**: Which upgrades hardware/a tier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaling out**: Which adds instances of a service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scaling up can be presented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a513d79-aa6c-4a23-87d8-3cabc2869497.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While for comparison, scaling out is described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c33d2df-b3f0-462c-bfd1-3bd650af9260.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, in the first scenario (scaling up), you will get a better performance from
    a single instance, while scaling out will allow you to parallelize your work.
    The use cases are different in both options and are basically dependent on the
    workload you are planning to run. These are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: If your code is sequential and there is no option to multiply it, use scaling
    up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your code requires much compute power in a unit of time rather than dividing
    it into multiple machines, use scaling up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a way to load balance your load, use scaling out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are able to perform the same work on multiple machines without a risk
    of collision, use scaling out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using scaling out can be compared to multithreading—but of course on a much
    bigger scale. In fact, the problems are quite the same. If your machine has multiple
    cores, and they are able to execute your code at the same time, you have to introduce
    very similar constraints.
  prefs: []
  type: TYPE_NORMAL
- en: The common problems of scaling out are often caused by the access to the state—whether
    it is shared via any kind of storage, or distributed amongst many machines. Make
    sure you are aware of these before using this feature.
  prefs: []
  type: TYPE_NORMAL
- en: In Azure, multiple services scale out/up differently. We will focus on three
    of them to get a better understanding of the topic.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling Azure App Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started our journey through Microsoft Azure by learning some basics of Azure
    App Services. This is a very common PaaS component, which is widely used amongst
    many Azure users, both for very simple websites and complex systems requiring
    high performance and reliability. To make sure that your Web App is always on,
    or to check if it is under pressure, you have to implement some kind of scaling
    rules. When it comes to this service, you have two options—either using manual
    scaling (and implementing some kind of alert, so that you know when such action
    should happen), or an autoscale feature, which makes things much easier in terms
    of maintenance. In this section, we will cover and compare both of them.
  prefs: []
  type: TYPE_NORMAL
- en: Manual scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Manual scaling is a feature that is available starting from the basic tier—it
    is not available for free or shared ones. Depending on the actual tier chosen,
    there will be a different amount of instances that can be used for your App Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here you can find how things look like for the B2tier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c2f624db-159a-4f2d-ad4b-f8d50bddc4b5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding configuration, the maximum number of instances available is
    set to three. However, if I scale up to the standardtier the result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c607a76-daea-426f-9f40-85489217e93c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Things look quite different—two features have changed:'
  prefs: []
  type: TYPE_NORMAL
- en: I can set the Instance count to the maximum number of 10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Autoscaling can be enabled
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that scaling up to the premium tier will allow you to set the maximum number
    of 20 instances for your App Service.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While manual scaling can be fine for less demanding websites and systems (as
    they do not require quick actions when something happens), when your application
    is, for example, a popular e-commerce shop, you want things to happen quickly,
    including scaling out. Let us try to enable autoscaling for now—it will display
    a form that enables you to manage these settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85583c51-eef5-46d3-9a2a-134cd4acdc65.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In fact, you have two options here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scale based on a metric: Allows you to select a metric, which will be a trigger
    for autoscaling'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scale to a specific instance count: Executed by default (so should be used
    along with scaling based on a metric)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To configure scale based on a metric, you will need a rule. You can add this
    by clicking on the + Add a rulelink. Doing so will display another form (which
    is far more complex than the current one), where you can select all that is interesting
    for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1eab9c44-c38c-4d0e-a920-17ece24af5a2.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding screenshot, you can see a rule that will trigger autoscaling
    when CPU utilization exceeds 70% over a 10 minute period. Once all conditions
    are met, the runtime will add another instance to the App Service. What is more,
    if the conditions are true after another 5 minutes (Cool down (minutes)period),
    the scaling out operation will be triggered once more. This will happen as long
    as the maximum number of instances, which you have set, are hit.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that you can set more than a single rule for your application. What
    is more, it seems like a good idea to create a decreasing count by rule, which
    will remove additional instances if the load gets back to normal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once your rule is added, you can click Save to confirm your changes—now your
    application will be scaled out anytime a rule is considered active. Before we
    go further, I would like to show you two more things. You probably noticed two
    additional sections on the Scale-outblade, JSON and Notify. They give you some
    additional options when it comes to managing a service:'
  prefs: []
  type: TYPE_NORMAL
- en: JSON:This generates a JSON template, which can be used with ARM Templates for
    automatic provisioning of your resource. It will automatically add scaling rules
    when a service is created.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Notify: This enables you to automatically send a notification to administrators
    of the resource in Azure, to notify them when something wrong happens there.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here you can find a JSON, which was generated for my rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Scaling Azure Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using PaaS services, you can configure how your application will behave
    when CPU utilization hits the maximum allowed value, or the number of requests
    exceeds the threshold. However, Azure offers services in other models—one of the
    most interesting is serverless architecture, which abstracts the control even
    more in favor of easier configuration, minimum maintenance, and ability to focus
    on delivering a business value.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will see the differences between Azure App Services and Azure
    Functions when it comes to scaling, both from the technical and conceptual point
    of view.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling serverless applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you are using serverless services (such as Azure Functions, Azure Cosmos
    DB, or Azure Event Grid) you have limited options when it comes to configuring
    the feature. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: In Azure Functions, you rely on the pricing model (consumption plan vs App Service
    Plan)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Azure Cosmos DB you modify the number of RUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Azure Event Grid you have no way to define how the service will scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is all caused by the fact that you do not control the application host—the
    underlying service engine is completely detached from your application and there
    is no possibility to directly modify it. What you can do is to control it indirectly,
    either by changing the number of processing units or via available configuration
    options, which can be interpreted and applied.
  prefs: []
  type: TYPE_NORMAL
- en: Note that serverless is meant to be a model where you are isolated from the
    runtime (and, in some cases, even from the cloud vendor). If the lack of control
    does not play well for you, it is better to try PaaS or IaaS models and services.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling Azure Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Azure Functions, there is no possibility to scale up, at least for the consumption
    plan. Of course, when using the App Service Plan, you can scale it up and get
    better hardware, but it does not affect the service itself. Instead it creates
    more resources to consume. On the other hand, you cannot scale out manually. The
    only possibility is to let Azure Functions scale automatically. To do so, this
    service implements the concept of a scale controller. This is an internal feature
    that constantly monitors how particular workers hosting the Function's runtime
    behave, and if one of them seems to be overloaded, another machine is added to
    the set.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions scaling behavior is quite sophisticated and only partially described,
    as it contains parts that are either open sourced, or not available publicly.
    I will try to describe it in detail in this chapter, so you are aware of the exact
    algorithm of making a scaling decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before your instance of Azure Functions will make a scaling decision, it will
    check the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaling interval**: Scaling only happens after a specific interval has passed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Current workers number**: If the number of workers (running the function''s
    hosts) exceeds the configured maximum, a decision will be made to remove one from
    the working set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Load factor**: If the load factor approaches the maximum value, a new worker
    will be added. Alternatively, if the load factor drops, one worker will be removed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Busy worker ratio**: If the number of busy workers exceeds the configured
    maximum, another worker will be added to the set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Free workers**: If the number of free workers is greater than the defined
    maximum, one of them will be removed from the working set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Defined values for above actions can be found as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The above values come from the GitHub repository of Azure Functions Host. They
    may be changed after a while, but if you are interested, take a look at the following
    project: [https://github.com/Azure/azure-functions-host](https://github.com/Azure/azure-functions-host)
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, you can control the maximum number of instances by providing
    the `WEBSITE_MAX_DYNAMIC_APPLICATION_SCALE_OUT` value in the Application settingsof
    your Function App:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64803ef4-3405-4209-94bd-638630fc7e44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'What is more, if you connect the instance of your Function App to an instance
    of Azure Application Insights, you will be able to check how many workers it has
    by checking the Live Metrics Streamfeature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d9d73ea1-2a92-4b52-9963-8720975ef810.png)'
  prefs: []
  type: TYPE_IMG
- en: Scaling Azure Service Fabric
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discussed two different models for scaling by working with two separate
    Azure services; Azure App Services and Azure Functions.
  prefs: []
  type: TYPE_NORMAL
- en: They are quite different when it comes to adding new instances or improving
    hardware performance, in that they introduce multiple concepts, and offer a different
    level of flexibility. In the last section of this chapter, we will cover one more
    service, Azure Service Fabric. This particular Azure product behaves in a slightly
    different manner when it comes to scaling up or out, as it requires you to manage
    VMs. In addition, a distinct set of skills is necessary to perform this operation
    seamlessly and in the right fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling a cluster manually
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Clusters in Azure Service Fabric can be scaled in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Manually**: By choosing appropriate options in the cluster configuration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Programatically**: By using the Azure SDK'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In fact, the characteristics of your cluster are selected at the very beginning,
    when you are choosing node types and their configuration, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ea7a121-f82c-4d89-8b97-90dded7bdd1f.png)'
  prefs: []
  type: TYPE_IMG
- en: Scaling Azure Service Fabric service is similar to scaling VMs, as it is based
    on nodes containing an unspecified number of virtual machines, which means you
    really depend on scale sets.
  prefs: []
  type: TYPE_NORMAL
- en: It is always better to set up a cluster that will handle the planned load than
    scale it under pressure, especially when you require strict transactional assurances,
    which may impact scaling time. Take a look at the *Further reading*section, where
    you will find an article describing efficient cluster planning.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using scaling with Azure Service Fabric, remember that adding machines
    to the scale set always takes time. Therefore, consider planning such operations
    early, so the impact on the current operations will be minimized. To actually
    scale out your cluster, you have use the Scaling feature of the scale set, which
    was created with it, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f81be57a-cb32-4403-b297-27196e4748e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The other option to perform such operation is to use ARM template with the
    following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: By providing the `<capacity> `value, you may easily change the number of virtual
    machines powering your SF cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Using Azure SDK to scale your cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another option to scale your cluster is to use the Azure compute SDK. You may
    wonder what are the use cases for that particular feature—all in all, we already
    have manual/auto-scaling available. However, there are more advanced scenarios,
    which may be suitable for scaling using your own controller:'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling using a custom metric, which is not available for autoscaling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing additional operations before scaling can happen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Full control over scaling operation in case of critical workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To get the Azure compute SDK, you have to download the following NuGet package: Microsoft.Azure.Management.Fluent
    available at: [https://www.nuget.org/packages/Microsoft.Azure.Management.Fluent/](https://www.nuget.org/packages/Microsoft.Azure.Management.Fluent/).
    Similar libraries can be found for other languages (like Java or Python—you can
    find them in the link in the *Further Reading* section).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To scale out your cluster, you may use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The same can be used for Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it is a pretty simple piece of code—you just need to obtain
    the current scale set ID to get a reference to it, and then change its capacity.
    In this example, I used a value of `1`, but there is nothing that prevents you
    from using other numbers.
  prefs: []
  type: TYPE_NORMAL
- en: With the preceding example, you can also scale down your cluster. However, remember
    that you should not scale down below the cluster's reliability tier. If you do
    so, you no longer can rely on it and may destabilize it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using a higher reliability tier than bronze**,** you do not need
    to worry about unused machines as they will be automatically removed. Otherwise,
    you have to do it manually. To do so, you actually have to know which VMs are
    not currently used. To remove a node that is no longer required, you can use the
    following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'They basically do three different things:'
  prefs: []
  type: TYPE_NORMAL
- en: Deactivate and remove a node from a cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Decrease a scale set capacity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove a node state
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To find a node to be removed, you have to query a cluster and seek the most
    recent machine added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You may wonder why the most recently added machine is selected to be the victim
    of the scaling operation. This is because work was delegated to it as the result
    of higher cluster utilization. Originally it was not a part of the set. and once
    it finished its job, it can be removed.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the scaling of three completely different services—Azure
    App Service, Azure Functions, and Azure Service Fabric. You saw how this operation
    works for different application models—sometimes you scale service instances,
    VMs, or simply you do not control it and let the runtime do it for you. In fact,
    scaling services in the cloud is much easier than when using your own servers.
    You do not have to reconfigure load balancers, firewalls, routers, and servers.
    When using the scaling feature, always try to automate the process—manual scaling
    works only for very simple scenarios, and tends to keep your servers underutilized.
  prefs: []
  type: TYPE_NORMAL
- en: In the next two chapters, we will cover two additional Azure services, Azure
    CDN and Azure Traffic Manager, which help in keeping your applications available,
    even under heavy load.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the difference between scaling up and scaling out?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the use cases for scaling out?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is scaling up available in serverless services?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does scaling out in Azure App Services affect the pricing of the service?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can scaling operation be dangerous in Azure Service Fabric?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the cons of manual scaling?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What do you do if you want to automatically scale your Azure App Service when
    CPU utilization reaches 80%?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Service Fabric cluster planning: [https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-capacity](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-capacity)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service Fabric cluster scaling: [https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-scaling](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-scaling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azure SDKs: [https://docs.microsoft.com/en-us/azure/index#pivot=sdkstools&panel=sdkstools-all](https://docs.microsoft.com/en-us/azure/index#pivot=sdkstools&panel=sdkstools-all)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
