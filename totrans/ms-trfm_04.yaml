- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Foundations of Cloud Architecture – Virtual Machines and Infrastructure-as-a-Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book aims to help you master Terraform, but what does it take to be a
    true master? Terraform is an **Infrastructure-as-Code** (**IaC**) tool that enables
    you to describe your cloud architecture using code. Without a solid understanding
    of the underlying architecture, you can never become a true master of Terraform.
    Therefore, I’ve included the next few chapters to provide the groundwork for ubiquitous
    architectural concepts across cloud platforms to lay the foundation for later
    chapters, when we will build sophisticated cloud architectures in three distinct
    cloud computing paradigms:'
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this foundation, you will understand the necessary concepts to follow along
    with the solution architectures we will build in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus on the key concepts that are critical for understanding,
    architecting, and automating virtual machine-based solutions. First, we will lay
    a foundation for fundamental networking concepts such as subnets, routing, perimeter-based
    security, peering, **Virtual Private Networks** (**VPNs**), and dedicated network
    connections.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll delve into the basic anatomy of virtual machines, including disks
    and network interfaces. We will then be considering the subtle nuances between
    Windows and Linux virtual machines. Next, we will cover auto-scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we’ll round it out by discussing how virtual machines are provisioned,
    covering both mutable and immutable infrastructure practices and their corresponding
    IaC practices and tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the key concepts of networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the key concepts of compute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the role of virtual machine images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the key concepts of networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Depending on how you and your organization plan on leveraging the cloud, you
    will likely work with one or more of the three paradigms for provisioning infrastructure:
    virtual machines, containers, or serverless. Each paradigm has different benefits
    and detractors that you must consider when selecting them for your solution architecture.
    Still, it is crucial to recognize that each paradigm has its own time and place
    that makes it worthwhile. In this book, I hope to help you learn how to leverage
    Terraform to deploy sophisticated solutions in these paradigms on the three significant
    hyperscalers (at the time of writing).'
  prefs: []
  type: TYPE_NORMAL
- en: Each of these paradigms has specific concepts that transcend cloud platforms
    that you—as a practitioner and architect—need to understand to design and implement
    solutions using Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines are a standard service on every cloud platform because most
    organizations would like to leverage the cloud with their existing applications
    with minimal change. Virtual machines enable these organizations to have complete
    control of the configuration of their environment from the operating system up.
    With this low level of control, organizations can move applications to cloud infrastructure
    with minimal change, yet ultimate control.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is practical because virtual machines are a concept and architecture
    that is well-known by most IT organizations. Organizations looking to migrate
    to the cloud probably already use virtual machines in their on-premises data centers.
  prefs: []
  type: TYPE_NORMAL
- en: That means that as you automate that infrastructure in the cloud, you’ll need
    to understand the core concepts and common architectural patterns.
  prefs: []
  type: TYPE_NORMAL
- en: With virtual machines, the good news is that most of the anatomy is relatively
    similar across cloud platforms, so if you know what you’re looking for, there
    is a good chance you will find the corresponding service—or Terraform resource—that
    implements that particular aspect of the solution. There may be subtle differences
    between cloud platforms that you must learn through conducting detailed analysis
    and optimizing your solutions. Still, if you understand the basic concepts, it’ll
    be pretty easy to map them across the cloud platforms and get productive using
    Terraform relatively quickly.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will build an end-to-end solution using virtual machines on
    AWS, Azure, and Google Cloud Platform. To do so, you must understand some critical
    concepts that transcend cloud platforms to help you navigate the architecture
    and relevant Terraform resources within the respective cloud platform’s Terraform
    provider.
  prefs: []
  type: TYPE_NORMAL
- en: Networking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All virtual machines live on a network and each cloud platform has a corresponding
    service that handles this aspect of the solution. A network itself is relatively
    simple to create. It only needs one primary piece of information: the network
    address space, a block of IP addresses that fall within a contiguous range.'
  prefs: []
  type: TYPE_NORMAL
- en: An IP address is made up of 32 bits. These bits are grouped into octets and
    translated into integers between `0` and `255`. IPv4 has four octets in a single
    IP address, resulting in over 4 billion addressable IP addresses. In IPv6, there
    are 16 octets and many more IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: CIDR notation is a method for representing IP address ranges as contiguous blocks.
    A CIDR block comprises an IP address starting the range and a prefix length separated
    by a forward slash. For example, `10.0.1.0/24` represents a range of IP addresses
    starting with `10.0.1.0` and extending through to `10.0.1.255`—256 IP addresses.
    `10.0.1.0` is the starting IP address, and `24` is the number of bits that should
    be in common. Since an IP address is composed of 32 bits and each decimal within
    the IP address represents 8 bits, 24 bits would mean that three of the four octets
    are shared within the range and only the last digit changes. Since the last digit
    ranges from `0` to `255`, that gives us 256 IP addresses starting with `10.0.1.0`
    and going through to `10.0.1.255`.
  prefs: []
  type: TYPE_NORMAL
- en: Several reserved IP address ranges exist for private networks. `10.0.0.0/8`
    and `172.0.0.0/12` are the most common ranges in enterprises, while I’m sure you’ve
    encountered `192.168.0.0/16` at home.
  prefs: []
  type: TYPE_NORMAL
- en: Getting familiar with CIDR notation and understanding the impact of selecting
    different-sized prefixes is essential. Usually, `/16` is the largest (65,536 IP
    addresses) and `/28` the smallest (16 IP addresses) prefix supported by cloud
    platforms—but it does vary, so you should check your cloud platform’s documentation.
    More importantly, consider your requirements and if you have an in-house networking
    team at your organization, by all means, consult them when settling on a range
    that fits for your solution.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, organizations maintain a list of IP address ranges that have been allocated
    to different teams or applications to prevent IP address conflicts. This practice
    is critical when starting in the cloud for the first time at your organization
    if you already have an on-premise network. If you use a default—such as `10.0.0.0/16`—or
    always use the same address range, you could be hurt if you ever want to connect
    your project to other networks within your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Although it can vary by cloud platform, you would usually provision a virtual
    network within a specific region, as on AWS and Azure. However, with Google Cloud
    Platform, virtual networks are global and span all regions.
  prefs: []
  type: TYPE_NORMAL
- en: Subnets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have settled on an IP address space for your network, you will be carving
    it into subnets. Subnets allow you to segment your network for various reasons,
    including improved security or organizational and operational efficiencies.
  prefs: []
  type: TYPE_NORMAL
- en: From a security standpoint, subnets are very important to isolate components
    of your architecture to reduce the blast radius if a problem occurs in one subnet.
    By creating routing rules to control network traffic between subnets, you can
    increase security by cutting down the surface area for an attack.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the cloud platform, subnets might also influence the physical location
    of resources provisioned within such as an availability zone. This is the case
    on AWS. However, Azure and GCP do not have this limitation, as their subnets can
    contain resources that span the entire region.
  prefs: []
  type: TYPE_NORMAL
- en: Routing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have segmented your virtual network using subnets, it’s crucial to
    establish the traffic patterns of network traffic using **route tables**.
  prefs: []
  type: TYPE_NORMAL
- en: Route tables allow you to direct network traffic to the correct endpoint based
    on different rules for different types of traffic. For example, there may be a
    delineation between internet traffic routed to an internet gateway or a NAT gateway.
    Similar network routing rules can route traffic to on-premise networks through
    VPN or Direct Connect connections, peered virtual networks, transit gateways,
    or service endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Network security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have a virtual network and a set of subnets, each with its own purpose
    and resources, you will likely need to apply security controls to ensure that
    only the expected network traffic can pass between resources within the various
    subnets.
  prefs: []
  type: TYPE_NORMAL
- en: Most cloud platforms have some manifestation of this concept, but they may have
    different names. They may have other mechanisms for attachment—either on a subnet,
    virtual machine, or virtual `Allow` and `Deny` rules, while other times they only
    support `Allow` rules.
  prefs: []
  type: TYPE_NORMAL
- en: Azure and AWS provide a lower-level mechanism focusing primarily on the physical
    network layer and a higher level focusing on more of the logical application layer.
    Google Cloud Platform wraps both concepts into one structure and calls them firewall
    rules.
  prefs: []
  type: TYPE_NORMAL
- en: AWS has **Network Access Control Lists** (**NACLs**), which attach to subnets
    and control the flow of network traffic between subnets. As a result, they only
    work on network address ranges—not AWS resources such as network gateways or service
    endpoints. They are stateless, which means that, in most cases, you need the inbound
    and outbound rules to match for connectivity to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, AWS also has security groups, which are stateful, only support
    `Allow` rules, and allow you to route traffic between different network address
    ranges and AWS resources using their unique identifiers. Security groups can be
    logically attached to a subnet or directly onto virtual machines (EC2 instances),
    but AWS evaluates them at the virtual machine level. Attaching a security group
    to a subnet only results in an implicit cascading attachment of that security
    group to all virtual machines within that subnet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure similarly has two constructs for constraining network traffic: **Network
    Security Groups** (**NSGs**) and **Application Security Groups** (**ASGs**). NSGs
    are in many ways a combination of AWS’s NACLs and security groups but shed some
    logical attachment capabilities with a focus on the physical network layer. ASGs
    are logical and can be associated with a virtual machine through NICs. Just like
    AWS NACLs, you can think of NSGs as controlling the flow of traffic between networks,
    while AWS’s security groups and Azure’s ASGs both focus on controlling traffic
    at a finer grain—with an application-centric lens—between resources within the
    network.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Google Cloud Platform has one construct: firewall rules. This construct is
    stateful but also supports `Allow` and `Deny` rules. It can be attached to a virtual
    network or a region, or it can be attached globally.'
  prefs: []
  type: TYPE_NORMAL
- en: Network peering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Virtual network peering** is a networking feature offered by most cloud platforms
    that allows you to connect virtual networks within the same cloud platform without
    additional VPN-based connectivity.'
  prefs: []
  type: TYPE_NORMAL
- en: To create a peering connection between two virtual networks, they must be in
    the same cloud platform, and there should not be any conflicts within their network
    address space. This potential quagmire is one reason why it’s essential to think
    through and apply proper governance around allocated network address ranges.
  prefs: []
  type: TYPE_NORMAL
- en: Peering is a capability that eliminates the need for more complex private site-to-site
    connections using VPN connections and is the preferred method for connecting networks
    within the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Service endpoints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most cloud platforms provide services that are primarily accessed directly via
    the internet. In situations where security is paramount, avoiding transmitting
    data across the internet is essential. Service endpoints are a feature provided
    by cloud platforms that enable private network communication between virtual networks
    and specific services within the cloud environment without traversing the public
    internet.
  prefs: []
  type: TYPE_NORMAL
- en: While this concept and goal exists and remains the same across all cloud providers
    we will cover in this book, it goes by different names, has varying support across
    each platform’s service offerings, and may have other attachment and routing mechanisms
    to set service endpoints up.
  prefs: []
  type: TYPE_NORMAL
- en: VPN and Direct Connect
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When virtual network peering isn’t an option, you can always leverage traditional
    site-to-site VPN connectivity options to connect networks from your on-premises
    networks or across cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: When setting up a VPN connection, most cloud platforms require you to provide
    a resource representing the source network and destination network configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The destination network is where you host the entry point for your VPN and where
    the VPN traffic traverses to gain connectivity to cloud-hosted resources. The
    source network is where you have devices that need to connect to the destination
    network. The source network is often on-premise, but it doesn’t have to be. After
    that, the most common use case is connecting networks on two different cloud platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned the critical concepts of cloud networking that you
    will encounter whenever you provision virtual machines, no matter your target
    cloud platform. There might be some subtle changes on each platform that affect
    how you’ll use each and how they will affect the availability and structure of
    your architecture, but their function is essentially the same.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at the critical concepts of virtual machines, including basic
    anatomy. This includes disks, NICs, and the virtual machine itself, as well as
    operating system-specific differences between Windows and Linux and cloud-specific
    capabilities such as auto-scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the key concepts of compute
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A virtual machine is a software emulation of a physical computer. Just like
    a regular computer, it runs an operating system and whatever applications you
    install on it. Ultimately, it does run on physical hardware. However, in the cloud,
    the cloud platform abstracts the physical hardware and the hypervisor that manages
    the virtual machines from the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Virtual machines are most commonly available on cloud platforms in two flavors:
    Linux and Windows, with various current and historical versions supported through
    marketplace offerings on the cloud platform itself.'
  prefs: []
  type: TYPE_NORMAL
- en: The primary configuration attributes of a virtual machine are its size, the
    virtual machine image to use as its operating system disk, additional data disks,
    and network configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud platforms use a **Stock-Keeping Unit** (**SKU**) to create a standard
    configuration that dictates the size and hardware profile of the virtual machine.
    This pattern is typical across cloud platforms, but the SKU names follow different
    naming conventions. Cloud platforms do have a similar organization system with
    sub-categories such as general purpose, compute-optimized, and memory-optimized.
    There are also those with particular hardware components such as **Graphics Processing**
    **Units** (**GPUs**).
  prefs: []
  type: TYPE_NORMAL
- en: The virtual machine image is a disk image of a pre-configured operating system,
    which can include additional software pre-installed depending on the image’s purpose.
    The virtual machine image is an essential component in the automation of virtual
    machines. We’ll go into further depth on this later.
  prefs: []
  type: TYPE_NORMAL
- en: Disks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Virtual machines can attach additional data disks to add extra storage. Like
    virtual machines, the disks can have varying sizes and performance characteristics.
    Unlike virtual machine sizes, which vary using categorical SKUs that indicate
    a fixed configuration type, disks use a continuous metric for sizing: **Gigabytes**
    (**GB**).'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the disk size, you can also choose from several different performance
    classes optimized for different workload scenarios, such as general purpose, throughput
    optimized, and provisioned IOPS, which seeks to guarantee a reliable level of
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: The SKU you select influences the number and class of disks you can attach to
    your virtual machine, with larger virtual machines supporting a larger quantity
    of disks.
  prefs: []
  type: TYPE_NORMAL
- en: Network Interface Cards (NICs)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual machines can attach NICs that logically represent a physical network
    interface card. As with disks, the size of a virtual machine can impact the number
    of NICs you can add and the features you can enable.
  prefs: []
  type: TYPE_NORMAL
- en: Through NIC configuration, you can either team the network interfaces together
    to create higher bandwidth or attach them to different subnets to connect a virtual
    machine. The latter option lets you straddle the line between two separate networks.
  prefs: []
  type: TYPE_NORMAL
- en: Linux versus Windows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linux and Windows virtual machines are identical anatomically in terms of virtual
    machine sizes, disks, and NICs. Still, there are a few key differences to be aware
    of when using Terraform and other tools to manage them.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication and remote access
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Windows virtual machines usually require an administrator username and password.
    In contrast, Linux virtual machines usually require an SSH key. After the initial
    setup, you can configure Windows to support SSH access, but password-based credentials
    are needed initially.
  prefs: []
  type: TYPE_NORMAL
- en: This caveat also manifests in remotely accessing virtual machines using Windows
    and Linux. Windows uses **Remote Desktop Protocol** (**RDP**), which requires
    a password-based login. Linux uses SSH, which can support either password or key-based
    login.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration scripts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Windows supports several different types of scripting by default. However, the
    most common are batch scripting, which uses the Windows **Command-Line Interpreter**
    (**CMD**), and **PowerShell**. While Microsoft initially developed PowerShell
    specifically for automating administration tasks on Windows, support for PowerShell
    has since been added on Linux, although community adoption has not hit critical
    mass.
  prefs: []
  type: TYPE_NORMAL
- en: While Linux distributions vary, `ksh`, `csh`, and `tsch`—and while their capabilities
    are similar to Bash, their popularity varies.
  prefs: []
  type: TYPE_NORMAL
- en: Windows has even joined the party by introducing **Windows Subsystem for Linux**
    (**WSL**), which, when installed, can execute Bash scripts natively on Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Auto-scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the quintessential advantages of leveraging the cloud is the ability
    to add elasticity to your solutions at scale. That is to increase capacity when
    there is heavy usage of your application and decrease capacity when your application’s
    use goes down.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud platforms provide mechanisms that make achieving this very easy. Although
    they may have different names for this capability, the anatomy of the solution
    remains the same. You simply give details on the virtual machine image that you
    want, how large the virtual machine should be, any hard range constraints in terms
    of the number of instances (such as a minimum and a maximum), and finally, you
    provide several parameters to control when and how fast to scale up or scale down.
  prefs: []
  type: TYPE_NORMAL
- en: This section has taught us some of the basics of how we provision virtual machines.
    These concepts manifest across different cloud platforms. While there may be small
    subtleties between the various cloud platforms, they operate similarly.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at the role that the virtual machine image plays in how we
    can automate virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the role of virtual machine images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Virtual machines need an operating system and other applications installed to
    serve their purpose. A virtual machine image is a single file containing a virtual
    disk with a bootable operating system installed on it. It’s a snapshot of a virtual
    machine at a particular point in time. This snapshot contains the state of the
    virtual machine, including the operating system, installed applications, and other
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: Static virtual machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When setting up a single virtual machine, or even a group of them with different
    roles and responsibilities within a solution’s architecture, there is a process
    of configuration that needs to happen to get each virtual machine into the state
    required to perform its duties as part of the solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'This configuration includes the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the operating system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configuring the operating system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installing software updates and security patches
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installing third-party software
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configuring third-party software
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Of course, each of these steps may change depending on the role of the virtual
    machine within the solution. The further down the order a step is, the more likely
    it becomes that the configuration will change, with operating system installation
    being the most stable and third-party software configuration having the most diversity
    depending on the virtual machine’s role.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a simple two-tier architecture requiring a Java web application
    to talk to a PostgreSQL database would have two roles. One role installs the Java
    Web Application server, while another installs the PostgreSQL database. Both virtual
    machines might share the exact same operating system, configuration, and security
    patches in this scenario. Still, when it comes to third-party software, one might
    need Java Web Application server software, while the other might need PostgreSQL
    database server software.
  prefs: []
  type: TYPE_NORMAL
- en: Each role requires different configuration steps to configure the server to
    fulfill its purpose. For example, these steps might include steps such as installing
    software packages, setting environment variables, updating configuration files,
    creating user accounts, setting up permissions, running custom scripts, or any
    other action required to set up the machine.
  prefs: []
  type: TYPE_NORMAL
- en: When working with the cloud, you pass this configuration to the virtual machine
    by specifying an operating system disk image. The disk image that is used will
    determine whether the virtual machine will spin up with nothing but a clean install
    of Ubuntu 22.04—ready to be manually configured—or a fully working Java Web Application
    server that requires no manual intervention whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: Each cloud platform provides a large set of disk images that you can use to
    start virtual machines for various purposes. The most common ones are baseline
    images with a specific version of an operating system installed, such as Windows
    Server 2019, Ubuntu 22.04, or RedHat Enterprise Linux.
  prefs: []
  type: TYPE_NORMAL
- en: With so many marketplace images providing a baseline operating system install,
    you can spin up a virtual machine with Ubuntu 22.04, install the Java Web Application
    software, configure it precisely to your specifications, and create a new virtual
    machine image. This new virtual machine image will boot up as a Java Web Application
    server rather than a brand new installation of Ubuntu 22.04, which means that
    you are that much closer to using this virtual machine to host your web application.
  prefs: []
  type: TYPE_NORMAL
- en: You can use automation technologies that manage this configuration to perform
    the actions you might perform manually, assuming you were starting from a clean
    operating system installation. Several automation tools focus on this problem—you
    might be surprised to learn that Terraform is not one of them. While Terraform
    can provide this configuration through several different techniques, that’s not
    its primary focus. Usually, Terraform should work together with another tool with
    this focus. The two of these tools should make a joint decision on how to share
    the responsibility of deploying this configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Using configuration manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One popular approach is to leverage Terraform to provision the virtual machines
    required in your solution and rely on the configuration management tool to handle
    the rest of the configuration on each virtual machine from the operating system.
  prefs: []
  type: TYPE_NORMAL
- en: This approach has the benefit of isolating the responsibility of configuration
    management entirely to a tool that is fit to handle this task. Some examples of
    popular tools include **Chef** or **Puppet**, which use agents to apply configuration
    onto virtual machines—or it could be a tool such as **Ansible** that requires
    no agent and uses SSH as the primary method to apply configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Due to Ansible’s heavy reliance on SSH and Windows’s limited support for this
    remote access method, Ansible has not historically been an ideal candidate for
    managing Windows-based virtual machines in this manner. Tools such as Chef and
    Puppet have seen more robust adoption in enterprise IT environments where Windows
    Server was the dominant server operating system. However, this does appear to
    be changing, with additional support from Ansible and newer versions of Windows
    making it easier to manage with this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Custom virtual machine images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After you have configured your virtual machine to the point that it is ready
    to take on its role within the system with only some minor final configuration
    changes, you can capture a snapshot of the operating system disk and create a
    virtual machine image from it that you can use to spin up additional virtual machines.
    When you use this image, these virtual machines will already have the configuration
    you have set up previously, with no need to set everything up again.
  prefs: []
  type: TYPE_NORMAL
- en: This approach has the benefit of increased startup speed. Since you already
    did most of the work when you built the image, that work doesn’t have to happen
    every time you spin up a new virtual machine. Instead, you will only need to wait
    for the cloud platform to launch the virtual machine. It will have everything
    you need installed and ready to go without waiting for the configuration manager
    to set everything up.
  prefs: []
  type: TYPE_NORMAL
- en: The most common tool used to do this is called **Packer**. It’s an open source
    product published by **HashiCorp**.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can write Packer templates in JSON or HCL. However, you should use the
    latter, as it makes managing and organizing your code much easier. A Packer template
    consists of three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Builders that establish connectivity to a target platform to build a virtual
    machine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provisioners that provide instructions that must be executed on the virtual
    machine before creating an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Post-processors that execute after the builders and provisioners and perform
    any last-minute operations before creating the artifact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Packer’s provisioners include three main types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Script execution**: Execute scripts in various shell environments supporting
    Windows and Linux'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**File**: Upload files or directories from the local environment to the virtual
    machine'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flow control**: Pause execution or trigger a Windows restart to let settings
    take effect'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build versus bake
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Taking a clean installation of the operating system and using a configuration
    management tool to apply the desired state on it is what I call the *build* approach.
    Its converse, the *bake* approach, uses an automation tool—such as Packer—that
    will launch a temporary virtual machine, set everything up, and then snap a new
    virtual machine image.
  prefs: []
  type: TYPE_NORMAL
- en: The build option is ideal for Day 2 Operations because it allows you to easily
    apply patches and manage the environment over time. With configuration management
    tools in charge, you have a live connection to your virtual machines and can update
    them quickly without disruption. In contrast, when using the bake approach, you
    will first need to bake a new image, then upgrade all the virtual machines to
    use the latest image. This results in downtime while you tear down the machine
    using the old image and spin up the machine using the new image. It can also be
    a slow process to develop the virtual machine image, as each bake can take a considerable
    amount of time, while the configuration management tool provides relatively near
    real-time feedback if there is an issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bake approach truly shines when there is time sensitivity in how fast you
    need to spin up additional virtual machines and you don’t want to wait for the
    configuration manager to do a clean install of your entire solution stack on the
    virtual machine, as this uses up valuable time that you could use to service end
    user requests. Situations that can benefit from this include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Failover and recovery**: When you have identified that a previously healthy
    virtual machine has become unhealthy and needs to be replaced rapidly, this situation
    could be due to an outage or transient hardware failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto-scaling**: When you need to scale up to meet spikes in traffic for your
    service, it’s ideal for your new virtual machine to pick up the load as quickly
    as possible when a scale-up event is triggered. If it does not, you may need to
    build in additional buffer times by reducing the threshold for scaling up and
    increasing the threshold for scaling down. This approach allows the system to
    spin up resources earlier and spin them down more slowly, ensuring that the inherent
    time delay doesn’t impact your end users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Build versus bake is not a mutually exclusive endeavor. There is usually a
    split between the two. In most situations, there are pieces of configuration that
    you can never bake into the images. These fall into the following categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Frequency**: You should bake configurations that change into the image at
    a very low frequency. Conversely, you should include configurations that you may
    need to adjust at runtime in the build.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Post-provisioning values**: You should bake configurations that require values
    that are only available after provisioning. These values might include private
    IP addresses, DNS hostnames, or other metadata generated during provisioning that
    is only known at the end.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, we’ve come to the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter looked at the core concepts required to understand virtual machines
    across multiple cloud platforms. In this book, we will build an end-to-end solution
    using virtual machine architecture for each of the three hyperscalers: AWS, Azure,
    and Google Cloud Platform. The providers for each will manifest and exercise these
    concepts slightly differently. The resources will change, but the concepts as
    they manifest in our architecture will be relatively consistent.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I have gone over common concepts across cloud platforms that
    are necessary to understand in order to automate solutions. These include cloud
    networking concepts like virtual networks, subnets, peering, and service endpoints,
    which are essential for creating and managing isolated network environments and
    ensuring efficient communication between resources. We also explored computing
    concepts such as virtual NICs for network connectivity and virtual disks for scalable
    storage solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Another critical topic discussed is the build vs. bake dilemma, addressing how
    much operating system configuration should be built into a machine image versus
    how much should be added after the machine has been provisioned. This involves
    understanding the trade-offs between pre-configuring images (baking) to streamline
    deployment processes and configuring them post-deployment (building) to enhance
    flexibility and reduce image management complexity. By understanding these concepts,
    you will be better equipped to design and automate robust, scalable solutions
    across different cloud platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will explore the core concepts needed for a new cloud
    computing paradigm: **containers**.'
  prefs: []
  type: TYPE_NORMAL
