- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Harnessing HashiCorp Utility Providers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in the first chapter, when we learned about Terraform’s architecture,
    Terraform was designed to be extensible. In the previous chapter, we spent a lot
    of time looking at the **HashiCorp Configuration Language** (**HCL**), which provides
    many tools that we can use to help us define our **infrastructure as code** (**IaC**).
    However, these language devices are not always sufficient. That is why HashiCorp
    has built a set of utility providers that provide a kind of base class library,
    or a set of reusable features that are helpful to specific scenarios, no matter
    what cloud platforms you are using to build your IaC solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with reality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adaptation and integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filesystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating system and networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with reality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When building our architecture with IaC, the product is not the code but living
    and breathing environments. While the code lives in the abstract realms of our
    minds, these environments operate within the real world, and just like how our
    best-laid plans get smashed by reality—so do our environments.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we need some tools to prepare our environments to meet and come to
    grips with reality. The `random` and `time` providers allow us to avoid conflicts
    between our resources and our environments—whether it’s the name of something
    or when something expires. These are all critical elements of our solution design
    that can make or break our architecture when it encounters the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Randomizing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `random` provider offers several ways to add randomness to your Terraform
    solution. Each `random` resource type may generate different types of random values
    and have other attributes to control the output. Still, all of them—with only
    a couple of exceptions—generate the random value through a single output called
    `result`. They also all have at least one attribute called `keepers`, which triggers
    Terraform to recreate the resource. This attribute can be helpful to set when
    you have transient resources that get replaced often, and you need to ensure there
    are no name conflicts when destroying and recreating the resource.
  prefs: []
  type: TYPE_NORMAL
- en: Random strings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generating random strings can be a great way to guarantee uniqueness across
    deployments, especially in situations where you are dynamically generating short-lived
    environments. Depending on the case, there are two ways to generate strings—one
    for non-sensitive data, such as resource names, and another for sensitive data,
    such as access keys and passwords.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generating non-sensitive dynamic names can be done using `random_string`. At
    the same time, `random_password` can create sensitive values you should protect
    from leakage by marking them as sensitive if you output them and by securing your
    state, since Terraform will store the resulting value in state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates a random string that can generate unique resource
    names within projects. Using short random strings to embed within the names of
    your resources is a great strategy when working with resources with minimal name
    length constraints, as it can be challenging to create a coherent naming convention
    across all your resources when one or two of the resources require abnormally
    small name lengths. This situation is common when resources need to have globally
    unique names, such as S3 buckets or Azure Storage accounts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'When you couple a random name suffix with part of your naming convention, you
    can still have a relatively rational resource name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Unique identifiers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can also generate a `random_uuid`. This can be helpful when your resource
    supports very long names, as these non-case-sensitive, alphanumeric values take
    the following format: `00000000-0000-0000-0000-000000000000`. You might need this
    to generate a unique correlation identifier to link resources within your deployments
    using a common tag.'
  prefs: []
  type: TYPE_NORMAL
- en: Just for fun
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There is also a fun little resource called `random_pet`, with a nod to the
    age-old jest of *pets versus cattle*, where you can generate pet names. This resource
    is probably not useful for production but can be helpful in development or lab
    environments where you can be more creative with resource names. The `random_pet`
    resource’s `id` output will generate names with an adjective-noun format. Here
    are some sample values I came up with using the sample included in this chapter
    of the book:'
  prefs: []
  type: TYPE_NORMAL
- en: '`notable-coyote`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`quiet-parakeet`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pure-woodcock`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`healthy-monkey`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mint-foal`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pet-serval`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ideal-lab`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`special-urchin`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see that almost all of them don’t make much sense, but some can be funny.
  prefs: []
  type: TYPE_NORMAL
- en: Random numbers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generating random numbers can also help generate random names or generate a
    random index from an array. `random_integer` offers a simple solution that allows
    you to pick a number between specified `min` and `max` values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following array of AWS availability zones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If we wanted to pick a random availability zone from this `list`, we could
    use `random_integer` to generate a random index from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code would allow us to generate a random integer between `0` and
    the length of the `list` minus `1`, which would be `4 - 1 = 3`. Therefore, we
    would randomly generate either `0`, `1`, `2`, or `3`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can access the random availability zone using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we could use the availability zone name to configure our AWS resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Beyond simple integers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When simple integers aren’t enough, you can use `random_id` to generate more
    sophisticated outputs. The only input is the `byte_length` to control how large
    the random number generated can be. This resource differs from other `random`
    providers’ resources as it does not have a `result` output, but has several others
    that present the random number in various formats, including decimal, hexadecimal,
    and Base64:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates a random number with a length of 8 bytes. Examples
    of the output values of the different formats are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`IpVgeF7uUY0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2492004038924456333`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`229560785eee518d`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IpVgeF7uUY0=`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`=` `IpVgeF7uUY0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, depending on your naming conventions, this can be useful for creating
    names or tags that uniquely identify your resources.
  prefs: []
  type: TYPE_NORMAL
- en: Shuffle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the previous example, when selecting availability zones from a list, we
    would have to generate various `random_integer` resources if we wanted to select
    multiple items from that list at random. Attempting to do so with `random_integer`
    is already pretty cumbersome, but it becomes more challenging if we have requirements
    to ensure that the second instance of `random_integer` isn’t the same as the first
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, an alternative approach to using `random_integer` to select the index
    of an array is to use a built-in resource for the specific task of choosing a
    random subset of items from a `list`. You can achieve this approach using the
    `random_shuffle` resource, passing in the `list` and the number of items you want
    using the `result_count` attribute. The output `result` will be a `list` of strings
    that you can use. This approach dramatically simplifies our solution if we want
    our AWS **Elastic Load Balancer** (**ELB**) to span multiple availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following array of AWS availability zones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We would use `random_shuffle` to generate two availability zones for our ELB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we set the `availability_zones` attribute using the `result` of `random_shuffle`
    because its output is the correct type of `list(string)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This resource is useful, but you need to watch out when using it as it can cause
    your solution to become non-deterministic—meaning that Terraform won’t be able
    to figure out how to create a plan until the `random_shuffle` resource has been
    created. This could require you to use targeted `terraform apply` operations to
    avoid first-time-apply failures.
  prefs: []
  type: TYPE_NORMAL
- en: Working with time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Terraform, the `time` provider offers several capabilities that make it easier
    to handle various scenarios where resource life cycle management is dictated by
    time.
  prefs: []
  type: TYPE_NORMAL
- en: While most cloud providers offer much better solutions for resource scheduling,
    there are still cases where time plays a crucial role in the provisioning of resources.
    This situation often involves certificates, where you need to set a fixed or rolling
    window for the certificate to expire. In this situation, you can use either a
    specific date/time in the future or one that is relative to the current date/time.
  prefs: []
  type: TYPE_NORMAL
- en: Current date/time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sometimes, you want to capture the current date and time, which you may like
    to use for the effective date of a secret’s value. There are two methods to obtaining
    the current date in Terraform—a function and the `time_static` resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code demonstrates using the `timestamp()` function. The following
    code shows how to use the `time_static` resource from the `time` provider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Both approaches will generate the current date/time on the first time you run
    `apply`. The difference is that the `timestamp()` function will always generate
    a current date/time stamp on every subsequent `apply`. This makes it more ideal
    for scenarios such as tagging a resource with its last modified date, which could
    be useful to determine the last time the resource was touched by Terraform. Another
    common scenario is triggering resource updates that you want to happen every time,
    but try to avoid this because this creates perpetual churn in your solution.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, the `time_static` resource will maintain, in State, the original
    date/time stamp at the first Terraform `apply`. This can be useful for life cycle
    management of the resources to determine when the deployment was originally created
    or for setting policies for backups, scaling, or decommissioning based on age.
  prefs: []
  type: TYPE_NORMAL
- en: Fixed date/time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A string representation of the date/time can be used to create a specific time
    in the future using an absolute date/time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will set the expiration date to May 4, 2024\. The format
    of the string representation of date/time is `YYYY-MM-DDTHH:MM:SSZ`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option is using the `time_static` resource and setting the `rfc3339`
    attribute, which is rarely used due to its limited value over simply setting a
    local:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Time offset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A specific time in the future using a period relative to the current date can
    be created using `time_offset`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will set the expiration date to exactly one year in the future.
    There are different attributes to adjust the offset date/time stamp by years,
    months, days, hours, minutes, and seconds. You can set the `base_rfc3339` attribute
    to change the date/time to which the offset is relative. This can be a great way
    to dynamically set certain expiration dates. However, you need to ensure that
    you routinely run Terraform to keep the target date in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Rotation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You may need to recreate resources on a regular cadence in several situations.
    This secret could need to be updated every 90 days or XXX days. In these situations,
    the `time_rotating` resource provides an advantage over its static siblings, both
    `time_static` and `time_offset`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Time offset seems like the solution for rotation as it is relative to the current
    date, but just like `time_static`, it is just another way of calculating a static
    date/time stamp that Terraform will store in State. The `time_rotating` resource’s
    superpower is that when the `rotation_days` period expires relative to the original
    date, you will see that the resource triggers a replacement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This also requires you to regularly run Terraform to keep the values in the
    future. If you utilize resources like this, make sure you coordinate with your
    change management procedures, as they can sneak up on you when you execute a `terraform
    plan` only to discover you’ve passed the magic date.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to randomize the names of our resources using
    the `random` provider, and even generate secrets that we can use to fully automate
    an environment with resources that need you to set passwords before Terraform
    can provision them. We also learned how we could use the `time` provider, when
    to use it versus the `timestamp()` function we looked at in [*Chapter 2*](B21183_02.xhtml#_idTextAnchor096),
    and other advanced scenarios of creating time periods and windows of rotation.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at some utility providers that help us overcome some limitations
    of Terraform whenever we encounter a situation in which Terraform doesn’t already
    have a built-in solution or an existing provider that tackles the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptation and integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we’ve discussed, Terraform and its providers are open source projects, so
    there may be limits to what it can do or what is available. As a result, we often
    need to find ways of overcoming these limitations—even temporarily. In this section,
    we’ll look at several providers that help Terraform reach outside and take advantage
    of external programs and systems that can enhance Terraform and help it overcome
    situations lacking a built-in solution.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing external resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like many utility providers, the `external` provider is tiny. It only has one
    data source of the same name as the provider: `external`. As the name implies,
    this data source allows you to integrate with third-party components. It enables
    you to execute a local program, pass its input, and process the output. This capability
    can be advantageous when you want to obtain dynamic configuration from an external
    source, perform complex transformations on inputs you receive from other providers,
    and integrate with third-party tools that you want to integrate with Terraform.'
  prefs: []
  type: TYPE_NORMAL
- en: This provider is very particular about the runtime requirements of the program
    that you specified. First, the program must run successfully by exiting with an
    exit code of zero. If the program returns a non-zero code, the provider will sound
    the alarm and scramble an error message to Terraform. Second, the provider expects
    both the input and the output to be in JSON format.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `external` provider works perfectly when your third-party program
    fulfills all these requirements. It is a happy coincidence indeed! If you are
    integrating with such a program, that’s great. However, this provider is the right
    choice when you author custom scripts or programs that explicitly meet these contractual
    obligations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To be as cross-platform as possible, the ideal programming language to write
    these custom scripts would be Python or Go. With these programming languages,
    you can create a lightweight script, designed and built, that is fit for the purpose
    of talking to the external system of your choice and providing Terraform-friendly
    outputs and error handling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we are executing the Python program on the local machine–this
    could be our laptop or the build agent of our **continuous integration/continuous
    delivery** (**CI/CD**) pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: When you want to make something from nothing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Terraform and its providers are open source projects. That means that we are
    at the mercy of friendly internet strangers who are keeping pace with the changes
    made to the platforms and technologies that we hope to automate. While Terraform
    has fantastic coverage across a wide set of public cloud platforms and technologies,
    sometimes, it needs a little help. There might be a small feature that lacks support
    that you can’t configure natively through the resources available in the provider.
    Sometimes, those small tweaks play a critical role in configuration, and we need
    to draw dependencies on them from other resources that can be provisioned natively
    through the Terraform provider. That’s where the `null_resource` comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: Null resource
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `null_resource` allows us to leverage meta-arguments such as `provisioner`
    to perform local and remote script executions. This allows you to execute critical
    command-line scripts that must be completed before Terraform can continue its
    plan. As a result, the `null_resource` has no attributes such as other Terraform
    resources. Its only attribute is a `list(string)` called `triggers`. When any
    strings within this array change, the `null_resource` is replaced. This is an
    important life cycle control that you need to consider when configuring the `provisioner`
    blocks you attach.
  prefs: []
  type: TYPE_NORMAL
- en: Time sleep
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is another technique of doing nothing. There can be situations where
    the action you try to trigger is non-deterministic, meaning you won’t know exactly
    when it finishes. This could be out of context or a true technical limitation
    of the resource or shim you use. The `time` provider offers a resource called
    `time_sleep`, which lets you create a sleep timer. You must declare `depends_on`
    meta-arguments to ensure that the sleep timer is invoked between the required
    resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Delayed `destroy` can be done using a different attribute called `destroy_duration`.
  prefs: []
  type: TYPE_NORMAL
- en: Making HTTP requests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, you can access data from external sources without using a local script
    or command-line utility, by directly accessing a REST API endpoint. This approach
    is advantageous when you want to fetch configuration information staged at a static
    HTTP endpoint, access information about resources managed outside of Terraform,
    integrate with a cloud provider or external services directly through a REST API,
    and integrate health checks into your Terraform process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `http` provider provides a single data source called `http`, allowing you
    to make an HTTP `GET` operation. The only required input is `url`, but you can
    provide several attributes you would expect to set on an HTTP request, such as
    HTTP request headers and body content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: After Terraform makes the HTTP request, you can access the HTTP response status
    code, headers, and body content.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to integrate with all sorts of external components—local
    programs or scripts, a remote server, and nothing at all.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at some utility providers that help us work with creating and
    accessing files. We’ve already encountered some functions that enable some of
    these scenarios, but some additional scenarios are only possible when we use utility
    providers.
  prefs: []
  type: TYPE_NORMAL
- en: Filesystem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When building IaC solutions using Terraform, there are many situations where
    we need to either use existing files or create new ones. In this section, we’ll
    look at the utility providers that enable more advanced scenarios that move beyond
    the `file` and `templatefile` functions and when we should use the providers versus
    using the functions.
  prefs: []
  type: TYPE_NORMAL
- en: Reading and writing local files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many situations when reading or writing files can be very useful to
    simplify how Terraform integrates with other tools by creating configuration files,
    scripts, or any other artifact required for your infrastructure deployment. To
    produce the desired output, you can define the content using templated files,
    input variables, or other expressions within your HCL code.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform has a utility provider called `local` that provides this functionality.
    This provider has two resources and two data sources named `local_file` and `local_sensitive_file`.
  prefs: []
  type: TYPE_NORMAL
- en: Why not just use the function? Functions do not participate in the dependency
    graph, so when you use the `file` or `template_file` functions, you cannot use
    them with files generated dynamically during a Terraform operation. Therefore,
    if you plan on generating and using a file within Terraform, you should always
    use the `local` provider’s resources.
  prefs: []
  type: TYPE_NORMAL
- en: Writing files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `local_file` resource (and the corresponding `local_sensitive_file` resource)
    allows you to create a new file at a target location specified in the `filename`
    attribute. There are several options for sourcing the content, either by using
    dynamically generated content inside Terraform or an existing file:'
  prefs: []
  type: TYPE_NORMAL
- en: '`content`: This attribute allows you to pass any string as long as it is UTF-8-encoded,
    using simple strings from resource outputs, local variables, or functions to generate
    a string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`content_base64`: This attribute allows you to pass binary data as a Base64-encoded
    string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source`: This attribute allows you to pass a path to an existing file from
    which you want to read the contents. When using this attribute, you copy the original
    file to a new location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following code, we are setting the `content` attribute to a simple constant
    string and using the `${path.module}` special token to specify the current module’s
    working directory as the output location for a file with the name of `foo.bar`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Be careful when destroying, especially if you dynamically generate the file’s
    contents inside Terraform using a `jsonencode`, `yamlencode`, or any other method—you
    may run into issues because of the way Terraform handles dependencies on this
    resource type.
  prefs: []
  type: TYPE_NORMAL
- en: Also, be aware when writing sensitive data to files, as it can pose a security
    risk. Likewise, filesystem access or I/O failures can create opportunities for
    additional points of failure when executing Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: Given these common pitfalls, generating file contents using Terraform can still
    be extremely effective. One such scenario is generating YAML inventories for Ansible,
    which can be an excellent way of integrating Terraform and Ansible as part of
    a broader maintenance process for long-lived environments that need configuration
    management changes at the operating system level.
  prefs: []
  type: TYPE_NORMAL
- en: Reading files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `local_file` data source (and the corresponding `local_sensitive_file` data
    source) allows you to read the contents of an existing file and output its contents
    in a variety of formats that you can use as inputs to other resources and modules
    within your code base. This capability is similar to what the `file` function
    can do but provides a few advantages.
  prefs: []
  type: TYPE_NORMAL
- en: First, it can create a standalone block referenced multiple times from multiple
    resources without repeating the filename’s path in the equivalent function call.
    Creating a central reference to the local file can make your code more maintainable
    by making the dependencies on the file more apparent to both Terraform and humans.
  prefs: []
  type: TYPE_NORMAL
- en: Second, by leveraging the data source, you immediately have several ways to
    output the data, including Base64-string, SHA, and MD5 options. By leveraging
    these output options, you can avoid additional nested function calls to perform
    the same encoding operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we access an existing file within the module’s current
    directory with a `foo.bar` filename:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We can then access the file’s raw content by using the `content` output of the
    data source or any of the other encoding options mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Templating files and directories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we covered templating files and surveyed HCL’s built-in
    functions, including the function called `template_file`. You should use this
    function when working with a single file, but the `template` provider offers a
    resource that you can use to apply templating across all the files within a given
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: The resource takes input files from the `source_dir` attribute and, for each
    file, substitutes the specified input variables for the corresponding placeholders,
    writing each output file to the established `destination_dir`. Using this resource
    is a great way to update configurations that span a multitude of files. Still,
    you must stage all files with a consistent set of placeholders for the templating
    engine to replace in the same fashion as the `template_file()` function operates.
  prefs: []
  type: TYPE_NORMAL
- en: Generating file archives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, it’s necessary to package outputs from Terraform into compressed
    archives that you can use for several different purposes, such as efficiently
    transferring configuration to the next stage in the application deployment pipeline,
    bundling configuration for easy distribution to other external repositories, and
    generating documentation or other artifacts to track deployment history, environmental
    changes, or snapshots of configuration as they change over time.
  prefs: []
  type: TYPE_NORMAL
- en: You should avoid this approach when working with secrets or sensitive data,
    as more appropriate solutions exist for those scenarios. Metadata related to the
    infrastructure generated by Terraform and needed by another tool in another format
    is the ideal scenario for this approach.
  prefs: []
  type: TYPE_NORMAL
- en: The `archive_file` resource generates a ZIP file at the specified `output_path`
    and includes one or more files, using either existing files or dynamically generated
    files.
  prefs: []
  type: TYPE_NORMAL
- en: Including existing files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you want to reference either existing files that are stored in your Terraform
    module directory or files generated by Terraform using the `local` provider, you
    should use `source_file` or `source_dir` to include a single file or an entire
    directory of files within the archive, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Including dynamically created files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you want to output content that’s dynamically generated by Terraform using
    object construction in local variables or other means, you need to use one or
    more `source` blocks and specify the `content` and the `filename` of the file
    to include it within the archive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Optionally, if you only want one dynamically generated file in the archive,
    you can use the top-level `source_content` and `source_filename` to have a single
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The preceding examples produce the same output, but the latter is slightly more
    concise for the single-file archive scenario. At the same time, the former allows
    you to add as many files to the archive as you like in the future using additional
    `source` blocks.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that each method for including files within the archive
    is mutually exclusive, so you must choose one—and only one—approach.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to leverage the `local`, `archive`, and `template`
    providers to handle more robust filesystem access scenarios where leveraging the
    existing functions may not be ideal.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we’ll look at some utility providers that help us work with setting
    up operating system configuration, security, and network access control.
  prefs: []
  type: TYPE_NORMAL
- en: Operating system and networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HashiCorp created Terraform’s utility providers to solve common problems that
    span cloud platforms. As a result, some utility providers solve problems relating
    to common architectural scenarios you will encounter when setting up or connecting
    to servers.
  prefs: []
  type: TYPE_NORMAL
- en: Generating certificates and SSH keys
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Terraform, the `tls` provider offers general capabilities related to **Transport
    Layer Security** (**TLS**) and cryptography. You should use this provider with
    a certificate authority to generate signed certificates for production workloads.
    Still, several features are very helpful in development and lab environments to
    streamline productivity.
  prefs: []
  type: TYPE_NORMAL
- en: SSH keys
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When working with virtual machines, an everyday use case is the need to generate
    `ssh-keygen`, but Terraform has a provider with resources for this very task,
    which makes it extremely easy and convenient to encapsulate the same SSH key generation
    with the infrastructure that is going to use it. It’s a perfect tool for short-lived
    lab environments to kick the tires on, but when using this approach, you’ll need
    to lock down your Terraform state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that Terraform has generated your resource, you can drop it into the secrets
    manager of your choice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we drop the `private_key_openssh` value into an Azure
    Key Vault secret, allowing us to use the SSH key from the Azure portal to connect
    to the machine directly or use Azure Bastion.
  prefs: []
  type: TYPE_NORMAL
- en: '`RSA` is the most popular algorithm used for SSH keys. It is tried and true,
    but you should use a key size of at least 4,096 bits. Newer algorithms such as
    `ECDSA` and `ED25519` are also supported, but you should ensure your clients support
    these algorithms before wider adoption within your organization.'
  prefs: []
  type: TYPE_NORMAL
- en: When you generate the SSH key, you don’t need to save it to the filesystem.
    You should save it to a certificate management service such as **AWS Certificate
    Manager** (**ACM**), Azure Key Vault, or Google Cloud’s Certificate Manager.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the way Terraform planning works, for Terraform to know whether or not
    the SSH key resource exists and whether your certificate manager has the resource,
    it needs to maintain critical attributes in the state file. Many of those key
    attributes are highly sensitive information, including the public and private
    keys. Therefore, securing your Terraform state’s backend will be crucial to prevent
    unauthorized access. It’s not an impossible or difficult task in its own right,
    but until you’ve got a secure backend strategy in place, this approach is probably
    good to skip for production workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Certificates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When generating a certificate, you typically need to generate a `PEM` file)
    and details about the certificate subject, including human-friendly information
    such as the organization name, physical address, and network address information
    such as domain names or IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform has a resource, `tls_cert_request`, that can generate the CSR. Like
    the `tls_private_key` resource that generates an SSH key, this resource performs
    a task a human operator would perform by using a graphical or command-line interface
    to generate the CSR. The output of this resource would then need to be passed
    to a CA to generate a signed certificate.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the `foo` resource to generate the certificate locally. The CSR
    provider will attempt to process it on the local machine running Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need a private key, which you can create using the `tls_private_key`
    resource we used to generate an SSH key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to generate the CSR using the `tls_cert_request` resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can generate a certificate using the private key and the CSR:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Generating CloudInit configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Cloud Init** is an open source, multi-platform tool for providing startup
    configuration to cloud-hosted virtual machines. It configures the new instance
    using metadata from the cloud and user data. For example, you can set the hostname,
    set up users and groups, mount and format disks, install packages, and run custom
    scripts.'
  prefs: []
  type: TYPE_NORMAL
- en: Basic usage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes, you can use data sources to generate content rather than talk to
    an external system. The `cloudinit_config` is a perfect example of this. It is
    designed with a schema to help simplify generating the sometimes-verbose Cloud-Init
    configuration file passed as input to newly created virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud-Init supports several different part types. Each type infers a different
    schema and format for passing in content, sometimes using JSON, YAML, bash scripts,
    or raw text. The full scope of what Cloud-Init can do is out of the scope of this
    book, but I’d encourage you to look into the online documentation for further
    details. I’ll cover a few everyday use cases to show how you can use your existing
    Cloud-Init knowledge and apply it while using the `cloudinit` Terraform provider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'To attach the output as user data to a new **Elastic Compute Cloud** (**EC2**)
    instance on AWS, we would use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Loading external content
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you have a large amount of external content you want to download to the
    instance, you can use `x-include-url` and `x-include-once-url`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Using custom scripts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you want to execute custom scripts stored within the Terraform module
    directory, you can use several different part types to run the scripts under other
    conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`x-shellscript`: This script will run whenever the instance is booted. That
    is, it will execute every time your instance starts up, whether it is the first
    boot after creation or a subsequent reboot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x-shellscript-per-boot`: This is the same as `x-shellscript`. It will also
    run on every boot of the instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x-shellscript-per-instance`: This script will run only once per instance.
    That is, the script will run on the first boot after the instance is created but
    will not run on subsequent reboots. This part is helpful for initialization tasks
    that only need to be done once for each instance, such as setting up software
    or users that persist across reboots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x-shellscript-per-once`: This script will run only once across all instances.
    If you create multiple instances with the same script, this script will only run
    on the first instance that boots. This part is helpful for tasks that only need
    to be done once in a set of instances, such as setting up a database or a leader
    node in a cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following script, which is stored in a bash script file called
    `foo.sh` in the Terraform module’s root folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We can embed this in a `cloudinit_config` data source to generate the user
    data we pass to a newly created virtual machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Cloud config files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cloud-Init supports a custom schema for performing various everyday tasks.
    Several different part types are supported, enabling you to include cloud config
    data in multiple formats in your Cloud-Init packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cloud-config`: This is the most commonly used content type for standard cloud-init
    YAML configuration files. You can use the `cloud-config` content type for general-purpose
    instance configuration tasks, such as setting up users and groups, managing packages,
    running commands, and writing files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloud-config-archive`: This content type provides multiple cloud-config parts
    in a single file. A `cloud-config-archive` file is a YAML file that contains a
    list of cloud-config parts, where each part is a map containing a filename, a
    content type, and the content itself. You should use this when applying multiple
    cloud-config files in a specific order. Their order in the list influences when
    they are applied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloud-config-jsonp`: This content type allows you to write **JSON with Padding**
    (**JSONP**) responses. JSONP is commonly used to bypass web browser cross-domain
    policies. You might use this content type if you’re writing a web app that needs
    to interact with a server on a different domain and uses JSONP to circumvent the
    same-origin policy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The full capabilities of cloud config are beyond the scope of this book, but
    I encourage you to explore them in more detail through online documentation. The
    following configuration demonstrates how we can use `cloud init` to generate a
    user, a group, assign the user to the group, and set up permissions and settings
    for the machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We can embed this in a `cloudinit_config` data source to generate the user
    data we pass to a newly created virtual machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Configuring DNS records
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Managing **Domain Name System** (**DNS**) using automation is critical to specific
    release strategies such as blue-green deployment. Terraform provides an extensible
    framework that can easily handle such essential configurations.
  prefs: []
  type: TYPE_NORMAL
- en: While most cloud providers offer their own DNS services, from Amazon’s Route
    53 to Azure’s Private DNS zones, there is usually a first-party solution for managing
    DNS on the cloud of your choice. Several third-party providers for public DNS
    registrars have DNS service offerings such as Cloudflare, Akamai, GoDaddy, and
    DynDNS.
  prefs: []
  type: TYPE_NORMAL
- en: However, because Terraform offers such an extensible foundation, managing DNS
    is not limited to public cloud platforms through their respective providers. You
    can also manage your on-premises DNS servers or any custom DNS infrastructure
    built using infrastructure as a service in your chosen public or private clouds.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the `DNS` provider with any DNS server that supports either the
    secret key (`RFC 2845`) or GSS-TSIG (`RFC 3645`) authentication method.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked in depth at the utility providers that HashiCorp
    has built to help us augment our IaC solutions. We learned how to integrate with
    external systems, work with assets stored on the filesystem, and randomize and
    fill in whitespace within Terraform. These Terraform providers are incredibly
    versatile, and as you explore them more, you will find them more and more valuable.
  prefs: []
  type: TYPE_NORMAL
- en: As you would when using other providers, always reference the provider in your
    `required_providers` block with an explicit version number. Do not implicitly
    take the latest. Other than that, resources from these providers can be embedded
    in any Terraform module. Take special care when designing reusable modules to
    ensure you have minimal provider requirements on upstream client modules, as this
    can add additional complexity to users who hope to reuse your module when it requires
    a dozen different providers to be declared!
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will establish some architectural concepts we can apply
    to our IaC, no matter the cloud platform we target. After all, our IaC is only
    as good as the architecture that it defines. Therefore, we must have a sound understanding
    of the typical elements of cloud service anatomy and the mechanics of different
    computational paradigms such as virtual machines and containers. So, next, we’ll
    look at virtual machine architecture through a multi-cloud lens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: Concepts of Cloud Architecture and Automation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Without a solid foundation in cloud architecture and software development processes,
    the journey into Infrastructure as Code would be a futile one. Luckily, many of
    these concepts transcend cloud platforms, and once you understand the key concepts,
    you’ll be ready to apply that knowledge within the cloud of your choice—be it
    AWS, Azure, or GCP.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B21183_04.xhtml#_idTextAnchor239), *Foundations of Cloud Architecture
    – Virtual Machines and Infrastructure-as-a-Service*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B21183_05.xhtml#_idTextAnchor278), *Beyond VMs – Core Concepts
    of Containers and Kubernetes*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B21183_06.xhtml#_idTextAnchor330), *Connecting It All Together
    – GitFlow, GitOps, and* *CI/CD*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
