- en: Chapter 1. Installing OpenStack with Ansible
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 1 章. 使用 Ansible 安装 OpenStack
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction – the OpenStack architecture
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 – OpenStack 架构
- en: Host network configuration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机网络配置
- en: Root SSH keys configuration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根 SSH 密钥配置
- en: Installing Ansible, playbooks, and dependencies
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Ansible、剧本和依赖项
- en: Configuring the installation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置安装
- en: Running the OpenStack-Ansible playbooks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 OpenStack-Ansible 剧本
- en: Troubleshooting the installation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障排除安装
- en: Manually testing the installation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动测试安装
- en: Modifying the OpenStack configuration
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改 OpenStack 配置
- en: Virtual lab - vagrant up!
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟实验室 - vagrant up!
- en: Introduction – the OpenStack architecture
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 – OpenStack 架构
- en: OpenStack is a suite of projects that combine into a software-defined environment
    to be consumed using cloud friendly tools and techniques. The popular open source
    software allows users to easily consume compute, network, and storage resources
    that have been traditionally controlled by disparate methods and tools by various
    teams in IT departments, big and small. While consistency of APIs can be achieved
    between versions of OpenStack, an administrator is free to choose which features
    of OpenStack to install, and as such there is no single method or architecture
    to install the software. This flexibility can lead to confusion when choosing
    how to deploy OpenStack. That said, it is universally agreed that the services
    that the end users interact with—the OpenStack services, supporting software (such
    as the databases), and APIs—must be highly available.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 是一套项目集合，通过软件定义环境结合起来，用户可以通过云计算友好的工具和技术进行消费。这款流行的开源软件使得用户能够轻松地消费计算、网络和存储资源，这些资源传统上由不同的
    IT 团队使用各种方法和工具来管理，不论是大型还是小型团队。尽管可以通过 OpenStack 版本之间 API 的一致性来实现兼容，管理员仍然可以自由选择安装
    OpenStack 的哪些功能，因此没有单一的安装方法或架构来安装该软件。这种灵活性可能会导致在选择如何部署 OpenStack 时产生困惑。尽管如此，全球一致认为，最终用户交互的服务—即
    OpenStack 服务、支持软件（如数据库）和 API—必须具备高可用性。
- en: A very popular method for installing OpenStack is the OpenStack-Ansible project
    ([https://github.com/openstack/openstack-ansible](https://github.com/openstack/openstack-ansible)).
    This method of installation allows an administrator to define highly available
    controllers together with arrays of compute and storage, and through the use of
    Ansible, deploy OpenStack in a very consistent way with a small amount of dependencies.
    Ansible is a tool that allows for system configuration and management that operates
    over standard SSH connections. Ansible itself has very few dependencies, and as
    it uses SSH to communicate, most Linux distributions and networks are well-catered
    for when it comes to using this tool. It is also very popular with many system
    administrators around the globe, so installing OpenStack on top of what they already
    know lowers the barrier to entry for setting up a cloud environment for their
    enterprise users.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 OpenStack 的一种非常流行的方法是 OpenStack-Ansible 项目（[https://github.com/openstack/openstack-ansible](https://github.com/openstack/openstack-ansible)）。这种安装方法允许管理员定义高度可用的控制节点以及计算和存储阵列，并通过使用
    Ansible，以非常一致的方式部署 OpenStack，且所需的依赖项较少。Ansible 是一种通过标准 SSH 连接进行系统配置和管理的工具。Ansible
    本身依赖项很少，而且由于它使用 SSH 进行通信，大多数 Linux 发行版和网络都能够很好地支持这个工具。它在全球许多系统管理员中非常受欢迎，因此在他们已有的知识基础上安装
    OpenStack，降低了为企业用户设置云环境的门槛。
- en: 'OpenStack can be architected in any number of ways; OpenStack-Ansible doesn''t
    address the architecture problem directly: users are free to define any number
    of controller services (such as Horizon, Neutron Server, Nova Server, and MySQL).
    Through experience at Rackspace and feedback from users, a popular architecture
    is defined, which is shown here:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 可以以多种方式进行架构设计；OpenStack-Ansible 并不直接解决架构问题：用户可以自由定义任意数量的控制服务（如 Horizon、Neutron
    Server、Nova Server 和 MySQL）。通过 Rackspace 的经验和用户反馈，定义了一种流行的架构，示例如下：
- en: '![Introduction – the OpenStack architecture](img/00002.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![介绍 – OpenStack 架构](img/00002.jpeg)'
- en: 'Figure 1: Recommended OpenStack architecture used in this book'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：本书推荐的 OpenStack 架构
- en: As shown in the preceding diagram (*Figure 1*), there are a few concepts to
    first understand. These are described as follows.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示（*图 1*），首先需要了解一些概念。这些概念如下所述。
- en: Controllers
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制节点
- en: The *controllers* (also referred to as *infrastructure or infra nodes*) run
    the heart of the OpenStack services and are the only servers exposed (via load
    balanced pools) to your end users. The *controllers* run the API services, such
    as Nova API, Keystone API, and Neutron API, as well as the core supporting services
    such as **MariaDB** for the database required to run OpenStack, and RabbitMQ for
    messaging. It is this reason why, in a production setting, these servers are set
    up as highly available as required. This means that these are deployed as clusters
    behind (highly available) load balancers, starting with a minimum of 3 in the
    cluster. Using odd numbers starting from 3 allows clusters to lose a single server
    without and affecting service and still remain with quorum (minimum numbers of
    votes needed). This means that when the unhealthy server comes back online, the
    data can be replicated from the remaining 2 servers (which are, between them,
    consistent), thus ensuring data consistency.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*控制器*（也称为*基础设施节点*或*infra 节点*）运行 OpenStack 服务的核心部分，是唯一通过负载均衡池对外暴露的服务器（通过负载均衡池）供最终用户使用。*控制器*运行
    API 服务，例如 Nova API、Keystone API 和 Neutron API，以及核心支持服务，如用于运行 OpenStack 所需数据库的**MariaDB**和用于消息传递的
    RabbitMQ。正因为如此，在生产环境中，这些服务器必须按照需求配置为高可用性。这意味着这些服务器作为集群部署在（高可用）负载均衡器后面，集群中至少有 3
    台服务器。使用从 3 开始的奇数集群，可以使集群在丧失一台服务器的情况下仍然保持服务不受影响，并且仍能保持法定人数（即需要的最小投票数）。这意味着，当不健康的服务器重新上线时，数据可以从剩余的
    2 台服务器中复制（它们之间是一致的），从而确保数据的一致性。'
- en: Networking is recommended to be highly resilient, so ensure that Linux has been
    configured to bond or aggregate the network interfaces so that in the event of
    a faulty switch port, or broken cable, your services remain available. An example
    networking configuration for Ubuntu can be found in *Appendix A*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 网络建议具有高度的弹性，因此需要确保 Linux 已配置为绑定或聚合网络接口，以便在发生交换机端口故障或电缆损坏时，您的服务仍然可用。Ubuntu 的示例网络配置可以在*附录
    A*中找到。
- en: Computes
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算节点
- en: These are the servers that run the hypervisor or container service that OpenStack
    schedules workloads to when a user requests a Nova resource (such as a virtual
    machine). These are not too dissimilar to hosts running a hypervisor, such as
    ESXi or Hyper-V, and OpenStack Compute servers can be configured in a very similar
    way, optionally using shared storage. However, most installations of OpenStack
    forgo the need for the use of shared storage in the architecture. This small detail
    of not using shared storage, which implies the virtual machines run from the hard
    disks of the compute host itself, can have a large impact on the users of your
    OpenStack environment when it comes to discussing the resiliency of the applications
    in that environment. An environment set up like this pushes most of the responsibility
    for application uptime to developers, which gives the greatest flexibility of
    a long-term cloud strategy. When an application relies on the underlying infrastructure
    to be 100% available, the gravity imposed by the infrastructure ties applications
    to specific data center technology to keep it running. However, OpenStack can
    be configured to introduce shared storage such as Ceph ([http://ceph.com/](http://ceph.com/))
    to allow for operational features such as live-migration (the ability to move
    running instances from one hypervisor to another with no downtime), allowing enterprise
    users move their applications to a cloud environment in a very safe way. These
    concepts will be discussed in more detail in later chapters on compute and storage.
    As such, the reference architecture for a compute node is to expect virtual machines
    to run locally on the hard drives in the server itself.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是运行虚拟化管理程序或容器服务的服务器，当用户请求Nova资源（例如虚拟机）时，OpenStack将工作负载调度到这些服务器上。它们与运行虚拟化管理程序的主机（如ESXi或Hyper-V）没有太大区别，OpenStack计算服务器的配置方式也非常相似，可以选择使用共享存储。然而，大多数OpenStack安装都会避免在架构中使用共享存储。这个不使用共享存储的小细节意味着虚拟机直接从计算主机的硬盘上运行，这对于讨论环境中应用的弹性时，会对OpenStack环境的用户产生较大影响。像这样设置的环境将大部分应用正常运行的责任交给开发者，这为长期云策略提供了最大的灵活性。当一个应用依赖于底层基础设施100%可用时，基础设施所施加的重力会将应用绑定到特定的数据中心技术上以确保其运行。然而，OpenStack可以配置为引入共享存储，例如Ceph（[http://ceph.com/](http://ceph.com/)），以支持像实时迁移（在不中断的情况下将正在运行的实例从一个虚拟化管理程序迁移到另一个虚拟化管理程序）的操作特性，这样可以非常安全地将企业用户的应用迁移到云环境中。这些概念将在后续的计算和存储章节中详细讨论。因此，计算节点的参考架构是预期虚拟机将直接运行在服务器本身的硬盘上。
- en: With regard to networking, like the *controllers*, the network must also be
    configured to be highly available. A compute node that has no network available
    might be very secure, but it would be equally useless to a cloud environment!
    Configure bonded interfaces in the same way as the controllers. Further information
    for configuring bonded interfaces under Ubuntu can be found in *Appendix A*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 关于网络配置，像*控制器*一样，网络也必须配置为高可用性。一个没有可用网络的计算节点可能非常安全，但对于云环境来说同样毫无用处！请像配置控制器一样配置绑定接口。有关在Ubuntu下配置绑定接口的更多信息，请参见*附录A*。
- en: Storage
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储
- en: Storage in OpenStack refers to block storage and object storage. Block storage
    (providing LUNs or *hard drives* to virtual machines) is provided by the Cinder
    service, while object storage (API driven object or blobs of storage) is provided
    by Swift or Ceph. Swift and Ceph manage each individual drive in a server designated
    as an object storage node, very much like a RAID card manages individual drives
    in a typical server. Each drive is an independent entity that Swift or Ceph uses
    to write data to. For example, if a storage node has 24 x 2.5in SAS disks in,
    Swift or Ceph will be configured to write to any one of those 24 disks. Cinder,
    however, can use a multitude of backends to store data. For example, Cinder can
    be configured to communicate with third-party vendors such as NetApp or Solidfire
    arrays, or it can be configured to talk to Sheepdog or Ceph, as well as the simplest
    of services such as LVM. In fact, OpenStack can be configured in such a way that
    Cinder uses multiple backends so that a user is able to choose the storage applicable
    to the service they require. This gives great flexibility to both end users and
    operators as it means workloads can be targeted at specific backends suitable
    for that workload or storage requirement.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 中的存储指的是块存储和对象存储。块存储（为虚拟机提供 LUN 或 *硬盘*）由 Cinder 服务提供，而对象存储（由 API 驱动的对象或数据块存储）由
    Swift 或 Ceph 提供。Swift 和 Ceph 管理服务器中每个被指定为对象存储节点的独立硬盘，就像 RAID 卡管理典型服务器中的硬盘一样。每个硬盘都是一个独立的实体，Swift
    或 Ceph 用它来写入数据。例如，如果一个存储节点有 24 块 2.5 英寸的 SAS 硬盘，Swift 或 Ceph 会配置为写入这 24 块硬盘中的任何一块。然而，Cinder
    可以使用多种后端来存储数据。例如，Cinder 可以配置为与第三方供应商（如 NetApp 或 Solidfire 存储阵列）通信，或者它可以配置为与 Sheepdog
    或 Ceph 通信，还可以与像 LVM 这样的简单服务通信。事实上，OpenStack 可以配置为让 Cinder 使用多个后端，从而使用户能够选择适用于他们所需服务的存储。这为最终用户和操作员提供了极大的灵活性，因为这意味着工作负载可以针对特定的后端进行优化，适合该工作负载或存储需求。
- en: This book briefly covers Ceph as the backend storage engine for Cinder. Ceph
    is a very popular, highly available open source storage service. Ceph has its
    own disk requirements to give the best performance. Each of the Ceph storage nodes
    in the preceding diagram are referred to as **Ceph OSDs** (**Ceph Object Storage
    Daemons**). We recommend starting with 5 of these nodes, although this is not
    a hard and fast rule. Performance tuning of Ceph is beyond the scope of this book,
    but at a minimum, we would highly recommend having SSDs for Ceph journaling and
    either SSD or SAS drives for the OSDs (the physical storage units).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本书简要介绍了 Ceph 作为 Cinder 的后台存储引擎。Ceph 是一个非常流行、高可用的开源存储服务。Ceph 有其自身的磁盘要求，以提供最佳的性能。在前面的图示中，每个
    Ceph 存储节点被称为**Ceph OSD**（**Ceph 对象存储守护进程**）。我们建议从 5 个节点开始，尽管这不是硬性规定。Ceph 性能调优超出了本书的范围，但至少，我们强烈推荐使用
    SSD 来进行 Ceph 日志存储，OSD（物理存储单元）则可以使用 SSD 或 SAS 驱动器。
- en: The differences between a Swift node and a Ceph node in this architecture are
    very minimal. Both require an interface (bonded for resilience) for replication
    of data in the storage cluster, as well as an interface (bonded for resilience)
    used for data reads and writes from the client or service consuming the storage.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中，Swift 节点和 Ceph 节点之间的区别非常小。两者都需要一个用于存储集群中数据复制的接口（为提高容错性，接口通常是绑定的），以及一个用于从客户端或服务读取和写入数据的接口（同样为了容错性，接口通常是绑定的）。
- en: The primary difference is the recommendation to use SSDs (or NVMe) as the journaling
    disks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的区别在于建议使用 SSD（或 NVMe）作为日志磁盘。
- en: Load balancing
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负载均衡
- en: The end users of the OpenStack environment expect services to be highly available,
    and OpenStack provides REST API services to all of its features. This makes the
    REST API services very suitable for placing behind a load balancer. In most deployments,
    load balancers would usually be highly available hardware appliances such as F5\.
    For the purpose of this book, we will be using HAProxy. The premise behind this
    is the same though—to ensure that the services are available so your end users
    can continue working in the event of a failed *controller* node.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 环境的最终用户期望服务具有高度可用性，OpenStack 为其所有功能提供 REST API 服务。这使得 REST API 服务非常适合放置在负载均衡器后面。在大多数部署中，负载均衡器通常是高度可用的硬件设备，例如
    F5。为了本书的目的，我们将使用 HAProxy。不过，背后的前提是相同的——确保服务在 *控制器* 节点故障的情况下仍然可用，以便最终用户可以继续工作。
- en: OpenStack-Ansible installation requirements
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenStack-Ansible 安装要求
- en: 'Operating installing System: Ubuntu 16.04 x86_64'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：Ubuntu 16.04 x86_64
- en: Minimal data center deployment requirements
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最小的数据中心部署要求
- en: 'For a physical installation, the following will be needed:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于物理安装，以下是所需的：
- en: Controller servers (also known as infrastructure nodes)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器服务器（也称为基础设施节点）
- en: At least 64 GB RAM
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 64 GB 内存
- en: At least 300 GB disk (RAID)
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 300 GB 硬盘（RAID）
- en: '4 Network Interface Cards (for creating two sets of bonded interfaces; one
    would be used for infrastructure and all API communication, including client,
    and the other would be dedicated to OpenStack networking: Neutron)'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 个网络接口卡（用于创建两组绑定接口；一组用于基础设施和所有 API 通信，包括客户端，另一组专用于 OpenStack 网络：Neutron）
- en: Shared storage, or object storage service, to provide backend storage for the
    base OS images used
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享存储或对象存储服务，提供基础 OS 镜像的后端存储
- en: Compute servers
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算服务器
- en: At least 64 GB RAM
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 64 GB 内存
- en: At least 600 GB disk (RAID)
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 600 GB 硬盘（RAID）
- en: 4 Network Interface Cards (for creating two sets of bonded interfaces, used
    in the same way as the controller servers)
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 个网络接口卡（用于创建两组绑定接口，和控制器服务器使用相同方式）
- en: Optional (if using Ceph for Cinder) 5 Ceph Servers (Ceph OSD nodes)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选（如果使用 Ceph 作为 Cinder）5 台 Ceph 服务器（Ceph OSD 节点）
- en: At least 64 GB RAM
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 64 GB 内存
- en: 2 x SSD (RAID1) 400 GB for journaling
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 个 400 GB SSD（RAID1）用于日志记录
- en: 8 x SAS or SSD 300 GB (No RAID) for OSD (size up requirements and adjust accordingly)
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 8 个 300 GB SAS 或 SSD（不使用 RAID）用于 OSD（根据需求调整大小）
- en: 4 Network Interface Cards (for creating two sets of bonded interfaces; one for
    replication and the other for data transfer in and out of Ceph)
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 个网络接口卡（用于创建两组绑定接口；一组用于复制，另一组用于在 Ceph 中的数据进出传输）
- en: Optional (if using Swift) 5 Swift Servers
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选（如果使用 Swift）5 台 Swift 服务器
- en: At least 64 GB RAM
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 64 GB 内存
- en: 8 x SAS 300 GB (No RAID) (size up requirements and adjust accordingly)
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 8 个 300 GB SAS（不使用 RAID）（根据需求调整大小）
- en: 4 Network Interface Cards (for creating two sets of bonded interfaces; one for
    replication and the other for data transfer in and out of Swift)
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 个网络接口卡（用于创建两组绑定接口；一组用于复制，另一组用于在 Swift 中的数据进出传输）
- en: Load balancers
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡器
- en: 2 physical load balancers configured as a pair
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置为一对的 2 台物理负载均衡器
- en: 'Or 2 servers running HAProxy with a Keepalived VIP to provide as the API endpoint
    IP address:'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者 2 台运行 HAProxy 和 Keepalived VIP 的服务器，作为 API 端点的 IP 地址：
- en: At least 16 GB RAM
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 16 GB 内存
- en: HAProxy + Keepalived
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: HAProxy + Keepalived
- en: 2 Network Interface Cards (bonded)
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 个网络接口卡（绑定）
- en: Tip
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Setting up a physical home lab? Ensure you have a managed switch so
    that interfaces can have VLANs tagged.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：在设置物理实验室时，请确保你有一个管理型交换机，以便接口可以打上 VLAN 标签。'
- en: Host network configuration
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主机网络配置
- en: Installation of OpenStack using an orchestration and configuration tool such
    as Ansible performs a lot of tasks that would otherwise have to be undertaken
    manually. However, we can only use an orchestration tool if the servers we are
    deploying to are configured in a consistent way and described to Ansible.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如 Ansible 这样的编排和配置工具安装 OpenStack 可以自动化很多原本需要手动完成的任务。然而，我们只能在服务器以一致的方式配置并且已向
    Ansible 描述时，使用编排工具。
- en: The following section will describe a typical server setup that uses two sets
    of active/passive bonded interfaces for use by OpenStack. Ensure that these are
    cabled appropriately.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将描述一种典型的服务器配置，使用两组活动/被动绑定接口供 OpenStack 使用。确保这些接口连接正确。
- en: 'We assume that the following physical network cards are installed in each of
    the servers; adjust them to suit your environment:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设每台服务器都已安装以下物理网络卡；根据你的环境进行调整：
- en: '`p2p1` and `p2p2`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p2p1` 和 `p2p2`'
- en: '`p4p1` and `p4p2`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p4p1` 和 `p4p2`'
- en: We assume that the *host* network is currently using `p2p1`. The *host* network
    is the basic network that each of the servers currently resides on, and it allows
    you to access each one over SSH. It is assumed that this network also has a default
    gateway configured, and allows internet access. There should be no other networks
    required at this point as the servers are currently unconfigured and are not running
    OpenStack services.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设 *主机* 网络当前使用 `p2p1`。*主机* 网络是每台服务器当前所在的基础网络，允许你通过 SSH 访问每台服务器。假设该网络已经配置了默认网关，并且可以访问互联网。在这一阶段，应该不需要其他网络，因为服务器尚未配置，也未运行
    OpenStack 服务。
- en: 'At the end of this section, we will have created the following bonded interfaces:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节末尾，我们将创建以下绑定接口：
- en: '`bond0`: This consists of the physical interfaces `p2p1` and `p4p1`. The `bond0`
    interface will be used for host, OpenStack management, and storage traffic.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bond0`：这由物理接口`p2p1`和`p4p1`组成。`bond0`接口将用于主机、OpenStack管理和存储流量。'
- en: '`bond1`: This consists of the physical interfaces `p2p2` and `p4p2`. The `bond1`
    interface will be used for Neutron networking within OpenStack.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bond1`：这由物理接口`p2p2`和`p4p2`组成。`bond1`接口将用于OpenStack中的Neutron网络。'
- en: 'We will have created the following VLAN tagged interfaces:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建以下VLAN标记的接口：
- en: '`bond0.236`: This will be used for the *container network*'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bond0.236`：该接口将用于*容器网络*。'
- en: '`bond0.244`: This will be used for the *storage network*'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bond0.244`：该接口将用于*存储网络*。'
- en: '`bond1.240`: This will be used for the *VXLAN tunnel network*'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bond1.240`：该接口将用于*VXLAN隧道网络*。'
- en: 'And the following bridges:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以及以下桥接：
- en: '`br-mgmt`: This will use the `bond0.236` VLAN interface, and will be configured
    with an IP address from the `172.29.236.0/24` range.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`br-mgmt`：该桥接将使用`bond0.236` VLAN接口，并将配置来自`172.29.236.0/24`范围内的IP地址。'
- en: '`br-storage`: This will use the `bond0.244` VLAN interface, and will be configured
    with an IP address from the `172.29.244.0/24` range.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`br-storage`：该桥接将使用`bond0.244` VLAN接口，并将配置来自`172.29.244.0/24`范围内的IP地址。'
- en: '`br-vxlan`: This will use the `bond1.240 VLAN` interface, and will be configured
    with an IP address from the `172.29.240.0/24` range.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`br-vxlan`：该桥接将使用`bond1.240 VLAN`接口，并将配置来自`172.29.240.0/24`范围内的IP地址。'
- en: '`br-vlan`: This will use the untagged `bond1` interface, and will not have
    an IP address configured.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`br-vlan`：该桥接将使用未标记的`bond1`接口，并且不会配置IP地址。'
- en: Tip
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Ensure that your subnets are large enough to support your current
    requirements as well as future growth!'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：确保你的子网足够大，既能满足当前需求，也能支持未来的扩展！'
- en: 'The following diagram shows the networks, interfaces, and bridges set up before
    we begin our installation of OpenStack:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了我们在开始安装OpenStack之前设置的网络、接口和桥接：
- en: '![Host network configuration](img/00003.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![主机网络配置](img/00003.jpeg)'
- en: Getting ready
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: We assume that each server has Ubuntu 16.04 installed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设每台服务器都已安装Ubuntu 16.04。
- en: Log in, as root, onto each server that will have OpenStack installed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以root身份登录到将安装OpenStack的每台服务器。
- en: How to do it…
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Configuration of the host's networking, on a Ubuntu system, is performed by
    editing the `/etc/network/interfaces` file.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在Ubuntu系统上配置主机网络是通过编辑`/etc/network/interfaces`文件完成的。
- en: 'First of all, ensure that we have the right network packages installed on each
    server. As we are using VLANs and Bridges, the following packages must be installed:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，确保每台服务器上已安装正确的网络包。由于我们使用VLAN和桥接，必须安装以下软件包：
- en: '[PRE0]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now edit the `/etc/network/interfaces` file on the first server using your
    preferred editor:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在使用你喜欢的编辑器编辑第一个服务器上的`/etc/network/interfaces`文件：
- en: '[PRE1]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will first configure the bonded interfaces. The first part of the file will
    describe this. Edit this file so that it looks like the following to begin with:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先配置绑定接口。文件的第一部分将描述这一点。编辑此文件，使其开始时看起来像以下内容：
- en: '[PRE2]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we will configure the VLAN interfaces that are tagged against these bonds.
    Continue editing the file to add in the following tagged interfaces. Note that
    we are not assigning IP addresses to the OpenStack bonds just yet:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将配置与这些绑定接口相关联的VLAN接口。继续编辑文件，添加以下标记的接口。请注意，我们尚未为OpenStack的绑定接口分配IP地址：
- en: '[PRE3]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tip
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Use appropriate VLANs as required in your own environment. The VLAN
    tags used here are for reference only.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：根据你自己的环境，使用适当的VLAN。这里使用的VLAN标签仅供参考。'
- en: Ensure that the correct VLAN tag is configured against the correct bonded interface.
    `bond0` is for host-type traffic, `bond1` is predominantly for Neutron-based traffic,
    except for storage nodes, where it is then used for storage replication.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保正确的VLAN标签配置在正确的绑定接口上。`bond0`用于主机类型的流量，`bond1`主要用于基于Neutron的流量，存储节点除外，在这种情况下它用于存储复制。
- en: 'We will now create the bridges, and place IP addresses on here as necessary
    (note that `br-vlan` does not have an IP address assigned). Continue editing the
    same file and add in the following lines:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将创建桥接，并根据需要在其上配置IP地址（请注意，`br-vlan`没有分配IP地址）。继续编辑相同的文件，添加以下行：
- en: '[PRE4]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Tip
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: These bridge names are referenced in the OpenStack-Ansible configuration file,
    so ensure you name them correctly.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些桥接名称会在OpenStack-Ansible配置文件中被引用，因此确保你正确命名它们。
- en: Be careful in ensuring that the correct bridge is assigned to the correct bonded
    interface.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小心确保正确的桥接被分配到正确的绑定接口。
- en: 'Save and exit the file, then issue the following command:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存并退出文件，然后执行以下命令：
- en: '[PRE5]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As we are configuring our OpenStack environment to be as highly available as
    possible, it is suggested that you also reboot your server at this point to ensure
    the basic server, with redundant networking in place, comes back up as expected:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们正在配置 OpenStack 环境，使其尽可能具有高可用性，因此建议你此时重新启动服务器，以确保基本的服务器，带有冗余网络，能够按预期重新启动：
- en: '[PRE6]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now repeat this for each server on your network.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在对你网络中的每台服务器执行相同操作。
- en: 'Once all the servers are done, ensure that your servers can communicate with
    each other over these newly created interfaces and subnets. A test like the following
    might be convenient:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有服务器完成配置，确保你的服务器能够通过这些新创建的接口和子网互相通信。类似下面的测试可能会很方便：
- en: '[PRE7]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Tip
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: We also recommend that you perform a network cable unplugging exercise
    to ensure that the failover from one active interface to another is working as
    expected.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：我们还建议你执行一个网络电缆拔除练习，以确保从一个活动接口切换到另一个接口的故障转移功能按预期工作。'
- en: How it works…
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We have configured the physical networking of our hosts to ensure a good known
    state and configuration for running OpenStack. Each of the interfaces configured
    here is specific to OpenStack—either directly managed by OpenStack (for example,
    `br-vlan`) or used for inter-service communication (for example, `br-mgmt`). In
    the former case, OpenStack utilizes the `br-vlan` bridge and configures tagged
    interfaces on `bond1` directly.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经配置了主机的物理网络，以确保在运行 OpenStack 时有一个良好的已知状态和配置。这里配置的每个接口都是 OpenStack 特定的—要么由
    OpenStack 直接管理（例如，`br-vlan`），要么用于服务间通信（例如，`br-mgmt`）。在前一种情况下，OpenStack 使用 `br-vlan`
    桥接并直接在 `bond1` 上配置标记接口。
- en: Note that the convention used here, of VLAN tag ID using a portion of the subnet,
    is only to highlight a separation of VLANs to specific subnets (for example, `bond0.236`
    is used by the `172.29.236.0/24` subnet). This VLAN tag ID is arbitrary, but must
    be set up in accordance with your specific networking requirements.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里使用的约定，VLAN 标签 ID 使用子网的一部分，仅用于突出 VLAN 到特定子网的分离（例如，`bond0.236` 用于 `172.29.236.0/24`
    子网）。此 VLAN 标签 ID 是任意的，但必须根据你的具体网络需求进行设置。
- en: Finally, we performed a fairly rudimentary test of the network. This gives you
    the confidence that the network configuration that will be used throughout the
    life of your OpenStack cloud is fit for purpose and gives assurances in the event
    of a failure of a cable or network card.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进行了一个相当基础的网络测试。这可以让你确信，OpenStack 云生命周期中将使用的网络配置是合适的，并且在网络电缆或网卡发生故障时，能够提供保障。
- en: Root SSH keys configuration
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Root SSH 密钥配置
- en: Ansible is designed to help system administrators drive greater efficiency in
    the datacenter by being able to configure and operate many servers using orchestration
    playbooks. In order for Ansible to be able to fulfill its duties, it needs an
    SSH connection on the Linux systems it is managing. Furthermore, in order to have
    a greater degree of freedom and flexibility, a hands-off approach using SSH public
    private key pairs is required.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible 旨在通过使用编排剧本配置和操作多台服务器，帮助系统管理员提高数据中心的效率。为了使 Ansible 能够履行其职责，它需要在其管理的 Linux
    系统上建立 SSH 连接。此外，为了获得更大的自由度和灵活性，必须使用 SSH 公私钥对的无人值守方法。
- en: As the installation of OpenStack is expected to run as root, this stage expects
    the deployment host's root public key to be propagated across all servers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 OpenStack 的安装预计以 root 身份运行，因此此阶段需要将部署主机的 root 公钥传播到所有服务器。
- en: Getting ready
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure that you are `root` on the deployment host. In most cases, this is the
    first infrastructure *controller* node that we have named for the purposes of
    this book to be called `infra01`. We will be assuming that all Ansible commands
    will be run from this host, and that it expects to be able to connect to the rest
    of the servers on this network over the host network via SSH.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你在部署主机上是`root`用户。在大多数情况下，这是我们为本书目的命名的第一个基础设施*控制器*节点，命名为`infra01`。我们将假设所有的
    Ansible 命令都将在这个主机上运行，并且它预计能够通过 SSH 通过主机网络连接到网络上的其他服务器。
- en: How to do it…
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In order to allow a hands-free, orchestrated OpenStack-Ansible deployment,
    follow these steps to create and propagate root SSH public key of `infra01` across
    all servers required of the installation:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现无需人工干预的自动化 OpenStack-Ansible 部署，请按照以下步骤创建并传播 `infra01` 的 root SSH 公钥至所有安装所需的服务器：
- en: 'As root, execute the following command to create an SSH key pair:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为 root，执行以下命令来创建 SSH 密钥对：
- en: '[PRE8]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output should look similar to this:'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应类似于以下内容：
- en: '[PRE9]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This has created two files in `/root/.ssh`, called `id_rsa` and `id_rsa.pub`.
    The file, `id_rsa` is the private key, and must not be copied across the network.
    It is not required to be anywhere other than on this server. The file, `id_rsa.pub`,
    is the public key and can be shared to other servers on the network. If you have
    other nodes (for example, named infra02), use the following to copy this key to
    that node in your environment:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这在 `/root/.ssh` 目录下创建了两个文件，分别叫做 `id_rsa` 和 `id_rsa.pub`。文件 `id_rsa` 是私钥，必须避免通过网络进行复制。它只需要存在于该服务器上。文件
    `id_rsa.pub` 是公钥，可以共享到网络上的其他服务器。如果你有其他节点（例如名为 infra02），可以使用以下命令将此密钥复制到你环境中的该节点：
- en: '[PRE10]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Tip
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Ensure that you can resolve `infra02` and the other servers, else
    amend the preceding command to use its host IP address instead.'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：确保你能解析 `infra02` 和其他服务器，否则修改前面的命令，使用主机的 IP 地址代替。'
- en: Now repeat step 2 for all servers on your network.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，对你网络上的所有服务器重复步骤 2。
- en: 'Important: finally, ensure that you execute the following command to be able
    to SSH to itself:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重要：最后，确保执行以下命令，以便能够进行自我 SSH 连接：
- en: '[PRE11]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Test that you can `ssh`, as the root user, from `infra01` to other servers on
    your network. You should be presented with a Terminal ready to accept commands
    if successful, without being prompted for a passphrase. Consult `/var/log/auth.log`
    on the remote server if this behavior is incorrect.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试你能否作为 root 用户，从 `infra01` 使用 `ssh` 连接到网络上的其他服务器。如果成功，应该会显示一个终端，准备接受命令，而不会要求输入密码。如果此行为不正常，请查看远程服务器上的
    `/var/log/auth.log`。
- en: How it works…
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其工作原理…
- en: We first generated a key pair file for use by SSH. The `-t` option specified
    the `rsa` type encryption, `-f` specified the output of the private key, where
    the public portion will get .`pub` appended to its name, and `-N ""` specified
    that no passphrase is to be used on this key. Consult your own security standards
    if the presented options differ from your company's requirements.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先生成了一个密钥对文件供 SSH 使用。`-t` 选项指定了 `rsa` 类型加密，`-f` 指定了私钥的输出路径，公钥部分将以 `.pub` 为文件名后缀，`-N
    ""` 表示不使用密码短语。若选项与贵公司要求不符，请参照贵公司安全标准。
- en: Installing Ansible, playbooks, and dependencies
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Ansible、剧本和依赖项
- en: In order for us to successfully install OpenStack using Ansible, we need to
    ensure that Ansible and any expected dependencies are installed on the deployment
    host. The OpenStack-Ansible project provides a handy script to do this for us,
    which is part of the version of OpenStack-Ansible we will be deploying.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功通过 Ansible 安装 OpenStack，我们需要确保在部署主机上安装了 Ansible 及所有预期的依赖项。OpenStack-Ansible
    项目为我们提供了一个方便的脚本来完成这项工作，该脚本是我们将要部署的 OpenStack-Ansible 版本的一部分。
- en: Getting ready
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Ensure that you are `root` on the deployment host. In most cases, this is the
    first infrastructure controller node, `infra01`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你在部署主机上以 `root` 身份登录。在大多数情况下，这将是第一个基础设施控制节点 `infra01`。
- en: At this point, we will be checking out the version of OpenStack-Ansible from
    GitHub.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们将从 GitHub 检出 OpenStack-Ansible 的版本。
- en: How to do it…
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'To set up Ansible and its dependencies, follow these steps:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置 Ansible 及其依赖项，请按照以下步骤操作：
- en: 'We first need to use `git` to check out the OpenStack-Ansible code from GitHub,
    so ensure that the following packages are installed (among other needed dependencies):'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先需要使用 `git` 从 GitHub 检出 OpenStack-Ansible 代码，因此确保安装了以下包（以及其他所需的依赖项）：
- en: '[PRE12]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We then need to grab the OpenStack-Ansible code from GitHub. At the time of
    writing, the Pike release branch (16.X) is described as follows, but the steps
    remain the same for the foreseeable future. It is recommended that you use the
    latest stable tag by visiting [https://github.com/openstack/openstack-ansible/tags](https://github.com/openstack/openstack-ansible/tags).
    Here we''re using the latest 16 (Pike) tag denoted by `16.0.5`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们需要从 GitHub 获取 OpenStack-Ansible 代码。写作时，Pike 发布分支（16.X）描述如下，但在可预见的未来步骤将保持不变。建议访问
    [https://github.com/openstack/openstack-ansible/tags](https://github.com/openstack/openstack-ansible/tags)
    来使用最新的稳定标签。此处我们使用的是最新的 16（Pike）标签，即 `16.0.5`：
- en: Tip
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: To use a branch of the Queens release, use the following: `-b 17.0.0`.
    When the Rocky release is available, use `-b 18.0.0`.'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：要使用 Queens 发布的某个分支，请使用以下命令：`-b 17.0.0`。当 Rocky 发布可用时，请使用 `-b 18.0.0`。'
- en: '[PRE13]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Ansible and the needed dependencies to successfully install OpenStack can be
    found in the `/opt/openstack-ansible/scripts` directory. Issue the following command
    to bootstrap the environment:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ansible 和成功安装 OpenStack 所需的依赖项可以在 `/opt/openstack-ansible/scripts` 目录中找到。运行以下命令以引导环境：
- en: '[PRE14]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: How it works…
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: The OpenStack-Ansible project provides a handy script to ensure that Ansible
    and the right dependencies are installed on the deployment host. This script (`bootstrap-ansible.sh`)
    lives in the `scripts/` directory of the checked out OpenStack-Ansible code, so
    at this stage we need to grab the version we want to deploy using Git. Once we
    have the code, we can execute the script and wait for it to complete.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack-Ansible 项目提供了一个便捷的脚本，以确保在部署主机上安装了 Ansible 和正确的依赖项。这个脚本（`bootstrap-ansible.sh`）位于检出的
    OpenStack-Ansible 代码的 `scripts/` 目录中，因此此时我们需要使用 Git 获取我们想要部署的版本。一旦获得代码，我们可以执行脚本并等待其完成。
- en: There's more…
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: Visit [https://docs.openstack.org/project-deploy-guide/openstack-ansible/latest](https://docs.openstack.org/project-deploy-guide/openstack-ansible/latest)
    for more information.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 [https://docs.openstack.org/project-deploy-guide/openstack-ansible/latest](https://docs.openstack.org/project-deploy-guide/openstack-ansible/latest)
    获取更多信息。
- en: Configuring the installation
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置安装
- en: OpenStack-Ansible is a set of official Ansible playbooks and roles that lay
    down OpenStack with minimal prerequisites. Like any orchestration tool, most effort
    is done up front with configuration, followed by a hands-free experience when
    the playbooks are running. The result is a tried and tested OpenStack installation
    suitable for any size environment, from testing to production environments.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack-Ansible 是一组官方的 Ansible playbook 和角色，它以最小的先决条件部署 OpenStack。像任何编排工具一样，大部分工作是在配置阶段完成的，然后在
    playbook 运行时实现免手动操作。最终的结果是一个经过多次验证的 OpenStack 安装，适用于任何规模的环境，从测试到生产环境。
- en: When we use OpenStack-Ansible, we are basically downloading the playbooks from
    GitHub onto a nominated *deployment server*. A deployment server is the host that
    has access to all the machines in the environment via SSH (and for convenience,
    and for the most seamless experience without hiccups, via keys). This deployment
    server can be one of the machines you've nominated as a part of your OpenStack
    environment as Ansible isn't anything that takes up any ongoing resources once
    run.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 OpenStack-Ansible 时，实际上是在将 playbooks 从 GitHub 下载到指定的 *部署服务器*。部署服务器是通过
    SSH 访问环境中所有机器的主机（为了便利以及提供无缝的体验，通常通过密钥进行访问）。这个部署服务器可以是你指定的任何一台机器，因为一旦运行，Ansible
    不会占用任何持续的资源。
- en: Tip
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Remember to back up the relevant configuration directories related
    to OpenStack-Ansible before you rekick an install of Ubuntu on this server!'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：在重新安装 Ubuntu 之前，记得备份与 OpenStack-Ansible 相关的配置目录！'
- en: Getting ready
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure that you are `root` on the *deployment host*. In most cases, this is
    the first infrastructure controller node, `infra01`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你是 *部署主机* 上的 `root` 用户。在大多数情况下，这将是第一个基础设施控制节点 `infra01`。
- en: How to do it...
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Let's assume that you're using the first infrastructure node, `infra01`, as
    the deployment server.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你使用的是第一个基础设施节点 `infra01` 作为部署服务器。
- en: 'If you have not followed the preceding *Installing Ansible, playbooks, and
    dependencies* recipe review, then as `root`, carry out the following if necessary:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有按照前面的 *安装 Ansible、playbooks 和依赖项* 章节进行操作，请作为 `root` 执行以下操作（如有必要）：
- en: '[PRE15]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This downloads the OpenStack-Ansible playbooks to the `/opt/openstack-ansible`
    directory.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把 OpenStack-Ansible playbook 下载到 `/opt/openstack-ansible` 目录。
- en: 'To configure our OpenStack deployment, carry out the following steps:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置 OpenStack 部署，请执行以下步骤：
- en: 'We first copy the `etc/openstack_deploy` folder out of the downloaded repository
    to `/etc`:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将 `etc/openstack_deploy` 文件夹从下载的仓库复制到 `/etc`：
- en: '[PRE16]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We now have to tell Ansible which servers will do which OpenStack function,
    by editing the `/etc/openstack_deploy/openstack_user_config.yml` file, as shown
    here:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须通过编辑 `/etc/openstack_deploy/openstack_user_config.yml` 文件，告诉 Ansible
    哪些服务器将执行哪些 OpenStack 功能，如下所示：
- en: '[PRE17]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The first section, `cidr_networks`, describes the subnets used by OpenStack
    in this installation. Here we describe the *container* network (each of the OpenStack
    services are run inside a container, and this has its own network so that each
    service can communicate with each other). We describe the tunnel network (when
    a user creates a tenant network in this installation of OpenStack, this will create
    a segregated VXLAN network over this physical network). Finally, we describe the
    storage network subnet. Edit this file so that it looks like the following:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一部分，`cidr_networks`，描述了 OpenStack 在此安装中使用的子网。在这里，我们描述了 *容器* 网络（每个 OpenStack
    服务都运行在一个容器中，并且每个服务有自己的网络，以便它们之间可以相互通信）。我们描述了隧道网络（当用户在 OpenStack 安装中创建租户网络时，这将创建一个在物理网络上隔离的
    VXLAN 网络）。最后，我们描述了存储网络子网。编辑此文件，使其看起来如下所示：
- en: '[PRE18]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Continue editing the file to include any IP addresses that are already used
    by existing physical hosts in the environment where OpenStack will be deployed
    (and ensuring that you''ve included any reserved IP addresses for physical growth
    too). Include the addresses we have already configured leading up to this section.
    Single IP addresses or ranges (start and end placed either side of a '','') can
    be placed here. Edit this section to look like the following, adjust as per your
    environment and any reserved IPs:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续编辑文件，包含已在 OpenStack 将要部署的环境中由现有物理主机使用的任何 IP 地址（并确保已包含用于物理扩展的任何保留 IP 地址）。包括我们在此章节前已经配置的地址。可以在此处添加单个
    IP 地址或地址范围（起始和结束地址用 ',' 分隔）。编辑此部分，使其看起来如下所示，按你的环境和任何保留的 IP 进行调整：
- en: '[PRE19]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `global_overrides` section describes the bridges and other specific details
    of the interfaces used environment—particularly pertaining to how the container
    network attaches to the physical network interfaces. For the example architecture
    used in this book, the following output can be used. In most cases, the content
    in this section doesn''t need to be edited apart from the load balancer information
    at the start, so edit to suit:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`global_overrides` 部分描述了用于环境的桥接和其他接口的具体细节——特别是容器网络如何连接到物理网络接口。对于本书中使用的示例架构，可以使用以下输出。在大多数情况下，除了开始时的负载均衡器信息外，本节内容无需编辑，因此根据需要调整：'
- en: '[PRE20]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The remaining section of this file describes which server each service runs
    from. Most of the sections repeat, differing only in the name of the service.
    This is fine as the intention here is to tell OpenStack-Ansible which server (we
    give it a name so that Ansible can refer to it by name, and reference the IP associated
    with it) runs the Nova API, RabbitMQ, or the Glance service, for example. As these
    particular example services run on our controller nodes, and in a production setting
    there are at least three controllers, you can quickly see why this information
    repeats. Other sections refer specifically to other services, such as OpenStack
    compute. For brevity, a couple of sections are shown here, but continue editing
    the file to match your networking:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本文件的剩余部分描述了每个服务运行的服务器。大部分章节内容重复，仅在服务名称上有所不同。这是可以接受的，因为此处的目的是告诉 OpenStack-Ansible
    每个服务（我们为它起一个名字，便于 Ansible 通过名称引用，并引用与其关联的 IP 地址）在哪个服务器上运行，例如 Nova API、RabbitMQ
    或 Glance 服务等。由于这些示例服务运行在我们的控制节点上，而在生产环境中至少有三个控制节点，所以你可以很快明白为什么这些信息会重复。其他章节则专门提到其他服务，如
    OpenStack 计算服务。为了简洁起见，这里展示了几个章节，继续编辑文件以适应你的网络配置：
- en: '[PRE21]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Save and exit the file. We will now need to generate some random passphrases
    for the various services that run in OpenStack. In OpenStack, each service—such
    as Nova, Glance, and Neutron (which are described through the book)—themselves
    have to authenticate with Keystone, and be authorized to act as a service. To
    do so, their own user accounts need to have passphrases generated. Carry out the
    following command to generate the required passphrases, which would be later used
    when the OpenStack playbooks are executed:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存并退出文件。接下来，我们需要为 OpenStack 中运行的各个服务生成一些随机密码短语。在 OpenStack 中，每个服务——如 Nova、Glance
    和 Neutron（本书中有描述）——都必须向 Keystone 进行身份验证，并授权它们作为服务进行操作。为此，它们自己的用户帐户需要生成密码短语。执行以下命令以生成所需的密码短语，这些密码短语将在稍后执行
    OpenStack playbook 时使用：
- en: '[PRE22]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, there is another file that allows you to fine-tune the parameters
    of the OpenStack services, such as which backing store Glance (the OpenStack Image
    service) will be using, as well as configure proxy services ahead of the installation.
    This file is called `/etc/openstack_deploy/user_variables.yml`. Let''s view and
    edit this file:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，还有另一个文件允许你对 OpenStack 服务的参数进行微调，例如 Glance（OpenStack 镜像服务）将使用的后端存储，并在安装之前配置代理服务。这个文件叫做`/etc/openstack_deploy/user_variables.yml`。让我们查看并编辑这个文件：
- en: '[PRE23]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In a typical, highly available deployment—one in which we have three controller
    nodes—we need to configure Glance to use a shared storage service so that each
    of the three controllers have the same view of a filesystem, and therefore the
    images used to spin up instances. A number of shared storage backend systems that
    Glance can use range from NFS to Swift. We can even allow a private cloud environment
    to connect out over a public network and connect to a public service like Rackspace
    Cloud Files. If you have Swift available, add the following lines to `user_variables.yml`
    to configure Glance to use Swift:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个典型的高可用部署中——即我们有三个控制节点的部署——我们需要配置 Glance 使用共享存储服务，这样三个控制节点就可以对文件系统有相同的视图，从而使启动实例时使用的镜像一致。Glance
    可以使用的一些共享存储后端系统包括 NFS 和 Swift。我们甚至可以允许一个私有云环境通过公共网络连接并连接到像 Rackspace Cloud Files
    这样的公共服务。如果你有可用的 Swift，可以将以下行添加到 `user_variables.yml` 文件中，配置 Glance 使用 Swift：
- en: '[PRE24]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Tip
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Latest versions of OpenStack-Ansible are smart enough to discover
    if Swift is being used and will update their configuration accordingly.'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：OpenStack-Ansible 的最新版本足够智能，能够自动检测是否使用了 Swift，并会相应地更新其配置。'
- en: View the other commented out details in the file to see if they need editing
    to suit your environment, then save and exit. You are now ready to start the installation
    of OpenStack!
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看文件中其他被注释掉的详细信息，看看是否需要根据你的环境进行编辑，然后保存并退出。现在你可以开始安装 OpenStack 了！
- en: How it works…
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'Ansible is a very popular server configuration tool that is well-suited to
    the task of installing OpenStack. Ansible takes a set of configuration files that
    *Playbooks* (a defined set of steps that get executed on the servers) use to control
    how they executed. For OpenStack-Ansible, configuration is split into two areas:
    describing the physical environment and describing how OpenStack is configured.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible 是一个非常流行的服务器配置工具，非常适合安装 OpenStack。Ansible 使用一组配置文件，*Playbooks*（一组在服务器上执行的步骤）用来控制它们的执行方式。对于
    OpenStack-Ansible，配置分为两个领域：描述物理环境和描述如何配置 OpenStack。
- en: 'The first configuration file, `/etc/openstack_deploy/openstack_user_config.yml`,
    describes the physical environment. Each section is described here:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个配置文件`/etc/openstack_deploy/openstack_user_config.yml`描述了物理环境。每个部分在这里都有描述：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This section describes the networks required for an installation based on OpenStack-Ansible.
    Look at the following diagram to see the different networks and subnets.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了基于 OpenStack-Ansible 安装所需的网络。查看下面的图示，了解不同的网络和子网。
- en: '**Container**: Each container that gets deployed gets an IP address from this
    subnet. The load balancer also takes an IP address from this range.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器**：每个部署的容器都会从这个子网中获取一个 IP 地址。负载均衡器也会从这个范围内获取一个 IP 地址。'
- en: '**Tunnel**: This is the subnet that forms the VXLAN tunnel mesh. Each container
    and compute host that participates in the VXLAN tunnel gets an IP from this range
    (the VXLAN tunnel is used when an operator creates a Neutron subnet that specifies
    the `vxlan` type, which creates a virtual network over this underlying subnet).
    Refer to [Chapter 4](part0048_split_000.html#1DOR01-189e69df43a248268db97cde1b1a8e47
    "Chapter 4. Neutron – OpenStack Networking"), *Neutron – OpenStack Networking*
    for more details on OpenStack networking.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隧道**：这是形成 VXLAN 隧道网格的子网。每个参与 VXLAN 隧道的容器和计算主机都会从这个范围内获得一个 IP（当操作员创建一个指定 `vxlan`
    类型的 Neutron 子网时，VXLAN 隧道会被使用，这在这个底层子网上创建了一个虚拟网络）。有关 OpenStack 网络的更多细节，请参阅 [第 4
    章](part0048_split_000.html#1DOR01-189e69df43a248268db97cde1b1a8e47 "Chapter 4.
    Neutron – OpenStack Networking")，*Neutron – OpenStack Networking*。'
- en: '**Storage**: This is the subnet that was used when a client instance spun up
    in OpenStack request Cinder block storage:'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：这是在 OpenStack 中启动客户端实例时使用的子网，要求 Cinder 块存储：'
- en: '[PRE26]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `used_ips:` section refers to IP addresses that are already in use on that
    subnet, or reserved for use by static devices. Such devices are load balancers
    or other hosts that are part of the subnets that OpenStack-Ansible would otherwise
    have randomly allocated to containers:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`used_ips:` 部分指的是已经在该子网中使用的 IP 地址，或为静态设备保留的 IP 地址。此类设备包括负载均衡器或其他属于子网的主机，否则
    OpenStack-Ansible 会将这些 IP 随机分配给容器：'
- en: '[PRE27]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `global_overrides:` section describes the details around how the containers
    and bridged networking are set up. OpenStack-Ansible's default documentation expects
    Linux Bridge to be used; however, Open vSwitch can also be used. Refer to [Chapter
    4](part0048_split_000.html#1DOR01-189e69df43a248268db97cde1b1a8e47 "Chapter 4. Neutron
    – OpenStack Networking"), *Neutron – OpenStack Networking*, for more details.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`global_overrides:` 部分描述了容器与桥接网络的设置细节。OpenStack-Ansible 的默认文档假设使用 Linux Bridge；但是，也可以使用
    Open vSwitch。有关更多细节，请参考[第4章](part0048_split_000.html#1DOR01-189e69df43a248268db97cde1b1a8e47
    "第4章 Neutron – OpenStack 网络")，*Neutron – OpenStack 网络*。'
- en: 'The `internal_lb_vip_address:` and `external_lb_vip_address:` sections refer
    to the *private* and *public* sides of a typical load balancer. The private (`internal_lb_vip_address`)
    is used by the services within OpenStack (for example, Nova calls communicating
    with the Neutron API would use `internal_lb_vip_address`, whereas a user communicating
    with the OpenStack environment once it has been installed would use `external_lb_vip_address`).
    See the following diagram:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`internal_lb_vip_address:` 和 `external_lb_vip_address:` 部分指的是典型负载均衡器的 *私有*
    和 *公共* 端口。私有端口（`internal_lb_vip_address`）由 OpenStack 内的服务使用（例如，Nova 调用与 Neutron
    API 的通信时会使用 `internal_lb_vip_address`，而用户在 OpenStack 环境安装后进行通信时则会使用 `external_lb_vip_address`）。请参见以下图示：'
- en: '![How it works…](img/00004.jpeg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理…](img/00004.jpeg)'
- en: A number of load balance pools will be created for a given **Virtual IP** (**VIP**)
    address, describing the IP addresses and ports associated with a particular service,
    and for each pool—one will be created on the public/external network (in the example,
    a VIP address of `192.168.100.117` has been created for this purpose), and another
    VIP for use internally by OpenStack (in the preceding example, the VIP address
    `172.29.236.117` has been created for this purpose).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为某个 **虚拟 IP** (**VIP**) 地址将创建多个负载均衡池，描述与特定服务相关的 IP 地址和端口，对于每个池——一个将在公共/外部网络上创建（在示例中，已为此目的创建了
    VIP 地址 `192.168.100.117`），另一个 VIP 将供 OpenStack 内部使用（在前面的示例中，已为此目的创建了 VIP 地址 `172.29.236.117`）。
- en: The `tunnel_bridge:` section is the name given to the bridge that is used for
    attaching the physical interface that participates in the VXLAN tunnel network.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`tunnel_bridge:` 部分是为连接参与 VXLAN 隧道网络的物理接口而设定的桥接名称。'
- en: The `management_bridge:` section is the name given to the bridge that is used
    for all of the OpenStack services that get installed on the container network
    shown in the diagram.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`management_bridge:` 部分是为所有在容器网络上安装的 OpenStack 服务设定的桥接名称，容器网络如图所示。'
- en: The `storage_bridge:` section is the name given to the bridge that is used for
    traffic associated with attaching storage to instances or where Swift proxied
    traffic would flow.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`storage_bridge:` 部分是为与实例连接存储或 Swift 代理的流量而设定的桥接名称。'
- en: Each of the preceding bridges must match the names you have configured in the
    `/etc/network/interfaces` file on each of your servers.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 上述每个桥接名称必须与在每台服务器的 `/etc/network/interfaces` 文件中配置的名称匹配。
- en: The next section, `provider_networks`, remains relatively static and untouched
    as it describes the relationship between container networking and the physical
    environment. Do not adjust this section.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分，`provider_networks`，相对静态且未更改，它描述了容器网络与物理环境之间的关系。请勿调整此部分。
- en: 'Following the `provider_networks` section are the sections describing which
    server or group of servers run a particular service. Each block has the following
    syntax:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`provider_networks` 部分后面是描述哪个服务器或服务器组运行特定服务的部分。每个块的语法如下：'
- en: '[PRE28]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Tip
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: Ensure the correct and consistent spelling of each server name (`ansible_inventory_name_for_server`)
    to ensure correct execution of your Ansible playbooks.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：确保每个服务器名称（`ansible_inventory_name_for_server`）的拼写正确一致，以确保 Ansible playbook
    的正确执行。'
- en: 'A number of sections and their use are listed here:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了若干部分及其用途：
- en: '`shared-infra_hosts`: This supports the shared infrastructure software, which
    is MariaDB/Galera and RabbitMQ'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shared-infra_hosts`：这些支持共享基础设施软件，如 MariaDB/Galera 和 RabbitMQ。'
- en: '`repo-infra_hosts`: This is the specific repository containers version of OpenStack-Ansible
    requested'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repo-infra_hosts`：这是指定的 OpenStack-Ansible 容器版本。'
- en: '`haproxy_hosts`: When using HAProxy for load balancing, this tells the playbooks
    where to install and configure this service'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haproxy_hosts`：在使用 HAProxy 进行负载均衡时，指示 playbook 安装和配置此服务的位置。'
- en: '`os-infra_hosts`: These include OpenStack API services such as Nova API and
    Glance API'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os-infra_hosts`：这些包括 OpenStack API 服务，如 Nova API 和 Glance API。'
- en: '`log_hosts`: This is where the rsyslog server runs from'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log_hosts`：这是运行 rsyslog 服务器的地方。'
- en: '`identity_hosts`: These are the servers that run the Keystone (OpenStack Identity)
    Service'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`identity_hosts`：这些是运行 Keystone（OpenStack Identity）服务的服务器。'
- en: '`storage-infra_hosts`: These are the servers that run the Cinder API service'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`storage-infra_hosts`：这些是运行 Cinder API 服务的服务器。'
- en: '`storage_hosts`: This is the section that describes Cinder LVM nodes'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`storage_hosts`：这是描述 Cinder LVM 节点的部分。'
- en: '`swift-proxy_hosts`: These are the hosts that would house the Swift Proxy service'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swift-proxy_hosts`：这些是将托管 Swift Proxy 服务的主机。'
- en: '`swift_hosts`: These are the Swift storage nodes'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swift_hosts`：这些是 Swift 存储节点。'
- en: '`compute_hosts`: This is the list of servers that make up your hypervisors'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`compute_hosts`：这是组成虚拟化服务器的主机列表。'
- en: '`image_hosts`: These are the servers that run the Glance (OpenStack Image)
    Service'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_hosts`：这些是运行 Glance（OpenStack Image）服务的服务器。'
- en: '`orchestration_hosts`: These are the servers that run the Heat API (OpenStack
    Orchestration) services'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`orchestration_hosts`：这些是运行 Heat API（OpenStack Orchestration）服务的服务器。'
- en: '`dashboard_hosts`: These are the servers that run the Horizon (OpenStack Dashboard)
    service'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dashboard_hosts`：这些是运行 Horizon（OpenStack Dashboard）服务的服务器。'
- en: '`network_hosts`: These are the servers that run the Neutron (OpenStack Networking)
    agents and services'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`network_hosts`：这些是运行 Neutron（OpenStack Networking）代理和服务的服务器。'
- en: '`metering-infra_hosts`: These are the servers that run the Ceilometer (OpenStack
    Telemetry) service'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metering-infra_hosts`：这些是运行 Ceilometer（OpenStack Telemetry）服务的服务器。'
- en: '`metering-alarm_hosts`: These are the servers that run the Ceilometer (OpenStack
    Telemetry) service associated with alarms'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metering-alarm_hosts`：这些是运行与告警相关的 Ceilometer（OpenStack Telemetry）服务的服务器。'
- en: '`metrics_hosts`: The servers that run the Gnocchi component of Ceilometer'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metrics_hosts`：运行 Ceilometer 组件（Gnocchi）的服务器。'
- en: '`metering-compute_hosts`: When using Ceilometer, these are the list of compute
    hosts that need the metering agent installed'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metering-compute_hosts`：使用 Ceilometer 时，这些是需要安装计量代理的计算主机列表。'
- en: Running the OpenStack-Ansible playbooks
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行 OpenStack-Ansible playbook。
- en: 'To install OpenStack, we simply run the relevant playbooks. There are three
    main playbooks in total that we will be using:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 OpenStack 时，我们只需运行相关的 playbook。总共有三个主要的 playbook，我们将依次使用：
- en: '`setup-hosts.yml`'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup-hosts.yml`。'
- en: '`setup-infrastructure.yml`'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup-infrastructure.yml`。'
- en: '`setup-openstack.yml`'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup-openstack.yml`。'
- en: Getting ready
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作。
- en: Ensure that you are the `root` user on the deployment host. In most cases, this
    is the first infrastructure controller node, `infra01`.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你是部署主机上的 `root` 用户。在大多数情况下，这将是第一个基础设施控制节点，`infra01`。
- en: How to do it…
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'To install OpenStack using the OpenStack-Ansible playbooks, you navigate to
    the `playbooks` directory of the checked out Git repository, then execute each
    playbook in turn:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 OpenStack-Ansible playbook 安装 OpenStack，首先导航到已克隆 Git 仓库的 `playbooks` 目录，然后依次执行每个
    playbook：
- en: 'First change to the `playbooks` directory by executing the following command:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先通过执行以下命令切换到 `playbooks` 目录：
- en: '[PRE29]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The first step is to run a syntax check on your scripts and configuration.
    As we will be executing three playbooks, we will execute the following against
    each:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是对你的脚本和配置进行语法检查。由于我们将执行三个 playbook，我们将针对每个 playbook 执行以下操作：
- en: '[PRE30]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now we will run the first playbook using a special OpenStack-Ansible wrapper
    script to Ansible that configures each host that we described in the `/etc/openstack_deploy/openstack_user_config.yml`
    file:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将使用一个特殊的 OpenStack-Ansible 包装脚本来运行第一个 playbook，配置我们在 `/etc/openstack_deploy/openstack_user_config.yml`
    文件中描述的每个主机：
- en: '[PRE31]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After a short while, you should be greeted with a PLAY RECAP output that is
    all green (with yellow/blue lines indicating where any changes were made), with
    the output showing all changes were OK. If there are issues, review the output
    by scrolling back through the output and watch out for any output that was printed
    out in red. Refer to the *Troubleshooting the installation* recipe further on
    in this chapter. If all is OK, we can proceed to run the next playbook for setting
    up load balancing. At this stage, it is important that the load balancer gets
    configured. OpenStack-Ansible installs the OpenStack services in LXC containers
    on each server, and so far we have not explicitly stated which IP address on the
    container network will have that particular service installed. This is because
    we let Ansible manage this for us. So while it might seem counter-intuitive to
    set up load balancing at this stage before we know where each service will be
    installed—Ansible has already generated a dynamic inventory ahead of any future
    work, so Ansible already knows how many containers are involved and knows which
    container will have that service installed. If you are using an F5 LTM, Brocade,
    or similar enterprise load balancing kit, it is recommended that you use HAProxy
    temporarily and view the generated configuration to be manually transferred to
    a physical setup. To temporarily set up HAProxy to allow an installation of OpenStack
    to continue, modify your `openstack_user_config.yml` file to include a HAProxy
    host, then execute the following:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 稍等片刻后，你应该看到一个完全绿色的 PLAY RECAP 输出（其中黄色/蓝色的行表示做出的任何更改），并且输出显示所有更改都成功。如果有问题，请通过滚动回输出内容来查看并留意任何红色输出的内容。请参考本章后面的*故障排除安装*部分。如果一切正常，我们可以继续运行下一个
    Playbook 以设置负载均衡。在此阶段，配置负载均衡器非常重要。OpenStack-Ansible 将 OpenStack 服务安装在每台服务器的 LXC
    容器中，到目前为止，我们还没有明确说明哪个容器网络的 IP 地址将安装哪个服务。这是因为我们让 Ansible 为我们管理这一切。因此，虽然在此阶段设置负载均衡似乎有些反直觉——因为我们还不知道每个服务会安装在哪个容器上——但
    Ansible 已经在未来的工作之前生成了动态清单，所以它已经知道涉及多少个容器，并知道哪个容器会安装该服务。如果你使用的是 F5 LTM、Brocade
    或类似的企业级负载均衡设备，建议你暂时使用 HAProxy，并查看生成的配置，以便手动转移到物理设备上。为了临时设置 HAProxy，使 OpenStack
    的安装能够继续，修改你的 `openstack_user_config.yml` 文件，包含一个 HAProxy 主机，然后执行以下命令：
- en: '[PRE32]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'If all is OK, we can proceed to run the next Playbook that sets up the shared
    infrastructure services as follows:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一切正常，我们可以继续运行下一个 Playbook 来设置共享基础设施服务，如下所示：
- en: '[PRE33]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This step takes a little longer than the first Playbook. As before, inspect
    the output for any failures. At this stage, we should have a number of containers
    running on each Infrastructure Node (also known and referred to as Controller
    Nodes). On some of these containers, such as the ones labelled Galera or RabbitMQ,
    we should see services running correctly on here, waiting for OpenStack to be
    configured against them. We can now continue the installation by running the largest
    of the playbooks—the installation of OpenStack itself. To do this, execute the
    following command:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个步骤比第一个 Playbook 花费的时间稍长。如同之前一样，检查输出是否有失败。在此阶段，我们应该在每个基础设施节点（也称为控制节点）上运行多个容器。在这些容器中，像
    Galera 或 RabbitMQ 这样的容器上，我们应该看到服务在正常运行，等待 OpenStack 对其进行配置。现在，我们可以通过运行最大的 Playbook
    来继续安装 OpenStack 本身。为此，请执行以下命令：
- en: '[PRE34]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This may take a while to run—running to hours—so be prepared for this duration
    by ensuring your SSH session to the deployment host will not be interrupted after
    a long time, and safeguard any disconnects by running the Playbook in something
    like `tmux` or `screen`. At the end of the Playbook run, if all is OK, congratulations,
    you have OpenStack installed!
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个过程可能需要一段时间——可能长达数小时——因此请确保你的 SSH 会话在长时间后不会中断，并通过像`tmux`或`screen`这样的工具来防止断开连接，做好准备。在
    Playbook 执行结束时，如果一切正常，恭喜你，OpenStack 已经安装完成！
- en: How it works…
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Installation of OpenStack using OpenStack-Ansible is conducted using a number
    of playbooks. The first playbook, `setup-hosts.yml`, sets up the hosts by laying
    down the container configurations. At this stage, Ansible knows where it will
    be placing all future services associated with OpenStack, so we use the dynamic
    inventory information to perform an installation of HAProxy and configure it for
    all the services used by OpenStack (that are yet to be installed). The next playbook,
    `setup-infrastructure.yml`, configures and installs the base Infrastructure services
    containers that OpenStack expects to be present, such as Galera. The final playbook
    is the main event—the playbook that installs all the required OpenStack services
    we specified in the configuration. This runs for quite a while—but at the end
    of the run, you are left with an installation of OpenStack.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenStack-Ansible 安装 OpenStack 是通过多个 Playbooks 完成的。第一个 Playbook `setup-hosts.yml`
    配置主机，设置容器配置。在此阶段，Ansible 已经知道将来会在哪些地方放置所有与 OpenStack 相关的服务，因此我们使用动态清单信息来安装 HAProxy，并将其配置为所有
    OpenStack 服务（这些服务尚未安装）使用的代理服务。下一个 Playbook `setup-infrastructure.yml` 配置并安装 OpenStack
    期望存在的基础设施服务容器，如 Galera。最后一个 Playbook 是主 Playbook——它安装我们在配置中指定的所有 OpenStack 服务。该过程会运行一段时间，但最终你会得到一个完整的
    OpenStack 安装。
- en: The OpenStack-Ansible project provides a wrapper script to the `ansible` command
    that would ordinarily run to execute Playbooks. This is called `openstack-ansible`.
    In essence, this ensures that the correct inventory and configuration information
    is passed to the `ansible` command to ensure correct running of the OpenStack-Ansible
    playbooks.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack-Ansible 项目提供了一个包装脚本，包装了通常用于执行 Playbooks 的 `ansible` 命令。这个脚本叫做 `openstack-ansible`。本质上，它确保将正确的清单和配置传递给
    `ansible` 命令，以确保正确运行 OpenStack-Ansible 的 Playbooks。
- en: Troubleshooting the installation
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装故障排除
- en: Ansible is a tool, written by people, that runs playbooks, written by people,
    to configure systems that would ordinarily be manually performed by people, and
    as such, errors can occur. The end result is only as good as the input.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible 是一款由人编写的工具，运行由人编写的 Playbooks，来配置通常需要人为手动操作的系统，因此错误是难免发生的。最终结果的质量取决于输入的质量。
- en: Typical failures either occur quickly, such as connection problems, and will
    be relatively self-evident, or after long running jobs that may be as a result
    of load or network timeouts. In any case, the OpenStack-Ansible playbooks provide
    an efficient mechanism to rerun playbooks without having to repeat the tasks it
    has already completed.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的故障通常会很快出现，例如连接问题，这些问题会比较明显，或者在长时间运行的任务后出现，可能是由于负载或网络超时导致的。无论如何，OpenStack-Ansible
    的 Playbooks 提供了一种高效的机制，可以在不重复已经完成的任务的情况下重新运行 Playbooks。
- en: On failure, Ansible produces a file in `/root` (as we're running these playbooks
    as `root`) called the *playbook* name, with the file extension of `.retry`. This
    file simply lists the hosts that had failed so this can be referenced when running
    the playbook again. This targets the single or small group of hosts, which is
    far more efficient than a large cluster of machines that successfully completed.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在失败时，Ansible 会在 `/root` 目录下生成一个文件（因为我们是以 `root` 身份运行这些 Playbooks），文件名为 *Playbook*
    的名称，文件扩展名为 `.retry`。该文件简单列出了失败的主机，方便在重新运行 Playbook 时参考。这样可以仅针对少数几个失败的主机重新执行，而不是对已经成功完成的大型集群进行重复操作，这样更加高效。
- en: How to do it...
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: We will step through a problem that caused one of the playbooks to fail.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步解决导致其中一个 Playbook 失败的问题。
- en: 'Note the failed playbook and then invoke it again with the following steps:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 注意失败的 Playbook，然后按照以下步骤重新执行：
- en: 'Ensure that you''re in the `playbooks` directory as follows:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你在 `playbooks` 目录下，如下所示：
- en: '[PRE35]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now rerun that Playbook, but specify the `retry` file:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在重新运行该 Playbook，但指定 `retry` 文件：
- en: '[PRE36]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In most situations, this will be enough to rectify the situation, however, OpenStack-Ansible
    has been written to be idempotent—meaning that the whole playbook can be run again,
    only modifying what it needs to. Therefore, you can run the Playbook again without
    specifying the `retry` file.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在大多数情况下，这足以解决问题，然而，OpenStack-Ansible 已经编写成幂等的——这意味着可以重新运行整个 Playbook，只修改需要的部分。因此，你可以在不指定
    `retry` 文件的情况下再次运行 Playbook。
- en: 'Should there be a failure at this first stage, execute the following:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在第一阶段发生故障，请执行以下操作：
- en: 'First remove the generated `inventory` files:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先删除生成的 `inventory` 文件：
- en: '[PRE37]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now rerun the `setup-hosts.yml` playbook:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在重新运行 `setup-hosts.yml` Playbook：
- en: '[PRE38]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In some situations, it might be applicable to destroy the installation and
    begin again. As each service gets installed in LXC containers, it is very easy
    to wipe an installation and start from the beginning. To do so, carry out the
    following steps:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，销毁安装并重新开始可能是适用的。由于每个服务都安装在LXC容器中，因此很容易擦除安装并从头开始。要执行此操作，请按照以下步骤操作：
- en: 'We first destroy all of the containers in the environment:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们销毁环境中的所有容器：
- en: '[PRE39]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: You will be asked to confirm this action. Follow the ons-screen prompts.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将被要求确认此操作。按照屏幕上的提示操作。
- en: 'We recommend you to uninstall the following package to avoid any conflicts
    with the future running of the playbooks, and also clear out any remnants of containers
    on each host:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们建议您卸载以下软件包，以避免与将来运行playbooks时的任何冲突，并清理每个主机上的任何残留容器：
- en: '[PRE40]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, remove the inventory information:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，删除清单信息：
- en: '[PRE41]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: How it works…
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: Ansible is not perfect and so are computers. Sometimes failures occur in the
    environment due to SSH timeouts, or some other transient failure. Also, despite
    Ansible trying its best to retry the execution of a playbook, the result might
    be a failure. Failure in Ansible is quite obvious—it is usually predicated by
    outputs of red text on the screen. In most cases, rerunning the offending playbook
    may get over some transient problems. Each playbook runs a specific task, and
    Ansible will state which task has failed. Troubleshooting why that particular
    task had failed will eventually lead to a good outcome. Worst case, you can reset
    your installation from the beginning.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible并不完美，计算机也不是。有时由于SSH超时或其他瞬时故障，环境中会发生失败。此外，尽管Ansible尝试重新执行playbook，但结果可能是失败。Ansible失败非常明显——通常会在屏幕上以红色文本输出。在大多数情况下，重新运行有问题的playbook可能会解决一些瞬时问题。每个playbook运行一个特定的任务，Ansible会说明哪个任务失败了。排除为何特定任务失败的故障将最终导致良好的结果。最坏的情况是，您可以从头开始重置安装。
- en: Manually testing the installation
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动测试安装
- en: Once the installation has completed successfully, the first step is to test
    the install. Testing OpenStack involves both automated and manual checks.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 安装成功后的第一步是测试安装。测试OpenStack涉及自动化和手动检查。
- en: Manual tests verify user-journeys that may not normally be picked up through
    automated testing, such as ensuring horizon is displayed properly.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 手动测试验证用户旅程，这些旅程通常不会通过自动化测试检测到，例如确保horizon正确显示。
- en: Automated tests can be invoked using a testing framework such as tempest or
    the OpenStack benchmarking tool—rally.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用诸如tempest或OpenStack基准测试工具（rally）之类的测试框架调用自动化测试。
- en: Getting ready
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作完成后
- en: Ensure that you are `root` on the first infrastructure controller node, `infra01`.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您是第一个基础架构控制器节点`infra01`上的`root`用户。
- en: How to do it…
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'The installation of OpenStack-Ansible creates several `utility` containers
    on each of the infra nodes. These utility hosts provide all the command-line tools
    needed to try out OpenStack, using the command line of course. Carry out the following
    steps to get access to a utility host and run various commands in order to verify
    an installation of OpenStack manually:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack-Ansible的安装在每个基础架构节点上创建了几个`utility`容器。这些实用程序主机提供了所有必需的命令行工具，用于尝试OpenStack，当然是使用命令行。按照以下步骤访问实用程序主机并手动验证OpenStack的安装：
- en: 'First, view the running containers by issuing the following command:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，通过执行以下命令查看正在运行的容器：
- en: '[PRE42]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'As you can see, this lists a number of containers because the OpenStack-Ansible
    installation uses isolated Linux containers for running each service. By the side
    of each one its IP address and running state will be listed. You can see here
    that the container network of `172.29.236.0/24` was used in this chapter and why
    this was named this way. One of the containers on here is the utility container,
    named with the following format: `nodename_utility_container_randomuuid`. To access
    this container, you can SSH to it, or you can issue the following command:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如您所看到的，这里列出了许多容器，因为OpenStack-Ansible安装使用隔离的Linux容器来运行每个服务。在每个容器旁边，将列出其IP地址和运行状态。您可以在这里看到本章中使用的容器网络为`172.29.236.0/24`，以及为什么这样命名。这里的一个容器是实用程序容器，采用以下格式命名：`nodename_utility_container_randomuuid`。要访问此容器，您可以通过SSH连接，或者可以执行以下命令：
- en: '[PRE43]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'You will now be running a Terminal inside this container, with access only
    to the tools and services belonging to that containers. In this case, we have
    access to the required OpenStack clients. The first thing you need to do is source
    in your OpenStack credentials. The OpenStack-Ansible project writes out a generated
    bash environment file with an `admin` user and project that was set up during
    the installation. Load this into your bash environment with the following command:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您将在这个容器内运行一个终端，只能访问属于该容器的工具和服务。在这种情况下，我们可以访问所需的OpenStack客户端。您需要做的第一件事是载入您的OpenStack凭证。OpenStack-Ansible项目会生成一个bash环境文件，其中包含安装过程中设置的`admin`用户和项目。使用以下命令将其加载到bash环境中：
- en: '[PRE44]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Tip
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: you can also use the following syntax in Bash: . `openrc`'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提示**：您还可以在Bash中使用以下语法： . `openrc`'
- en: 'Now you can use the OpenStack CLI to view the services and status of the environment,
    as well as create networks, and launch instances. A few handy commands are listed
    here:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以使用OpenStack CLI查看服务和环境状态，创建网络并启动实例。以下是一些常用命令：
- en: '[PRE45]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: How it works…
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The OpenStack-Ansible method of installing OpenStack installs OpenStack services
    into isolated containers on our Linux servers. On each of the controller (or infra)
    nodes are about 12 containers, each running a single service such as nova-api
    or RabbitMQ. You can view the running containers by logging into any of the servers
    as root and issuing a `lxc-ls -f` command. The `-f` parameter gives you a full
    listing showing the status of the instance such as whether it is running or stopped.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack-Ansible安装OpenStack的方法会将OpenStack服务安装到我们Linux服务器上的隔离容器中。在每个控制节点（或基础设施节点）上大约有12个容器，每个容器运行一个单独的服务，如nova-api或RabbitMQ。您可以通过以root身份登录任一服务器并执行`lxc-ls
    -f`命令来查看运行中的容器。`-f`参数将显示完整的列表，展示实例的状态，例如它是运行中还是已停止。
- en: 'One of the containers on the infra nodes has `utility` in its name, and this
    is known as a *utility container* in OpenStack-Ansible terminology. This container
    has OpenStack client tools installed, which makes it a great place to start manually
    testing an installation of OpenStack. Each container has at least an IP address
    on the container network—in the example used in this chapter this is the `172.29.236.0/24`
    subnet. You can SSH to the IP address of this container, or use another `lxc`
    command to attach to it: `lxc-attach -n` `<name_of_container>`. Once you have
    a session inside the container, you can use it like any other system, provided
    those tools are available to the restricted four-walls of the container. To use
    OpenStack commands, however, you first need to source the resource environment
    file which is named `openrc`. This is a normal bash environment file that has
    been prepopulated during the installation and provides all the required credentials
    needed to use OpenStack straight away.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施节点上的一个容器名称中包含`utility`，在OpenStack-Ansible术语中称之为*实用容器*。这个容器安装了OpenStack客户端工具，非常适合手动测试OpenStack的安装。在这个容器中，每个容器至少有一个IP地址，在本章使用的示例中，IP地址属于`172.29.236.0/24`子网。您可以SSH连接到该容器的IP地址，或者使用另一个`lxc`命令附加到容器：`lxc-attach
    -n` `<name_of_container>`。一旦进入容器内部，您可以像使用其他系统一样使用它，前提是容器内可以使用相应的工具。但是，要使用OpenStack命令，您首先需要载入名为`openrc`的资源环境文件。这是一个标准的bash环境文件，在安装过程中已预先填充，并提供了使用OpenStack所需的所有凭证。
- en: Modifying the OpenStack configuration
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修改OpenStack配置
- en: It would be ludicrous to think that all of the playbooks would be needed to
    run again for a small change such as changing the CPU contention ratio from 4:1
    to 8:1\. So instead, the playbooks have been developed and tagged so that specific
    playbooks can be run associated with that particular project that would reconfigure
    and restart the associated services to pick up the changes.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 如果认为为了像将CPU争用比率从4:1更改为8:1这样的小改动而需要重新运行所有的playbook，那简直是荒谬的。因此，playbook已被开发并标记，以便可以运行与特定项目关联的playbook，重新配置并重启相关服务，以便应用更改。
- en: Getting ready
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure that you are `root` on the *deployment host*. In most cases, this is
    the first infrastructure controller node, `infra01`.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您在*部署主机*上是`root`用户。在大多数情况下，这将是第一个基础设施控制节点`infra01`。
- en: How to do it...
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The following are the common changes and how they can be changed using Ansible.
    As we'll adjust the configuration, all of these commands are executed from the
    same host you used to perform the installation.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是常见的更改及其如何通过 Ansible 进行修改。在调整配置时，所有这些命令都将在你用于执行安装的同一主机上执行。
- en: 'To adjust the CPU overcommit/allocation ratio, carry out the following steps:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 要调整 CPU 超分配/分配比率，请执行以下步骤：
- en: 'Edit the `/etc/openstack_deploy/user_variables.yml` file and modify (or add)
    the following line (adjust the figure to suit):'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑`/etc/openstack_deploy/user_variables.yml`文件，并修改（或添加）以下行（根据需要调整数字）：
- en: '[PRE46]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now execute the following commands to make changes in the environment:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在执行以下命令以对环境进行更改：
- en: '[PRE47]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'For more complex changes, for example, to add configuration that isn''t a simple
    one-line change in a template, we can use an alternative in the form of overrides.
    To make changes to the default Nova Quotas, carry out the following as an example:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的更改，例如添加不是简单单行更改的配置，我们可以使用覆盖的替代方法。要更改默认的 Nova 配额，请按以下示例操作：
- en: 'Edit the `/etc/openstack_deploy/user_variables.yml` file and modify (or add)
    the following line (adjust the figure to suit):'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑`/etc/openstack_deploy/user_variables.yml`文件，并修改（或添加）以下行（根据需要调整数字）：
- en: '[PRE48]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now execute the following commands to make changes in the environment:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在执行以下命令以对环境进行更改：
- en: '[PRE49]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Changes for Neutron, Glance, Cinder, and all other services are modified in
    a similar way. Adjust the name of the service in the syntax used. For example,
    to change a configuration item in the `neutron.conf` file, you would use the following
    syntax:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 对 Neutron、Glance、Cinder 及所有其他服务的更改方式类似。只需在使用的语法中调整服务名称。例如，要更改`neutron.conf`文件中的配置项，可以使用以下语法：
- en: '[PRE50]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Then execute the following commands:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 然后执行以下命令：
- en: '[PRE51]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: How it works…
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We modified the same OpenStack-Ansible configuration files as in the *Configuring
    the installation* recipe and executed the `openstack-ansible playbook` command,
    specifying the playbook that corresponded to the service we wanted to change.
    As we were making configuration changes, we notified Ansible of this through the
    `--tag` parameter.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们修改了与*安装配置*章节相同的 OpenStack-Ansible 配置文件，并执行了`openstack-ansible playbook`命令，指定了与我们想要更改的服务相对应的
    playbook。当我们进行配置更改时，通过`--tag`参数通知 Ansible。
- en: Refer to [https://docs.openstack.org/](https://docs.openstack.org/) for all
    configuration options for each service.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 有关每个服务的所有配置选项，请参考[https://docs.openstack.org/](https://docs.openstack.org/)。
- en: Virtual lab - vagrant up!
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟实验室 - vagrant up!
- en: In an ideal world, each of us would have access to physical servers and the
    network kit in order to learn, test, and experiment with OpenStack. However, most
    of the time this isn't the case. By using an orchestrated virtual lab, using Vagrant
    and VirtualBox, allows you to experience this chapter on OpenStack-Ansible using
    your laptop.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想的世界里，我们每个人都会有物理服务器和网络设备，以便学习、测试和实验 OpenStack。然而，实际情况往往并非如此。通过使用 Vagrant 和
    VirtualBox 创建的虚拟实验室，可以让你在自己的笔记本电脑上体验本章关于 OpenStack-Ansible 的内容。
- en: The following Vagrant lab can be found at [http://openstackbook.online/](http://openstackbook.online/).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Vagrant 实验室可以在[http://openstackbook.online/](http://openstackbook.online/)找到。
- en: 'This is the architecture of the Vagrant-based OpenStack environment:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这是基于 Vagrant 的 OpenStack 环境架构：
- en: '![Virtual lab - vagrant up!](img/00005.jpeg)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![虚拟实验室 - vagrant up!](img/00005.jpeg)'
- en: 'Essentially there are three virtual machines that are created (a controller
    node, a compute node and a client machine), and each host has four network cards
    (plus an internal bridged interface used by VirtualBox itself). The four network
    cards represent the networks described in this chapter:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，创建了三个虚拟机（一个控制节点，一个计算节点和一个客户端机器），每个主机有四个网络卡（加上 VirtualBox 本身使用的内部桥接接口）。这四个网络卡表示本章描述的网络：
- en: '**Eth1**: This is included in the `br-mgmt` bridge, and used by the container
    network'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Eth1**：它包含在`br-mgmt`桥接中，并由容器网络使用。'
- en: '**Eth2**: This is included in the `br-vlan` bridge, and used when a VLAN-based
    Neutron network is created once OpenStack is up and running'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Eth2**：它包含在`br-vlan`桥接中，并在 OpenStack 启动并运行后，用于创建基于 VLAN 的 Neutron 网络。'
- en: '**Eth3**: This is the client or host network—the network we would be using
    to interact with OpenStack services (for example, the public/external side of
    the load balancer)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Eth3**：这是客户端或主机网络——我们用来与 OpenStack 服务交互的网络（例如，负载均衡器的公共/外部端）。'
- en: '**Eth4**: This is included in the `br-vxlan` bridge, and used when a VXLAN-based
    Neutron overlay network is created once OpenStack is up and running'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Eth4**：该接口包含在 `br-vxlan` 桥接中，并在 OpenStack 启动并运行后用于创建基于 VXLAN 的 Neutron 覆盖网络。'
- en: Note that the virtual machine called `openstack-client`, which gets created
    in this lab, provides you with all the command-line tools to conveniently get
    you started with working with OpenStack.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在此实验中创建的虚拟机 `openstack-client` 为您提供所有命令行工具，方便您开始使用 OpenStack。
- en: Getting ready
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'In order to run a multi-node OpenStack environment, running as a virtual environment
    on your laptop or designated host, the following set of requirements are needed:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在笔记本或指定的主机上运行多节点的 OpenStack 环境作为虚拟环境，以下一组要求是必须的：
- en: A Linux, Mac, or Windows desktop, laptop or server. The authors of this book
    use macOS and Linux, with Windows as the host desktop being the least tested configuration.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台 Linux、Mac 或 Windows 桌面、笔记本电脑或服务器。本书的作者使用 macOS 和 Linux，Windows 作为主机桌面的配置测试较少。
- en: At least 16GB RAM. 24GB is recommended.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 16GB 内存，推荐 24GB。
- en: About 50 GB of disk space. The virtual machines that provide the infra and compute
    nodes in this virtual environment are thin provisioned, so this requirement is
    just a guide depending on your use.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约需要 50GB 的磁盘空间。提供基础设施和计算节点的虚拟机是薄配置的，因此这个要求仅作为参考，具体取决于你的使用情况。
- en: An internet connection. The faster the better, as the installation relies on
    downloading files and packages directly from the internet.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个互联网连接。连接速度越快越好，因为安装过程依赖于从互联网直接下载文件和软件包。
- en: How to do it…
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'To run the OpenStack environment within the virtual environment, we need a
    few programs installed, all of which are free to download and use: VirtualBox,
    Vagrant, and Git. VirtualBox provides the virtual servers representing the servers
    in a normal OpenStack installation; Vagrant describes the installation in a fully
    orchestrated way; Git allows us to check out all of the scripts that we provide
    as part of the book to easily test a virtual OpenStack installation. The following
    instructions describe an installation of these tools on Ubuntu Linux.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 要在虚拟环境中运行 OpenStack 环境，我们需要安装几个程序，所有这些程序都可以免费下载安装：VirtualBox、Vagrant 和 Git。VirtualBox
    提供虚拟服务器，代表正常 OpenStack 安装中的服务器；Vagrant 以完全自动化的方式描述安装过程；Git 允许我们检出本书中提供的所有脚本，轻松测试虚拟的
    OpenStack 安装。以下说明描述了在 Ubuntu Linux 上安装这些工具的步骤。
- en: 'We first need to install VirtualBox if it is not already installed. We recommend
    downloading the latest available releases of the software. To do so on Ubuntu
    Linux as `root`, follow these steps:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 如果还没有安装 VirtualBox，首先需要安装它。我们建议下载该软件的最新版本。在 Ubuntu Linux 上以 `root` 用户执行以下步骤：
- en: 'We first add the `virtualbox.org` repository key with the following command:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先使用以下命令添加 `virtualbox.org` 仓库密钥：
- en: '[PRE52]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next we add the repository file to our `apt` configuration, by creating a file
    called `/etc/apt/sources.list.d/virtualbox.conf` with the following contents:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们通过创建一个名为 `/etc/apt/sources.list.d/virtualbox.conf` 的文件，并包含以下内容，将仓库文件添加到
    `apt` 配置中：
- en: '[PRE53]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We now run an `apt update` to refresh and update the `apt` cache with the following
    command:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在执行 `apt update` 以刷新并更新 `apt` 缓存，使用以下命令：
- en: '[PRE54]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Now install VirtualBox with the following command:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在使用以下命令安装 VirtualBox：
- en: '[PRE55]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Once VirtualBox is installed, we can install Vagrant. Follow these steps to
    install Vagrant:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 VirtualBox 后，我们可以安装 Vagrant。请按照以下步骤安装 Vagrant：
- en: 'Vagrant is downloaded from [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html).
    The version we want is Debian 64-Bit. At the time of writing, this is version
    2.0.1\. To download it on our desktop issue the following command:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vagrant 从 [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html)
    下载。我们需要的版本是 Debian 64 位版本。本文写作时，版本为 2.0.1。要在桌面上下载，执行以下命令：
- en: '[PRE56]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We can now install the file with the following command
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在可以使用以下命令安装该文件：
- en: '[PRE57]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The lab utilizes two vagrant plugins: `vagrant-hostmanager` and `vagrant-triggers`.
    To install these, carry out the following steps:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 该实验使用了两个 vagrant 插件：`vagrant-hostmanager` 和 `vagrant-triggers`。要安装这些插件，请执行以下步骤：
- en: 'Install `vagrant-hostmanager` using the `vagrant` tool:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `vagrant` 工具安装 `vagrant-hostmanager`：
- en: '[PRE58]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Install `vagrant-triggers` using the `vagrant` tool:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `vagrant` 工具安装 `vagrant-triggers`：
- en: '[PRE59]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'If Git is not currently installed, issue the following command to install `git`
    on a Ubuntu machine:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Git 目前没有安装，可以通过以下命令在 Ubuntu 机器上安装 `git`：
- en: '[PRE60]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now that we have the required tools, we can use the `OpenStackCookbook` Vagrant
    lab environment to perform a fully orchestrated installation of OpenStack in a
    VirtualBox environment:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了所需的工具，可以使用`OpenStackCookbook` Vagrant实验环境在VirtualBox环境中执行一个完全协调的OpenStack安装：
- en: 'We will first checkout the lab environment scripts and supporting files with
    `git` by issuing the following command:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先通过`git`检出实验环境脚本和支持文件，使用以下命令：
- en: '[PRE61]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We will change into the `vagrant-openstack` directory that was just created:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将切换到刚刚创建的`vagrant-openstack`目录：
- en: '[PRE62]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We can now orchestrate the creation of the virtual machines and installation
    of OpenStack using one simple command:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用一个简单的命令来协调虚拟机的创建和OpenStack的安装：
- en: '[PRE63]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Tip
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Tip**: This will take quite a while as it creates the virtual machines and
    runs through all the same playbook steps described in this chapter.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：这将需要一段时间，因为它将创建虚拟机并执行本章中描述的所有相同的剧本步骤。'
- en: How it works…
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Vagrant is an awesome tool for orchestrating many different virtual and cloud
    environments. It allows us to describe what virtual servers need to be created,
    and using Vagrant's provisioner allows us to run scripts once a virtual machine
    has been created.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: Vagrant 是一个很棒的工具，可以协调许多不同的虚拟和云环境。它允许我们描述需要创建的虚拟服务器，利用 Vagrant 的配置器，在虚拟机创建后运行脚本。
- en: Vagrant's environment file is called **Vagrantfile**. You can edit this file
    to adjust the settings of the virtual machine, for example, to increase the RAM
    or number of available CPUs.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: Vagrant的环境文件名为**Vagrantfile**。你可以编辑这个文件来调整虚拟机的设置，例如增加内存或可用的CPU数量。
- en: 'This allows us to describe a complete OpenStack environment using one command:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得我们可以通过一个命令描述一个完整的OpenStack环境：
- en: '[PRE64]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The environment consists of the following:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 该环境包含以下组件：
- en: A controller node, `infra-01`
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个控制节点，`infra-01`
- en: A compute node, `compute-01`
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个计算节点，`compute-01`
- en: A client virtual machine, `openstack-client`
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个客户端虚拟机，`openstack-client`
- en: Once the environment has finished installing, you can use the environment by
    navigating to `http://192.168.100.10/` in your web browser. To retrieve the admin
    password, follow the steps given here and view the file named `openrc`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦环境安装完成，你可以通过在浏览器中访问`http://192.168.100.10/`来使用该环境。要获取管理员密码，请按照此处给出的步骤，并查看名为`openrc`的文件。
- en: 'There is a single controller node that has a `utility` container configured
    for use in this environment. Attach to this with the following commands:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个单独的控制节点，它配置了一个`utility`容器，供本环境使用。可以使用以下命令连接：
- en: '[PRE65]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Once you have retrieved the `openrc` details, copy these to your `openstack-client`
    virtual machine. From here you can operate OpenStack, mimicking a desktop machine
    accessing an installation of OpenStack utilizing the command line.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 获取`openrc`详情后，将其复制到你的`openstack-client`虚拟机中。从这里，你可以像在桌面机器上操作一样，使用命令行访问并操作OpenStack。
- en: '[PRE66]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: You should now be able to use OpenStack CLI tools to operate the environment.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该能够使用OpenStack CLI工具来操作该环境。
