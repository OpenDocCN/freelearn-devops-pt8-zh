- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenShift Pipelines – Tekton
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far in this book, we’ve already discussed the challenges related to the
    current hybrid cloud world and covered aspects regarding the OpenShift architecture
    and deployment. Now, we are going to shift gears and bring you an exciting DevOps-related
    feature: **OpenShift Pipelines**!'
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift Pipelines is a Kubernetes-native **continuous integration and continuous
    delivery** (**CI/CD**) tool based on the Tekton open source project, which is
    included at *no additional cost with Red Hat’s OpenShift subscription*. In this
    chapter, we will walk you through it and learn how to install and use it. By doing
    this, you will understand how it can be helpful in your DevOps pipelines and automation.
  prefs: []
  type: TYPE_NORMAL
- en: After [*Chapter 5*](B18015_05.xhtml#_idTextAnchor090), *OpenShift Deployment*,
    you should have an OpenShift cluster working in your environment. We will use
    that cluster in this chapter to implement some exercises. If you don’t have an
    OpenShift cluster available, then you can use **CodeReady Containers** (**CRC**)
    as a lab. Here, you can run an OpenShift cluster locally and quickly using an
    all-in-one VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is OpenShift Pipelines?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing OpenShift Pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Tekton pipeline from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using triggers with GitHub webhooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fixing the failed PipelineRun due to YAML issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we mentioned previously, OpenShift Pipelines is a Kubernetes native application
    and, as such, is a lightweight tool that uses **Custom Resource Definitions**
    (**CRDs**) to extend the OpenShift API’s functionalities. In the upcoming sections,
    you will see that the installation is fairly simple and only involves installing
    an operator – a *“Next, Next, Finish”* sort of experience. To be able to install
    it and run the exercises in this chapter, you only need an OpenShift cluster with
    the following available resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 2 vCPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2 GB of RAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you don’t have an OpenShift cluster available to use, we recommend that
    you try CRC to spin up a cluster locally on your machine. To use CRC, you need
    to have the following system requirements on your workstation:'
  prefs: []
  type: TYPE_NORMAL
- en: 4 physical CPU cores (AMD64 or Intel 64)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 9 GB of free memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 35 GB of storage space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the following operating systems:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows (Windows 10 Fall Creators Update or later)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: macOS (10.14 Mojave or later)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux (Red Hat Enterprise Linux/CentOS 7.5 or later and on the latest two stable
    Fedora releases)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux (Ubuntu 18.04 LTS or newer and Debian 10 or newer *are not officially*
    supported and may require you to manually set up the host machine
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The source code used in this chapter is available at [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter09](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter09).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will demonstrate how to install and use CRC using a Linux
    (Fedora) workstation. Please refer to the following site to find out more about
    the installation process on Windows or macOS: [https://crc.dev/crc/](https://crc.dev/crc/).'
  prefs: []
  type: TYPE_NORMAL
- en: What Is a CRD?
  prefs: []
  type: TYPE_NORMAL
- en: A CRD is a Kubernetes resource that allows you to expand the Kubernetes APIs
    by defining custom entities. A CRD is composed of a name and a schema that specify
    the API’s properties.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and using CRC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The CRC installation process is simple – you need to have the following packages
    installed in your box:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To install CRC, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the latest release of CRC for your platform at [https://console.redhat.com/openshift/create/local](https://console.redhat.com/openshift/create/local).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the contents of the archive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a terminal, go to the path where you extracted the archive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following command to set up CRC:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you want to set up parameters, such as the amount of CPU and memory that’s
    available for CRC, run the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start CRC by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It is going to take up to 20 minutes to completely start the cluster. At the
    end of the process, you will see a screen similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – CRC startup ](img/B18015_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – CRC startup
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have CRC or any other OpenShift cluster up and running, we are
    ready to introduce OpenShift Pipelines and learn what you can do with it.
  prefs: []
  type: TYPE_NORMAL
- en: What is OpenShift Pipelines?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you already have a lab environment, let’s start our engines and drive
    through OpenShift Pipelines! As we mentioned previously, OpenShift Pipelines is
    Red Hat’s implementation of the Tekton open source project. Let’s learn what Tekton
    is and how it differs from other CI/CD pipeline tools on the market.
  prefs: []
  type: TYPE_NORMAL
- en: What is Tekton?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tekton provides a framework for creating Kubernetes native CI/CD pipelines quickly
    and easily. It uses CRDs to extend the Kubernetes APIs functionalities and add
    some custom objects that are used to implement CI/CD pipelines. You can also integrate
    Tekton with industry-standard CI/CD pipeline tools such as Jenkins, GitLab CI,
    and any others to use the best technology for each case.
  prefs: []
  type: TYPE_NORMAL
- en: Tekton is a part of the **Continuous Delivery Foundation**, which is sponsored
    by huge companies such as AWS, Red Hat, Google, Netflix, and many others. This
    is usually a good indication that a project will have a long life and stability
    – an important factor for an enterprise’s investment decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Main benefits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using Tekton can bring you many benefits, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Tekton can be considered as a serverless CI/CD pipeline system that consumes
    resources on demand using isolated containers, which likely reduce the infrastructure
    or cloud costs associated with the CI/CD tool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is tightly integrated with Kubernetes, working as an extension of it using
    CRDs. This means that you don’t need to spend time and resources with complex
    integrations between the CI/CD tools and OpenShift.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both the aforementioned aspects also mean that you will not need additional
    human resources to deploy, support, and maintain the CI/CD tool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a Kubernetes native tool, you can define and run pipelines by applying a
    simple YAML file to Kubernetes (the same way you would do to create a Pod, Service,
    Or Deployment). This makes Tekton easy to use and integrate with other tools for
    complex pipelines that are composed of several components (legacy VMs, containers,
    microservices, and so on).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By integrating Tekton with **Argo CD**, you can have a really powerful stack
    in which Tekton resides on the *continuous integration* side while Argo CD is
    responsible for the *continuous delivery* side. We will look at Argo CD in detail
    in [*Chapter 10*](B18015_10.xhtml#_idTextAnchor204), *OpenShift GitOps – Argo
    CD*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a true open source solution that’s backed by a strong foundation, which
    is good evidence that it will be supported and evolve for years to come.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tekton components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will walk through each of the Tekton components. In a nutshell,
    the main Tekton components are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tekton Pipelines**: It is composed of several CRDs, which are the building
    blocks for developing and running CI/CD pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tekton Triggers**: These are objects that listen to events and trigger a
    pipeline or task. They are often used to run a pipeline after a pull or push request
    in a GitHub repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tkn`) to interact with Tekton.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tekton Catalog**: A community-driven repository of tasks ready to be used
    in your pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tekton Operator**: This is used to easily install, manage, and remove Tekton
    from a Kubernetes cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To learn Tekton, you need to understand some concepts first:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step**: An action that has a set of inputs and produces a set of outputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Task**: A set of structured steps required to run a specific task, such as
    cloning a GitHub repository or building source code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pipeline**: A set of structured tasks that composes a CI/CD pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TaskRun**: This object represents the instantiation of a task. While the
    task is the generic definition of it, a TaskRun defines the input parameters and
    the other components that are needed to run it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PipelineRun**: This is similar to a TaskRun, but for pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To dive into these concepts, we will cover an example where we will build and
    run a meaningful pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Installing OpenShift Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The installation process is really simple, as you will see in the following
    steps.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You must have access to the OpenShift cluster with cluster-admin permissions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Access the **OpenShift Web Console** from the administrator’s perspective.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate to **Operators** | **OperatorHub**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.2 – OperatorHub ](img/B18015_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – OperatorHub
  prefs: []
  type: TYPE_NORMAL
- en: 'Search for `OpenShift Pipelines` using the *Filter by keyword* box:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Red Hat OpenShift Pipelines on OperatorHub ](img/B18015_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Red Hat OpenShift Pipelines on OperatorHub
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Red Hat OpenShift Pipelines** tile and then the **Install**
    button to see the **Install Operator** screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Installing OpenShift Pipelines ](img/B18015_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Installing OpenShift Pipelines
  prefs: []
  type: TYPE_NORMAL
- en: Now, select `openshift-operators` namespace and permits the operator to install
    OpenShift Pipelines instances in any target namespace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Automatic** or **Manual** for the upgrade’s **Approval Strategy**.
    If you go for **Automatic**, upgrades will be performed automatically by the **Operator
    Lifecycle Manager** (**OLM**) as soon as they are released by Red Hat, while if
    you go for **Manual**, you need to approve it before it’s applied.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select an **Update channel option**. The stable channel is recommended as it
    contains the latest stable and *supported* version of the operator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click the **Install** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Installing the operator ](img/B18015_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Installing the operator
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait up to 5 minutes until you see the following message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Operator installed ](img/B18015_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Operator installed
  prefs: []
  type: TYPE_NORMAL
- en: Once you have installed OpenShift Pipelines, we recommend that you install the
    `tkn` CLI to help with ordinary tasks. Let’s learn how to install the `tkn` CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the tkn CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`tkn` is a CLI that makes it easier to work with Tekton. Through it, you can
    manage (list, delete, describe, get logs, and so on) tasks, pipelines, triggers,
    and all the available Tekton objects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the `tkn` CLI, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download tkn from the URL link provided after you click the *question mark*
    icon of your OpenShift Web Console, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Help menu | Command line tools ](img/B18015_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Help menu | Command line tools
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the client for your workstation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.8 – tkn download links ](img/B18015_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – tkn download links
  prefs: []
  type: TYPE_NORMAL
- en: 'After downloading it to your machine, you need to decompress it and add it
    to your path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If everything went well, you will see the output below by running `tkn version`.
    Ignore the warning message you will see that specifies the pipeline version; it
    is an expected message as we haven’t logged any OpenShift clusters yet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that you have installed OpenShift Pipelines and `tkn`, let’s use them to
    create a pipeline from scratch. In the next section, we will learn about Tekton’s
    main concepts while taking a practical approach.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Tekton pipeline from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will create a Tekton pipeline from scratch so that we can
    learn from it. We are going to use a sample from our GitHub repository: [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook).
    To practice the concepts we will cover here, fork this repository to your GitHub
    account and follow the instructions provided in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline that we will work on is simple but helpful. It will consist of
    the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9 – Build and deploy pipeline ](img/B18015_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 – Build and deploy pipeline
  prefs: []
  type: TYPE_NORMAL
- en: In the next few sections, you will learn how to use Tasks, TaksRuns, Pipelines,
    and PipelineRuns, which are Tekton’s main objects.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create this pipeline, you need to understand the foundational concept of
    a task. As we mentioned previously, a task provides a set of structured steps
    for performing a certain action, such as cloning a GitHub repository or building
    source code. Now, let’s go deeper and learn about some important aspects of it.
    The first important aspect that you need to understand is the task scope, which
    defines whether you need to use a Task or a ClusterTask:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Task**: A task is only available within a specific namespace. You will usually
    use tasks for actions that apply specifically to a certain application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ClusterTask**: This is identical to a task but can be used in any namespace.
    They are usually used with generic actions that can be applied to any application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In our example, we will use Tasks and ClusterTasks to understand how they work
    and the differences between them. A Task has the following elements. We will use
    these in our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Parameters**: The parameters that are required to run the task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resources**: This includes the input or output resources that are supplied
    by **PipelineResources** objects. We recommend that you use workspaces instead
    of PipelineResources since they are more difficult to troubleshoot, making tasks
    less reusable and more limited than workspaces. Due to that, we won’t be using
    PipelineResources in our example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steps**: This is where you define the actions that will be performed in a
    task. You need to use a container image to run the actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Workspaces**: This is an artifact that’s used to define a commonly shared
    storage volume between different tasks in a pipeline. Workspaces can be used for
    different purposes, such as sharing data between different tasks, a mount point
    for configurations (using ConfigMaps), credentials, and sensitive data (with secrets),
    and also to store reusable artifacts that have been shared between different tasks
    and pipelines. Workspaces are also helpful for caching artifacts to speed up builds
    and other jobs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Results**: These are string result variables that can be passed to other
    tasks in a pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our sample pipeline, we are going to reuse our existing tasks for the GitHub
    clone and build the source code. The last two tasks we will look at will be custom
    ones that we will create specifically for our pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Reusing tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, let’s learn how to search for and reuse tasks to build a pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: The first place where you can look for existing tasks is your local OpenShift
    cluster. When you install OpenShift Pipelines, several `tkn` CLI or the OpenShift
    UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how to use `tkn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is some example output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To do the same using the OpenShift UI, go to `tkn` CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.10 – ClusterTasks for reuse ](img/B18015_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 – ClusterTasks for reuse
  prefs: []
  type: TYPE_NORMAL
- en: Another great tool to look for and reuse existing tasks is **Tekton Hub**. We
    will use it shortly to extend our sample and validate our YAML files using the
    **YAML Lint** tool.
  prefs: []
  type: TYPE_NORMAL
- en: Notes
  prefs: []
  type: TYPE_NORMAL
- en: '**Tekton Hub** is a web portal where you can get reusable assets from Tekton
    Catalog. It can be accessed at [https://hub.tekton.dev/](https://hub.tekton.dev/).'
  prefs: []
  type: TYPE_NORMAL
- en: '**YAML Lint** is a tool that validates YAML file syntax, checking indentation,
    trailing spaces, and many other possible issues. Go to [https://yamllint.readthedocs.io/en/stable/](https://yamllint.readthedocs.io/en/stable/)
    to learn more.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the ClusterTasks, we have decided to reuse the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`git-clone`: To clone the source code from the GitHub repository'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`buildah`: To build the source code and generate a container image as a result'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s learn how to create a custom task for when you need something specific.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new (custom) task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Defining a new task is as simple as creating a pod or deployment. For our example,
    we need to create three new tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apply-manifests`: This task will be responsible for applying some K8s manifest
    files that will deploy the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`update-deployment`: This task will update the deployment, replacing the container
    image with the one that has been built in the previous tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`check-app-health`: This task checks the application pod’s status and the URL
    to validate whether the application is accessible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s create these tasks, explore their content, and learn from them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we have highlighted some parts with numbers. Let’s take
    a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[1]**: An object of this kind defines a new Tekton task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[2]**: The task’s name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`git-clone` task (the first task).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[4]**: The parameters that are required for the task to run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[5]**: The steps that are performed with the task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`step` commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[7]**: The commands that will perform the desired action – in this case,
    applying the k8s manifests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we have looked at the task’s structure, let’s create it in our sample
    environment and run it using another object – **TestRun**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new project for our example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, check if the pipeline’s service account has been created automatically:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `apply-manifest` task in the `pipelines-sample` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `tkn` confirm that the task has been created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s create other custom tasks (`update-image-version` and `check-route-health`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have created our custom tasks, let’s learn how to run and test them
    using a `TaskRun` object.
  prefs: []
  type: TYPE_NORMAL
- en: TaskRun
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our task needs a persistent volume to store the source code from GitHub. As
    such, before we run TaskRun, we need to create a **PersistentVolumeClaim**. Note
    that you need to have a **StorageClass** to provision a **PersistentVolume** automatically
    for you. If you don’t have one, the PersistentVolumeClaim will be *Pending*, waiting
    for the PersistentVolume to be created manually.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to create the PersistentVolumeClaim:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now, we must create two TaskRuns. In the first, we will use the `git-clone`
    ClusterTask to clone the GitHub repository and store it in the workspace that
    uses a PersistentVolume. In the second, we will use the custom task that we created
    previously, which deploys the application by applying some manifests (the `apply-manifests`
    task).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the structure of a TaskRun:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at this code in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TaskRun` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[2]**: The name of the task that will be run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ClusterTask` but can be omitted for regular tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[4]**: Parameter values to be used during the task’s execution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[5]**: Workspaces to be used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the following command to apply the `TaskRun` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have created the `git-clone` object, you can look at the logs using
    the following `tkn` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, run `apply-manifests` using the following TaskRun:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the logs, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: With that, you have learned how to run a particular task using a `TaskRun` object.
    You also know how to reuse and create a custom task. We will use this knowledge
    to create our first pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will create our first meaningful pipeline! I like to compare
    a pipeline’s design to a LEGO® set, in which you need to have all the pieces at
    hand before assembling it. If the LEGO set is too big to assemble at once, you
    need to break it into smaller blocks of meaningful parts. In our pipeline, the
    *LEGO pieces* are the **tasks** that we have already built and the ones we will
    reuse. We have all we need, so *let’s assemble our LEGO set*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use our example to understand how to define a pipeline object. The
    first part of any pipeline is its metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The next part is its specification (`spec`), which is composed of the following
    items:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Workspaces**: This is a shared workspace that’s required to store the source
    code and any other pipeline artifacts that need to be passed between the tasks:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Parameters**: These are the input parameters that are required to run the
    pipeline:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`taskRef` (the reference to the task that will be used), as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For `kind` attribute within the `taskRef` group, like so:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can find the complete pipeline at [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter06](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/blob/main/chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to create our pipeline. To do so, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have defined our pipeline, let’s run it!
  prefs: []
  type: TYPE_NORMAL
- en: PipelineRun
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are multiple ways to run the pipeline: through the OpenShift Console
    UI, using `tkn`, or by creating and applying a PipelineRun object manually. At
    the end of the day, no matter how you run it, a PipelineRun will always be created
    (the only difference is that the PipelineRun is created automatically for you
    when you use `tkn` or the web UI). For didactic reasons, we will do this using
    a `PipelineRun` object to learn about and understand it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows our `PipelineRun` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at this code in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PipelineRun` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[2]**: The pipeline to be run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[3]**: The parameter values to be used with the pipeline'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[4]**: The workspace’s definition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apply the `PipelineRun` object and check the logs to see the pipeline’s execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With that, you have custom tasks and a pipeline that has been tested and is
    working already. Now, let’s make it even better by using a trigger to run this
    pipeline automatically when a Git push occurs in the repository.
  prefs: []
  type: TYPE_NORMAL
- en: Using triggers with GitHub webhooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a CI/CD workflow, it is typical to use an event, such as a pull or push
    request on Git, to trigger a new pipeline run. With Tekton, you use **EventListeners**
    to listen for events and run one or more triggers. There are some out-of-the-box
    event processors, named **Interceptors**, for the following platforms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**GitHub**: This allows you to validate and filter GitHub webhooks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GitLab**: The same as the previous point but for GitLab.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bitbucket**: The same as the previous points for Bitbucket.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CEL**: This allows you to use **Common Expression Language** (**CEL**) to
    filter and modify payloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Webhook**: This allows you to process any webhook payload and apply any business
    logic to it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our example, we will use a GitHub interceptor to process a webhook, filter
    push events, and trigger the pipeline we created previously. You can also implement
    your custom interceptors by implementing an object named `ClusterInterceptors`.
    Check out the links in the *Further reading* section if you need to create a ClusterInterceptor
    or use any interceptor other than the GitHub one that we will use in our example.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the GitHub webhook requires a publicly accessible URL to send the
    HTTP webhook posts. Due to that, you will need an OpenShift cluster with a public
    IP and domain that can be accessed from the internet. That said, in this case,
    you will not be able to use CRC to test Tekton triggers using GitHub webhooks
    unless you make your CRC URL routes public on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: What is CEL?
  prefs: []
  type: TYPE_NORMAL
- en: CEL is a simple but fast and portable language for expression evaluation. Created
    and maintained by some Google engineers, it is an open source project that was
    released under the Apache License and used with many Google projects and services.
    For more information, go to [https://opensource.google/projects/cel](https://opensource.google/projects/cel).
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the **EventListener**, a Tekton trigger is composed of several other
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trigger**: This defines which action will be performed after the EventListener
    detects a new event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TriggerTemplate**: This specifies a blueprint of objects that will be applied
    as a result of the trigger, usually using a PipelineRun object, which, in turn,
    will run a pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TriggerBinding**: This defines the field data that will be extracted from
    the event payload to be used with the associated PipelineRun.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ClusterTriggerBinding**: This is the same as the TriggerBinding but cluster-scoped.
    It can be reused among different namespaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following objects will be used in our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.11 – Tekton Trigger objects ](img/B18015_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 – Tekton Trigger objects
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s put this into practice! You have already created the tasks and pipeline
    in your lab, so let’s create the trigger objects that will use the existing pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: TriggerBinding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**TriggerBinding** will parse the data that’s been extracted from the GitHub
    payload, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at this code in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TriggerBinding` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[2]**: The parameters that will be assigned according to the payload data
    fields'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the following command to create the TriggerBinding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The next object we need to create is `TriggerTemplate`. Let’s take a look.
  prefs: []
  type: TYPE_NORMAL
- en: TriggerTemplate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`TriggerTemplate` will create a PipelineRun that executes our sample pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at this code in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TriggerTemplate` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TriggerBinding` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[3]**: The objects that will be created as a result of the trigger'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the following command to create the `TriggerTemplate` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can create the `Trigger` object, which uses all the objects we have
    created.
  prefs: []
  type: TYPE_NORMAL
- en: Trigger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `Trigger` object will be the glue between the GitHub interceptor, `TriggerBinding`,
    and `TriggerTemplate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at this code in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Trigger` object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[2]**: The list of event interceptors to be used to trigger the actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[3]**: The interceptor from GitHub.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[4]**: The secret that’s been configured in the GitHub webhook.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[5]**: The trigger event types that Tekton will react to. In this case, it
    will be GitHub “push” events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TriggerBinding` object that will be used with this trigger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TriggerTemplate` object that will be used with this trigger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows an example of the GitHub secret (**[4]**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following command to create the secret and trigger:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The last object we need to create to put the trigger into practice is `EventListener`.
    Let’s take a look.
  prefs: []
  type: TYPE_NORMAL
- en: EventListener
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we need to create an **EventListener** object that will listen for
    HTTP requests and be used with the GitHub webhook configuration. We will learn
    how to configure the GitHub webhook soon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at this code in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`EventListener` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EventListener` object is sensitized'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the following command to create the `EventListener` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '`EventListener` will create a service on OpenShift that you need to expose
    externally. The route URL that’s generated will be used during the GitHub webhook
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are ready to configure a new GitHub webhook that will use the `EventListener`
    object we just created to fire Tekton’s trigger.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a GitHub webhook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create a webhook, you need to fork our GitHub repository. If you haven’t
    forked it yet, do so now in your personal GitHub account: [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the GitHub forked repository and go to **Settings** | **Webhook**. On
    the following page, click on the **Add webhook** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.12 – Adding a webhook on GitHub ](img/B18015_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 – Adding a webhook on GitHub
  prefs: []
  type: TYPE_NORMAL
- en: 'Fill out the form by providing the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Payload URL**: The route URL we created in the previous section. You can
    get this URL by running the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`application/json`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tekton`):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 9.13 – Adding a webhook on GitHub ](img/B18015_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.13 – Adding a webhook on GitHub
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few seconds, you should see a green check mark next to the webhook
    we created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.14 – Webhook added ](img/B18015_09_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.14 – Webhook added
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our `Trigger` objects from the Tekton side and the webhook
    configured on GitHub, let’s test it!
  prefs: []
  type: TYPE_NORMAL
- en: Testing the Tekton trigger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Run a `commit` and push the trigger to the webhook event, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Access the `push` command has been run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.15 – PipelineRun on Red Hat ](img/B18015_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.15 – PipelineRun on Red Hat
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations – you have successfully created a CI/CD pipeline on Tekton and
    ran it automatically after a Git push event using a trigger! To wrap up this chapter,
    we will enhance our pipeline by adding a validation task for YAML files using
    the YAML linter tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, let’s use Tekton Hub to find a reusable task. Go to [https://hub.tekton.dev/](https://hub.tekton.dev/)
    and search for YAML using the search box at the top right of the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.16 – Tekton Hub ](img/B18015_09_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.16 – Tekton Hub
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **YAML linter** task to find the instructions on how to install and
    use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.17 – YAML linter ](img/B18015_09_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.17 – YAML linter
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, we will use the **Pipeline Builder** page to add the YAML linter
    task. To do so, access the OpenShift UI and select the **Developer** console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.18 – Developer console ](img/B18015_09_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.18 – Developer console
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Access the `build-and-deploy` pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.19 – The Pipelines menu ](img/B18015_09_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.19 – The Pipelines menu
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, click the **Actions** button and then **Edit Pipeline**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.20 – The build-and-deploy pipeline ](img/B18015_09_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.20 – The build-and-deploy pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'On the following screen, click on the **fetch-repository** box and then the
    **+** sign next to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.21 – The Pipeline builder feature ](img/B18015_09_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.21 – The Pipeline builder feature
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the `yaml lint`, and click the **Install and add** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.22 – Adding a new task using the Pipeline builder feature ](img/B18015_09_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.22 – Adding a new task using the Pipeline builder feature
  prefs: []
  type: TYPE_NORMAL
- en: 'The new task should have been added. You should see an exclamation mark next
    to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.23 – Adding a new task using the Pipeline builder feature ](img/B18015_09_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.23 – Adding a new task using the Pipeline builder feature
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, click it and input `./sample-go-app/clouds-api/k8s` as the `shared-workspace`
    as the **Workspaces** group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.24 – Setting the yaml-lint task’s parameters ](img/B18015_09_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.24 – Setting the yaml-lint task’s parameters
  prefs: []
  type: TYPE_NORMAL
- en: Now, click on **Save**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, our pipeline has a new step that validates the YAML content
    of our Kubernetes manifest files. To test our previous change, let’s run it from
    the same web UI. To do so, click the **Actions** menu from the **Pipeline details**
    screen and select the **Start** action:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.25 – Running the pipeline from the Developer console ](img/B18015_09_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.25 – Running the pipeline from the Developer console
  prefs: []
  type: TYPE_NORMAL
- en: Fill out the form by using the following values and click `clouds-api`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**git-url**: <Your forked repository>'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`main`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`image-registry.openshift-image-registry.svc:5000/pipelines-sample/clouds-api`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`./sample-go-app/clouds-api/`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`VolumeClaimTemplate`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.26 – PipelineRun parameters ](img/B18015_09_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.26 – PipelineRun parameters
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the `PipelineRun` object on the following screen. You will get an error
    regarding the new **yaml-lint** task we added:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.27 – PipelineRun failed due to YAML linter validations ](img/B18015_09_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.27 – PipelineRun failed due to YAML linter validations
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **yaml-lint** step and check out the logs to find the issue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.28 – PipelineRun failed due to YAML linter validations ](img/B18015_09_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.28 – PipelineRun failed due to YAML linter validations
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the YAML linter detected errors in some YAML files. Those errors
    are expected and have been prepared especially for you to simulate what a real
    CI/CD pipeline looks like. Now, practice the skills you’ve just acquired to fix
    those errors and get the pipeline working again (or look at the solution in the
    next section)!
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the failed PipelineRun due to YAML issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get your pipeline working again, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `---` to the first line of all the YAML files in the`./sample-go-app/clouds-api/k8s`
    folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Fix the indentation of the `kustomization.yaml` file by adding two spaces at
    the beginning of all the lines after `resources`, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Add a new line at the end of the `service.yaml` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Commit and push the changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: A new PipelineRun should be triggered automatically and complete.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we dived into Tekton, from installing it on OpenShift to using
    it. You learned how to create custom tasks, reuse existing ones, build a pipeline,
    and then run it. You also learned how to set a trigger to run the pipeline when
    a push event occurs in your GitHub repository. The objects you have seen in this
    chapter are the main ones you will use to create most Tekton pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will bring more power to your CI/CD process by adding
    **Argo CD** and **GitOps** to your pipelines. We will also start looking at ways
    to deploy applications into multiple clusters at once. Let’s get started and take
    a deeper dive into OpenShift GitOps!
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you want to learn more about what we covered in this chapter, check out
    the following references:'
  prefs: []
  type: TYPE_NORMAL
- en: '*OpenShift Pipelines official documentation:* [https://docs.openshift.com/container-platform/4.9/cicd/pipelines/understanding-openshift-pipelines.html](https://docs.openshift.com/container-platform/4.9/cicd/pipelines/understanding-openshift-pipelines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tekton official documentation:* [https://tekton.dev/docs/](https://tekton.dev/docs/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*How to create custom interceptors using* **ClusterInterceptor**: [https://tekton.dev/docs/triggers/clusterinterceptors/](https://tekton.dev/docs/triggers/clusterinterceptors/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tekton Hub (a collection of reusable tasks):* [https://hub.tekton.dev/](https://hub.tekton.dev/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
