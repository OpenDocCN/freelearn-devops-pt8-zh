<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Governing Your Environments Using AWS CloudTrail and AWS Config</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we learned how to leverage and utilize AWS WAF for protecting your web applications against commonly occurring web attacks and exploitations. In this chapter, we will be exploring two really useful and must-have security and governance services in the form of AWS CloudTrail and AWS Config!</p>
<p>Keeping this in mind, let's have a quick look at the various topics that we will be covering in this chapter:</p>
<ul>
<li>Introducing AWS CloudTrail, its concepts, and how it works</li>
<li>Enabling CloudTrail for your AWS environment by creating your very own Trail</li>
<li>Integrating and managing CloudTrail Logs using Amazon CloudWatch</li>
<li>Automating Amazon CloudWatch alarms for CloudTrail using CloudFormation</li>
<li>Viewing CloudTrail Logs using Amazon Elasticsearch</li>
<li>Introducing Amazon Config and how it works</li>
</ul>
<p>There is so much to do, so let's get started right away!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introducing AWS CloudTrail</h1>
                </header>
            
            <article>
                
<p>As we learned in the previous chapter, AWS provides a wide variety of tools and managed services which allow you to safeguard your applications running on the cloud, such as AWS WAF and AWS Shield. But this, however, just forms one important piece in a much larger jigsaw puzzle! What about compliance monitoring, risk auditing, and overall governance of your environments? How do you effectively analyze events occurring in your environment and mitigate against the same? Well, luckily for us, AWS has the answer to our problems in the form of AWS CloudTrail.</p>
<p>AWS CloudTrail provides you with the ability to log every single action taken by a user, service, role, or even API, from within your AWS account. Each action recorded is treated as an event which can then be analyzed for enhancing the security of your AWS environment. The following are some of the key benefits that you can obtain by enabling CloudTrail for your AWS accounts:</p>
<ul>
<li><strong>In-depth visibility</strong>: Using CloudTrail, you can easily gain better insights into your account's usage by recording each user's activities, such as which user initiated a new resource creation, from which IP address was this request initiated, which resources were created and at what time, and much more!</li>
<li><strong>Easier compliance monitoring</strong>: With CloudTrail, you can easily record and log events occurring within your AWS account, whether they may originate from the Management Console, or the AWS CLI, or even from other AWS tools and services. The best thing about this is that you can integrate CloudTrail with another AWS service, such as Amazon CloudWatch, to alert and respond to out-of-compliance events.</li>
<li><strong>Security automations</strong>: As we saw in the previous chapter, automating responses to security threats not only enables you to mitigate the potential threats faster, but also provides you with a mechanism to stop all further attacks. The same can be applied to AWS CloudTrail as well! With its easy integration with Amazon CloudWatch events, you can now create corresponding Lambda functions that trigger automatically each time a compliance is not met, all in a matter of seconds!</li>
</ul>
<p>With these key points in mind, let's have a quick look at some of CloudTrail's essential concepts and terminologies:</p>
<ul>
<li><strong>Events</strong>: Events are the basic unit of measurement in CloudTrail. Essentially, an event is nothing more than a record of a particular activity either initiated by the AWS services, roles, or even an AWS user. These activities are all logged as API calls that can originate from the Management Console, the AWS SDK, or even the AWS CLI as well. By default, events are stored by CloudTrail with S3 buckets for a period of 7 days. You can view, search, and even download these events by leveraging the events history feature provided by CloudTrail.</li>
<li><strong>Trails</strong>: Trails are essentially the delivery mechanism, using which events are dumped to S3 buckets. You can use these trails to log specific events within specific buckets, as well as to filter events and encrypt the transmitted log files. By default, you can have a maximum of <em>five trails</em> created per AWS region, and this limit cannot by increased.</li>
<li><strong>CloudTrail Logs</strong>: Once your CloudTrail starts capturing events, it sends these events to an S3 bucket in the form of a CloudTrail Log file. The log files are JSON text files that are compressed using the <kbd>.gzip</kbd> format. Each file can contain one or more events within itself. Here is a simple representation of what a CloudTrail Log looks like. In this case, the event was created when I tried to add an existing user by the name of <kbd>Mike</kbd> to an <em>administrator</em> group using the AWS Management Console:</li>
</ul>
<pre style="padding-left: 60px">{"Records": [{ 
    "eventVersion": "1.0", 
    "userIdentity": { 
        "type": "IAMUser", 
        "principalId": "12345678", 
        "arn": "arn:aws:iam::012345678910:user/yohan", 
        "accountId": "012345678910", 
        "accessKeyId": "AA34FG67GH89", 
        "userName": "Alice", 
        "sessionContext": {"attributes": { 
            "mfaAuthenticated": "false", 
            "creationDate": "2017-11-08T13:01:44Z" 
        }} 
    }, 
    "eventTime": "2017-11-08T13:09:44Z", 
    "eventSource": "iam.amazonaws.com", 
    "eventName": "<strong>AddUserToGroup</strong>", 
    "awsRegion": "us-east-1", 
    "sourceIPAddress": "127.0.0.1", 
    "userAgent": "<strong>AWSConsole</strong>", 
    "requestParameters": { 
        "userName": "<strong>Mike</strong>", 
        "groupName": "<strong>administrator</strong>" 
    }, 
    "responseElements": null 
}]} </pre>
<p>You can view your own CloudTrail Log files by visiting the S3 bucket that you specify during the trail's creation. Each log file is named uniquely using the following format:</p>
<pre>AccountID_CloudTrail_RegionName_YYYYMMDDTHHmmZ_UniqueString.json.gz </pre>
<p>Where:</p>
<ul>
<li><kbd>AccountID</kbd>: Your AWS account ID.</li>
<li><kbd>RegionName</kbd>: AWS region where the event was captured: <strong>us-east-1</strong>, and so on.</li>
<li><kbd>YYYYMMDDTTHHmmz</kbd>: Specifies the year, month, day, hour (24 hours), minutes, and seconds. The <kbd>z</kbd> indicates time in UTC.</li>
<li><kbd>UniqueString</kbd>: A randomly generated 16-character-long string that is simply used so that there is no overwriting of the log files.</li>
</ul>
<p>With the basics in mind, let's quickly have a look at how you can get started with CloudTrail for your own AWS environments!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Working with AWS CloudTrail</h1>
                </header>
            
            <article>
                
<p>AWS CloudTrail is a fairly simple and easy to use service that you can get started with in a couple of minutes. In this section, we will be walking through a simple setup of a CloudTrail Trail using the AWS Management Console itself.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating your first CloudTrail Trail</h1>
                </header>
            
            <article>
                
<p>To get started, log in to your AWS Management Console and filter the <span class="packt_screen">CloudTrail</span> service from the <span class="packt_screen">AWS services</span> filter. On the CloudTrail dashboard, select the <span class="packt_screen">Create Trail</span> option to get started:</p>
<ol>
<li>This will bring up the <span class="packt_screen">Create Trail</span> wizard. Using this wizard, you can create a maximum of five-trails per region. Type a suitable name for the Trail in to the <span class="packt_screen">Trail name</span> field to begin with.</li>
</ol>
<ol start="2">
<li>Next, you can either opt to <span class="packt_screen">Apply trail to all regions</span> or only to the region out of which you are currently operating. Selecting all regions enables CloudTrail to record events from each region and dump the corresponding log files into an S3 bucket that you specify. Alternatively, selecting to record out of one region will only capture the events that occur from the region out of which you are currently operating. In my case, I have opted to enable the Trail only for the region I'm currently working out of. In the subsequent sections, we will learn how to change this value using the AWS CLI:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/7ae9080d-34d8-4143-8a20-7d9269e5964d.png" width="606" height="225"/></div>
<ol start="3">
<li>Next, in the <span class="packt_screen">Management events</span> section, select the <em>type</em> of events you wish to capture from your AWS environment. By default, CloudTrail records all management events that occur within your AWS account. These events can be API operations, such as events caused due to the invocation of an EC2 <span class="packt_screen">RunInstances</span> or <span class="packt_screen">TerminateInstances</span> operation, or even non-API based events, such as a user logging into the AWS Management Console, and so on. For this particular use case, I've opted to record <span class="packt_screen">All</span> management events.</li>
</ol>
<div class="mce-root packt_infobox"><span>Selecting the <span class="packt_screen">Read-only</span> option will capture all the <kbd>GET</kbd> API operations, whereas the <kbd>Write-only</kbd> option will capture only the <kbd>PUT</kbd> API operations that occur within your AWS environment.</span></div>
<ol start="4">
<li>Moving on, in the <span class="packt_screen">Storage location</span> section, provide a suitable name for the S3 bucket that will store your CloudTrail Log files. This bucket will store all your CloudTrail Log files, irrespective of the regions the logs originated from. You can alternatively select an existing bucket from the <span class="packt_screen">S3 bucket</span> selection field:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="376" width="548" class=" image-border" src="Images/750ce232-581b-493d-9ec6-0bbb676679c8.png"/></div>
<ol start="5">
<li>Next, from the <span class="packt_screen">Advanced</span> section, you can optionally configure a <span class="packt_screen">Log file prefix</span>. By default, the logs will automatically get stored under a folder-like hierarchy that is usually of the form <kbd>AWSLogs/ACCOUNT_ID/CloudTrail/REGION</kbd>.</li>
<li>You can also opt to <span class="packt_screen">Encrypt log files</span> with the help of an AWS KMS key. Enabling this feature is highly recommended for production use.</li>
<li>Selecting <span class="packt_screen">Yes</span> in the <span class="packt_screen">Enable log file validation</span> field enables you to verify the integrity of the delivered log files once they are delivered to the S3 bucket.</li>
</ol>
<ol start="8">
<li>Finally, you can even enable CloudTrail to send you notifications each time a new log file is delivered to your S3 bucket by selecting <span class="packt_screen">Yes</span> against the <span class="packt_screen">Send SNS notification for every log file delivery</span> option. This will provide you with an additional option to either select a predefined SNS topic or alternatively create a new one specifically for this particular CloudTrail. Once all the required fields are filled in, click on <span class="packt_screen">Create</span> to continue.</li>
</ol>
<p>With this, you should be able to see the newly created Trail by selecting the <span class="packt_screen">Trails</span> option from the CloudTrail dashboard's navigation pane, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/bad61e60-483b-46d2-9928-85247959904d.png" width="928" height="252"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Viewing and filtering captured CloudTrail Logs and Events</h1>
                </header>
            
            <article>
                
<p>With the Trail created, you can now view the captured events and filter them using the <em>event history</em> option from the CloudTrail dashboard's navigation pane. Here, you can view the last 7 days of captured events, and even filter specific ones by using one or more supporting filter attributes.</p>
<p>Here's a quick look at the <span class="packt_screen">Filter</span> attributes that you can use in conjunction with the <span class="packt_screen">Time range</span> to extract the required events and logs:</p>
<ul>
<li><span class="packt_screen">Event ID</span>: Each event captured by CloudTrail has a unique ID that you can filter and view.</li>
<li><span class="packt_screen">Event name</span>: The name of the event. For example, EC2 events <span class="packt_screen">RunInstances</span>, <span class="packt_screen">DescribeInstances</span>, and so on.</li>
<li><span class="packt_screen">Event source</span>: The AWS service to which the request was made. For example, <kbd>iam.amazonaws.com</kbd> or <kbd>ec2.amazonaws.com</kbd>.</li>
<li><span class="packt_screen">Resource name</span>: The name or ID of the resource referenced by the event. For example, a bucket named <kbd>useast-prod-wordpress-code</kbd> or an instance ID <kbd>i-1234567</kbd> for an EC2 instance.</li>
<li><span class="packt_screen">Resource type</span>: The type of resource referenced by the event. For example, a resource type can be a <span class="packt_screen">Bucket</span> for S3, an <span class="packt_screen">Instance</span> for EC2, and so on.</li>
<li><span class="packt_screen">User name</span>: The name of the user that created or performed an action on the said event. For example, an IAM user logging into the AWS Management Console, and so on:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="222" width="1094" class=" image-border" src="Images/4b9582c6-4d78-4acc-a302-03dc5a69c827.png"/></div>
<p>Once you have selected a particular filter and provided its associated attribute value, you can use the <span class="packt_screen">Time range</span> to narrow your search results based on a predefined time window. To analyze further, you can select the <span class="packt_screen">View event</span> option present in the details pane of an <span class="packt_screen">Event</span> as well. Selecting this option will view the event in a JSON format, as shown in the following code:</p>
<pre>{ 
    "eventVersion": "1.05", 
    "userIdentity": { 
        "type": "IAMUser", 
        "principalId": "AIDAIZZ25SDDZAQTF2K3I", 
        "arn": "arn:aws:iam::01234567890:user/yohan", 
        "accountId": "01234567890", 
        "accessKeyId": "ASDF56HJERW9PQRST", 
        "userName": "yohan", 
        "sessionContext": { 
            "attributes": { 
                "mfaAuthenticated": "false", 
                "creationDate": "2017-11-07T08:13:26Z" 
            } 
        }, 
        "invokedBy": "signin.amazonaws.com" 
    }, 
    "eventTime": "2017-11-07T08:25:32Z", 
    "eventSource": "s3.amazonaws.com", 
    "eventName": "CreateBucket", 
    "awsRegion": "us-east-1", 
    "sourceIPAddress": "80.82.129.191", 
    "userAgent": "signin.amazonaws.com", 
    "requestParameters": { 
        "bucketName": "sometempbucketname" 
    }, 
    "responseElements": null, 
    "requestID": "163A30A312B21AB2", 
    "eventID": "e7b7dff6-f196-4358-be64-aae1f5e7fed6", 
    "eventType": "AwsApiCall", 
    "recipientAccountId": "01234567890" 
} </pre>
<div class="packt_infobox">You can additionally select the Download icon and select whether you wish to export all the logs using the <span class="packt_screen">Export to CSV</span> or <span class="packt_screen">Export to JSON</span> option.</div>
<p>You can alternatively even download the log files by accessing your CloudTrail S3 bucket and downloading the individual compressed JSON files, as per your requirements.</p>
<p>With this, we come towards the end of this section. You can use these same steps and create different Trails for capturing data as well as management activities. In the next section, we will see how we can leverage the AWS CLI and update our newly-created Trail.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Modifying a CloudTrail Trail using the AWS CLI</h1>
                </header>
            
            <article>
                
<p>With the Trail in place, you can now use either the AWS Management Console or the AWS CLI to modify its settings. In this case, we will look at how to perform simple changes to the newly created Trail using the AWS CLI itself. Before proceeding with this section, however, it is important that you have installed and configured the AWS CLI on your desktop/laptop, based on the guides provided at <a href="http://docs.aws.amazon.com/cli/latest/userguide/installing.html">http://docs.aws.amazon.com/cli/latest/userguide/installing.html</a>.</p>
<p>Once the CLI is installed and configured, we can now run some simple commands to verify its validity. To start off, let's first check the status of our newly-created Trail by using the <kbd>describe-trails</kbd> command, as shown in the following command:</p>
<pre><strong># aws cloudtrail describe-trails</strong> </pre>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/118d5718-9d27-40eb-aa4b-deb1c50870c7.png" width="1108" height="379"/></div>
<p>This will display the essential properties of your CloudTrail Trails, such as the <kbd>Name</kbd>, the <kbd>TrailARN</kbd>, whether the log file validation is enabled or not, and whether the Trail is a multi-regional Trail or it belongs to a single region. In this case, the <kbd>IsMultiRegionTrail</kbd> value is set to <kbd>false</kbd>, which means that the Trail will only record events for its current region, that is, <kbd>us-east-1</kbd>. Let's go ahead and modify this using the AWS CLI.</p>
<p>To do so, we will be using the <kbd>update-trail</kbd> command:</p>
<pre><strong># aws cloudtrail update-trail \ 
--name useast-prod-CloudTrail-01 \ 
--is-multi-region-trail </strong></pre>
<p>The following code will simply change the <kbd>IsMultiRegionTrail</kbd> value from <kbd>false</kbd> to <kbd>true</kbd>. You can verify the same by using the <kbd>describe-trails</kbd> command, as performed earlier. Similarly, you can use the <kbd>update-trail</kbd> command to change other settings for your CloudTrail Trail, such as enabling the log file validation feature, as described in the following command:</p>
<pre><strong># aws cloudtrail update-trail \ 
--name useast-prod-CloudTrail-01 \ 
--enable-log-file-validation</strong> </pre>
<p>Finally, you can even use the AWS CLI to check the current status of your Trail by executing the <kbd>get-trail-status</kbd> command, as shown in the following command:</p>
<pre><strong># aws cloudtrail get-trail-status \ 
--name useast-prod-CloudTrail-01 </strong> </pre>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/1f5a6170-3897-4feb-99a2-b17991f79a5c.png" width="894" height="317"/></div>
<p>Apart from these values, the <kbd>get-trail-status</kbd> command will additionally show two more fields (<kbd>LatestNotificationError</kbd> and <kbd>LatestDeliveryError</kbd>) in case an Amazon SNS subscription fails or if a CloudTrail Trail was unsuccessful at writing the events to an S3 bucket.</p>
<p>With this completed, we will now move on to the next section of this chapter, in which we will learn how you can effectively monitor your Trails with the help of CloudWatch Logs.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Monitoring CloudTrail Logs using CloudWatch</h1>
                </header>
            
            <article>
                
<p>One of the best features of using CloudTrail is that you can easily integrate it with other AWS services for an enhanced security auditing and governance experience. One such service that we are going to use and explore here with CloudTrail is Amazon CloudWatch.</p>
<p>Using CloudWatch, you can easily set up custom metric filters and an array of alarms that can send notifications to the right set of people in case a specific security or governance issue occurs in your AWS environment. To get started with CloudWatch using CloudTrail, you will first need to configure your Trail to send the captured log events to CloudWatch Logs. This can be easily configured using both the AWS Management Console and the AWS CLI. Next, once this is done, you will be required to define custom CloudWatch metric filters to evaluate the log events for specific matches. Once a match is made, you can then additionally configure CloudWatch to trigger corresponding alarms, send notifications, and even perform a remediation action based on the type of alarm generated.</p>
<p>Here is a diagrammatic representation of CloudTrail's integration with CloudWatch:</p>
<div class="CDPAlignCenter CDPAlign"><img height="741" width="934" class=" image-border" src="Images/441f4deb-1f5f-413e-93f5-5e606816c434.png"/></div>
<p>In this section, we will be using the AWS CLI to integrate the Trail's logs with Amazon CloudWatch Logs:</p>
<ol>
<li>First, we will need to create a new CloudWatch Log Group using the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong># aws logs create-log-group --log-group-name useast-prod-CloudTrail-LG-01</strong> </pre>
<ol start="2">
<li>Next, you will need to extract and maintain the newly created Log Group's ARN for the forthcoming steps. To do so, type in the following command and make a note of the Log Group's ARN, as shown here:</li>
</ol>
<pre style="padding-left: 60px"><strong># aws logs describe-log-groups</strong></pre>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/beb84f9e-191b-4c97-9f73-f705188f07f1.png" width="1089" height="274"/></div>
<ol start="3">
<li>With the Log Group successfully created, we will now need to create a new IAM Role that will essentially enable CloudTrail to send its logs over to the CloudWatch Log Group. To do so, we first need to create a policy document that assigns the <kbd>AssumeRole</kbd> permission to our CloudTrail Trail. Create a new file and paste the following contents into that file. Remember to to create the file with a <kbd>.json</kbd> extension:</li>
</ol>
<pre style="padding-left: 60px"># vi policy.json 
{ 
  "Version": "2012-10-17", 
  "Statement": [ 
    { 
      "Sid": "", 
      "Effect": "Allow", 
      "Principal": { 
        "Service": "cloudtrail.amazonaws.com" 
      }, 
      "Action": "sts:AssumeRole" 
    } 
  ] 
} </pre>
<ol start="4">
<li>With the file created, use the <kbd>create-role</kbd> command to create the role with the required permissions for CloudTrail:</li>
</ol>
<pre style="padding-left: 60px"><strong># aws iam create-role --role-name useast-prod-CloudTrail-Role-01 \ 
--assume-role-policy-document file://policy.json</strong> </pre>
<ol start="5">
<li>Once this command executed, make a note of the newly created role's ARN. Next, copy and paste the following role policy document into a new file. This policy document grants CloudTrail the necessary permissions to create a CloudWatch Logs log stream in the Log Group that you created a while back, so as to deliver the CloudTrail events to that particular log stream:</li>
</ol>
<pre>    # vi permissions.json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
    
          "Sid": "CloudTrailCreateLogStream",
          "Effect": "Allow",
          "Action": [
            "logs:CreateLogStream"
          ],
          "Resource": [
            "<strong>&lt;YOUR_LOG_GROUP_ARN&gt;</strong>"
          ]
    
        },
        {
          "Sid": "CloudTrailPutLogEventsToCloudWatch",
          "Effect": "Allow",
          "Action": [
            "logs:PutLogEvents"
          ],
          "Resource": [
            "<strong>&lt;YOUR_LOG_GROUP_ARN&gt;</strong>"
          ]
        }
      ]
    }</pre>
<ol start="6">
<li>Next, run the following command to apply the permissions to the role. Remember to provide the name of the policy that we created during the earlier steps here:</li>
</ol>
<pre style="padding-left: 60px"><strong># aws iam put-role-policy --role-name useast-prod-CloudTrail-Role-01 \ 

--policy-name cloudtrail-policy \ 
--policy-document file://permissions.json </strong></pre>
<ol start="7">
<li>The final step is to update the Trail with the Log Group ARN as well as the CloudWatch Logs role ARN, using the following command snippet:</li>
</ol>
<pre style="padding-left: 60px"><strong># aws cloudtrail update-trail --name useast-prod-CloudTrail-01 \ 
 --cloud-watch-logs-log-group-arn &lt;YOUR_LOG_GROUP_ARN&gt; \ 
 --cloud-watch-logs-role-arn &lt;YOUR_ROLE_ARN&gt;</strong> </pre>
<p>With this you have now integrated your CloudTrail Logs to seamlessly flow into the CloudWatch Log Group that we created. You can verify this by viewing the <span class="packt_screen">Log Groups</span> provided under the <span class="packt_screen">CloudWatch Logs</span> section of your CloudWatch dashboard.</p>
<p>In the next section, we will be leveraging this newly created Log Group and assign a custom metric as well as an alarm for monitoring and alerting purposes.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating custom metric filters and alarms for monitoring CloudTrail Logs</h1>
                </header>
            
            <article>
                
<p>With the Log Group created and integrated with the CloudTrail Trail, we can now continue to create and assign custom metric filters as well as alarms. These alarms can be leveraged to trigger notifications whenever a particular compliance or governance issue is identified by CloudTrail.</p>
<p>To begin with, let's first create a custom metric filter using CloudWatch Logs. In this case, we will be creating a simple filter that triggers a CloudWatch alarm each time an S3 bucket API call is made. This API call can be either a simple PUT or DELETE operation on the bucket's policies, life cycle, and so on:</p>
<ol>
<li>Log in to your Amazon CloudWatch dashboard or, alternatively, select the link provided here to get started, at <a href="https://console.aws.amazon.com/cloudwatch/">https://console.aws.amazon.com/cloudwatch/</a>.</li>
</ol>
<ol start="2">
<li>Once logged in, select the <span class="packt_screen">Logs</span> option from the navigation pane. Select the newly created Log Group that we created a while back, and opt for the <span class="packt_screen">Create Metric Filter</span> option, as depicted in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="193" width="374" class=" image-border" src="Images/c6af2920-4e7e-4486-bdb7-bf7181339a35.png"/></div>
<ol start="3">
<li>Here, in the <span class="packt_screen">Create Metric Filter and Assign a Metric</span> page, start off by providing a suitable <span class="packt_screen">Filter Name</span> for the new metric, followed by populating the <span class="packt_screen">Filter Pattern</span> option with the following snippet:</li>
</ol>
<pre style="padding-left: 60px">{($.eventSource = s3.amazonaws.com) &amp;&amp; (($.eventName = PutBucketAcl) || ($.eventName = PutBucketPolicy) || ($.eventName = PutBucketLifecycle) || ($.eventName = DeleteBucketPolicy) || ($.eventName = DeleteBucketLifecycle))} </pre>
<ol start="4">
<li>Once done, type in a suitable <span class="packt_screen">Metric Namespace</span> value followed by a <span class="packt_screen">Metric Name</span> as well. Leave the rest of the values to their defaults, and select the option <span class="packt_screen">Create filter</span> to complete the process.</li>
<li>With this step completed, you now have a working CloudWatch filter up and running. In order to assign this particular filter an alarm, simply select the <span class="packt_screen">Create Alarm</span> option adjacent to the filter, as depicted in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="204" width="631" class=" image-border" src="Images/88608185-edc6-4b7a-92b3-31e0f2db04b7.png"/></div>
<ol start="6">
<li>Creating an alarm is a fairly straightforward and simple process, and I'm sure you would be more than qualified enough to set it up. Start off by providing a <span class="packt_screen">Name</span> and an optional <span class="packt_screen">Description</span> to your alarm, followed by configuring the trigger by setting the event count as <kbd>&gt;= 1</kbd> for <kbd>1</kbd> consecutive period. Consequently, also remember to set up the <span class="packt_screen">Actions</span> section by selecting an SNS <span class="packt_screen">Notification List</span> or, alternatively, creating a new one. With all the settings configured, select the <span class="packt_screen">Create Alarm</span> option to complete the process.</li>
</ol>
<p>With this step completed, the only thing remaining is to give the filter a try! Log in to your S3 dashboard and create a new bucket, or alternatively, update the bucket policy of an existing one. The CloudTrail Trail will pick up this change and send the logs to your CloudWatch Log Group, where our newly created metric filter triggers an alarm by notifying the respective cloud administrator! Simply awesome isn't it? You can use more custom filters and alarms for configuring CloudWatch's notifications, as per your requirements.</p>
<p>In the next section, we will be looking at a fairly simple and automated method for creating and deploying multiple CloudWatch alarms using a single CloudFormation template.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Automating deployment of CloudWatch alarms for AWS CloudTrail</h1>
                </header>
            
            <article>
                
<p>As discussed in the previous section, you can easily create different CloudWatch metrics and alarms for monitoring your CloudTrail Log files. Luckily for us, AWS provides a really simple and easy to use CloudFormation template, which allows you to get up and running with a few essential alarms in a matter of minutes! The best part of this template is that you can extend the same by adding your own custom alarms and notifications as well. So without any further ado, let's get started with it.</p>
<p>The template itself is fairly simple and easy to work with. You can download a version at <a href="https://s3-us-west-2.amazonaws.com/awscloudtrail/cloudwatch-alarms-for-cloudtrail-api-activity/CloudWatch_Alarms_for_CloudTrail_API_Activity.json">https://s3-us-west-2.amazonaws.com/awscloudtrail/cloudwatch-alarms-for-cloudtrail-api-activity/CloudWatch_Alarms_for_CloudTrail_API_Activity.json</a>.</p>
<p>At the time of writing this book, this template supports the creation of metric filters for the following set of AWS resources:</p>
<ul>
<li>Amazon EC2 instances</li>
<li>IAM policies</li>
<li>Internet gateways</li>
<li>Network ACLs</li>
<li>Security groups</li>
</ul>
<ol>
<li>To create and launch this CloudFormation stack, head over to the CloudFormation dashboard by navigating to <a href="https://console.aws.amazon.com/cloudformation">https://console.aws.amazon.com/cloudformation</a>.</li>
<li>Next, select the option <span class="packt_screen">Create Stack</span> to bring up the CloudFormation template selector page. Paste <a href="https://s3-us-west-2.amazonaws.com/awscloudtrail/cloudwatch-alarms-for-cloudtrail-api-activity/CloudWatch_Alarms_for_CloudTrail_API_Activity.json">https://s3-us-west-2.amazonaws.com/awscloudtrail/cloudwatch-alarms-for-cloudtrail-api-activity/CloudWatch_Alarms_for_CloudTrail_API_Activity.json</a> in the <span class="packt_screen">Specify an Amazon S3 template URL</span> field, and click on <span class="packt_screen">Next</span> to continue.</li>
<li>In the <span class="packt_screen">Specify Details</span> page, provide a suitable <span class="packt_screen">Stack name</span> and fill out the following required parameters:
<ul>
<li><span class="packt_screen">Email</span>: A valid email address that will receive all SNS notifications. You will have to confirm this email subscription once the template is successfully deployed.</li>
<li><span class="packt_screen">LogGroupName</span>: The name of the Log Group that we created earlier in this chapter.</li>
</ul>
</li>
</ol>
<ol start="4">
<li>Once the required values are filled in, click on <span class="packt_screen">Next</span> to proceed. Review the settings of the template on the <span class="packt_screen">Review</span> page and finally select the <span class="packt_screen">Create</span> option to complete the process.</li>
</ol>
<p>The template takes a few minutes to completely finish the creation and configuration of the required alarms. Here is a snapshot of the alarms and metrics that get created for your environment:</p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td>
<p><strong>Logical ID of resources created</strong></p>
</td>
<td>
<p><strong>Type of resource</strong></p>
</td>
</tr>
<tr>
<td>
<p><kbd>AlarmNotificationTopic</kbd></p>
</td>
<td>
<p><kbd>AWS::SNS::Topic</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>AuthorizationFailuresAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>CloudTrailChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>CloudTrailChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>ConsoleSignInFailuresAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>ConsoleSignInFailuresMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>EC2InstanceChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>EC2InstanceChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>EC2LargeInstanceChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>EC2LargeInstanceChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>GatewayChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>GatewayChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>IAMPolicyChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>IAMPolicyChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>NetworkAclChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>NetworkAclChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>SecurityGroupChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>SecurityGroupChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>VpcChangesAlarm</kbd></p>
</td>
<td>
<p><kbd>AWS::CloudWatch::Alarm</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>VpcChangesMetricFilter</kbd></p>
</td>
<td>
<p><kbd>AWS::Logs::MetricFilter</kbd></p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>So far, we have seen how to integrate CloudTrail's Log files with CloudWatch Log Groups for configuring custom metrics as well as alarms for notifications. But how do you effectively analyze and manage these logs, especially if you have extremely large volumes to deal with? This is exactly what we will be learning about in the next section, along with the help of yet another awesome AWS service called <strong>Amazon Elasticsearch</strong>!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Analyzing CloudTrail Logs using Amazon Elasticsearch</h1>
                </header>
            
            <article>
                
<p>Log management and analysis for many organizations starts and ends with just three letters: <em>E</em>, <em>L</em>, and <em>K</em>, which stands for Elasticsearch, Logstash, and Kibana. These three open-sourced products are essentially used together to aggregate, parse, search, and visualize logs at an enterprise scale:</p>
<ul>
<li><strong>Logstash</strong>: Logstash is primarily used as a log collection tool. It is designed to collect, parse, and store logs originating from multiple sources, such as applications, infrastructure, operating systems, tools, services, and so on.</li>
<li><strong>Elasticsearch</strong>: With all the logs collected in one place, you now need a query engine to filter and search through these logs for particular events. That's exactly where Elasticsearch comes into play. Elasticsearch is basically a search server based on the popular information retrieval software library, Lucene. It provides a distributed, full-text search engine along with a RESTful web interface for querying your logs.</li>
<li><strong>Kibana</strong>: Kibana is an open source data visualization plugin, used in conjunction with Elasticsearch. It provides you with the ability to create and export your logs into various visual graphs, such as bar charts, scatter graphs, pie charts, and so on.</li>
</ul>
<p>You can easily download and install each of these components in your AWS environment, and get up and running with your very own ELK stack in a matter of hours! Alternatively, you can also leverage AWS own Elasticsearch service! Amazon Elasticsearch is a managed ELK service that enables you to quickly deploy operate, and scale an ELK stack as per your requirements. Using Amazon Elasticsearch, you eliminate the need for installing and managing the ELK stack's components on your own, which in the long run can be a painful experience.</p>
<p>For this particular use case, we will leverage a simple CloudFormation template that will essentially set up an Amazon Elasticsearch domain to filter and visualize the captured CloudTrail Log files, as depicted in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img height="576" width="874" src="Images/1f2a768f-400a-4254-87e3-77ab75367cf1.png"/></div>
<ol>
<li>To get started, log in to the CloudFormation dashboard, at <a href="https://console.aws.amazon.com/cloudformation">https://console.aws.amazon.com/cloudformation</a>.</li>
<li>Next, select the option <span class="packt_screen">Create Stack</span> to bring up the CloudFormation template selector page. Paste <a href="http://s3.amazonaws.com/concurrencylabs-cfn-templates/cloudtrail-es-cluster/cloudtrail-es-cluster.json">http://s3.amazonaws.com/concurrencylabs-cfn-templates/cloudtrail-es-cluster/cloudtrail-es-cluster.json</a> in, the <span class="packt_screen">Specify an Amazon S3 template URL</span> field, and click on <span class="packt_screen">Next</span> to continue.</li>
</ol>
<ol start="3">
<li>In the <span class="packt_screen">Specify Details</span> page, provide a suitable <span class="packt_screen">Stack name</span> and fill out the following required parameters:
<ul>
<li><span class="packt_screen">AllowedIPForEsCluster</span>: Provide the IP address that will have access to the nginx proxy and, in turn, have access to your Elasticsearch cluster. In my case, I've provided my laptop's IP. Note that you can change this IP at a later stage, by visiting the security group of the nginx proxy once it has been created by the CloudFormation template.</li>
<li><span class="packt_screen">CloudTrailName</span>: Name of the CloudTrail that we set up at the beginning of this chapter.</li>
<li><span class="packt_screen">KeyName</span>: You can select a key-pair for obtaining SSH to your nginx proxy instance:</li>
</ul>
</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/73c6bade-fe86-45b8-861d-af025942fe37.png" width="875" height="276"/></div>
<ul>
<li style="list-style-type: none">
<ul>
<li><span class="packt_screen">LogGroupName</span>: The name of the CloudWatch Log Group that will act as the input to our Elasticsearch cluster.</li>
<li><span class="packt_screen">ProxyInstanceTypeParameter</span>: The EC2 instance type for your proxy instance. Since this is a demonstration, I've opted for the <span class="packt_screen">t2.micro</span> instance type. Alternatively, you can select a different instance type as well.</li>
</ul>
</li>
</ul>
<ol start="4">
<li>Once done, click on <span class="packt_screen">Next</span> to continue. Review the settings of your stack and hit <span class="packt_screen">Create</span> to complete the process.</li>
</ol>
<p>The stack takes a good few minutes to deploy as a new Elasticsearch domain is created. You can monitor the progress of the deployment by either viewing the CloudFormation's <span class="packt_screen">Output</span> tab or, alternatively, by viewing the Elasticsearch dashboard. Note that, for this deployment, a default <strong>t2.micro.elasticsearch</strong> instance type is selected for deploying Elasticsearch. You should change this value to a larger instance type before deploying the stack for production use.</p>
<div class="packt_infobox">You can view information on Elasticsearch <em>Supported Instance Types</em> at <a href="http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-supported-instance-types.html">http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-supported-instance-types.html</a>.<a href="http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-supported-instance-types.html"/></div>
<p>With the stack deployed successfully, copy the Kibana URL from the CloudFormation <span class="packt_screen">Output</span> tab:</p>
<pre>"KibanaProxyEndpoint": "http://&lt;NGINX_PROXY&gt;/_plugin/kibana/"</pre>
<p>The Kibana UI may take a few minutes to load. Once it is up and running, you will need to configure a few essential parameters before you can actually proceed. Select <span class="packt_screen">Settings</span> and hit the <span class="packt_screen">Indices</span> option. Here, fill in the following details:</p>
<ul>
<li><span class="packt_screen">Index contains time-based events</span>: Enable this checkbox to index time-based events</li>
<li><span class="packt_screen">Use event times to create index names</span>: Enable this checkbox as well</li>
<li><span class="packt_screen">Index pattern interval</span>: Set the <span class="packt_screen">Index pattern interval</span> to <span class="packt_screen">Daily</span> from the drop-down list</li>
<li><span class="packt_screen">Index name of pattern</span>: Type <span><kbd>[cwl-]YYYY.MM.DD</kbd> in to this field</span></li>
<li><span class="packt_screen">Time-field name</span>: Select the <span class="packt_screen">@timestamp</span> value from the drop-down list</li>
</ul>
<p>Once completed, hit <span class="packt_screen">Create</span> to complete the process. With this, you should now start seeing logs populate on to Kibana's dashboard. Feel free to have a look around and try out the various options and filters provided by Kibana:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/b9c0ebe5-a974-4ca4-a8bb-e4b2225a3726.png" width="1108" height="385"/></div>
<p>Phew! That was definitely a lot to cover! But wait, there's more! AWS provides yet another extremely useful governance and configuration management service that we need to learn about as well, so without any further ado, here's introducing AWS Config!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introducing AWS Config</h1>
                </header>
            
            <article>
                
<p>AWS Config is yet another managed service, under the security and governance wing of services, that provides a detailed view of the configurational settings of each of your AWS resources. Configurational settings here can be anything, from simple settings made to your EC2 instances or VPC subnets, to how one resource is related to another, such as how an EC2 instance is related with an EBS volume, an ENI, and so on. Using AWS Config, you can actually view and compare such configurational changes that were made to your resource in the past, and take the necessary preventative actions if needed.</p>
<p>Here's a list of things that you can basically achieve by using AWS Config:</p>
<ul>
<li>Evaluate your AWS resource configurations against a desired setting</li>
<li>Retrieve and view historical configurations of one or more resources</li>
<li>Send notifications whenever a particular resource is created, modified, or deleted</li>
<li>Obtain a configuration snapshot of your resource that you can later use as a blueprint or template</li>
<li>View relationships and hierarchies between resources, such as all the instances that are part of a particular network subnet, and so on</li>
</ul>
<p>Using AWS Config enables you to manage your resources more effectively by setting governing policies and standardizing configurations for your resources. Each time a configuration change is violated, you can trigger off notifications or even perform a remediation against the change. Furthermore, AWS Config also provides out-of-the-box integration capabilities with the likes of AWS CloudTrail, as well to providing you with a complete end-to-end auditing and compliance monitoring solution for your AWS environment.</p>
<p>Before we get started by setting up AWS Config for our own scenario, let's first take a quick look at some of its important concepts and terminologies.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Concepts and terminologies</h1>
                </header>
            
            <article>
                
<p>The following are some of the key concepts and terminologies that you ought to keep in mind when working with AWS Config:</p>
<ul>
<li><strong>Config rules</strong>: Config rules form the heart of operations at AWS Config. These are essentially rules that represent the desired configuration settings for a particular AWS resource. While the service monitors your resources for any changes, these changes get mapped to one or more set of config rules, that in turn flag the resource against any non-compliances. AWS Config provides you with some rules out of the box that you can use as-is or even customize as per your requirements. Alternatively, you can also create custom rules completely from scratch.</li>
<li><strong>Configuration items</strong>: Configuration items are basically a point-in-time representation of a particular AWS resource's configuration. The item can include various metadata about your resource, such as its current configuration attributes, and its relationships with other AWS resources, if any, its events, such as when it was created, last updated, and so on. Configuration items are created by AWS Config automatically each time it detects a change in a particular resource's configuration.</li>
<li><strong>Configuration history</strong>: A collection of configuration items of a resource over a particular period of time is called its <strong>configuration history</strong>. You can use this feature to compare the changes that a resource may undergo overtime, and then decide to take necessary actions. Configuration history is stored in an Amazon S3 bucket that you specify.</li>
<li><strong>Configuration snapshot</strong>: A configuration snapshot is also a collection of configuration items of a particular resource over time. This snapshot acts as a template or benchmark that can then be used to compare and validate your resource's current configurational settings.</li>
</ul>
<p>With this in mind, let's look at some simple steps which allow you to get started with your own AWS Config setup in a matter of minutes!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting started with AWS Config</h1>
                </header>
            
            <article>
                
<p>Getting started with AWS Config is a very simple process, and it usually takes about a minute or two to complete. Overall, you start off by specifying the resources that you want AWS Config to record, configure an Amazon SNS topic, and Amazon S3 bucket for notifications and storing the configuration history, and, finally, add some config rules to evaluate your resources:</p>
<ol>
<li>To begin, access the AWS Config dashboard by filtering the service from the AWS Management Console or by navigating to <a href="https://console.aws.amazon.com/config/">https://console.aws.amazon.com/config/</a>.</li>
<li>Since this is our first time configuring this, select the <span class="packt_screen">Get Started</span> option to commence the Config's creation process.</li>
<li>In the <span class="packt_screen">Resource types to record</span> section, select the type of AWS resource that you wish config to monitor. By default, config will record the activities of all supported AWS resources. You can optionally specify only the services which you want to monitor by typing in the <span class="packt_screen">Specific types</span> field, as shown in the following screenshot. In this case, I've opted to go for the default values: <span class="packt_screen">Record all resources supported in this region</span> and <span class="packt_screen">Include global resources</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/147cf7af-b5b3-4370-a03b-02ce74d85ecd.png" width="921" height="318"/></div>
<ol start="4">
<li>Next, select a location to store your configuration history as well as your configuration snapshots. In this case, I've opted to create a new S3 bucket for AWS Config by providing a unique <span class="packt_screen">Bucket name</span>.</li>
<li>Moving on, in the <span class="packt_screen">Amazon SNS topic</span> section, you can choose to create a new SNS topic that will send email notifications to your specified mailbox, or choose a pre-existing topic from your account.</li>
</ol>
<ol start="6">
<li>Finally, you will need to provide config with a <span class="packt_screen">Read-only</span> access role so that it can record the particular configuration information as well as send that over to S3 and SNS. Based on your requirements, you can either <span class="packt_screen">Create a role</span> or, alternatively, <span class="packt_screen">Choose a role from your account</span>. Click <span class="packt_screen">Save</span> to complete the basic configuration for your AWS Config.</li>
</ol>
<p style="padding-left: 90px">With this step completed, we can now go ahead and add Config rules to our setup. To do so, from the AWS Config dashboard's navigation pane, select the <span class="packt_screen">Rules</span> and click on the <span class="packt_screen">Add rule</span> option.</p>
<ol start="7">
<li>In the <span class="packt_screen">AWS Config rules</span> page, you can filter and view predefined rules using the <em>filter</em> provided. For this particular scenario, let's go ahead and add two rules for checking whether any of the account's S3 buckets have either public read prohibited or public write prohibited on them or not. To do so, simply type in <kbd>S3-bucket</kbd> in the filter and select either of the two config rules, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="266" width="1042" class=" image-border" src="Images/e9b363ad-c911-4320-958d-32cb259ed266.png"/></div>
<ul>
<li style="list-style-type: none">
<ul>
<li><strong>Resources</strong>: When any resource that matches the evaluation criteria is either created, modified, or deleted</li>
<li><strong>Tags</strong>: When any resource with the specified tag is created, modified, or deleted</li>
<li><strong>All changes</strong>: When any resource recorded by AWS Config is created, modified, or deleted</li>
</ul>
</li>
</ul>
<ol start="8">
<li>Selecting a particular rule will pop up that rule's configuration page, where you can define the rule's trigger as well as its scope. Let's pick the <span class="packt_screen">s3-bucket-public-read-prohibited</span> rule for starters and work with that.</li>
</ol>
<ol start="9">
<li>In the <span class="packt_screen">Configure rule</span> page, provide a suitable <span class="packt_screen">Name</span> and <span class="packt_screen">Description</span> for your new rule. Now, since this is a managed rule, you will not be provided with an option to change the <span class="packt_screen">Trigger type</span>; however, when you create your own custom rules, you can specify whether you wish to trigger the rule based on a <span class="packt_screen">Configuration change</span> event or using a <span class="packt_screen">Periodic</span> check approach that uses a time frequency that you specify to evaluate the rules.</li>
<li>Next, you can also specify when you want the rule's evaluations to occur by selecting the appropriate options provided under the <span class="packt_screen">Scope of changes</span> section. In this case, I've opted for the <span class="packt_screen">Resources</span> scope and selected <span class="packt_screen">S3: Bucket</span> as the resource, as depicted in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/eea146c0-7703-4a23-be63-d30f118f1398.png" width="600" height="235"/></div>
<ol start="11">
<li>Optionally, you can also provide the ARN of the resource that you wish config to monitor using the <span class="packt_screen">Resource identifier</span> field. Click on <span class="packt_screen">Save</span> once done.</li>
</ol>
<p>Similarly, using the aforementioned steps, create another managed config rule called <span class="packt_screen">s3-bucket-public-write-prohibited</span>.</p>
<p>With the rules in place, select the <span class="packt_screen">Resources</span> option from the config's navigation pane to view the current set of resources that have been evaluated against the set compliance.</p>
<p>In my case, I have two S3 buckets present in my AWS environment: one that has public read enabled on it while the other doesn't. Here's what the <span class="packt_screen">Resources evaluated</span> dashboard should look like for you:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/0b219e69-55ca-482c-ae19-af13efc85665.png" width="1075" height="265"/></div>
<p>Here, you can view the evaluated resources against a <span class="packt_screen">Config timeline</span> by simply selecting the name of the resource from the column with the same name. This will bring up a time series of your particular resource's configuration state. You can choose between the different time series options to view the state changes, as well as toggle between the time periods using the Calendar icon. The best part of using this feature of config is that you can simultaneously change your resource's configuration by selecting the <span class="packt_screen">Manage resource</span> option. Doing so will automatically open the S3 buckets configuration page, as in this case. You can alternatively select the <span class="packt_screen">Dashboard</span> option from AWS Config navigation pane and obtain a visual summary of the current status of your overall compliance, as depicted in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="Images/f9acb8f3-15c7-40c7-8a03-b91629f860c1.png" width="728" height="352"/></div>
<p>You can use the same concepts to create more such managed config rules for a variety of other AWS services, including EC2, EBS, Auto Scaling, DynamoDB, RDS, Redshift, CloudWatch, IAM, and much more! For a complete list of managed rules, check out <a href="http://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html">http://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html</a>.</p>
<p>With the managed config rules done, the last thing left to do is create a customized config rule, which is exactly what we will be covering in the next section.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating custom config rules</h1>
                </header>
            
            <article>
                
<p>The process for creating a custom config rule remains more or less similar to the earlier process, apart from a few changes here and there. In this section, we will be exploring how to create a simple compliance rule that will essentially trigger a config compliance alert if a user launches an EC2 instance other than the <strong>t2.micro</strong> instance type:</p>
<ol>
<li><span>To get started, select the <span class="packt_screen">Rules</span> option from the AWS Config navigation pane, then select the <span class="packt_screen">Add custom rule</span> button present on the <span class="packt_screen">Add rule</span> page. </span>The creation of the custom rule starts off like any other, by providing a suitable <span class="packt_screen">Name</span> and <span class="packt_screen">Description</span> for the rule. Now, here's where the actual change occurs. Custom config rules rely on AWS Lambda to monitor and trigger the compliance checks. And this is actually perfect, as Lambda functions are event driven and perfect for hosting the business logic for our custom rules.</li>
<li>Select the <span class="packt_screen">Create AWS Lambda function</span> to get things started. Here, I'm going to make use of a pre-defined Lambda blueprint that was essentially created to work in conjunction with AWS Config. Alternatively, you can create your config rule's business logic from scratch, and deploy the same in a fresh function. For now, type in the following text in the <span class="packt_screen">Blueprints</span> filter, as shown in the following screenshot (<span class="packt_screen">config-rule-change-triggered</span>):</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="322" width="672" class=" image-border" src="Images/7236e020-beff-4303-8a83-a996832d35e6.png"/></div>
<ol start="3">
<li>Ensure that the blueprint is selected, and click on <span class="packt_screen">Next</span> to continue.</li>
<li>In the function's <span class="packt_screen">Basic Information</span> page, provide a <span class="packt_screen">Name</span> for your function followed by selecting the <span class="packt_screen">Create new role from template(s)</span> option from the <span class="packt_screen">Role</span> drop-down list. The role will essentially provide the Lambda function with the necessary permissions to read from EC2 and write the output back to AWS Config as well as to Amazon CloudWatch.</li>
<li>Type in a suitable <span class="packt_screen">Role name</span> and select the <span class="packt_screen">Create function</span> option to complete the process. Once the function is deployed, make a note of its ARN, as we will be requiring the same in the next step.</li>
<li>Return back to the AWS Config <span class="packt_screen">Add custom rule</span> page and paste the newly created function's ARN in the <span class="packt_screen">AWS Lambda function ARN</span> file, as shown in the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="299" width="670" class=" image-border" src="Images/73db2580-9b26-4ac9-a320-b6d63c14c599.png"/></div>
<ol start="7">
<li>With the function's ARN pasted, the rest of the configuration for the custom rule remains the same. Unlike the managed rules, you can opt to change the <span class="packt_screen">Trigger type</span> between <span class="packt_screen">Configuration changes</span> or <span class="packt_screen">Periodic</span>, as per your requirements. In this case, I've opted to go for the <span class="packt_screen">Condition changes</span> as my trigger mechanism, followed by <span class="packt_screen">EC2: Instance</span> as the <span class="packt_screen">Resource</span> type.</li>
<li>Last, but not least, we also need to specify the <span class="packt_screen">Rule parameters</span>, which is basically a key-value pair that defines an attribute against which your resources will be validated. In this case, <span class="packt_screen">desiredInstanceType</span> is the <span class="packt_screen">Key</span> and <kbd>t2.micro</kbd> is the <span class="packt_screen">Value</span>. Click <span class="packt_screen">Save</span> to complete the setup process:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="221" width="723" class=" image-border" src="Images/2f5cbc09-97ff-487e-bf6a-17c128561410.png"/></div>
<ol start="9">
<li>With the rule in place, all you need to do now is take it for a small test run! Go ahead and launch a new EC2 instance that is other than <span class="packt_screen">t2.micro</span>. Remember that the instance has to be launched in the same region as that of your Lambda function! Sure enough, once the instance is launched, the change gets immediately reflected in AWS Config's dashboard:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img height="464" width="988" class=" image-border" src="Images/c644035b-99e2-4dc8-abdd-4e609b469ec7.png"/></div>
<p>With this, we come towards the end of this section as well as the chapter! However, before we conclude, here's a quick look at some interesting best practices and next steps that you ought to keep in mind when working with AWS CloudTrail and AWS Config!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Tips and best practices</h1>
                </header>
            
            <article>
                
<p>Here's a list of a few essential tips and best practices that you ought to keep in mind when working with AWS CloudTrail, AWS Config, and security in general:</p>
<ul>
<li><span><strong>Analyze and audit security configurations periodically</strong>: Although AWS provides a variety of services for safeguarding your cloud environment, it is the organization's mandate to ensure that the security rules are enforced and periodically verified against any potential misconfigurations.</span></li>
<li><strong>Complete audit trail for all users</strong><span><span>: Ensure that all resource creation, modifications, and terminations are tracked minutely for each user, including root, IAM, and federated users.</span></span></li>
<li><strong>Enable CloudTrail globally</strong><span>: By enabling logging at a global level, CloudTrail can essentially capture logs for all AWS services, including the global ones such as IAM, CloudFront, and so on.</span></li>
<li><strong>Enable CloudTrail Log file validation</strong><span>: An optional setting, however it is always recommended to enable CloudTrail Log file validations for an added layer of integrity and security.</span></li>
<li><strong>Enable access logging for CloudTrail and config buckets</strong>: <span>Since both CloudTrail and config leverage S3 buckets to store the captured logs, it is always recommended that you enable access tracking for them to log unwarranted and unauthorized access. Alternatively, you can also restrict access to the logs and buckets to a specialized group of users as well.</span></li>
<li><strong>Encrypt log files at rest</strong>: <span>Encrypting the log files at rest provides an additional layer of protection from unauthorized viewing or editing of the logged data.</span></li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Well this has surely been a really interesting chapter to cover! Before we move ahead with the next chapter, let's quickly summarize all that we have learned so far!</p>
<p>We started off the chapter with a brief overview of AWS CloudTrail, along with a small step-by-step guide on getting started with your very own CloudTrail Trail. We also learned about AWS CloudTrail Logs, and their integration capabilities with Amazon CloudWatch Logs for better alerting and notifications capabilities. We also leveraged a couple of CloudFormation templates to deploy pre-configured CloudWatch alarms for monitoring our Trail, as well as setting up an entire Amazon Elasticsearch domain for viewing and filtering the CloudTrail Logs. Last, but not least, we also covered AWS Config as a configuration management and compliance service by deploying both managed as well as custom config rules.</p>
<p>In the next chapter, we will be continuing and concluding our security journey with two really amazing services: AWS IAM and AWS Organizations, so stay tuned!</p>


            </article>

            
        </section>
    </div>



  </body></html>