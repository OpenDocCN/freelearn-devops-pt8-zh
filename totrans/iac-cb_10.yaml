- en: Chapter 10. Maintaining Docker Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing Docker containers with BATS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test-Driven Development (TDD) with Docker and ServerSpec
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The workflow for creating automated Docker builds from Git
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The workflow for connecting the Continuous Integration (CI) system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scanning for vulnerabilities with Quay.io and Docker Cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sending Docker logs to AWS CloudWatch Logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and getting information out of Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging containers using sysdig
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll explore some advanced and highly interesting areas that
    probably most developers today are already used to. Infrastructure code is still
    code, so it should be no different than software code; the same principle should
    apply. This means that the Docker code should be testable, the builds automatic,
    and the CI systems connected to our Git servers so they could continuously apply
    the tests. In addition to this, security checks should be part of the mandatory
    release process and the logs easy to access, even if the application is scaled
    on multiple machines. Also note that containers shouldn't be black boxes, and
    highly performant debugging tools should be available for us to do our work. The
    good news is that these topics will be covered in this chapter, because all of
    this can be done easily.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Docker containers with BATS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**BATS** (**Bash Automated Testing System**) allows you to have quick and easy
    tests in a very natural language, without the need of a lot of dependencies. BATS
    can also grow in complexity as per your requirement. In this section, we''ll use
    Docker with Docker Compose to handle the build and a Makefile to tie the dependencies
    between the build process and the BATS testing process; this will make it easier
    to later integrate this process into a CI system.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A BATS installation (it's available for all major Linux distributions and Mac
    OS)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: BATS Version 0.4.0 is used in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s start with this simple Dockerfile that will install Apache and run it
    after clearing the cache:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For convenience, let''s create a `docker-compose.yml` file so the image can
    be built and run easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This way, running `docker-compose up` will also build the image if absent.
    Alternatively, to just build the image, use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Creating BATS tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''ll now test two of the main actions this image is supposed to do:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Apache 2.4.10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clean the APT cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Start by creating a `test` folder at the root of our repository that will host
    the BATS tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Our first test is to verify that the installed version of Apache is `2.4.10`,
    as required. How would we do it manually? We''d probably just execute the following
    and check the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This translates in Docker with our image in the following command (`-v` being
    the command (`CMD`) for the `apache2ctl` `ENTRYPOINT` instruction):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Basically, now we just have to run `grep` for the correct version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If `grep` is successful, it returns `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'A simple BATS test for a command return code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have everything we need to write our first BATS test in `test/httpd.bats`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To execute our test, let''s launch BATS with the folder containing the tests
    as arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Good! We're now assured that the correct Apache version is installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s ensure the APT cache is cleaned after we build the image so we don''t
    waste precious space. Deleting the APT lists means the `/var/lib/apt/lists` folder
    will become empty, so if you count the files in this folder after this, it should
    return `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'However, we cannot just send this command to the container like we did for
    the Apache version; the entry point is `apache2ctl`, and it needs to be overridden
    by `sh` on the `docker run` command line. Here''s the `apt.bats` test file, executing
    the shell command instead of `apache2ctl`, expecting a successful execution and
    an output of `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Execute the BATS tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Using Makefile to glue it all together
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now this whole process might be a bit tedious in CI, with some additional steps
    needed before the testing is done (the image needs to be built and made available
    before it is tested, for example). Let''s create a `Makefile` that will take care
    of the prerequisites for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when you execute the `make test` command, it will launch the `bats` suite,
    which itself depends on building the image by `docker-compose`—a much simpler
    command to integrate in the CI system of your choice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Information on BATS at [https://github.com/sstephenson/bats](https://github.com/sstephenson/bats)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test-Driven Development (TDD) with Docker and ServerSpec
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker containers might have a simpler language, but in the end, general concepts
    remain common and still apply. Testing is good for quality, and writing tests
    first ensures that we write code that would make a test pass, instead of writing
    tests after the code is written, which would somehow lead to missed errors. To
    help us with this, we'll use ServerSpec, based on RSpec, to initiate a TDD workflow
    along with writing and testing a Docker container. Working like this usually ensures
    a very high quality of work overall and very sustainable containers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A working Ruby environment (including Bundler)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our goal is to create an NGINX container following TDD principles. Before we
    start to code, let's begin by setting up our environment.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ServerSpec environment using Bundler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'ServerSpec comes as a gem (a Ruby package), and as we''ll use Docker APIs,
    we''ll need the `docker-api` gem as well. For ease of deployment, let''s create
    `Gemfile` containing our dependencies inside a `test` group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Install these dependencies using Bundler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we''ll be able to execute `rspec` in our local context using Bundler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Initializing the tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s start by creating our first Docker Rspec test that will just, for now,
    initialize the libraries we need and build the Docker image before anything else.
    It looks like this in `spec/Dockerfile_spec.rb`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: TDD – using the Debian Jessie base's Docker image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We now want to use a Debian stable for our project, which happens to be Debian
    8 at the moment. To know the current version of a Debian system, just look at
    the `/etc/debian_version` file (on Red-Hat-based systems, it''s under `/etc/redhat_release`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Good! Let''s create a definition in ServerSpec, checking for the Debian version
    through this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the `debian_version` content can be easily queried, for example, by this
    check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'If this system is running Debian 8, then the test will pass. If the `Dockerfile`
    is empty, the test will fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Good! Our test has failed. Let''s write the `FROM` instruction in Dockerfile
    that will make it pass; this is because the current Debian stable is version 8:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the file and launch the test again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Good job! Our test has passed, meaning this really is Debian 8.
  prefs: []
  type: TYPE_NORMAL
- en: TDD – installing the NGINX package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our next objective is to install the `nginx` package. Let''s write the Rspec
    test in `Dockerfile_spec.rb` that will check for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch the test to be sure it fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s now time to add the instructions to the `Dockerfile` on how to install
    NGINX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Relaunch the tests (it will take some time as it needs to build the image):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We're now sure the `nginx` package is installed.
  prefs: []
  type: TYPE_NORMAL
- en: TDD – running NGINX
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have our image built with NGINX, execute it. Using ServerSpec,
    we can start a container using the `id` attribute of the image we built earlier.
    In the `Dockerfile_spec.rb` file, create and start the container using the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Using standard ServerSpec checks, verify that an NGINX process is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We can''t stop here without cleaning up the container. We need to stop it when
    we''re done with the tests and delete it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can run the test that will execute the container and fail upon checking
    for an `nginx` process (we didn''t write anything that would launch `nginx`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s execute `/usr/bin/nginx` for our container in the foreground, specifically
    in the `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Rerun the tests to check whether the `nginx` process is now running as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To add simplicity when integrating these tests in CI systems, let''s create
    a simple `Makefile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Now a simple `make test` command will launch the ServerSpec tests.
  prefs: []
  type: TYPE_NORMAL
- en: Good job! We've built our first simple Docker container following TDD principles.
    We can now build more complex and secure containers using this technique.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RSpec at [http://rspec.info/](http://rspec.info/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker-api at [https://github.com/swipely/docker-api](https://github.com/swipely/docker-api)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ServerSpec at [http://serverspec.org/](http://serverspec.org/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The workflow for creating automated Docker builds from Git
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building local containers is a nice thing to do, but what about its wide distribution?
    We can use the Docker Hub service to store and distribute our containers (or its
    alternative Quay.io); however, uploading each and every container and version
    manually will soon be a problem. Consider you need to rebuild dozens of containers
    in an emergency, because of the existence of another OpenSSL security bug; nobody
    would want to be the one to upload them one by one, especially with the bad uplink
    at work. And as we''re working with our Docker code using branches and tags, it
    will be awesome to see the same behavior reflected automatically on the remote
    Docker registry. This includes two of the Docker Hub (or Quay.io) features: automatically
    build Docker images upon changes and serve them to the world. We''ll do exactly
    this in this section: create an automated build and distribution pipeline from
    our code to GitHub to the Docker Hub.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A free GitHub account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A free Docker Hub account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Docker project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our objective is to get a fully working Docker build pipeline. To achieve this,
    we''ll use two free, popular services: GitHub and the Docker Hub. Let''s start
    with the code from the previous section that helped us build an NGINX container;
    we can alternatively use any other repository on GitHub containing at least a
    buildable `Dockerfile`. The code needs to actually be on GitHub not just versioned
    using Git locally. The repository should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/B05671_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This repository is ready to communicate with other build services.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an automated build on the Docker Hub
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Docker Hub is one of the commercial services from the company that created
    Docker. It's both a public Docker registry service (with private or public containers,
    depending on your subscription) and a Docker image build service that can automatically
    create new images when changes occur in the code. Go to [https://hub.docker.com](https://hub.docker.com)
    and log in or create an account if you don't have any.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Create Automated Build** in the **Create** menu:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating an automated build on the Docker Hub](img/B05671_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Choose the provider where the infrastructure code is hosted; in our case, it''s
    **GitHub**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating an automated build on the Docker Hub](img/B05671_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When the synchronization is done, choose the GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating an automated build on the Docker Hub](img/B05671_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, decide on a name for the image (it doesn''t have to be the name of
    the GitHub repository) and the namespace. The namespace could either be your username
    or an organization if you have one. Write a short description and choose the visibility
    of the image: private stuff should remain private, while public can stay public.
    Let''s be careful about what we ship:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating an automated build on the Docker Hub](img/B05671_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Navigate to **Build Settings** of our Docker Hub''s project to trigger an initial
    build:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating an automated build on the Docker Hub](img/B05671_10_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Clicking on the **Trigger** button will create a build. This is done by having
    `master` as the **Branch** type of our repository; tag the build with the `latest`
    tag. If, for some reason, the `Dockerfile` of our project wasn't at the root,
    we could specify it here. This build also allows us to manage different `Dockerfile`
    for different purposes, such as building the development and production containers
    differently, among other options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the build is complete (should happen in minutes), navigating to the **Tags**
    tab will show the available tags (**latest** is the only one we have now) and
    the size of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating an automated build on the Docker Hub](img/B05671_10_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The **Dockerfile** tab shows the content of the `Dockerfile` from which the
    image has been built, while the **Build Details** tab will list all the builds
    and their details, including the build output. This is very useful for debugging
    when things go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a GitHub to a Docker Hub-automated build pipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now let''s make a modification to the `Dockerfile`, for example, adding a label
    for the image''s name and version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Commit and push this change to GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'What''s happening on the Docker Hub? It automatically starts building a new
    image as soon as it becomes aware of the change on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Configuring a GitHub to a Docker Hub-automated build pipeline](img/B05671_10_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'A few seconds later, our newest build is available for everyone to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Building Docker images using Git tags
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we''re happy with this release, we''d like it to be available as a `1.0`
    tag on the Docker Hub. To do this, we''ll need to complete two actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Configure the Docker Hub to build and tag according to Git tags and not just
    branches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tag and push our release on Git
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the Docker Hub to build images with the same tags than the ones we set
    on Git, let''s add a new type called **Tag** in the **Build Settings** tab. This
    will now make the Docker Hub follow the tags we set on Git. It will also build
    any other tag you may create in the future:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Docker images using Git tags](img/B05671_10_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s tag our code as `1.0` on Git so we can refer to it later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This just triggered a new build on the Docker Hub, using the tag **1.0**, as
    we asked to match:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Docker images using Git tags](img/B05671_10_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Everyone can now refer to this stable build and use it without fearing a breaking
    change from the master branch; this branch will always be built with the latest
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Even better, from now on, our future Docker projects that need both this container
    and the stability can simply start with the following line on the `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We now have a nice initial workflow for building master and tagged, stable releases
    of our containers.
  prefs: []
  type: TYPE_NORMAL
- en: The workflow for connecting the Continuous Integration (CI) system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As people working with code and writing tests for it, there's no reason not
    to see those tests executed in CI. The same way every program has language requirements,
    ours need to be able to build Docker containers and execute some Ruby code. Being
    able to fully execute a whole pile of tests automatically, upon any code check-in,
    is a major quality improvement step. No one can test each and every possibility
    and regression and special cases from months or maybe years ago. It's true in
    software code, and it's the same in infrastructure code as well. Let's find an
    elegant and automated way to execute our infrastructure code tests in CI systematically
    so this could be another dot connected to the bigger map.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A free Travis CI account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''d like our RSpec integration tests to be executed automatically each time
    we commit a change on Git. This is the perfect job for a CI system, such as Jenkins,
    the Circle CI, or the Travis CI. Our only requirement is that the CI platform
    should build and execute Docker containers and run RSpec tests. Docker support
    is good with Travis, and it works out of the box. Jenkins would work equally well
    behind the firewall when properly configured, like most other CI systems. Here''s
    how to configure our CI platform to automatically execute tests on a new commit:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a free account for the Travis CI or use your own ([https://travis-ci.org/](https://travis-ci.org/)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **+** button to add a new GitHub repository:![How to do it…](img/B05671_10_14.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enable the watching of the repository by Travis:![How to do it…](img/B05671_10_11.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now add a configuration file for Travis named `.travis.yml` at the root of
    the repository. This file can contain a lot of information to do many things,
    but for now, it should simply tell Travis that we need a Ruby environment in a
    recent Linux distribution running Docker. Also, it should simply execute `make
    test` for `Makefile`. In our case, this command will execute the RSpec tests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Commit and push this file and it will trigger our first test on Travis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Navigating back to the Travis CI, we can see the tests begin:![How to do it…](img/B05671_10_12.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A few seconds later, the tests pass successfully, assuring us the build is consistent
    with our expectations. Travis even gives easy access to the output of the commands:![How
    to do it…](img/B05671_10_13.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We just initiated new steps for integrating automated tests in our workflow.
    This is getting increasingly important as every project or team grows, and it's
    getting riskier to ship untested containers into production.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It''s also highly recommended that you include any other test that can be done
    in this CI system, such as the Docker linters check from earlier in this book.
    Quality can only go higher: the more the checks, the better. Building quicker
    tests for a faster feedback loop will then be a new subject.'
  prefs: []
  type: TYPE_NORMAL
- en: As with every CI system, the final step after the tests are completed is to
    package, ship, and deploy the containers. As exciting as this step is, it's also
    unfortunately far beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Scanning for vulnerabilities with Quay.io and Docker Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One major issue when working with containers is their deprecation and maintenance
    costs. Too often, containers are built one day, shipped to production because
    they work, and forgotten there until the next rebuild (which may not happen anytime
    soon). Libraries are still libraries, and security fixes are pushed every day
    into distributions package repositories. Sysadmins are used to patch the systems;
    however, now it's a total anti-pattern to update a running container. Containers
    need to be rebuilt, exactly like developers are used to rebuilding applications
    with updated libraries to get rid of bugged code. The exception is that we are
    lucky enough to have tools that monitor each and every layer of our Docker images
    and tell us how and when they are vulnerable, allowing us to simply rebuild and
    redeploy them.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A free account at Quay.io and/or a paid account at the Docker Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the free Quay.io account (by the CoreOS team), push an image to their
    Docker Registry service after logging in using `docker login`. Here''s how to
    do this using an earlier image from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Quay.io has a very nice security feature: as Docker stores passwords in plain
    text on the local workstation, it''s possible to generate an encrypted password
    from the **settings** tab of your Quay.io account not only for Docker use, but
    also for Kubernetes, rkt, or Mesos. It''s a much better option to use this encrypted
    password to log in to the service.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After a while, in the **Repository Tags** tab of our image, we''ll get a **SECURITY
    SCAN** summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/B05671_10_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we have issues to investigate further:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/B05671_10_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Many vulnerabilities are displayed, but don't be frightened. In fact, none are
    fixable in our case (click on **Only show fixable** to see what you can do). The
    reasons are multiple, such as no fix is available currently, the vulnerability
    doesn't concern the platform we're running on, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a screenshot of a really vulnerable container and the Quay.io scanner
    giving helpful advice on the available fixes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/B05671_10_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Quay.io Security Scanner** will also send reminders by e-mail with a summary
    of the vulnerabilities found on all the containers it hosts on our account. So
    we don''t have to worry too much about missing out on important security issues.'
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker Security Scanning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There''s a similar feature on the Docker Hub that uses a paid account, though
    still in preview at the time of this writing. By default, Docker Security Scanning
    is not activated, so we have to navigate to the billing tab of the account''s
    interface and tick it to enable it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Docker Security Scanning](img/B05671_10_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'From now on, when a new Docker image is created or pushed, the system will
    scan it quickly and report issues, tag by tag. To access the report summary, just
    click on the **Tag** tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Docker Security Scanning](img/B05671_10_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To see details (and the corresponding vulnerabilities), click on the tag number:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Docker Security Scanning](img/B05671_10_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This layer has clear issues! But don't follow this blindly and double-check
    the said vulnerabilities. All the critical issues in this example only concern
    Apple platforms and we're running Linux containers.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Under the hood, the Quay Security Scanner is based on Clair. Clair is an open
    source static analysis vulnerability scanner by CoreOS that we can run ourselves
    or build tools upon. It currently handles Debian, Ubuntu, Alpine, Oracle, and
    Red Hat security data sources. It gives access to a simple API. Our custom tool
    can send each Docker image layer we're interested in and get the corresponding
    vulnerabilities or fixes.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CoreOS Clair at [https://github.com/coreos/clair/](https://github.com/coreos/clair/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sending Docker logs to AWS CloudWatch logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we run dozens or hundreds of containers in production, hopefully on a clustered
    container platform, it soon becomes difficult and tedious to read, search, and
    process logs—just like it was before when containers with services ran on dozens
    or hundreds of physical or virtual servers. The problem is that traditional solutions
    don't work out of the box to handle Docker logs. Luckily, AWS has a nice and easy
    log-aggregating service, named AWS CloudWatch. Docker has a logging driver just
    for it. We'll send our Tomcat logs to it right away!
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use AWS CloudWatch Logs, we need at least one **log group**. Use this book's
    chapter on Terraform code to create a CloudWatch Logs group and a dedicated IAM
    user, or manually create both.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As always, with AWS, it's highly recommended that you use a dedicated IAM user
    for each AWS key pair we'll use. In our case, we can associate the prebuilt IAM
    policy, named CloudWatchLogsFullAccess, with a new dedicated user in order to
    be up and running quickly in a secured way.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Docker daemon needs to run with the AWS credentials in the memory—it''s
    not information we pass to containers, as it''s handled by the Docker daemon''s
    log driver. To give the Docker daemon access to the keys we created, let''s create
    an added `systemd` configuration file for the Docker service in `/etc/systemd/system/docker.service.d/aws.conf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Don''t forget to reload the `systemd` daemon and restart Docker to apply the
    changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: We're now ready to talk to the AWS APIs through the Docker daemon.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Docker run
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here''s a simple way to execute the Tomcat 9 container that uses the `awslogs`
    driver. Utilize the CloudWatch log group named `docker_logs` on the `us-east-1`
    data center and automatically create a new stream named `www`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Navigating over the AWS Console, the new log stream will appear under **Search
    Log Group**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the Docker run](img/B05671_10_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on the log stream name will give us access to all the output logs
    from our Tomcat container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the Docker run](img/B05671_10_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We now have access to unlimited log storage and search features, and the amount
    of effort we put was very limited!
  prefs: []
  type: TYPE_NORMAL
- en: Using docker-compose
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It''s also possible to configure the logging driver using Docker Compose. Here''s
    how it works with creating a log stream named `tomcat` under the same log group
    in `docker-compose.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Launch the compose as usual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The `tomcat` CloudWatch log stream is now automatically created and the logs
    flow into it.
  prefs: []
  type: TYPE_NORMAL
- en: Using systemd
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another useful way to launch containers is through the use of systemd. Here''s
    how to create a dynamically named log stream using the systemd unit name (in this
    case, `tomcat.service`). This is useful on platforms that use multiple instances
    of the same container to let them all send their logs separately. Here''s a working
    Tomcat systemd service that is running Docker and sending the logs to a dynamically
    allocated stream name in `/etc/systemd/system/tomcat.service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Reload systemd and start the `tomcat` unit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now a third log stream is created with the service name, with the systemd unit
    logs streaming into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using systemd](img/B05671_10_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Enjoy a centralized and powerful way of storing and accessing logs before you
    eventually process them!
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Docker daemon can stream logs not only to AWS, but also to the more common
    syslog. This enables a lot of options (such as having traditional `rsyslog` setups
    and online services compatible with the traditional format). Similarly, it not
    only sends the logs to `journald`, but also supports the Graylog or Logstash GELF
    log format. The Fluentd unified logging layer is also supported, while on the
    platform front, we find support for Splunk and Google Cloud together with AWS
    CloudWatch logs.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and getting information out of Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s often important to get some quick and useful information out of our Docker
    system when weird problems arise or strange issues start to cripple our performance.
    What''s going on in the system? Is there a container taking up all of the memory?
    Maybe one minor container just crashed and is eating up all of the CPU. All of
    this information shouldn''t be hard to get, but they are precious for building
    quality containers. We''ll see two tools quite fit for the job: the first one
    is simply the one shipped with Docker itself, and the second one is a totally
    different tool by Google named cAdvisor—a web user interface with a lot of useful
    and easy-to-get information.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There's a few ways to get information out of Docker. We'll explore the first
    one through the main Docker program.
  prefs: []
  type: TYPE_NORMAL
- en: Using docker stats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To get live metrics about the running containers (CPU, memory, and network),
    we can use the simple `docker stats` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s, however, not overwhelmingly helpful as it''s using containers'' IDs
    and not names, and when running many containers, it can start becoming useless
    because it would be unreadable. So we can use a trick: ask the stats (`docker
    stats`) of all the running containers (`docker ps`) whose names we extracted using
    a Go template formatter `(--format`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Using Google's cAdvisor tool
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Google created a nice web tool to see what''s going on in machines that run
    containers: **cAdvisor**. It collects, organizes, and displays metrics about resource
    usage, container by container, on a given host. Though not interactive, it''s
    still powerful enough, given how easy it is to install and use. To install and
    use it, simply run the cAdvisor Docker image with volume access to all of the
    required system information, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, if using `docker-compose`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Navigating to the host''s `8080` port (or whatever port you choose to publish)
    with a web browser will present a web interface where we can navigate and see
    graphical information about container usage on the host:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Google''s cAdvisor tool](img/B05671_10_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Or, we may have more general gauges giving live indication of resource usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Google''s cAdvisor tool](img/B05671_10_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'A very useful process table with top-like data from the underlying host is
    also available with a container-aware context. All of these pieces of data are
    browsable and they help you gain more in-depth information about a specific container
    and its content and usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Google''s cAdvisor tool](img/B05671_10_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: cAdvisor can also be plugged in to many backend storage systems, such as Prometheus,
    ElasticSearch, InfluxDB, Redis, statsD, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you plan to let cAdvisor run permanently, it is a good idea to restrict access
    using simple HTTP authentication. This is supported out of the box by cAdvisor
    using `--http_auth_file /cadvisor.htpasswd --http_auth_realm my_message`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: cAdvisor GitHub at [https://github.com/google/cadvisor](https://github.com/google/cadvisor)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: cAdvisor storage backends at [https://github.com/google/cadvisor/blob/master/docs/storage/README.md](https://github.com/google/cadvisor/blob/master/docs/storage/README.md)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging containers using sysdig
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sysdig is an awesome tool that can be used for many purposes, including monitoring,
    logging, process debugging, network analyzing, and exploring a system in depth.
    Plus, it includes fantastic Linux container support. It's also scriptable and
    can be fed with recorded real traffic packet captures for offline analysis. It's
    an incredible tool that each and every person working with containers should at
    least know the basics of, and as infrastructure developers used to working with
    code, we know how important debugging tools are. This is no different with sysdig,
    and we'll now discover some of its fantastic features related to containers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To step through this recipe, you will need:'
  prefs: []
  type: TYPE_NORMAL
- en: A working Docker installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sysdig installed and running on the host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Installing sysdig is easy on most platforms, including CoreOS ([http://www.sysdig.org/install/](http://www.sysdig.org/install/)).
    However, if you''re in a hurry, here''s a one liner that will do the job of installing
    Sysdig on your Linux host. We''d probably choose a better way to deploy it programmatically
    though, such as Ansible or Chef, through a Docker container or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how to get an htop-like view of all the running containers on the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '![How to do it...](img/B05671_10_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Navigating to the **F2/Views** menu helps you enter many different options
    to see what''s running, from processes to syslog to open files and even the Kubernetes,
    Marathon, or Mesos integration. Want to see which container is draining all of
    the IO? You''re at the right place:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/B05671_10_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s an example of a Tomcat container with a view of all the local and remote
    connections, IPs, ports, protocols, bandwidth, IOs, and the corresponding commands—terribly
    useful to find suspicious behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/B05671_10_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Another useful tool is `F5`/`Echo`, grabbing what''s transiting on this container:
    (un)encrypted content, logs, output, and more. This is also very useful to maybe
    catch something wrong with a container acting weird:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/B05671_10_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Another very powerful tool from sysdig is `F6`/`Dig`. This basically offers
    nothing less than a full-fledged `strace` for a container; imagine the debugging
    power it has:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/B05671_10_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `F8`/`Actions` feature is a full Docker command integration tool available
    right from inside sysdig. Select a container and we''ll be able to enter it, read
    logs, see its image history, kill it, and more:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/B05671_10_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Those commands are also always available right from the main interface: want
    to gain a shell on this selected container? Just type `b`.'
  prefs: []
  type: TYPE_NORMAL
- en: These are just a few of the many powerful things we can do with Sysdig using
    Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More general sysdig usage examples at [http://www.sysdig.org/wiki/sysdig-examples/](http://www.sysdig.org/wiki/sysdig-examples/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
