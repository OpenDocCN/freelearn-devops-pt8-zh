- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenShift Troubleshooting, Performance, and Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concepts explained in [*Chapter 5*](B18015_05.xhtml#_idTextAnchor090), *OpenShift
    Deployment*, provided the foundation for you to initiate your first contact with
    an OpenShift cluster. In this chapter, we will give some tips on how to perform
    a health check on a cluster, dive into some **root cause analysis** (**RCA**),
    and also provide details on how to make a cluster run according to some best practices.
    Our intention with this chapter is to give you some general guidance about troubleshooting,
    however, it is important you always open a support ticket with Red Hat before
    making any changes in the platform due to troubleshooting attempts.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Things that can crash a cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting reference guide—how to start
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding misleading error messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The source code used in this chapter is available at [https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter06](https://github.com/PacktPublishing/OpenShift-Multi-Cluster-Management-Handbook/tree/main/chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: Things that can crash a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every time we start learning about some technology, it is common to be twice
    as careful with the installation, configuration, or adjustment to be as thorough
    as possible. Sometimes, to achieve these goals related to troubleshooting, performance,
    and best practices, the reader would turn to multiple expert readings on each
    of the related topics, or go through the pain of trial and error, which takes
    a lot of effort to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift is a great and disruptive technology, but you will navigate through
    a puzzle of different aspects related to storage, compute, network, and others.
    Obviously, in the official documentation—or even in quick internet searches—you
    will find commands to start from scratch, but in many situations, even with the
    necessary commands and parameters, it is difficult to navigate from troubleshooting
    to a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, OpenShift has an automatic recovery system, but this is usually not
    enough to ensure a stable environment. For this self-healing to take place successfully,
    many prerequisites need to be checked on the cluster first. So, before we understand
    what can potentially crash, let’s understand how this self-adjustment mechanism
    works.
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the world of technology, there are many roles played, and some of them are
    linked to the administration of the infrastructure. There are several names for
    this role, the most common still being the **system administrator**, or **sysadmin**,
    who operates the servers and services of an **information technology** (**IT**)
    infrastructure. Likewise, OpenShift has *operators* that are nothing more than
    **applications designed to monitor platform behavior and maintain an operation**.
  prefs: []
  type: TYPE_NORMAL
- en: How do operators work? Operators are assigned to fulfill a single task of maintaining
    the application and all its components according to a standard. Understand that
    operators are not the same for all applications—that is, operators are unique,
    each with its own parameter definitions, configurations that are required and
    optional, and others.
  prefs: []
  type: TYPE_NORMAL
- en: The operator parameters’ contract is described in the **Custom Resource Definition**
    (**CRD**). A CRD is a definition that extends a Kubernetes **application programming
    interface** (**API**) functionality, giving more flexibility to the cluster to
    store a collection of objects of a certain type. Once a CRD is defined, you can
    create a **Custom Resource** (**CR**) that will allow you to add a Kubernetes’
    custom API to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Operators are a tool for keeping a cluster or application healthy, so why should
    we care about learning about OpenShift troubleshooting if it fixes itself? Indeed,
    operators are a powerful tool, but as we mentioned earlier, OpenShift is a big
    puzzle, and the pieces need to fit together perfectly for it to work properly.
    Although it is reigned by operators that are somehow prepared to maintain its
    integrity, failures can occur, and the role of the cluster administrator and their
    experience in solving problems will help keep all these operators healthy.
  prefs: []
  type: TYPE_NORMAL
- en: In the next sections, we’ll go deeper into the main components of OpenShift
    and which aspects to be concerned about.
  prefs: []
  type: TYPE_NORMAL
- en: etcd
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the case of OpenShift clusters, etcd is a distributed key-value service
    responsible for storing the state of the cluster. Through it, all objects contained
    in the cluster are shown in a key-value format, so it is important to consider
    at least three important factors in this service, which is the heart of the control
    plane’s operation. Note the following:'
  prefs: []
  type: TYPE_NORMAL
- en: etcd is *highly sensitive* to an infrastructure’s **latency** and **bandwidth**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: etcd needs to be distributed on all master nodes—that is, to be highly available,
    an OpenShift cluster infrastructure demands this service be distributed on three
    master nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike many **high-availability** (**HA**) services, in which you have a main
    and a secondary server, with etcd, this concept is based on **quorum** members
    and **leadership**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Red Hat made the etcd complexity easier by establishing the number of master
    nodes to be `3` as default and also by using a cluster operator that manages etcd
    and reports any issue in it; however, you must still understand how etcd works
    to be able to troubleshoot if any complex issue occurs. Go ahead to learn how
    the quorum and leader-based etcd algorithm works.
  prefs: []
  type: TYPE_NORMAL
- en: How do the quorum and leader-based schemes work?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An etcd cluster works on the concept of **leader** and **followers**, which
    is known as the **Raft Distributed Consensus** protocol. This protocol implements
    an algorithm based on a *leader election* to establish a distributed consensus
    among all members of an etcd cluster. Once members are added to an etcd cluster
    and a leader is elected, the process only requires sending periodic heartbeats
    to confirm that the leader still responds within a suitable latency time.
  prefs: []
  type: TYPE_NORMAL
- en: In case of an unanswered heartbeat time frame, the members start a new election
    to guarantee cluster resilience, self-healing, and continuity of service.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is recommended that an etcd cluster has an odd number of nodes so that the
    following formula guarantees the tolerance of a given number of failing members.
    To this we give the name of **quorum**:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Quorum = (n/2)+1, where “n” represents the number of members.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'A cluster must always have at least the *quorum* number of members working
    to be functioning properly. For the sake of clarity, let’s check out some scenarios,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scenario 1**: Three-member cluster, all up and running, as illustrated in
    the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Healthy etcd cluster (three-node member health) ](img/B18015_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Healthy etcd cluster (three-node member health)
  prefs: []
  type: TYPE_NORMAL
- en: '*Analysis*: Quorum is OK as there are a majority of working members and leadership
    is assured, so the cluster is healthy.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scenario 2**: Three-member cluster with two members working, as illustrated
    in the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Healthy etcd cluster (two-node member health; risk of outage)
    ](img/B18015_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Healthy etcd cluster (two-node member health; risk of outage)
  prefs: []
  type: TYPE_NORMAL
- en: '*Analysis*: Quorum is OK as there are a majority of working members and leadership
    is assured. There is a degradation risk in case of disruption of one more node,
    but the cluster is healthy.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scenario 3**: Three-member cluster with one member working, as illustrated
    in the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Degraded etcd cluster (one-node member health; unhealthy cluster)
    ](img/B18015_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Degraded etcd cluster (one-node member health; unhealthy cluster)
  prefs: []
  type: TYPE_NORMAL
- en: '*Analysis*: There is no quorum as the majority of members are down, so it is
    no longer possible to elect a new leader, and the cluster is degraded.'
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting etcd
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned earlier, OpenShift is managed by its operators, which can provide
    standardization, self-healing, and activities metrics, but this is not always
    enough to keep the cluster fully functional.
  prefs: []
  type: TYPE_NORMAL
- en: Situations such as scenarios *2* and *3* can occur due to different factors
    related to any infrastructure layer. It is important to carry out an in-depth
    analysis to restore the cluster to a functional state. Here’s an approach to troubleshooting
    etcd.
  prefs: []
  type: TYPE_NORMAL
- en: For troubleshooting, it is important to consider what kind of disruption the
    cluster has been hit with. If we are still able to use the OpenShift API to access
    the nodes, you can use the first approach. Otherwise, if the API is unavailable,
    you must refer to the second scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario 1 – etcd member is degraded
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In cases where it is still possible to execute `oc` or `kubectl` commands, use
    the `rsh` command to the etcd pod, and performing the following steps through
    `etcdctl` is the quickest approach.
  prefs: []
  type: TYPE_NORMAL
- en: An etcd degradation can occur for many different reasons, such as storage or
    network failures, live migration of the master nodes, or even manipulations in
    the **operating system** (**OS**), which may cause immediate disruption of the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned before, run the following commands to open a terminal in an etcd
    pod and identify the failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that in the previous output, two out of three masters are getting issues,
    so let’s `rsh` to `master-3`, perform a backup, and recreate the etcd nodes, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the **identifiers** (**IDs**) of the failed members are determined, the
    next step is to remove the etcd members, leaving only the one that is running
    as part of the cluster. To do so, first run the backup of etcd, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The etcd backup will be saved in the `home` directory of the `core` user in
    the same node as the one where the etcd pod is running. It is highly recommended
    you copy it to an off-node location as this will avoid the risk of losing access
    to the node and, as such, losing the etcd backup file and putting the cluster
    recovery at risk.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have already identified the problem with the etcd cluster, see
    next the suggested steps to recover your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: How to solve it?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Formerly, on OpenShift version 3, the usual solution for both cases was reestablishing
    the etcd cluster using a backup. Now, with OpenShift 4, it is easier to provision
    new master nodes in your infrastructure. That said, if your issue is the first
    scenario (API is still available) and your installation is the **installer-provisioned
    infrastructure** (**IPI**) method, we suggest you take the following steps to
    recreate the problematic master node, using a new node name:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the **YAML Ain’t Markup Language** (**YAML**) machine descriptor for any
    current master node by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The YAML file should look like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Make the required changes in the YAML file to provision the new master, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Remove the following sections or fields:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Entire `status`, `metadata.annotations`, and `metadata.generation` sections.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete `metadata.resourceVersion`, `metadata.uid`, and `spec.providerId` fields.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: II. Change the `metadata.name` field to a new name (for example, `<clustername>-<clusterid>-master-3`).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Also update the node name in the `metadata.selfLink` field.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Delete the problematic master node using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the following command to monitor the deletion process and certify it has
    been deleted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As soon as the problematic master has been deleted, you can now provision a
    new one using the YAML we prepared previously. To do so, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Repeat this procedure if necessary, changing only the `metadata.name` and `metadata.selfLink`
    fields for each problematic master node in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the new master nodes have been provisioned, observe the following steps
    to verify whether the etcd cluster is healthy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check if all etcd pods are running, as follows. You must see three pods running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There are some cases in which the etcd pod is not deployed automatically with
    the master provisioning. If you don’t see three pods running, you may run the
    following command to force the etcd operator to deploy the etcd pod in the new
    node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s check from inside the etcd cluster whether it is working as expected.
    To do so, run the following command to open a terminal inside one of the etcd
    pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, check the cluster member list, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In some cases, you will still see the problematic etcd node that we already
    removed as part of the cluster members. Therefore, if the previous command shows
    more than three members, use the following command to remove the nonfunctional
    etcd members:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Scenario 2 – cluster API down
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If the OpenShift API is down, it is important to perform any steps with much
    more caution to avoid an irreversible loss to the cluster. In such a scenario,
    you can’t use the `rsh` command, get logs using `oc logs`, OR use any `oc` or
    `kubectl` command, as all of them use the OpenShift API, which makes troubleshooting
    and finding a solution much more difficult and complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to that, there must be regular etcd backups in place before the cluster
    malfunctions. If there is no previous backup, the first step is to perform a direct
    backup on the node that is in operation. To do so, proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check out the etcd state by running the `crictl` command, like so:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the etcd pod ID and run the `crictl exec` statement to identify the cluster’s
    node state, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Note that the etcd members are unreachable except for one that is in the started
    state. Run a backup by going to the node and running the backup command, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the pod ID of etcd, obtained by `crictl`, run the following command to
    identify the cluster nodes and their state:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this stage, it is possible to draw some conclusions. We understand that there
    is no minimum quorum to keep the cluster up, so the API became unavailable. Continue
    next for a suggestion on how to proceed in this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: How to solve it?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In general, to restore a cluster in this scenario you will use the command `etcdctl
    member remove` to remove all problematic etcd members and then use the procedure
    we described in the previous *How to solve it?* section to remove problematic
    master nodes and provision new ones. However, troubleshooting a cluster in this
    scenario is much more challenging, work with Red Hat support to find the best
    way to restore it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have already gone through etcd troubleshooting, let’s discuss another
    important aspect of it: performance analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: etcd performance analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes clusters are highly sensitive to latency and throughput. Due to this,
    some precautions are necessary to have a stable cluster and also great performance.
    OpenShift is a platform designed for HA, and, as such, the expected etcd use and
    consumption are traffic-intensive. It is important, then, to follow some best
    practices to have a stable cluster. Let’s look at some recommended configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: etcd’s disk usage is intensive, so it is recommended to use **solid-state drive**
    (**SSD**) disks for a fast write/read response time. Regarding response times,
    we could say that 50 sequential **input/output operations per second** (**IOPS**)
    would be a minimum requirement, but from our experience, the OpenShift usage grows
    really fast, so we recommend you consider disks that can deliver at least 500
    concurrent IOPS, to maintain the cluster’s health and stability. However, note
    that some providers do not publish the sequential IOPS but only the shared IOPS.
    In such cases, consider that concurrent IOPS is equivalent to 10 times the sequential
    IOPS value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of how to measure the performance of the etcd disks using
    a customized version of the `fio` tool. In the OpenShift cluster, run the `debug`
    command to get access to a master node, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As soon as the command is executed, the following message will be displayed.
    Execute the `chroot` command after the shell to be able to execute commands in
    privileged mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a container, as indicated in the following code snippet. After the `etcd-perf`
    container starts, it will automatically run performance checks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, we have used the following annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[1]**: A chunk size of 22 **megabytes** (**MB**) is usually enough to analyze
    performance results.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[2]**: Instead of using 4k block size, etcd uses small chunks of 2.3k block
    size, so it guarantees performance, including with small writing fragmentations.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[3]**: Bandwidth required considering traffic between the node and underlying
    storage. It is recommended you use at least a network interface of 1 **gigabyte**
    (**GB**). For medium and large clusters, the recommendation is a 10 GB interface.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[4]**: The recommendation is at least 500 concurrent IOPS, as explained previously.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[5]**: The report of the etcd IO check. In the example, 5.40 **milliseconds**
    (**ms**) demonstrates a reliable performance—for it to be so, it must be under
    10 ms.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides using `etcd-perf` to check the disk performance, you could also perfectly
    use custom parameters as you need, such as block size, chunk size, and so on,
    using the `fio` binary tool, which is available using the standard Red Hat package
    manager (for example, by executing `yum/dnf install fio`).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For didactic reasons, we suppressed some results, leaving only items that are
    pertinent to our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: etcd sizing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To avoid any problems related to the **central processing unit** (**CPU**),
    you must understand whether your cluster is well-sized. You must consider some
    factors to check the cluster sizing, such as the number of customers using the
    platform, the expected number of requests per second, and the amount of storage
    available for etcd.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s give you some parameters to consider for your cluster size:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18015_06_Table_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following table demonstrates some use cases using public clouds and on-premises
    infrastructures according to the amount of CPU, memory, disk IOPS, and bandwidth
    linked to the cluster size:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18015_06_Table_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In a nutshell, when you size a cluster, you should consider these thresholds
    because this is already benchmarked by the etcd community, and their performance
    will likely be acceptable if these recommendations are followed. Further information
    regarding sizing the etcd cluster can be found at the link we have provided in
    the *Further reading* session of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you have seen some ways to check etcd performance and troubleshoot,
    and you also got some important information regarding sizing best practices. We
    hope you enjoyed the approach and take a close look at the next section about
    authentication, which will be another interesting theme.
  prefs: []
  type: TYPE_NORMAL
- en: Authentication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another important aspect of an OpenShift cluster is user authentication and
    authorization flow. OpenShift’s flexibility and easy-to-use authentication plugins
    are a smart way of setting up users and groups. Instead of simply having a vault
    of usernames and passwords, OpenShift’s authentication service can authenticate
    a user in a variety of ways—we call it an **identity provider** (**IdP**). In
    this way, OpenShift is responsible for trusting the IdP and allowing or denying
    authentication according to the provider. In the following diagram, you can see
    how the process of authenticating a user works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Authentication and authorization flow ](img/B18015_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Authentication and authorization flow
  prefs: []
  type: TYPE_NORMAL
- en: The IdP is responsible for notifying OpenShift if the username and password
    are valid and returning to OpenShift the `success` or `failure` authentication
    status. This process is known as **authentication** (**AuthN** in some literature).
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned that the authentication process uses IdPs to validate the user
    against an authentication provider, but, more importantly, you need to understand
    how **authorization** (aka as **AuthZ**) occurs. Initially, a user on OpenShift
    doesn’t have any permissions in any project; however, they can log on. They will
    not have rights to perform any tasks except creating their own new projects if
    the cluster has the self-provisioner role enabled (self-provisioner is a role
    that allows any logged user to create their own projects). To add permissions
    to a user, it is necessary to inform the appropriate role. This can be accomplished
    through the inclusion of a user group or by directly assigning it to the user.
    This process of adding roles to users or groups is named **RoleBindings**.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand which role best fits a user or group, consider looking
    at the default roles that already exist in an OpenShift cluster, as set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`admin`—This is a project admin. It allows changes with all project-scoped
    resources, including the ability to create RoleBindings using ClusterRoles. It
    does not allow the modification of quotas, limits, or cluster resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`edit`—This is a project editor. It allows usage and manipulation of all project-scoped
    resources, but cannot change authorization objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`view`—This is a project viewer. It allows the inspection of project-scoped
    resources and works like a read-only RoleBinding. Secrets inspections are not
    allowed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cluster-admin`—This is the equivalent of a root user on a *nix-like OS. It
    allows total control of any resource in the entire cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cluster-reader`—This is useful for allowing special users permissions, especially
    those that work with cluster monitoring. This RoleBinding is read-only and does
    not allow users to escalate or manipulate objects on the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You must also understand the scope of the RoleBinding, which can be one of
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`edit` role to user *X* in project *Z*. Creating local RoleBindings is as simple
    as running the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`cluster-admin` role to user *X*. To create a cluster RoleBinding, run the
    following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similar commands can be applied to groups, just replacing `user` with `group`
    (for example, `add-role-to-group` and `add-cluster-role-to-group`). Similarly,
    to remove a role from a user or group, use `remove-role-from-user/group`, as in
    the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'These are some of the most popular default roles that are used with OpenShift,
    but you can create custom ones if needed. To create a custom role, you need to
    first understand what are **verbs** and **resources**, so here are definitions
    of these:'
  prefs: []
  type: TYPE_NORMAL
- en: A `get`, `list`, `create`, `update`, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `pod`, `deployment`, `service`, `secret`, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'That said, to define a custom role, you need to know which verbs for the user
    or group will be allowed to run over which objects. As soon as you have defined
    verbs and resources, a role can be created using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Have a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: There are more things about authentication and authorization with OpenShift
    that it's not our intention to bring to light here. We tried to highlight some
    of the important aspects you need to know about it, and we left a set of links
    in the *Further reading* section of this chapter if you want to go even deeper
    into this subject.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, we have demystified the authentication process a bit, and you can
    now perform the process of **AuthN** and **AuthZ**. The previous diagram showed
    a quick point of view about the steps of an authentication process. It is important
    to give proper permissions to each user or group, and—more importantly—to plan
    the roles you will need to have in place to give your users and groups the proper
    permissions to perform their job. In the following section, we will cover another
    important aspect that an OpenShift operator needs to know about: troubleshooting.'
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting reference guide – how to start
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will see some approaches to troubleshooting your OpenShift
    cluster if you face any issues. Due to the power of the `oc` **command-line interface**
    (**CLI**), you will have different ways to succeed in almost any troubleshooting
    scenario of your OpenShift cluster. Along with your training, you will gain the
    experience you need to take a step further in using and troubleshooting your OpenShift/Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Describing objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have mentioned, the `oc` CLI is a powerful tool to help OpenShift users
    to do a lot of operations and also do some troubleshooting. One of the first steps
    of troubleshooting is to get some details and descriptions of the objects. Suppose,
    for instance, you have an issue related to a pod that is not coming up, for some
    reason. Let’s start our troubleshooting by checking the pod details, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the output in the `Events` section of the object to see what is preventing
    the pod from spinning up, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In this case, you were able to see quickly in the `oc describe` command that
    the error is related to the connection between the node and the image registry
    (`no route to host`). You can act accordingly to fix the connectivity issue and
    get the pod up and running. You can also use the `Events` log to see other meaningful
    information, as you can see in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Events
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another parameter on the `oc` CLI that helps with problem investigation is
    the `oc get events` command. This is very useful for showing a log of tasks recently
    executed, along with presenting *success* or *error* messages. Events can be executed
    cluster-wide or project scoped. Check out the following sample of event logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If the pod is up and running but you still have some issues in an application,
    you can also use OpenShift to check the application logs, as you will see next.
  prefs: []
  type: TYPE_NORMAL
- en: Pod logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Regularly, pod logs bring important information related to the scheduler, pod
    affinity/anti-affinity, container images, and persistent volumes. There are several
    ways to check the pod logs, as outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The common way—inside the namespace—is shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s how to check them from any namespace:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s how to check the logs of a specific container inside a pod:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can also check the logs using the OpenShift console `Logs` tab of the desired
    namespace and pod, as illustrated in the following screenshot:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Pod logs example (OpenShift console graphical UI (GUI)) ](img/B18015_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Pod logs example (OpenShift console graphical UI (GUI))
  prefs: []
  type: TYPE_NORMAL
- en: You may also have issues during the application deployment. See next what you
    can check to find evidence of deployment problems.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, a pod does not start and remains in a constant crashing state,
    which makes it difficult to get any logs. In such cases, you can check the `deployment`
    or `deploymentconfig` logs, which can help you to identify deployment misconfigurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to pod logs, `deployment` logs are accessible by running the `oc logs`
    command. For `deployment` logs, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'For `deploymentconfigs` logs, use this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Usually, you will not find the exact issue or the root cause and the solution
    to be applied, but it will give you a good indication of why it is failing—for
    example, dependent components that are missing in the solution, such as images
    not available; security context constraint with incorrect permissions; configmaps,
    secrets, and serviceaccounts missing; and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Another useful way you may use to troubleshoot an issue is to use the `debug`
    command with temporary root privileges. Learn more on this in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another interesting tool to troubleshoot a pod that is constantly crashing
    can be used by executing the `oc debug deployment` or `oc debug deploymentconfig`
    command. Through this, you can instruct OpenShift to not fail and restart the
    pod as it crashes. The pod will still be alive, so you can check the logs, access
    it, and troubleshoot it from inside the container. To use the tool, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `oc debug` command allows some interesting options, such as `--as-user`
    to run the pod with a defined user. To see a comprehensive list of allowed parameters
    and examples, run the `oc debug -h` command.
  prefs: []
  type: TYPE_NORMAL
- en: Operator logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we already covered in this book, OpenShift uses several operators to deploy
    and monitor critical features for the platform. That said, operators bring helpful
    logs to identify some configuration issues and instability with the platform.
    Those logs are stored in namespaces starting with the name `openshift-*`, which
    is a standard for most tools included with OpenShift.
  prefs: []
  type: TYPE_NORMAL
- en: The reason to maintain several operator pods as a part of project pods is related
    to some affinity/anti-affinity rules and taints/toleration strategies that a user
    can apply to the cluster. Operator pods are the watchdog to maintain namespaces’
    health, watching the CRD, its standards, liveness, and readiness, and preventing
    OpenShift’s critical namespaces from suffering undesirable changes.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main benefits of operators for the cluster’s stability is the ability
    to maintain the desired state of the operator namespace’s objects. In other words,
    if any unwanted changes are made by mistake directly into the namespace’s objects,
    they will be reverted by the operator itself. Every change in the operator’s objects
    needs to be done through the operator itself, by editing ConfigMaps or CR objects,
    according to the operator’s specification. That also means that any changes are
    checked and confirmed by operators before they are effectively applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check the cluster operators’ functions, you must do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'List the cluster operators, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Describe the details of the cluster operator, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the status output for error messages, if they exist, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the previous example, only a warning message about setting up a default storage
    class for a cluster is shown. No critical issues were found at storage. In case
    of any issue, look at the events and pod logs in the operator’s namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Other oc CLI commands and options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `oc` CLI has some other powerful commands for troubleshooting. Some useful
    and powerful commands for troubleshooting are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example command for high-verbosity logs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And here’s one for cluster events:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, you can see an example command for namespaced events:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s how to execute a single command inside the pod (double dash required):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s how to execute a single command inside a pod in a specific container
    (double dash required):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create iterative commands spawning a pseudo-terminal, like so:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similar to the `exec` command, `rsh`—shown here—opens a terminal inside the
    pod:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'All of the previous commands help you to identify problems in a cluster or
    even an application. Furthermore, you can investigate the node directly using
    the `oc debug` command, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The `oc debug` command gives you non-root privilege access, and you cannot
    run many OS commands without escalation. To do so, we recommend you run the `chroot`
    command, like so. After that, you can regularly use OS shell commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, OpenShift has a lot of useful debugging commands to help you
    identify cluster-wide or scoped issues. It is not recommended, but it is possible
    to also directly `ssh` on nodes. This kind of approach requires good knowledge
    of the *Red Hat CoreOS* OS, `podman`, and `crio` to avoid node disruption.
  prefs: []
  type: TYPE_NORMAL
- en: In any situation, we also recommend you open a support ticket with Red Hat,
    which will assist and give you the right guidance to solve your problem. The Red
    Hat support team often asks for the result of the `must-gather` command, which
    generates a temporary pod and concatenates meaningful logs and configurations
    that are useful for the Red Hat engineering team to analyze and correlate events
    and find the issue or root cause.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common way to run `must-gather` is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This will create a `tar` file under the chosen directory with all logs collected,
    which can be very useful to identify problems. We suggest you always run this
    command and upload it when you are opening the support ticket to speed up the
    process of analyzing the issue.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you saw different debug approaches that will certainly help
    you in everyday life. In the next section, you will see the most common error
    messages that occur at pod startup, and in this way, you will be able to draw
    your own line of reasoning that will help you in the problem solution.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding misleading error messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even if you have learned the different ways to identify a problem, it is not
    unusual that the error shown does not provide enough information to help you to
    detect the issue and fix it. Having that in mind, we decided to highlight some
    very common error messages in this section and also some suggestions to solve
    the problem.
  prefs: []
  type: TYPE_NORMAL
- en: ImagePullBackOff
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a common error related to a missing container image. Check out the
    following lines of code to become familiarized with this kind of issue when you
    face it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a message that may come up when investigating the pod log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Looking at the error message, it is typically linked to the absence of the image
    in the registry. This can occur due to some problems, such as the image and its
    tags not being available in the registry, or incorrect pointing in the **deployment/deployment
    config**. Another correlation would be the node where the pod is running is not
    able to reach the image registry.
  prefs: []
  type: TYPE_NORMAL
- en: CrashLoopBackOff
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is an error that requires some knowledge before acting on solving it effectively.
    It occurs because the application crashes constantly, so the root cause issue
    can be due to several different reasons. You can see an example of this here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a message you may see when investigating the pod log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The log usually gives you some hints about the issue’s root cause, but it can
    also be a trap to conduct you to a wrong conclusion. It is important to take into
    account when a pod has a persistent volume or it has a precedence order that depends
    on another application to start first and prepare a persistent volume, as well
    as many other different scenarios that can lead to this error.
  prefs: []
  type: TYPE_NORMAL
- en: Init:0/1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you get an `Init:0/1` error message, it typically means the pod is waiting
    for another pod or a condition that hasn’t been satisfied yet. The following lines
    of code demonstrate what kinds of conditions can result from this message and
    how to solve this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a message you may see when investigating the pod log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This, perhaps, can be a confusing status when you are troubleshooting error
    messages. Certainly, it can be anything wrong in the namespace, so the error message
    only shows `PodInitializing`. You could interpret it as a condition when a pod
    is waiting to start; meanwhile, this message means that a condition isn’t satisfied.
  prefs: []
  type: TYPE_NORMAL
- en: 'To help you, we have listed here some items that must be checked that may be
    preventing the pod from starting:'
  prefs: []
  type: TYPE_NORMAL
- en: Check whether the service account used in the pod exists in the namespace, as
    some containers need a specific service account name and policy applied to start.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the **security context constraints** (**SCCs**) and make sure that these
    are properly set according to the required permissions for the pod.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Check other containers and pods in the namespace: depending on the build strategy,
    it is possible to define pod dependencies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are not familiar with SCC yet, don’t freak out. We will be covering it
    in depth in [*Chapter 8*](B18015_08.xhtml#_idTextAnchor153), *OpenShift Security*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we focused on important components of OpenShift, such as operators
    and their role in maintaining the resilience of a cluster, and we also talked
    about situations that can cause damage to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We have dived into the heart of OpenShift, which is its distributed database
    (known as etcd), understanding its importance in the cluster and how to prepare
    it to receive a high volume of traffic, as well as verifying its sizing and performance,
    and understanding how to perform troubleshooting in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: We have also discussed a bit about the AuthN and AuthZ process, so you now know
    the power and flexibility of the Openshift IDPs. We finally have seen some important
    troubleshooting tips and tools that will certainly help you in your daily job,
    operating OpenShift clusters and applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will present some other important information about
    the network on OpenShift. We will discuss and give examples to understand the
    main differences between a pod network and a service network, as well as understand
    the difference between North-South and East-West traffic. Keep up with us in this
    interesting reading and learn more in [*Chapter 7*](B18015_07.xhtml#_idTextAnchor133),
    *OpenShift Network*.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you want to look at more information on what we covered in this chapter,
    check out the following references:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Red Hat Knowledgebase—etcd recommendation*: [https://access.redhat.com/solutions/4770281](https://access.redhat.com/solutions/4770281)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*etcd quorum model*: [https://etcd.io/docs/v3.5/faq/](https://etcd.io/docs/v3.5/faq/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Understanding etcd quorum*: [http://thesecretlivesofdata.com/raft/](http://thesecretlivesofdata.com/raft/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*etcd hardware sizing recommendations*: [https://etcd.io/docs/v3.5/op-guide/hardware/](https://etcd.io/docs/v3.5/op-guide/hardware/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*etcd tuning options*: [https://etcd.io/docs/v3.5/tuning/](https://etcd.io/docs/v3.5/tuning/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*etcd benchmarking thresholds*: [https://etcd.io/docs/v3.5/benchmarks/](https://etcd.io/docs/v3.5/benchmarks/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*etcd benchmark CLI tool*: [https://etcd.io/docs/v3.5/op-guide/performance/#benchmarks](https://etcd.io/docs/v3.5/op-guide/performance/#benchmarks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes authentication flow*: [https://kubernetes.io/docs/reference/access-authn-authz/authentication/](https://kubernetes.io/docs/reference/access-authn-authz/authentication/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Openshift IDPs*: [https://docs.openshift.com/container-platform/4.7/authentication/understanding-identity-provider.html](https://docs.openshift.com/container-platform/4.7/authentication/understanding-identity-provider.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learn more about SCCs*: [https://docs.openshift.com/container-platform/4.8/authentication/managing-security-context-constraints.html](https://docs.openshift.com/container-platform/4.8/authentication/managing-security-context-constraints.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*More information about troubleshooting*: [https://docs.openshift.com/container-platform/4.7/support/troubleshooting/investigating-pod-issues.html](https://docs.openshift.com/container-platform/4.7/support/troubleshooting/investigating-pod-issues.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recommended etcd practices*: [https://docs.openshift.com/container-platform/4.10/scalability_and_performance/recommended-host-practices.html#recommended-etcd-practices_recommended-host-practices](https://docs.openshift.com/container-platform/4.10/scalability_and_performance/recommended-host-practices.html#recommended-etcd-practices_recommended-host-practices)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*How to calculate IOPS in a storage array (blog article)*: [https://www.techrepublic.com/article/calculate-iops-in-a-storage-array/](https://www.techrepublic.com/article/calculate-iops-in-a-storage-array/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
