- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building Docker Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applications that have components running as software containers are quite a
    new development and a great way of avoiding problems with underlying infrastructure.
    As we learned in the previous chapter, containers are processes that are executed
    on hosts using their kernels, isolated using features present in these kernels
    (in some cases, for years), and encapsulated in their own filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will use container images, which are template-like objects,
    to create containers. Building these images is the first step to creating your
    own container-based applications. We will learn different procedures to create
    container images. These images will be our new application’s artifacts, and as
    such, we need to build them securely and be ready to run them on our laptops or
    computers, staging and production servers, or even cloud-provisioned infrastructures.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how copy-on-write filesystems work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building container images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding common Dockerfile keys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The command line for creating images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced image creation techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices for container image creation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will teach you how to build container images and use them
    in your code-compiling workflow. We will use open source tools, as well as a few
    commercial ones that can run without licensing for non-professional use, to build
    images and verify their security. We have included some labs in this chapter to
    help you understand the content presented. These labs have been published at the
    following GitHub repository: [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter2](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter2).
    Here, you will find some extended explanations that have been omitted from this
    book’s content to make the chapters easier to follow. The *Code In Action* video
    for this chapter can be found at [https://packt.link/JdOIY](https://packt.link/JdOIY).'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how copy-on-write filesystems work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building a container image is the first step that’s required when you develop
    an application using containers. In this chapter, we will learn about different
    methods to build images. But first, it will be interesting to deep dive into how
    images can be created in terms of filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: Containers are processes that run isolated thanks to kernel features. They run
    on top of a host system with its own filesystem as if they were running completely
    independently within their own sub-system. Files included in this filesystem are
    grouped in different layers, one layer on top of another. Files that have to be
    modified from a lower layer are copied to the layer where the modification is
    going to be made, and these changes are then committed. New files are only created
    on the upper layer. This is the basis of **copy-on-write** (**CoW**) filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: As we can expect with this model, the container runtime will manage all these
    changes. Every file modification requires host resources to copy the file between
    layers and, thus, makes this mechanism a problem to create files continuously.
    Before creating a new file in the upper layer, all layers must be read to verify
    that the file isn’t present yet to copy its content to the upper layer.
  prefs: []
  type: TYPE_NORMAL
- en: All these layers are presented in **read-only** mode to a container every time
    we create a container using a specific container image as a template, and a new
    layer is added on top of other layers in **read-write** mode. This new layer is
    the layer that will contain all the file changes since the container started.
    However, this behavior will occur in all containers running on your system. All
    containers based on the same container images share these read-only layers, which
    is very important in terms of disk usage. Only the **container layer** differs
    every time a new container is executed.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: All data that should persist across different container executions must be declared
    and used outside the containers’ life cycle – for instance, by using **volumes**,
    as we will learn in [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096), *Running
    Docker Containers*. We can declare volumes during the container-image-building
    process, which indicates that the content exists outside of the image’s layers.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, using these templates speeds up container creation and reduces
    the size of all containers in our systems. If we compare this with virtual machines,
    it works like virtual machine templates or snapshots. Only changes are stored
    at the host level, although it is important to mention here that containers use
    very little space.
  prefs: []
  type: TYPE_NORMAL
- en: However, performance is always affected when using CoW filesystems, which you
    should be aware of. Never store logs in a container layer as they may be lost
    if you remove the container, and it is very important to remember that due to
    the searching-copying-writing process for any file, your application performance
    may also be impacted. Therefore, we will never use a container layer to store
    logs, where processes are continuously writing files or monitoring data. You should
    write these files on remote backends or use the container volumes feature. This
    performance decrease applies when you write a lot of small files (thousands),
    the opposite (a few enormous files), or lots of directories with quite a deep
    tree structure. You, as a developer, must avoid any of these cases in your applications,
    and you should prepare your containers to avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the behavior of these CoW filesystems, applied to both container
    image creation and their execution, let’s learn how to build images.
  prefs: []
  type: TYPE_NORMAL
- en: Creating container images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review the different methods to build container images,
    along with their pros and cons and use cases, so that you can choose the right
    one, depending on your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three ways to create container images:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a base image within a Dockerfile, which is a recipe file that contains
    different automated steps that are executed to create an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interactively and manually executing commands and storing the resulting filesystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From an empty filesystem, using a Dockerfile recipe file and copying only the
    binaries and libraries required for our application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easy to see that the last method is the best in terms of security, but
    this can be difficult to implement if your code has many dependencies and is very
    integrated with operating system files. Let’s explore these methods, starting
    with the most common.
  prefs: []
  type: TYPE_NORMAL
- en: Using Dockerfiles to create container images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we describe this method, let’s learn what a **Dockerfile** is.
  prefs: []
  type: TYPE_NORMAL
- en: A Dockerfile is an **Open Container Initiative** (**OSI**)-compliant file that
    works as a recipe, containing a step-by-step procedure to create a container image.
    It contains a set of key-value pairs that describe different executions and meta-information
    regarding the image’s behavior. We can use variables to expand arguments that
    are passed when building images, and it is perfect for automation. If a Dockerfile
    is well written, we can ensure its reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned before, this file describes all the steps required to assemble
    an image. Let’s provide a quick overview of the steps taken in the presented Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: The first line, `FROM debian:stable-slim`, indicates that this container image
    will be taken as a base image; hence, all its layers will be used. The container
    runtime will download (*pull*) all these layers if they are not present in our
    host. If any of them are already in our host, they will be used. This layer could
    have come from any other image already in our host. Container image layers are
    reused.
  prefs: []
  type: TYPE_NORMAL
- en: The second line, `RUN apt-get update -qq && apt-get install -qq package1 package2`,
    executes all the content included as values. First, `apt-get update –qq` will
    be executed, and if it’s successful, `apt-get install -qq package1 package2` will
    be executed. This full step creates just one layer, on top of the previous one.
    This layer will automatically be enabled for any other image using the same execution,
    using the same `debian:stable-slim` base image.
  prefs: []
  type: TYPE_NORMAL
- en: The third line, `COPY . /myapp`, will copy all the files available in the current
    directory to a directory named `/myapp`, in a new layer. As mentioned in the second
    line, this also creates a reusable layer for any new image that contains the same
    entry.
  prefs: []
  type: TYPE_NORMAL
- en: The fourth line, `RUN make /myapp`, executes the `make /myapp` command and creates
    a new line. Remember that this is an example. We added a `make` sentence to build
    our source code. In this step, for example, we run a compiler, previously installed
    in the image, and build our binary artifact. All executing layers (those that
    include a `RUN` key) should exit correctly. If this doesn’t happen, the image
    build process will break and be stopped. If this happens, all previous layers
    will remain in your system. The container runtime creates a layers cache, and
    all following executions will reuse them by default. This behavior can be avoided
    by recreating all previous images during the build process.
  prefs: []
  type: TYPE_NORMAL
- en: The two final steps don’t add layers. The `CMD` key declares which command line
    will be executed (remember that a container runs a main process), and `EXPOSE`
    adds the meta-information regarding which port should be exposed (listening).
    This way, we explicitly declare in which port our application will listen to any
    kind of communication.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You should declare all relevant meta-information in your Dockerfiles, such as
    the *ports exposed*, the *volumes* for persistent data, the *username* (or *userid*)
    defined for your main process, and the command line that should run on startup.
    This information may be required by your container’s orchestrator administrators
    because it is very important to avoid security issues. They will probably force
    some security policies in the production platform that disallow your application’s
    execution. Ask them whether some security policies are applied to ensure you added
    the required information. Anyway, if you follow the security practices described
    in this book, you probably won’t have any problems in production.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this is a pretty reproducible process. This recipe will create
    the same image every time if we don’t change anything. This helps developers focus
    on their code. However, creating reproducible images is not that easy. If you
    take a closer look at the used `FROM` value, we use `debian:stable-slim`, which
    means that the default image `docker.io`. For now, you just have to know that
    a registry is a store for all container image layers. The value of the `FROM`
    key indicates that a `debian` image, with a specific tag of `stable-slim`, will
    be used, and thus, if Docker changes this image, all your image builds will also
    change. Tags are the way we identify images, but they are not uniquely identified.
    Each image and layer within images are uniquely identified by **digest hashes**,
    and these are the real relevant values that you should closely monitor. To get
    these values, we have to either pull the image or review the information in the
    defined registry. The easier method is to pull the image, which happens when you
    execute your build process, but in this example, we used a mocked Dockerfile,
    so it won’t work as-is.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s pull the image from the official Docker images registry, at [https://hub.docker.com](https://hub.docker.com),
    or by using the `docker.io` command-line tool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, we execute `docker image pull debian:stable-slim` to download this image
    from `docker.io`. All its layers will be downloaded. The Docker Hub website provides
    lots of useful information, such as all the tags associated with an image and
    the vulnerabilities detected in the contained files.
  prefs: []
  type: TYPE_NORMAL
- en: 'The digest shown in the previous code snippet will identify this image uniquely.
    We can verify the image of our system and review its information by executing
    `docker image inspect`, using its **image ID**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: All containers’ related objects are identified by object IDs, and as such, we
    can use them to refer to each object. In this example, we used the image ID to
    inspect the object.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use `–-digests` when listing local images to retrieve all their digests
    – for example, with the image used in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '`$ docker image` `ls --digests`'
  prefs: []
  type: TYPE_NORMAL
- en: '`REPOSITORY   TAG           DIGEST                   IMAGE ID       CREATED      ``SIZE`'
  prefs: []
  type: TYPE_NORMAL
- en: '`debian       stable-slim   sha256:f711bda490b4e5803ee7f634483c4e6fa7dae54102654f2c231ca58eb233a2f1   4ea5047878b3   9
    days ago   ``80.5MB`'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that image IDs are different from their digests. The
    ID represents the current compilation or identifier generated on your system,
    while the digest represents the compendium of all the layers and essentially identifies
    the image anywhere – on your laptop, on your servers, or even in the registry
    where it is remotely stored. The image digest is associated with the image content
    manifest ([https://docs.docker.com/registry/spec/manifest-v2-2/](https://docs.docker.com/registry/spec/manifest-v2-2/))
    and is used in V2 registries (the current version for most modern registry implementations).
    Since your local builds are not in a registry format, the digest will be displayed
    as `none`. Pushing your images to a V2 registry will change this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review this process, as well as the image IDs and digests, by looking
    at a quick and simple example. We will build a couple of images using the following
    two lines of a Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the current `debian:stable-slim` image, we will update its content and
    install the `curl` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will build two images, `one` and `two`, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – The execution of two consecutive container image builds. No
    changes are expected; hence, the images are equal](img/B19845_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – The execution of two consecutive container image builds. No changes
    are expected; hence, the images are equal
  prefs: []
  type: TYPE_NORMAL
- en: The first build process will create a layers cache, and thus, the second build
    will reuse them and the process will be faster as the layers are the same. No
    installation process will be triggered. We have used the current directory as
    the **build context**. Container runtimes such as Docker are executed in a client-server
    model, and as such, we talk with the Docker daemon using our Docker command line.
    The building process sends all files in the *current context* (*path*) to the
    daemon so that it can use them to create the image’s filesystem. This is critical
    because if we choose the wrong context, a lot of files will be sent to the daemon,
    and this will impact the building process. We should correctly specify which directory
    contains our code, and this will be used during the build process. In this context
    folder, we should avoid binaries, libraries, documentation, and so on. It is important
    to note that we can use Git repositories (in URL format) as the build context,
    which makes it very interesting for CI/CD integrations.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid sending irrelevant files to the daemon during the build process, we
    can use the `.dockerignore` file. In this file, we will add the list of files
    and folders that should be excluded, even if they are present in our build context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review the information we have from these images on our system. If we
    execute `docker image ls –digest`, we will obtain their image IDs and their digests:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – A list of the created container images, showing their completely
    equal IDs](img/B19845_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – A list of the created container images, showing their completely
    equal IDs
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we can see is that both images, `one` and `two`, have the same
    image ID. This is because we reused their layers. In the second build process,
    using the same Dockerfile, the container runtime reuses all previous equal image
    layers (those coming from the same execution), and the image was created very
    fast. They are the same image with two different tags.
  prefs: []
  type: TYPE_NORMAL
- en: We can also see that only the base image shows its digest. As mentioned previously,
    it is the only one that comes from a V2 registry. If we upload one of our images
    to *Docker Hub* (or any other V2-compatible registry), its digest will be created.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To be able to upload images to Docker Hub, you need a working account. Create
    your account by going to [https://hub.docker.com/signup](https://hub.docker.com/signup).
    The process is pretty simple, and you will have a Docker Hub registry account
    within a minute.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how uploading the image works and how it will have its immutable and
    unique reference digest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before initiating the process, we will just log in to Docker Hub using our
    account name. We will be prompted for our password, after which we should receive
    a `Login` `Succeeded` message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now that we are logged in, we need to retag our image. Image tags are the human-readable
    format we use to reference images. In the build processes used for this example,
    we used `one` and `two` as tags through the command line by writing `docker build
    –t <TAG>`. However, we saw that both were the same image; hence, we can say that
    tags are names for an image ID, which may cause you some confusion. *Can we trust
    image tags?* The short answer is, *no, we can’t*. They don’t represent a unique
    image state. We can have different tags for an image ID and change these images,
    but if you still use those tags, you will be using completely different images.
    In our example, anyone can change our `debian:stable-slim` image. If we rebuild
    some of our images, based on this tag, we will create a new image with completely
    different content. What if the new image contains some code exploitation because
    a malicious attacker included it in that base image? This should not happen in
    very controlled image registries such as Docker Hub, but this problem does exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s retag and upload our image by using `docker tag` and then `docker push`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Tagging and pushing an image to obtain its digest](img/B19845_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – Tagging and pushing an image to obtain its digest
  prefs: []
  type: TYPE_NORMAL
- en: Note that we need to push the image. Just re-tagging does not work. Now, we
    have a unique image, and anyone can use our tag to reference it. If we update
    our `one` image, by adding some new content or changing the command line to be
    executed, this digest will change. And even if we still use the same `frjaraur/one`
    tag, a new build process using our image will create new content.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: As a developer, you should be aware of any changes introduced in the images
    you use as a reference for creating your images. You might be wondering which
    method is correct to manage these changes. The short answer would be always using
    image digests (following the example tags and digest, we will use `FROM debian:stable-slim@sha256:f711bda490b4e5803ee7f634483c4e6fa7dae54102654f2c231ca58eb233a2f1`).
    This method can be very complex, but it is the most secure. Another method would
    be using your own registry, isolated from the internet, where you store your images.
    With your own managed private registry, you may be comfortable using image tags.
    You will be the only one able to update your base images; hence, you manage the
    complete image life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned at the beginning of this example, we built two images using
    the same Dockerfile, and we realized that both images have the same image ID;
    hence, they are exactly the same. Let’s change this a bit and use the `docker
    build –no-cache` option, which avoids reusing previously created layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Executing the image-building process without a cache](img/B19845_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – Executing the image-building process without a cache
  prefs: []
  type: TYPE_NORMAL
- en: We can see that a completely new image was built, even though we are using the
    same Dockerfile. This is due to the time between executions. Layers change between
    build executions because we made modifications at two different points in time.
    Of course, we can also include new changes due to package updates, but in this
    case, it is even simpler.
  prefs: []
  type: TYPE_NORMAL
- en: What we can learn from this is that reusing layers helps us maintain image sizes
    and build times (we didn’t notice this in this example because we used a simple
    two-line Dockerfile, but when you are compiling or downloading a bunch of modules
    for your code, it can take a lot of time), but when we need to refresh the image
    content, disabling the cache is a must. This is very useful when we create base
    image files for our projects – for example, our own .NET Core and Python projects.
    We will use these base images, uploaded into our registry, and we will be sure
    of their content. When a new release arrives, we can rebuild these images and
    all their dependent images (our applications’ images). This process should be
    part of our automated CI/CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how to build images using Dockerfiles, we will move on
    to a new method that can be helpful in very specific cases.
  prefs: []
  type: TYPE_NORMAL
- en: Creating container images interactively
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We haven’t mentioned it before, but it is important to comment here that the
    Dockerfile `RUN` lines create intermediate containers to execute the commands,
    written as values after the `RUN` key. Hence, the `docker build` command launches
    a series of chained containers that create the different layers that are finally
    part of an image. Before executing a new container, this process stores the modified
    files (container layer) in the system, using the container runtime’s `commit`
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: These containers run one after another, using the layer created by the previous
    one. The interactive process we are about to describe follows this workflow in
    a simplified way. We will run a container, using an image as a base, and manually
    run and copy all the commands and content required by our application. Changes
    will be created on the fly, and we will commit the created container layer when
    we have finished. This method may be interesting when we need to install software
    that asks for different configurations interactively and we can’t automate the
    process.
  prefs: []
  type: TYPE_NORMAL
- en: This method lacks reproducibility and shouldn’t be used if we can find a way
    to automate the image creation process. No one will have any clue of how you installed
    the content inside the image (the shell history will contain the steps if you
    didn’t remove it, but interactive commands will not be there). Let’s introduce
    a command that will help us understand how images were built – `docker image history`.
    This command shows all the steps taken to create an image, including the meta-information
    added in the process, in reverse order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at this output using one of the images from the previous
    section, *Using Dockerfiles to create* *container images*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Reviewing all the steps that were used to create a container
    image](img/B19845_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – Reviewing all the steps that were used to create a container image
  prefs: []
  type: TYPE_NORMAL
- en: Image history must be read in reverse order, starting from the latest line.
    We will start with an `ADD` key, which represents the initial `FROM` key from
    our Dockerfile. This is because the `FROM` key is interpreted as copying all the
    base image content on top of the base layer.
  prefs: []
  type: TYPE_NORMAL
- en: We used `–-no-trunc` to be able to read the full command line from the output.
    We can easily see that this image was created using the `/bin/sh -c apt-get update
    –q && apt-get install –qq curl` command. The `docker image history` command will
    show us the steps that were executed to build any image created from a Dockerfile,
    but it won’t work for interactively created ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see a simple example of installing a Postfix mail server using the *Debian*
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – The manual execution of a Postfix mail package](img/B19845_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – The manual execution of a Postfix mail package
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the installation process has finished, we will be prompted to configure
    various aspects of the server. This configuration is completely interactive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – The Postfix installation is interactive because it asks users
    for specific configurations](img/B19845_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – The Postfix installation is interactive because it asks users for
    specific configurations
  prefs: []
  type: TYPE_NORMAL
- en: 'The installation process will ask you for some configurations interactively
    and after that, the Postfix server will be ready to work. We can exit the container
    process by executing `exit`, and we will commit the container layer as a new image.
    We use `docker container ls –l` to only list the last container executed, and
    then we execute `docker commit` (or `docker container commit` – both commands
    will work as they both refer to containers) to save the current container layer
    as a new image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Committing the container layer to create an image](img/B19845_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – Committing the container layer to create an image
  prefs: []
  type: TYPE_NORMAL
- en: However, as we previously mentioned about this method, we can’t know the steps
    taken to create the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try using the `docker image` `history` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – History does not show any commands when an interactive process
    was followed](img/B19845_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 – History does not show any commands when an interactive process
    was followed
  prefs: []
  type: TYPE_NORMAL
- en: All we can see in the output is that we used `bash` to do something. We will
    have the commands in its `.bash_history` file, but this is not how things should
    be done. If you must use this method in specific cases, such as when your application’s
    installation requires some interactive steps, remember to document all the changes
    you made in the file to let other developers understand your process.
  prefs: []
  type: TYPE_NORMAL
- en: This method is not recommended because it is not reproducible, and we can’t
    add any meta-information to the container image. In the next section, we will
    describe possibly the best method to remedy this, but it requires a lot of knowledge
    about your application binary files, libraries, and hidden dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Creating images from scratch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this method, as its name already indicates, we will create an empty layer
    and all files will be introduced, using a packaged set of files. You may have
    noticed that all the image history we have seen so far involved using the `ADD`
    key as the first step. This is how a container runtime starts the building process
    – by copying the content of the base image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this method, you can ensure that only explicit required files will be
    included in the container image. It works very well with coding languages such
    as Go because you can include all their dependencies in binaries; hence, adding
    your compiled artifacts will probably be enough for your application to work correctly.
    This method also uses Dockerfile files, but in this case, we will start with a
    simple `FROM scratch` line. This creates an empty layer for our files. Let’s take
    a look at a simple example Dockerfile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is a simple Dockerfile in which we just add files and meta-information.
    It will contain our binary file, on top of an empty structure, and the meta-information
    required to build a complete container image. As you can imagine, this method
    creates the most secure images because the attack surface is completely reduced
    to our own application. Developers can create images from scratch, packaging all
    the files required for their applications. This can be very tricky and lots of
    effort is required to include all dependencies. As mentioned earlier in this section,
    it works very well with applications running static binaries, which include all
    their dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: This method can also be used to create images based on exotic or highly customized
    operating systems for which we don’t have base images. In these cases, you should
    remove all non-required files and all references to the underlying hardware. This
    can be very difficult, and that’s why it is usually recommended to use official
    container images. We will learn a bit more about the different types of images
    and how to ensure their origin, immutability, and ownership in [*Chapter 3*](B19845_03.xhtml#_idTextAnchor082),
    *Shipping* *Docker Images*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to make container images using different methods, we should
    review the most important keys we will use in Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding common Dockerfile keys
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will take a look at the most important keys and their best
    practices. For full reference, it is better to review the documentation provided
    by Docker Inc. ([https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)).
  prefs: []
  type: TYPE_NORMAL
- en: Container runtimes can create container images by reading a series of instructions
    written in a Dockerfile. Following this recipe-like file, a container runtime
    will assemble a container image.
  prefs: []
  type: TYPE_NORMAL
- en: FROM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All Dockerfiles always start with a `FROM` key. This key is used to set the
    base image and initialize the build process. We can use any valid container image
    as a valid value for the `FROM` key, and a `scratch` keyword is reserved to build
    images based on an empty layer.
  prefs: []
  type: TYPE_NORMAL
- en: A Dockerfile can include multiple image build processes, although usually, we
    will use different files for each process.
  prefs: []
  type: TYPE_NORMAL
- en: We can refer to images using their names and tags, and we can include their
    digests to ensure image uniqueness. If no tag is used, `latest` will be used automatically.
    Try to avoid this bad practice and always use the appropriate tag, or, even better,
    add its digest if you use public image registries. It is also possible to define
    a reference for each building process using the `AS` key. This way, we can share
    content between container images built with a unique Dockerfile. **Multi-stage
    building** is a practice in which we copy content from an image into others. We
    will explore a use case in the *Advanced image build processes* section later
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, a Dockerfile can include multiple build definitions,
    and we will name them using the `AS` key, which allows us to execute only specific
    targets, and the `–-``target` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'To modify the behavior of the building process, we will use the `ARG` and `ENV`
    keys. We can use the `–-build-arg` option to include additional arguments in the
    build process, and the container runtime will evaluate these values whenever the
    `ARG` key is found. The following line shows an example of how arguments can be
    passed to the `build` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note here that we used a specific `context` and non-default Dockerfile by adding
    the `–file` argument. We also added `myvalue` to the `myvariable` variable, and
    we should have included the `ARG` key in the `myDockerfile` file to expand this
    value.
  prefs: []
  type: TYPE_NORMAL
- en: ARG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ARG` is the only key that can be used before `FROM` to use build arguments
    – for example, to choose a specific base image. As a developer, you may want to
    have two different images for production and development, with some small changes,
    such as enabling debugging flags. We will use only one Dockerfile, but two build
    processes will be triggered, depending on the arguments passed. The following
    simple example may help you understand this use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We will use `–build-arg CODE_VERSION=prod` whenever we need to build a production
    image, using a specific base image, `base:prod`, which may contain fewer files
    and binaries.
  prefs: []
  type: TYPE_NORMAL
- en: It is also usual to add the `ENV` key with `ARG`. The `ENV` key is used to add
    or modify environment variables for the containers that are used during the build
    process – for example, to add some path to `LD_LIBRARY` or change the `PATH` variable.
    `ARG` can then be used to modify environment variables at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: To include meta-information in our final container image, we can use the `LABEL`
    key. Labels will help us identify a framework that’s been used, a release version,
    the creator and maintainer of the content, and so on, or even a short description
    of its usage.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The OCI defines some conventional labels that may be used, and it would be interesting
    to use them instead of creating your own as many applications integrate this standard.
    You can review these labels at [https://github.com/opencontainers/image-spec/blob/main/annotations.md](https://github.com/opencontainers/image-spec/blob/main/annotations.md).
    You will find labels such as `org.opencontainers.image.authors`, `org.opencontainers.image.vendor`,
    and `org.opencontainers.artifact.description`, all of which are standard and integrated
    into many container-related tools.
  prefs: []
  type: TYPE_NORMAL
- en: WORKDIR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All command executions defined in a Dockerfile will run relative to a working
    directory. We can change this by using the `WORKDIR` key. Once defined in our
    Dockerfile, all subsequent defined steps will use this environment – for example,
    to copy files inside the image layers.
  prefs: []
  type: TYPE_NORMAL
- en: COPY and ADD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adding files to image layers is always needed. We will include our code or binaries,
    libraries, some static files, and so on. However, we shouldn’t add certificates,
    tokens, passwords, and so on. In general, any content that requires some security
    or may change frequently must be included during runtime, and not in the image
    layers.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the `COPY` and `ADD` keys to add files to image layers. The `COPY`
    instruction copies files and directories into specified image paths. If relative
    paths are used for the source, files must be included in the build context directory.
    If relative paths are used for the destination, the `WORKDIR` key will be used
    as the reference path. We can also copy files from other images declared in the
    same Dockerfile by using `–-from=<IMAGE_TARGET_NAME>`. It is important to note
    that file ownership can be changed using the `–-chown=<USERNAME or USERID>:<GROUPNAME
    or GROUPID>` command; if omitted, the user from the current container execution
    step will be used.
  prefs: []
  type: TYPE_NORMAL
- en: '`ADD` works like `COPY`, but in this case, you can use remote URLs as a source,
    as well as TAR and gzip packaged files. If you use a compressed and packaged file,
    it will be unpackaged and uncompressed automatically for you in the specified
    destination.'
  prefs: []
  type: TYPE_NORMAL
- en: Each file that’s passed is verified against the checksums of image files, but
    the modification time isn’t recorded, so you must be aware of the changes you
    make to your files before executing the building process. It is better to add
    a separate `COPY` line for those files you are often editing (for example, your
    application’s code), or simply disable caching if you are not sure whether your
    file changes were correctly copied.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid copying some files inside our project folders, we can use the `.dockerignore`
    file. This file contains a list of files that shouldn’t be included in the Docker
    build context; hence, they will not be copied into the image layers.
  prefs: []
  type: TYPE_NORMAL
- en: RUN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `RUN` key is used to execute the command line inside containers that were
    created during the build process. This action is fundamental to creating container
    images. All commands passed as a value to this key will be executed, and the resulting
    container layer will be committed as a new image layer; hence, all the `RUN` keys
    create a layer. Only the `COPY`, `ADD`, and `RUN` keys create layers; none of
    the other keys increase image size because they modify the resulting image behavior
    and add meta-information. You will probably see the `RUN` values use multiple
    lines, starting with `&&` and ending with `\`. This simple trick will avoid the
    creation of new layers for each command executed. This way, you can concatenate
    multiple executions in one line and separate them into multiple lines for easy
    reading. Lines will be treated as if they were just one line, and thus, only one
    layer will be created. You should take care here because you may lose layer reusability,
    and this method can also mask errors during building processes. If you are having
    issues with one long line that contains a lot of commands, decouple them into
    multiple executions to isolate the error and, once solved, concatenate the lines
    again to create just one line.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple example would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: These five lines will be interpreted like three different executions in the
    same container, so they will just create one layer for the final image.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that the build process does not store process
    states. This means that if we run a process and we expect it to be running upon
    the next `RUN` line, it won’t because the container runtime only stores files
    from the container layer. This also applies to services or daemons. The build
    process will not work if you expect to have some processes already running and
    you apply some data or files to them. Each execution ends when the `RUN` line
    is processed.
  prefs: []
  type: TYPE_NORMAL
- en: USER
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, the container runtime will execute all commands inside containers
    with `userid`, which is defined in the base image, and `root` if we are creating
    an image from scratch. You will find that most official Docker container images
    will run as `root`. Docker Inc. and other vendors prepare their images to allow
    you to install and manage additional software and binaries. You should ensure
    that your images run with the principle of *less privilege*, and thus, you must
    declare which user will run a container’s main process. Dockerfile’s `USER` key
    will help us define this user and even switch them multiple times in the same
    Dockerfile. Switching users will ensure that each Dockerfile line runs with the
    appropriate user, and containers created with this image will also run with the
    right user.
  prefs: []
  type: TYPE_NORMAL
- en: It is mandatory to avoid using containers with privileged users. This will essentially
    protect your applications and the underlying infrastructure. If you need to use
    `root` or any other privileged users, you should declare this situation explicitly.
    You can use a label, for example, to indicate that your image requires a privileged
    account to run.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you are developing an application that requires a root user for its execution,
    you can use user namespace mappings. This feature lets us map a container’s root
    user with a normal user in our host. If you need to set up this feature, you can
    follow the instructions provided at [https://docs.docker.com/engine/security/userns-remap/](https://docs.docker.com/engine/security/userns-remap/).
  prefs: []
  type: TYPE_NORMAL
- en: ENTRYPOINT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s introduce how to declare which processes will run inside our container.
    The following keys add the meta-information required in an image to define which
    binary or script will run.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the `ENTRYPOINT` key to define the main process the container will
    run. If this key isn’t defined, the `/bin/sh` shell will be used for Linux containers
    and `cmd.exe` for Microsoft Windows containers. This key can come already modified
    in our base images, with a custom value, but we can also override it in our Dockerfile
    declaration to modify our container’s behavior.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use the `CMD` key, which allows you to specify which arguments
    should be passed to the shell, Windows command, or any other defined `ENTRYPOINT`.
    As such, we can think of the main process execution as the concatenation or sum
    of the `ENTRYPOINT` and `CMD` keys. For example, if we use the default `/bin/sh`
    shell’s `ENTRYPOINT`, and we define our `CMD` key as `ping 8.8.8.8`, the final
    command that executes inside our container will be `/bin/sh -c ping 8.8.8.8`;
    in other words, a shell is expanded to execute our `ping` command. We can modify
    any of them during container creation, but remember that the user defined with
    the `USER` key will be the process’s owner.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, we can change image behavior by changing these very
    important keys. `ENTRYPOINT` and `CMD` are managed by the container runtime as
    arrays, although we can define them in our Dockerfile as strings, which are also
    commonly used to manually execute a container. The container runtime concatenates
    both arrays to build the final command line. Due to this behavior, setting `ENTRYPOINT`
    as a string will force `CMD` to be ignored, but we can use `CMD` as a string while
    `ENTRYPOINT` is an array, and `CMD` will be treated as an array of 0 size.
  prefs: []
  type: TYPE_NORMAL
- en: Both values can be overridden on container execution, but usually, we will just
    customize the container arguments by using `CMD`; as such, this key can be used
    in the Dockerfile as a default value. As a developer, you should always provide
    as much information about your application’s behavior as possible to make it usable,
    and `LABEL`, `USER`, and `CMD` must be present in your Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: EXPOSE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We should also add the `EXPOSE` key to this list, which defines what ports will
    be used by your application. You can define as many ports as required using ranges
    and the transport protocol that will be used, be it TCP or UDP. With this information,
    you will ensure that anyone using your application will know which ports your
    processes will be listening to.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following scheme shows a simple Dockerfile stack in practice, including
    the container layer on top:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – The schema of container image layers created by using a Dockerfile.
    The container layer is on top to keep track of changes created by processes](img/B19845_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – The schema of container image layers created by using a Dockerfile.
    The container layer is on top to keep track of changes created by processes
  prefs: []
  type: TYPE_NORMAL
- en: 'This figure represents the order obtained by using the `docker image history`
    command. For this example, we performed the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: We used a simple `alpine:3.5` base image. We updated the package sources and
    installed `nginx` and `curl`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we prepared NGINX logs to stream their output to `/dev/stdout` and `/dev/stderr`.
    This will ensure that we can read the application logs through the container runtime
    because these descriptors will be used by the container’s main process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We copied our custom NGINX configuration file, overwriting the default one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We exposed port `80`, indicating that our main process will listen on this port.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we defined the default command line. In this case, `/bin/sh -c "nginx
    –g daemon off;"` will be executed every time we run a container using this image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: HEALTHCHECK
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To ensure that our main process runs correctly within our container, we should
    add a health probe that will indicate whether this process is healthy or not.
    Let’s imagine we run a web server application and it gets stuck. Processes will
    continue running but functionality will be completely lost. To remedy this, we
    can use the `HEALTHCHECK` key to define a command line that will check our main
    application’s health. We can use a script or binary with arguments, such as `curl`
    for web servers, or a database client if we run a database server. What is very
    important for health checks is that the command exits correctly (`exit 0`) if
    the application is healthy. If our check process exits with any other signal,
    the container will die as a result of the application being set as unhealthy.
    The `HEALTHCHECK` key will allow us to manage how the checks must be executed,
    to keep the application up and running. We can modify the number of checks that
    will mark the main process as unhealthy and the interval for these checks. When
    the defined number of tries is reached with a negative response (any exit different
    than 0), the container runtime is informed that even if the main process seems
    to be running correctly, the service is not working, and the container should
    die. This usually means a new healthy one is created, but for this process to
    work, we should configure that container with the `restart: always` option. We
    will deep dive into container execution in [*Chapter 3*](B19845_03.xhtml#_idTextAnchor082),
    *Running* *Docker Containers*.'
  prefs: []
  type: TYPE_NORMAL
- en: VOLUME
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To end this section, we will review the `VOLUME` key. As the container image
    build process is based on the execution of multiple containers and storing their
    layers, this key is used to avoid certain directories from a container’s life
    cycle. It is good practice to include this key to indicate which folders in your
    image you prepared for persistent storage. You can use this key after all the
    `RUN` keys to avoid losing an application’s folders during the build process.
  prefs: []
  type: TYPE_NORMAL
- en: We have provided clear and simple examples of these keys to help you understand
    their usage at the end of this chapter, in the *Labs* section.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will present you with some of the most important command-line
    options that are commonly used to build container images.
  prefs: []
  type: TYPE_NORMAL
- en: The command line for creating images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will take a closer look at Docker and other tools that you
    will commonly use to create container images for your projects.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by reviewing the `docker` command line, which is the most popular
    tool for developers and users due to its simplicity and friendly environment.
  prefs: []
  type: TYPE_NORMAL
- en: Docker uses a common schema for all its arguments and options. We will use `docker
    <OBJECT> <ACTION> <OPTIONS>`. As a Docker container runtime identifies its objects
    by their IDs, it is common to omit the `<OBJECT>` primitive, but you should make
    sure that you use the right object. It is improbable that you will commit an error,
    but it is good practice to remember to include the object as part of the command.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the basics – that is, learning which command will create an
    image.
  prefs: []
  type: TYPE_NORMAL
- en: Actions for creating images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We use the `build` action to create images using a Dockerfile. By default,
    it will search for a file in your current directory, but we can use any name and
    path to store our build manifests. We must always declare the build context, and
    usually, we will use the `–tag` option to define a name and tag for our image.
    Here is an example of its common usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Executing a simple image build process](img/B19845_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – Executing a simple image build process
  prefs: []
  type: TYPE_NORMAL
- en: In this example, `context2` is the name of the folder that contains all the
    files that should be sent to the container runtime, some of which should be copied
    to the final image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the most common options that you will probably add to `docker` `image
    build`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--build-arg` is the way we can provide arguments for the build process. It
    is commonly used with the `ARG` Dockerfile key to modify image creation – for
    example, we can use `build` arguments to add some **c****ertificate** **a****uthority**
    (**CA**) certificates to the commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'When you are behind a proxy server, it is very common to pass the well-known
    Linux `HTTPS_PROXY`, `HTTP_PROXY`, and `NO_PROXY` variables as arguments using
    -`–build-arg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker build --build-arg` `HTTP_PROXY=$http_proxy \`'
  prefs: []
  type: TYPE_NORMAL
- en: '`--build-arg HTTPS_PROXY=$http_proxy --build-arg` `NO_PROXY="$no_proxy" \`'
  prefs: []
  type: TYPE_NORMAL
- en: '`--build-arg http_proxy=$http_proxy --build-arg` `https_proxy=$http_proxy \`'
  prefs: []
  type: TYPE_NORMAL
- en: '`--build-arg no_proxy="$no_proxy" -t` `myimage:tag mycontext`'
  prefs: []
  type: TYPE_NORMAL
- en: '`--force-rm` will clean all intermediate containers. By default, all containers
    created during the building process will remain in your host unless your process
    ends successfully, hence occupying disk space. It is good practice to clean intermediate
    containers if you know that your build will create big layers – for example, when
    your application is compiled in containers and many dependencies are created,
    after which the process breaks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--label` will let you add further labels to your container image. Adding all
    the required information, such as special library versions, the author, a short
    description, and anything that will let other developers understand your content,
    will be greatly appreciated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--no-cache` will let us decide whether previously created and locally stored
    layers will be used. Using this argument, your build process will create fresh
    new layers, even if they already exist in your host. Be aware that without caching,
    all processes will be executed and store the intermediate container data locally;
    hence, the build will take more time. You will gain a faster build process by
    reusing the layers already included in your underlying host as much as possible.
    This can be very important when you are compiling your applications inside your
    image build, where a few minor changes will restart processes completely if no
    caching is used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--target` is used to identify a build definition inside a Dockerfile. This
    can represent a specific compilation or a stage in a multi-stage build. We can
    use targets, for example, to maintain a unique Dockerfile with different build
    definitions, such as `small`, `complete`, and `debug`, each one requiring different
    steps and base images. We can trigger the build process for one specific definition
    to build the smallest release for a production environment. This can also be managed
    with arguments, with different base images chosen depending on variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--cpuquota`, `--cpu-shares`, and `--memory` will help us manage the resources
    available per build process. This is especially interesting if you are running
    out of resources on your desktop computer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have learned about the command line to build images, let’s look
    at managing images.
  prefs: []
  type: TYPE_NORMAL
- en: Managing container images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Container images will reside in your host in different directories, decoupling
    the data files from the meta-information. The location of your files will depend
    on the container runtime you are using, or in the case of **Podman**, they will
    probably be in your home directory. This runtime runs in rootless mode and without
    any daemon, so it is ideal for user containers. Irrespective of this, you will
    never directly access container image files.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most commonly used actions within Docker (and any other container
    runtime client) is `list` (or `ls`), which is used to list the objects available
    in our host (or remote runtime). By default, images can be represented by their
    names (or repositories – we will learn how to store and manage images in these
    repositories in [*Chapter 3*](B19845_03.xhtml#_idTextAnchor082)*, Shipping Docker
    Images*), IDs, tags, creation time, and size. In this context, size is the amount
    of space the image occupies in our host. The smaller the images, the better, and
    that’s why you, as a developer, should be aware of the content of your images.
    Include only strictly necessary files, and think about your layer strategy if
    you are working with projects in which you share dependencies. Use the `.dockerignore`
    file to avoid non-required files as this can help you save a lot of space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code snippet shows that we have multiple names (repositories)
    with the same content; we know this because they have the same ID. Images with
    the same ID are equal; they just differ in their tags. Therefore, we can add more
    than one tag to an image. We will use `docker tag <ORIGINAL> <NEWTAG>` to tag
    images. This is necessary to be able to upload images to registries as they are
    stored in their own repositories. Tags will help you identify images in our registry,
    but although tags are unique in each repository, we can have a lot to refer to
    the same image, and you should ensure that you are using the right image.
  prefs: []
  type: TYPE_NORMAL
- en: Developers may choose to tag their images following the application’s life cycle,
    and you will probably encounter many images tagged using the `release.minor.fixes`
    model. This is good practice, and adding some key labels to identify the author,
    the project, and so on will improve your work.
  prefs: []
  type: TYPE_NORMAL
- en: You probably also noticed an image without any tag or name. This is a *dangling*
    container image that has been unused by others, and it is untagged because another
    one was created using the same repository and tag. It is not referenced by any
    image and now just occupies space. These dangling images should be removed, and
    we can use `docker image prune` to delete all of them.
  prefs: []
  type: TYPE_NORMAL
- en: To delete individual images, we can use `docker image rm <IMAGE>`. It is important
    to understand that images cannot be removed if there are references to them in
    containers or other images. We can force the removal by using `–force`, but it
    will only work if containers are stopped (or dead). It is also worth noting that
    multiple image tags can be deleted by using their ID, instead of their image repository
    names.
  prefs: []
  type: TYPE_NORMAL
- en: To review all the information included in the container image object, we can
    use `docker image inspect <IMAGE>`. Very useful information will be presented,
    including the image digest (if the image has a reference from a registry), the
    architecture for which the image was built, its labels, its layers, and the configuration
    that will be used to start the containers, such as environment variables and the
    main command to be executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth introducing some formatting and filtering options we can use with
    some commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--filter` will allow us to use defined labels to filter objects from a list.
    This will work for any list provided by the container runtime – for example, if
    we labeled our images with the `environment` key, we could use it to obtain only
    specific images:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker image list \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --format "table {{.Repository}}:{{.Tag}}\t{{.Size}}"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: REPOSITORY:TAG        SIZE
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: example1:0.0          9.51MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: postfix:test          169MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: frjaraur/two:180223   105MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: two:latest            105MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: one:latest            105MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: frjaraur/one:180223   105MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: alpine:latest         7.05MB
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: docker image ls --format "{{json .}}".To obtain all the labels from a specific
    image, we can use `docker image inspect <IMAGE> --format "{{ index .``Config.Labels
    }}"`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the next section, we will learn about the options available at the command
    line to share images between hosts or users.
  prefs: []
  type: TYPE_NORMAL
- en: Actions for sharing images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may be thinking, all these examples were built on a host, so we need to
    be able to share our images with other developers, or even move them to the servers
    that are prepared to manage the application’s life cycle (such as testing, staging,
    certification, or production). We can dump our container images and import them
    to new locations, but using image registries is a better option because these
    stores will be shared with the containers’ orchestrators, and the container runtimes
    will automate the pull process for us.
  prefs: []
  type: TYPE_NORMAL
- en: '`docker image pull` and `docker image push` to pull and push images, respectively.
    For this to work, you’re usually required to log in to your registry. To be able
    to access your registry, you will require a username and a password. Docker Hub
    (`docker.io`) is probably the most recognized container registry. It works as
    a cloud service, providing an image store, scanning, and automations to build
    images. There are other options; all cloud providers offer registry services,
    and many code repositories also provide an image store (as they are considered
    code artifacts). We can deploy some of these solutions on-premises, but we can
    find also solutions such as Harbor, from VMware, which was prepared specifically
    for data centers. You may notice that your container runtime also stores images,
    and in fact, it can be considered a registry – a local registry. The `podman`
    command line, which supports all actions described in this chapter and can be
    used instead of the Docker client, will build your images as `localhost/IMAGE_NAME:TAG`,
    where `IMAGE_NAME` is the name of the repository. We will learn how image registries
    work in [*Chapter 3*](B19845_03.xhtml#_idTextAnchor082), *Shipping Docker Images*;
    for now, we will just review the most commonly used options to share images.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When someone asks us for an image, we can use `docker image save` to dump a
    container image to a file. This will completely package all its layers and meta-information.
    By default, standard output will be used to stream all data, but we can use the
    `–output` option to specify a file. You can copy this file to another workstation
    or server and execute `docker image load` to import all image layers and metadata.
    By default, the command will use standard input, but we can add the `–input` option
    to specify a file instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Saving images to files for sharing is easy](img/B19845_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 – Saving images to files for sharing is easy
  prefs: []
  type: TYPE_NORMAL
- en: We can verify that the image size is retained, and if we list the files included
    in the package file, we will obtain the layers and metadata files.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker client can be used with `docker image load` to integrate this image
    into our local registry, but we can also use `docker image import` to only upload
    image layers. This is interesting as it can be used as the base image for builds
    from scratch, but be aware that without the metadata manifest JSON file, you would
    not be able to execute a container. You will need to add its exposed ports, user,
    main process, arguments, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, `docker image save` and `docker image load` work in small
    environments, but they don’t when you need to distribute files on a dozen servers.
    Images are hard to sync if you don’t maintain good tag maintenance; hence, try
    to use representative tags and label your images to help others understand their
    content.
  prefs: []
  type: TYPE_NORMAL
- en: Before reviewing some best practices and recommendations, we will learn about
    some topics that will help us optimize our workflow so that we can build new images.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced image creation techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will review some options and techniques available to speed
    up the building process and optimize image sizes.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B19845_01.xhtml#_idTextAnchor015), *Modern Infrastructure and
    Applications with Docker*, we learned that images are a package of layers. These
    layers are distributed one over another, containing all the files, and the merging
    of all these layers gives us a distribution of files optimized for disk space
    reduction, using CoW filesystems. When a file from a lower layer has to be modified,
    it is copied to the top layer if it doesn’t exist there yet. All unmodified files
    are used in read-only mode. With that said, it is easy to understand that managing
    the CoW process correctly will help speed up image creation times.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we add new `RUN` commands at the end of our Dockerfile, all previous
    layers will be used (unless we specify `–-no-cache`); hence, the container runtime
    just needs to create new layers according to these new changes. However, whenever
    we add a new line to copy a new file in the middle of the Dockerfile, or even
    when a file has been modified, the layers included after this change are invalidated.
    This occurs with `COPY`, `ADD`, and `RUN` because these Dockerfile keys add new
    layers, but `WORKDIR` and `ENV` can also modify the building process behavior
    and, hence, the subsequent layers. Once a layer changes, the container runtime
    has to rebuild all downstream layers, even if we didn’t modify any line in our
    Dockerfile after the aforementioned change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some recommendations that may help your building process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-stage builds are key to minimizing and securing container images. We
    will define different targets in our Dockerfile to use them as stages to compile
    our code and dependencies, and we will add only the required files to the final
    image. With this technique, we can ensure that no compilers will be included in
    the final image. This is a simple example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is a very simple Dockerfile; the final image contains only the docs directory,
    retrieved from our Git code repository. We will see a better example in this chapter’s
    *Labs* section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Ordering layers is key to speeding up and maintaining application changes. Try
    to find the best logical order to declare your Dockerfile’s recipe. If we have
    some time-intensive tasks, such as installing a lot of software packages, it is
    preferable to make these changes at the beginning of the build process. Conversely,
    the files that we change more often, probably our application’s code, should be
    close to the end of the Dockerfile.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This also works with the `COPY` key; if your application has a lot of dependencies,
    copying all your code and requirements at once can be problematic. It is better
    to split your files into different `COPY` sentences and copy your module requirements
    declaration files, then update these dependencies, and after that, copy the code
    for building. This ensures that all our code changes will not cause the dependencies
    to be downloaded again in the container-building process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have to remind you again that you should only keep the necessary files inside
    container images. Avoid any unnecessary files. This will increase the building
    time and the final image size, and sometimes, it may be relevant to decide where
    to store them. Also, using `.dockerignore` will help you avoid sending unnecessary
    files to the container runtime, even if they will not be kept in the final image.
    Avoid copying full directories using `COPY . /src` if you are unsure of the content,
    any previous artifact builds, whether you are going to re-build them during image
    creation, or the logs, for example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid non-required dependencies when you install packages. Depending on your
    base operating system distribution, you will have different arguments or options
    to only install specific packages, avoiding, for example, the recommended, but
    not required, associated packages. You will probably need to update the packages
    list before installing; do this once at the beginning if you don’t add or modify
    any package repository. It is also recommended to clean a package cache when you
    are not going to install any other package. We can use `RUN` `--mount type=cache,target=DIRECTORY_PATH
    <INSTALL_EXPRESSION>` to install packages. This option will keep the content of
    the defined directory between different build processes, which will speed up installing
    new software.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sensitive information shouldn’t be included inside container images. It is
    possible to include some files with passwords, certificates, tokens, and so on
    in your Dockerfile using the `COPY` or `ADD` keys, or even as arguments for your
    `docker build` command, and remove them before finishing. Although these don’t
    look like bad solutions at first, they are not good enough because unconsciously,
    you can leave sensible data behind. A multi-stage build can help us if secrets
    are used to download binaries or libraries, and we can easily copy them to a final
    stage without adding any sensible data to its layers. However, there is a better
    solution – using `buildx`. This Docker tool includes the option to mount secrets
    only during specific `RUN` steps, without storing them in any layer, as if they
    were a file from a volume. Here is a simple example of its usage:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To pass a value to the `mysecret` key, we can use an environment variable –
    for example, we can execute the build process with the following command line:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '`buildx` even allows us to mount files with data, such as user credentials,
    tokens, certificates, and so on, for use as secrets inside containers running
    within the build process, by using `docker image buildx build –secret id=mysecret,src=<FULLPATH_TO_SECRETFILE>`.
    By default, these files will be included inside containers in `/run/secrets/<SECRETID>`,
    but we can add `target` to the Dockerfile’s `mount` definition with a full path
    to the destination file we want to create.'
  prefs: []
  type: TYPE_NORMAL
- en: It is good practice to keep layers as small as possible. We will try to use
    `RUN`, `COPY`, and `ADD`, executing as many changes as possible, although this
    may impact layer reusability. We will combine multiple `RUN` executions into one
    line. Fewer Dockerfile lines mean smaller caching, which is good, but you can’t
    reuse layers too often for new images. Any small variation between your Dockerfiles
    will invalidate caching from one Dockerfile to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the heredocs format to combine multiple lines. This improves Dockerfile
    readability. For example, we can write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RUN <<EOF`'
  prefs: []
  type: TYPE_NORMAL
- en: '`set -e`'
  prefs: []
  type: TYPE_NORMAL
- en: '`apt-get` `update -qq`'
  prefs: []
  type: TYPE_NORMAL
- en: '`apt-get install` `mypackage1 mypackage2`'
  prefs: []
  type: TYPE_NORMAL
- en: '`EOF`'
  prefs: []
  type: TYPE_NORMAL
- en: Docker client installation also provides the unique features of `buildx` to
    help us reduce building times and size. We can configure garbage collections to
    remove unused layers, based on time, and enable remote caching locations. This
    feature improves CI/CD pipelines that use distributed caches for projects that
    must compile a lot of dependencies or low-level languages, such as *C* or *Rust*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple-processor architectures, such as `riscv64` or `arm64`, can be built
    by using `docker buildx build –platform`, with one unique Dockerfile. In the past,
    we usually had different Dockerfiles, one for each architecture. Machines to use
    these different processors were also required, and the building process was executed
    on each one. This new feature allows you to prepare images for different platforms
    on your laptop with Docker Desktop. We will prepare a container image for `arm64`
    in this chapter’s *Labs* section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can considerably reduce the final image size by using `–squash` when the
    image contains many layers. Squashing container images is an experimental feature
    that’s available in the Docker container runtime. This means that we need to enable
    `docker.json` file, and once configured, we will be able to use the `docker image
    build –squash` command. Reducing the number of layers to one will reduce its size,
    but you will lose the advantage of sharing layers. It’s important to mention here
    that you shouldn’t expect miracles. Squashing images depends on the number of
    layers used; hence, the final size may be pretty much the same as when fewer layers
    are used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before starting with the labs, we will review the content learned in this chapter
    by providing an overview of the best practices to build your container images.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for container image creation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to recommend a list of the best practices you
    can follow to create your applications, thus improving your applications’ security,
    reusability, and building processes:'
  prefs: []
  type: TYPE_NORMAL
- en: Only include the files that are strictly necessary for your application. Don’t
    install packages, binaries, libraries, and any file your application doesn’t need,
    and keep image content as small as possible, exposing a minimal attack surface.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `.dockerignore` file to avoid passing unnecessary files from your build
    context to container runtimes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare debugging versions of your images, including some binaries or tools
    that may help you resolve an issue, but never use these images in production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare the logic of your Dockerfiles to accommodate your changes; hence, include
    your code close to the end of the file, and think about how many modules or dependencies
    may need to be changed to execute the updates in the proper section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use layer caching whenever it is possible to speed up the build process and
    remember that using many layers will allow reusability but affect performance
    when files need runtime changes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Never use `root` in your applications unless it is strictly required. If you
    do, you should understand its risks and manage them. You can use the `USER` key
    multiple times to change the execution user during builds, but always finish your
    Dockerfile with a non-root user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Never include sensitive information, such as certificates, passwords, and tokens,
    in your final container images. This information should be provided at runtime.
    Use Docker’s `buildx` to include secrets only during the build process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Declare all your application requirements, such as your process user, the exposed
    ports, and the command line to be executed, in your Dockerfile. This will help
    other developers use your applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use labels to add information about your application’s life cycle, maintainer,
    special libraries that are required, and so on. This information will be great
    for other developers to help them understand how they can integrate their code
    into your images or evolve your Dockerfiles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image size matters, especially if you are running your containerized applications
    in a distributed environment. Container runtimes must download images if a container
    must be created on a host. Depending on the number of changes you make to your
    images, this can be a challenge, and resilience in the face of application issues
    may be affected if your platform defines an *always-pull* policy. We have covered
    some techniques to reduce image size; use them, but remember that a layer’s reusability
    may be affected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this list, you can prepare your own container image creation workflow.
    Some of this advice can be tricky and requires some practice, but I can assure
    you that it is worth it, and you will deliver quality images for your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen the different methods to build images, the command line
    we will commonly use, and some advanced techniques and advice to create good and
    secure images, it’s time to put all this into practice with some labs in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following labs will provide examples to help you put the concepts and procedures
    you’ve learned in this chapter into practice. We will use Docker Desktop or any
    other container runtime. We will use different tools such as **Podman** and **nerdctl**
    to show you some of the possibilities you have at hand, although some of the features
    that are required for specific labs may be only available with a specific tool
    (or one tool has a more friendly interface). In these cases, we will ask you to
    use a specific command-line interface.
  prefs: []
  type: TYPE_NORMAL
- en: The first step for all labs would be to download the most updated version of
    this book’s GitHub repository at [https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git](https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git).
    To do this, simply execute `git clone https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git`
    to download all its content. If you have already downloaded it before, ensure
    you have the newest version by executing `git pull` inside its directory.
  prefs: []
  type: TYPE_NORMAL
- en: We will start this section with a simple lab about using caching to speed up
    the building process. All commands presented in these labs will be executed inside
    the `Docker-for-Developers-Handbook/Chapter2` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To show you the different tools to work with containers, we will use `nerdctl`
    in these labs, but you can use `podman` or `docker` (standalone or within Docker
    Desktop). Each tool has features and particularities, but most of the work within
    containers will execute similarly. We will explicitly notify you if some command
    shown requires a specific tool. Follow the specific instructions in this book’s
    GitHub code repository to install each tool. We will use `containerd` as the container
    runtime and integrates the `nerdctl` command line inside WSL 2, but all labs can
    be executed with the Docker command line as well, with `docker` replacing `nerdctl`.
  prefs: []
  type: TYPE_NORMAL
- en: Caching layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this first lab, we will review the importance of caching to speed up the
    building process. We are going to use `nerdctl`, but `docker` or `podman` will
    work, as well as `buildah` ([https://buildah.io](https://buildah.io)), which is
    another open source tool prepared specifically to enhance the build process.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will build a simple *Node.js* application that I prepared for quick demos
    a few years ago. Its only purpose is to show some information regarding the container
    in which it runs, the request headers, and its version. It will be interesting
    to better understand the load balancing processes within container orchestrators
    later on in this book, but we will focus on the build process for now:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will move inside the `Chapter2/colors/nodejs` folder and execute
    a simple build, using `ch2lab1:first` as the image name and tag. We will use the
    following Dockerfile in this process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that here, we have separated the content copy into three lines, although
    we could have used just one with all the content – for example, by using `COPY
    . .`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: As you may have noticed, this Dockerfile does not include any `USER` directive,
    but its application runs without any privileges because it is very simple and
    doesn’t use any Linux capability or privileged port. Anyway, it is good practice
    to include the `USER` directive, and you can add it to your local repository.
    Everything described in the following steps will work.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will add `time` to the `build` command to measure the time the build process
    takes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After these lines, our Dockerfile starts to be processed by the container runtime:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the required layers have been loaded, our tasks to execute commands start.
    In our example, many packages must be installed:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: var APP_VERSION="1.1";.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ time nerdctl build -t ch2lab1:two \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --label nodejs=18.14.2 \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --label=base=alpine3.16  nodejs  \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --progress plain
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#1 [internal] load .dockerignore'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#1 transferring context: 2B done'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'CACHED indicate that the layers were already created; we use these instead
    of executing the actual line to create a layer:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '#9 [5/6] COPY app.js app.js'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#9 DONE 0.0s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#10 [6/6] COPY index.xhtml index.xhtml'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#10 DONE 0.0s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '#11 sending tarball'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#11 sending tarball 0.6s done'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#11 DONE 0.7s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: unpacking docker.io/library/ch2lab1:two (sha256:bfffba0cd2d7cc82f686195b0b996731d0d5a49e4f689a3d39c7b0e6c57dcf0e)…
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Loaded image: docker.io/library/ch2lab1:two'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: real    0m1.272s
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: user    0m0.007s
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: index.xhtml or our simple code in app.js, all the packages will be downloaded
    again.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s repeat this process by changing the copy process in our Dockerfile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We execute the build process again. We expect it to last less than 12 seconds
    because the base image is already in our host:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '#7 [3/4] COPY . .'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#7 DONE 0.0s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#8 [4/4] RUN apk add --no-cache --update curl && rm -rf /var/cache/apk && npm
    install'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#8 DONE 2.8s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#9 sending tarball 0.6s done'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#9 DONE 0.8s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: unpacking docker.io/library/ch2lab1:three (sha256:b38074f0ee5a9e6c4ee7f68e90d8a25575dc7df9560b0b66906b29f3feb8741c)...
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Loaded image: docker.io/library/ch2lab1:three'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: real    0m4.634s
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: user    0m0.004s
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'APP_VERSION to a new value variable to see what happens if we build again.
    Change it from var APP_VERSION="1.1"; to var APP_VERSION="1.2";, and execute it
    again:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The previous layers were cached, but a minimal change broke all the processes,
    and the layers must be recreated:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, it takes the same time as the previous execution because the
    container runtime can’t identify and isolate the small changes and reuse the layers
    that were created previously.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this lab, we reviewed how caching layers works and how to avoid build problems
    by choosing the right logic for our application’s Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: In the next lab, we will execute a multi-stage build process using an empty
    layer for the final image.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a multi-stage build process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a very interesting use case since our code is in the Go language and
    we will be including static dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Move to the `Chapter2/colors` folder and use the `go` sub-folder this time.
    The multi-stage Dockerfile looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will use a `golang:1.20-alpine3.17` image to compile our code. The compiled
    binary is copied from the *builder* image to our final image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '#6 [builder 1/4] FROM docker.io/library/golang:1.20-alpine3.17@sha256:48f336ef8366b9d6246293e3047259d0f614ee167db1869bdbc343d6e09aed8a'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#6 DONE 3.2s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#6 [builder 1/4] FROM docker.io/library/golang:1.20-alpine3.17@sha256:48f336ef8366b9d6246293e3047259d0f614ee167db1869bdbc343d6e09aed8a'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#6 extracting sha256:752c438cb1864d6b2151010a811031b48f0c3511c7aa49f540322590991c949d'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#6 DONE 4.8s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#7 [builder 2/4] WORKDIR /src'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#7 DONE 0.2s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#8 [builder 3/4] COPY ./src/* .'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#8 DONE 0.0s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#9 [builder 4/4] RUN mkdir bin && go build -o bin/webserver /src/webserver.go'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'FROM key is reached and a new image build process starts – in this case, just
    copying the content from the previous one:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final image is really small because it only contains our application code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this output, you can compare the different sizes we obtained (sizes may change
    because some updates may be expected in the code in this book’s GitHub repository).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Creating images from scratch using binaries can be very tricky, but they are
    the best way of delivering our applications.
  prefs: []
  type: TYPE_NORMAL
- en: This lab showed you how you can create a container image from scratch by using
    static build binaries, which are the best application images you can create.
  prefs: []
  type: TYPE_NORMAL
- en: For the next lab, we will use Docker’s `buildx` features, and therefore, we
    will use the `docker` command line.
  prefs: []
  type: TYPE_NORMAL
- en: Building images for different architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you followed the lab with `nerdctl` command line, please exit **Rancher Desktop**
    and launch **Docker Desktop** (or your own Docker engine implementation).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Podman and nerdctl also provide multiplatform support on new releases, and a
    multi-architecture build is commonly available; hence, any of these tools will
    be right for this lab.
  prefs: []
  type: TYPE_NORMAL
- en: Note that when you change from one container runtime to another, the list of
    images is completely different. Each container runtime manages its own environment
    as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue this lab inside the `Chapter2/colors` folder. We are going
    to build the image for multiple architectures – that is, `amd64` and `arm64`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use `buildx` with the `–-platform` argument and `arm64`. But first,
    we will ensure that we can build images for other architectures by executing the
    `docker buildx` `ls` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker buildx build -t ch2lab1:six \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --label nodejs=18.14.2 \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --label=base=alpine3.16 \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: nodejs --progress plain \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --platform arm64 \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --load –no-cache
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#1 [internal] load build definition from Dockerfile'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#1 transferring dockerfile: 32B done'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#1 DONE 0.0s'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'aarch64 architecture image is downloaded during the process:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can verify this image architecture by using `docker inspect`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this build process, we also used `--load` and `–-no-cache`. The first argument
    is used to load the image that was built into our container runtime. If we don’t
    use this with Docker’s `buildx`, the image is used as a cache for new builds only
    by default. To avoid any cached layer within this build process, we used `–-no-cache`,
    and this ensures the complete execution of each step defined in the Dockerfile.
  prefs: []
  type: TYPE_NORMAL
- en: This lab showed you that you can prepare your images for any available architecture
    by using a unified Dockerfile and executing the build process with the `–-``platform`
    argument.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to create container images for applications.
    We started with an overview of CoW filesystems, which are the base for creating
    container images using layers. We looked at different methods to build images,
    along with their pros, cons, and examples. Using Dockerfiles is the best method
    because it provides a reproducible way of creating images by using different steps,
    written in order in these files. We provided a quick overview of the most important
    directives we can use in Dockerfiles and the command line and the arguments for
    using them. As the container-image-building process can be tricky, we presented
    some advanced features and practices we can use to improve our workflow in terms
    of speed, reusability, and quality.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will provide a quick overview of image registries, learn
    how to store and tag our images in them, and learn how to improve integrity and
    security by signing and scanning container images.
  prefs: []
  type: TYPE_NORMAL
