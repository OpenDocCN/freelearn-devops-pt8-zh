<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer109">
<h1 class="chapter-number" id="_idParaDest-214"><a id="_idTextAnchor231"/>10</h1>
<h1 id="_idParaDest-215"><a id="_idTextAnchor232"/>Leveraging Application Data Management in Kubernetes</h1>
<p>Deploying applications in Kubernetes helps in managing resilience, <strong class="bold">high availability</strong> (<strong class="bold">HA</strong>), and scalability <a id="_idIndexMarker1131"/>by using replicated instances. But none of these features can be used without knowing how your application actually works and how to <a id="_idIndexMarker1132"/>manage its data. In this chapter, we will review how to create and manage <strong class="bold">Secrets</strong>, <strong class="bold">ConfigMaps</strong>, and different <strong class="bold">volume</strong> options. While Secret and ConfigMap resources will be used to integrate different authentication options inside containers, volumes are used to manage an application’s data, as we briefly introduced in <a href="B19845_08.xhtml#_idTextAnchor170"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Deploying Applications with </em><em class="italic">the </em><em class="italic">Kubernetes Orchestrator</em>. Applications can be either stateful, stateless or – as is usually the case – a combination of both. We will learn in this chapter about different options for managing data and separating it from the application’s <span class="No-Break">life cycle.</span></p>
<p>The following main concepts are reviewed in <span class="No-Break">this chapter:</span></p>
<ul>
<li>Understanding the data within <span class="No-Break">your application</span></li>
<li>Applying configurations <span class="No-Break">using ConfigMaps</span></li>
<li>Managing sensitive data using <span class="No-Break">Secret resources</span></li>
<li>Managing stateless and <span class="No-Break">stateful data</span></li>
<li>Enhancing storage <a id="_idIndexMarker1133"/>management in Kubernetes with <strong class="bold">PersistentVolume</strong> (<span class="No-Break"><strong class="bold">PV</strong></span><span class="No-Break">) resources</span></li>
</ul>
<h1 id="_idParaDest-216"><a id="_idTextAnchor233"/>Technical requirements</h1>
<p>You can find the labs for this chapter at <a href="https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter10">https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter10</a>, where you will find some extended explanations, omitted in the chapter’s content to make it easier to follow. The <em class="italic">Code In Action</em> video for this chapter can be found <span class="No-Break">at </span><a href="https://packt.link/JdOIY"><span class="No-Break">https://packt.link/JdOIY</span></a><span class="No-Break">.</span></p>
<p>As the data used by your application is very important, we will first review the different options we have and the resources we can use <span class="No-Break">within Kubernetes.</span></p>
<h1 id="_idParaDest-217"><a id="_idTextAnchor234"/>Understanding the data within your application</h1>
<p><strong class="bold">Microservices architecture</strong> improves the performance and resilience of your applications <a id="_idIndexMarker1134"/>by distributing functionalities in different pieces, allowing us to scale them up or down and continue serving some functionalities even when some components fail. But this distribution of functionalities entails the distribution of <a id="_idIndexMarker1135"/>the data associated with each component and somehow sharing it when more than one component needs it. It is very important to also understand that your application must allow scaling up without corrupting the data in case more than one replica is accessing the same data. Running application components as containers will help us distribute the processes, keeping the same data content in each replica, and starting and stopping processes quickly. The container runtime will attach defined volumes to the containers, but it doesn’t manage your application’s logic. That’s why it is key to understand how data will be used when you are preparing your applications for running in <span class="No-Break">container-orchestrated environments.</span></p>
<p>Container orchestrators will provide you with mechanisms for injecting configurations into your containers, maintaining these configurations synced within all container replicas. These configurations can be used as either files within the containers or environment variables. You must understand that if your application uses configurations in clear text, you will not be able to protect them from attackers if they get into your containers. This will always be the case, even if you encrypt your configurations before they are injected into the containers. If your code reads the configuration content in clear text, it will always be accessible because permissions will be adequate to allow your processes to read the configurations, and the container will use the main process user to attach any new processes (via <strong class="source-inline">docker exec</strong> or <strong class="source-inline">kubectl exec</strong>). If you use environment variables, they will be easily readable by any process running inside the container. But these things don’t mean that your information is insecure inside containers. Different mechanisms, such as RBAC, allow us to limit access to containers from the orchestrated platform, but accessing cluster nodes will override the platform’s security. You should never run commands from cluster nodes. Your container orchestrator <a id="_idIndexMarker1136"/>administrators may provide you with a complete <strong class="bold">continuous deployment</strong> (<strong class="bold">CD</strong>) solution, or you may use your platform client (command line or graphical interface) to <span class="No-Break">gain access.</span></p>
<p>Injecting data into an application’s containers can be accomplished by using any of the <span class="No-Break">following mechanisms:</span></p>
<ul>
<li><strong class="bold">Command-line arguments</strong>: We can pass values to a container’s main process by adding the <strong class="source-inline">arguments</strong> key to any Pod resource. You should never pass sensitive data using <span class="No-Break">this method.</span></li>
<li><strong class="bold">Environment variables</strong>: It is usual to include information by using environment variables. Some coding languages even have standardized nomenclature for working directly with variables; in any case, your application must be <a id="_idIndexMarker1137"/>prepared to include them. This method should also be avoided when including sensitive data unless it is combined with Secret resources, as we will learn about in the <span class="No-Break">next section.</span></li>
<li><strong class="bold">ConfigMaps</strong>: These resources are the best option for adding configurations to our workloads. We can use them to add files inside containers, knowing that they will be available no matter which node runs the instance. The container orchestrator will manage and sync any change in its content. They can also be used to set up some variables with their values and use them as <span class="No-Break">environment variables.</span></li>
<li><strong class="bold">Secrets</strong>: Secret resources are the appropriate method for managing sensitive data in either Kubernetes or Docker Swarm platforms. However, there’s a big difference in how they are packaged inside each platform. Docker Swarm encrypts their content, and we aren’t even allowed to retrieve the content, while Kubernetes uses the Base64 format for storing content within a cluster. Encryption for storing Secret resources at rest in etcd can be enabled, but it is not enabled by default. This only affects the etcd database, which shouldn’t be accessible to normal users, but it may be useful to ask your Kubernetes administrators about such configuration if you are worried about the data you keep in your Secret resources. It is quite common to use Secret resources for either adding sensitive files, such as passwords, authentication tokens, certificates, or even container image registry connection strings, or to present variables <span class="No-Break">to containers.</span></li>
<li><strong class="bold">Volumes</strong>: Volumes are not intended to be used for injecting data but for storing it during the execution of the containers. They can be either ephemeral or stateful, to persist data between executions. In Kubernetes, we consider volumes as those storage resources integrated into the Kubernetes platform’s code. A lot of cloud storage solutions were integrated from the beginning of its development <a id="_idIndexMarker1138"/>because it was part of the design, although host bind mounts, ephemeral directories, NFS, and other on-premises solutions are also available. ConfigMap and Secret resources are also Volumes, but we will treat them differently because of <span class="No-Break">their content.</span></li>
<li><strong class="bold">The downward API</strong>: Although the downward API is considered a Volume resource, we can think of it as a completely different concept due to its usage. You can mount metadata information from the current namespace’s resources to be used in your application by using the downward API, which automatically manages the required requests to the Kubernetes API to <span class="No-Break">retrieve it.</span></li>
<li><strong class="bold">PVs</strong>: A PV is storage <a id="_idIndexMarker1139"/>provisioned by the Kubernetes administrator to accommodate a <strong class="bold">PersistentVolumeClaim</strong> (<strong class="bold">PVC</strong>) resource, which is a request for storage for your application component. Whenever you create a PVC resource, it will be bound to an existing PV resource if there is one free with the required size <span class="No-Break">and properties.</span></li>
</ul>
<p class="callout-heading">Important note</p>
<p class="callout">The concept <a id="_idIndexMarker1140"/>of <strong class="bold">Projected Volumes</strong> also exists, which is a specific map of different volumes integrated into the same directory inside a container. This feature allows us to locate Secret and ConfigMap resources in the <span class="No-Break">same directory.</span></p>
<p>We will learn how to inject data and use it inside containers by using ConfigMaps to include <span class="No-Break">non-sensitive information.</span></p>
<h1 id="_idParaDest-218"><a id="_idTextAnchor235"/>Applying configurations using ConfigMaps</h1>
<p>In this section, we are going to learn how to use ConfigMap resources, mount files inside containers <a id="_idIndexMarker1141"/>or as environment variables, and present the information for our <span class="No-Break">application’s processes.</span></p>
<p>The content of a ConfigMap resource is stored in the Kubernetes etcd key-value store. Due to this, the content can’t exceed 1 MB in size. The manifest of these resources doesn’t have a <strong class="source-inline">spec</strong> section. Instead, we can have either <strong class="source-inline">data</strong> or <strong class="source-inline">binaryData</strong> (for Base64 content) keys for defining the content. The following screenshot shows an example of a <span class="No-Break">ConfigMap manifest:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer099">
<img alt="Figure 10.1 – ConfigMap resource manifest" height="388" src="image/B19845_10_01.jpg" width="464"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – ConfigMap resource manifest</p>
<p>In the code in the presented screenshot, we have declared two types of configurations. While <strong class="source-inline">APP_VAR1</strong> and <strong class="source-inline">APP_VAR2</strong> are defined in key-value format, the <strong class="source-inline">appsettings</strong> section defines a complete configuration file that can be mounted. Notice the pipe symbol (<strong class="source-inline">|</strong>) used to define the <strong class="source-inline">appsettings</strong> key. This allows us to include all the subsequent content as the value for the key. You should be very careful with the indentation of the YAML file to avoid any issues with the <span class="No-Break">file content.</span></p>
<p>Let’s see now how we will use these configurations in <span class="No-Break">a Pod:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer100">
<img alt="Figure 10.2 – Pod resource manifest using a ConfigMap resource" height="592" src="image/B19845_10_02.jpg" width="826"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Pod resource manifest using a ConfigMap resource</p>
<p>In the Pod <a id="_idIndexMarker1142"/>manifest shown in the preceding screenshot, we have presented two mechanisms for using the information declared in a ConfigMap resource. We used the key-value definitions in the <strong class="source-inline">settings</strong> ConfigMap as environment variables. But the content of the <strong class="source-inline">appsettings</strong> key, defined in the <strong class="source-inline">settings</strong> ConfigMap too, is presented as a volume in the <strong class="source-inline">demo</strong> container. In this case, a <strong class="source-inline">/app/config/appsettings</strong> file will be created, with the content of the <strong class="source-inline">appsettings</strong> key. Notice that we used the <strong class="source-inline">ReadOnly</strong> key to define that the mounted file will not <span class="No-Break">be writable.</span></p>
<p>In this example, we didn’t use the simplest mechanism for mounting configuration files. Let’s see how we simply add a complete configuration file, created with <strong class="source-inline">kubectl create configmap &lt;CONFIGMAP_NAME&gt; --from-file=&lt;CONFIGURATION_FILE&gt;</strong>. We will use the <strong class="source-inline">appsettings.json</strong> file as an example, with any content, and created using <strong class="source-inline">kubectl create cm </strong><span class="No-Break"><strong class="source-inline">appsettings –from-file=appsettings.json</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod
    image: myregistry/myimage
    volumeMounts:
    - name: config
      mountPath: "/app/config/appsettings.json"
      subPath: appsettings.json
      readOnly: true
  volumes:
  - name: config
    configMap:
      name: appsettings</pre> <p>In this case, we used the <strong class="source-inline">subPath</strong> key to set up the filename and complete path for the <span class="No-Break">configuration file.</span></p>
<p>Configuration <a id="_idIndexMarker1143"/>files can be updated at any time unless we have used the <strong class="source-inline">immutable</strong> key (which defaults to <strong class="source-inline">false</strong>), in which case we will need to recreate the resource. To modify the content or any of the allowed keys (use <strong class="source-inline">kubectl explain configmap</strong> to review them), we can use any of the <span class="No-Break">following methods:</span></p>
<ul>
<li>Use <strong class="source-inline">kubectl edit</strong> to edit and modify its <span class="No-Break">values online.</span></li>
<li>Patch the file by using <strong class="source-inline">kubectl </strong><span class="No-Break"><strong class="source-inline">patch</strong></span><span class="No-Break"> (</span><a href="https://kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch"><span class="No-Break">https://kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch</span></a><span class="No-Break">).</span></li>
<li>Replace the resource with a new manifest file by using <strong class="source-inline">kubectl replace –f &lt;MANIFEST_FILE&gt;</strong>. This is the preferred option as all changes can be followed by storing <a id="_idIndexMarker1144"/>the manifest files (using <strong class="bold">GitOps</strong> methodology, as we will learn in <a href="B19845_13.xhtml#_idTextAnchor287"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, <em class="italic">Managing the Application </em><span class="No-Break"><em class="italic">Life Cycle</em></span><span class="No-Break">).</span></li>
</ul>
<p>ConfigMap resources will be updated on your running workloads unless their values are used in your containers as environment variables or mounted using the <strong class="source-inline">subPath</strong> key, in which case this will not be done. It is very important to understand how updates will be managed <a id="_idIndexMarker1145"/>by Kubernetes in your application’s workloads. Even if your configuration is updated, it depends on how your application uses it, when it is loaded, and how these changes affect your container processes. If your processes only read configurations when they start, you will need to recreate the application’s Pods. Hence, the only way you can ensure that a new configuration is applied is by recreating the containers. Depending on the workloads you used for your configuration, you will just need to remove or scale your resources down/up to make the configuration <span class="No-Break">changes update.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">We can use <strong class="source-inline">kubectl create cm &lt;CONFIGMAP_NAME&gt; --from-literal=KEY=VALUE</strong> to create ConfigMap resources with key-value resource <span class="No-Break">types directly.</span></p>
<p>We can add annotations to our ConfigMap resources and update them to trigger the update of your workloads. This will ensure that your Pods will be recreated, hence the ConfigMap is updated immediately. By default, when a ConfigMap is updated, Kubernetes will update the content on the Pods using this configuration at regular intervals. This automatic update doesn’t work if you use the <strong class="source-inline">subPath</strong> key to mount the content. However, notice that updating the content of the file does not include the update of your application; it depends on how your application works and how often the configuration <span class="No-Break">is refreshed.</span></p>
<p>Kubernetes also allows us to include information in Pods at runtime. We will use the downward API to inject Kubernetes data into Pods, which we will learn about in the <span class="No-Break">next section.</span></p>
<h2 id="_idParaDest-219"><a id="_idTextAnchor236"/>Using the downward API to inject configuration data</h2>
<p>We will <a id="_idIndexMarker1146"/>use the downward API mount endpoints to inject information about the current Pod resource. This way, we can import information such as the Pod’s name (<strong class="source-inline">metadata.name</strong>), its annotations, labels, and service account, for example. Information can be passed as environment variables or mounted as a <span class="No-Break">volume file.</span></p>
<p>Imagine a Pod with the <span class="No-Break">following annotations:</span></p>
<pre class="source-code">
...
metadata:
  annotations:
    environment: development
    cluster: cluster1
    location: Berlin
...</pre> <p>We can mount this information in a Pod’s container with a volume definition and the <strong class="source-inline">mountPath</strong> parameter <span class="No-Break">inside it:</span></p>
<pre class="source-code">
...
  containers:
  ...
    volumeMounts:
        - name: podinfo
          mountPath: /etc/pod-annotations
  volumes:
    - name: podinfo
      downwardAPI:
        items:
          - path: "annotations"
            fieldRef:
              fieldPath: metadata.annotations
...</pre> <p>Notice <a id="_idIndexMarker1147"/>that we are injecting the annotations inside the <strong class="source-inline">/etc/pod-annotations</strong> file. We can use either static data (added manually) or dynamic information, retrieved <span class="No-Break">from Kubernetes.</span></p>
<p>Next, let’s see how to include sensitive data by <span class="No-Break">using Secrets.</span></p>
<h1 id="_idParaDest-220"><a id="_idTextAnchor237"/>Managing sensitive data using Secret resources</h1>
<p>We should always avoid adding sensitive information to our application images. Neither passwords, connection strings, tokens, certificates, nor license information should be written <a id="_idIndexMarker1148"/>inside container images; all this content must be included in the runtime. Therefore, instead of using ConfigMap resources, which are stored in clear text, we will use Secrets. Kubernetes Secret resource <a id="_idIndexMarker1149"/>content is described in <strong class="source-inline">base64</strong> format. They are not encrypted, and anyone with access to them can read their data. This includes any user who can create a Pod in the same namespace, as the Secret can be included and hence read. Only appropriate RBAC resource access can ensure Secrets’ security. Therefore, it is important to understand that you should avoid access to your Secret resources using appropriate Kubernetes <strong class="bold">Roles</strong> and <strong class="bold">RoleBindings</strong> (Kubernetes RBAC). Also, by default, Kubernetes doesn’t encrypt Secrets in etcd, hence access to the key-value data files at the filesystem level shouldn’t be allowed. Secrets are namespaced resources, therefore we will be able to manage Kubernetes access at the namespace level. Your Kubernetes administrators should ensure the appropriate access at the <span class="No-Break">cluster level.</span></p>
<p>We will use Secret resources as <strong class="bold">volumes</strong> (presenting files such as certificates or tokens), as <strong class="bold">environment variables</strong> (with their content hidden when you review the online Pod resource’s manifest), or as <strong class="bold">authentication</strong> for accessing a remote registry (on-premise or <span class="No-Break">cloud service).</span></p>
<p>We can use <strong class="source-inline">kubectl create secret generic &lt;SECRET_NAME&gt; --from-file=&lt;SENSITIVE_DATA_FILE&gt;</strong> or <strong class="source-inline">kubectl create secret generic &lt;SECRET_NAME&gt; --from-literal=SECRET_VARIABLE_NAME=SECRET_VALUE</strong>. Either the <strong class="source-inline"> --from-file</strong> or <strong class="source-inline">--from-literal</strong> arguments can be used multiple times to add multiple data keys. The following Secret resource types can <span class="No-Break">be created:</span></p>
<ul>
<li><strong class="source-inline">generic</strong>: This is the most usual type and can be used to include any sensitive file <span class="No-Break">or value.</span></li>
<li><strong class="source-inline">tls</strong>: This <a id="_idIndexMarker1150"/>stands for <strong class="bold">Transport Layer Security</strong>. We will use this type to add certificates to our application. Notice that this will only add a Secret with a key and associated certificate that you must include in your application somehow; for example, by adding an <strong class="source-inline">SSL_CERT_FILE</strong> variable with its content or by using the associated <strong class="source-inline">.cert</strong> and <strong class="source-inline">.key</strong> files in <span class="No-Break">your configuration.</span></li>
<li><strong class="source-inline">docker-registry</strong>: These resources can include <strong class="source-inline">dockercfg</strong> or <strong class="source-inline">dockerconfigjson</strong> content. They will be used to configure a profile for pulling images from <span class="No-Break">a registry.</span></li>
</ul>
<p>Kubernetes, by default, creates a Secret for each service account automatically. These Secret <a id="_idIndexMarker1151"/>resources contain an associated token <a id="_idIndexMarker1152"/>that can be used for interacting with the Kubernetes API from your application’s components. This token is used to authenticate and authorize your processes <span class="No-Break">with Kubernetes.</span></p>
<p>Ask your <a id="_idIndexMarker1153"/>Kubernetes administrators if you have some <strong class="bold">ResourceQuota</strong> resources associated with your applications’ namespaces because Secrets, as with many other resources, can be limited in their number. Hence, you may be limited when creating lots of Secrets, and you have to think about the information included. The size of Secret content is also limited to 1 MB, which will usually be more than enough for delivering sensitive configurations. If you need more, you may need to use appropriate Volumes <span class="No-Break">or PVs.</span></p>
<p>Let’s look at a quick example. We used <strong class="source-inline">kubectl create secret settings --from-literal=user=test --from-literal=pass=testpass --from-file=mysecretfile --dry-run=client -o yaml</strong> to generate the following <span class="No-Break">Secret manifest:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer101">
<img alt="Figure 10.3 – Secret manifest" height="320" src="image/B19845_10_03.jpg" width="694"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Secret manifest</p>
<p>We will <a id="_idIndexMarker1154"/>now use the Secret values in a <a id="_idIndexMarker1155"/>Pod as environment variables and mounted as <span class="No-Break">a volume:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer102">
<img alt="Figure 10.4 – Example of the usage of a Secret resource" height="614" src="image/B19845_10_04.jpg" width="977"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4 – Example of the usage of a Secret resource</p>
<p>In the previous screenshot, we used <strong class="source-inline">user</strong> and <strong class="source-inline">pass</strong> two times. First, we added their values as environment variables, but we also used them as volumes, mounted inside <strong class="source-inline">/etc/settings</strong>. In this example, three files were created: <strong class="source-inline">/etc/settings/user</strong>, <strong class="source-inline">/etc/settings/pass</strong>, and <strong class="source-inline">/etc/settings/mysecretfile</strong>. Each file’s content was defined in the Secret. Notice that we defined the file permissions using the <strong class="source-inline">defaultMode</strong> key, and we mounted the volumes in read-only mode. If we just need to mount a Secret as a file and we require this file in a specific path, we use the <strong class="source-inline">subPath</strong> key to define the name of the file. For example, if we used <strong class="source-inline">kubectl create secret generic example --from-file=mysecretfile</strong>, we could mount it <span class="No-Break">as follows:</span></p>
<pre class="console">
   volumeMounts:
   - name: mysecret
     mountPath: "/etc/settings/mysecretfile"
     subPath: mysecretfile</pre> <p>We will <a id="_idIndexMarker1156"/>never store Secret file manifests in <a id="_idIndexMarker1157"/>clear text in our code repository. You can use any third-party tool to encrypt its content before uploading it. On the <a id="_idIndexMarker1158"/>other hand, a better solution may be a solution such as <strong class="bold">Bitnami’s Sealed Secrets</strong> (<a href="https://github.com/bitnami-labs/sealed-secrets">https://github.com/bitnami-labs/sealed-secrets</a>) to create an <a id="_idIndexMarker1159"/>intermediate encrypted Kubernetes <strong class="bold">custom resource</strong> (<strong class="bold">CR</strong>) entity, <strong class="source-inline">SealedSecret</strong>, which generates your Secret for you. In the <strong class="source-inline">SealedSecret</strong> manifests, the data is encrypted and you can manage it in your repositories without any problems. The <strong class="source-inline">SealedSecret</strong> entity works inside the Kubernetes cluster, hence your <strong class="source-inline">SealedSecret</strong> instance is the only software that can decrypt your data (encrypted by using certificate exchange). Your data will be safely encrypted, and it will be automatically decrypted <span class="No-Break">when needed.</span></p>
<p>You can use more <a id="_idIndexMarker1160"/>complex solutions such as <strong class="bold">Hashicorp’s Vault</strong> to manage your Kubernetes Secret resources. This solution provides a lot of functionalities that can help you manage sensitive data for multiple platforms, not only Kubernetes, but it may require lots of hardware resources and management if you plan to have a highly <span class="No-Break">available environment.</span></p>
<p>Cloud providers have their own software tools for deploying sensitive data on your Kubernetes <a id="_idIndexMarker1161"/>cluster. They provide different access control integrations with your cloud <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) and may be a better solution if you plan to use a cloud platform for production. It is always interesting to ask your Kubernetes administrators for the best solution for deploying your Secrets in <span class="No-Break">your environment.</span></p>
<p><strong class="bold">Projected Volumes</strong> allow us to <a id="_idIndexMarker1162"/>mount multiple resources (only Secrets, ConfigMaps, the downward API, or ServiceAccount tokens are allowed) into a container’s directory. The following example shows how to mount a Secret, a container’s specifications, and a <span class="No-Break">ConfigMap resource:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer103">
<img alt="Figure 10.5 – Example of a Projected Volume" height="560" src="image/B19845_10_05.jpg" width="935"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.5 – Example of a Projected Volume</p>
<p>Now that <a id="_idIndexMarker1163"/>we know how to inject configurations <a id="_idIndexMarker1164"/>and sensitive data cluster-wide using Kubernetes resources, we will continue by reviewing how to store data from our applications. We will start with volumes, which are a storage solution included in <span class="No-Break">Kubernetes’ core.</span></p>
<h1 id="_idParaDest-221"><a id="_idTextAnchor238"/>Managing stateless and stateful data</h1>
<p>When we think about storing an application’s data, we must consider whether the data should persist or whether it’s temporary. If the data must persist when a Pod is recreated, we must take into account that data should be available cluster-wide because <a id="_idIndexMarker1165"/>containers may run on any worker host. Containers’ state isn’t stored by Kubernetes. If your application manages its state by using files, you may <a id="_idIndexMarker1166"/>use volumes, but if this is not possible – for example, because multiple instances work at the same time – we should implement a mechanism such as a database to store its status and make it available to <span class="No-Break">all instances.</span></p>
<p>Storage can be either filesystem-based, block-based, or object-based. This also applies to Kubernetes data volumes, hence before moving forward on how Kubernetes provides different solutions for volumes, let’s have a quick review of these <span class="No-Break">storage-type concepts:</span></p>
<ul>
<li><strong class="bold">Filesystem-based storage</strong>: When we use filesystem-based storage (or file storage), we manage <a id="_idIndexMarker1167"/>it by saving all <a id="_idIndexMarker1168"/>the data in a hierarchal structure of folders and subfolders, provided by a local or remote operating system, where the files are kept. We use access control lists to decide whether a user is able to read or modify <span class="No-Break">files’ content.</span><p class="list-inset">Filesystems are quite common and easy to use. We use them every day locally in our <a id="_idIndexMarker1169"/>workstation or remotely via NAS, <strong class="bold">Common Internet File System</strong> (<strong class="bold">CIFS</strong>), or even with cloud-specific solutions. Filesystem storage works fine for a limited number of files, with limited size, but it may be problematic with large files. In these solutions, files are indexed and this limits usage when we have an enormous number of files. It also doesn’t scale well, and it’s difficult to manage file locks when multiple processes are accessing the same file remotely, although it works very well for <span class="No-Break">local storage.</span></p></li>
<li><strong class="bold">Block storage</strong>: Block <a id="_idIndexMarker1170"/>storage (or block devices) is used <a id="_idIndexMarker1171"/>by splitting your data into small blocks of a defined size that can be distributed in different physical local devices. Block devices can be used locally or remotely (SAN or even cloud-provided solutions), and they may be used directly or formatted using different filesystem options, depending on the underlying operating system. This storage solution is <a id="_idIndexMarker1172"/>faster than filesystems and can include HA and resilience <a id="_idIndexMarker1173"/>using distributed devices. But redundancy isn’t cheap as it is based on the duplication of blocks. Applications must be prepared for working with block devices, and block storage isn’t commonly used because it depends a lot on the infrastructure. It is very efficient for virtualization and database solutions prepared <span class="No-Break">for it.</span></li>
<li><strong class="bold">Object storage</strong>: Object storage is a solution that divides the data into separate units <a id="_idIndexMarker1174"/>that are stored in an underlying <a id="_idIndexMarker1175"/>storage backend (block devices or filesystems). We can use distributed backends, which improves resilience and HA. Files are identified uniquely using IDs, and access to the data is easier to manage by using ACLs. It also provides redundancy and versioning. It was first developed for publishing storage on cloud providers but it is now very common in data centers. It’s usually consumed via a REST API (HTTP/HTTPS), which makes it easy to include in our applications. Many backup solutions are prepared for object storage backends nowadays because they are suitable for storing large files and an enormous number <span class="No-Break">of items.</span></li>
</ul>
<p>Kubernetes includes some drivers that will allow us to use the reviewed storage solutions mounted as volumes, but we will use PVC resources for more <span class="No-Break">advanced results.</span></p>
<h2 id="_idParaDest-222"><a id="_idTextAnchor239"/>Using volumes for storing data</h2>
<p>Volumes in <a id="_idIndexMarker1176"/>Kubernetes are used by adding their definitions <a id="_idIndexMarker1177"/>to the <strong class="source-inline">.spec.volumes</strong> key. Kubernetes supports different types of volumes, and Pod resources can use any number of volume types at the same time. We have temporal (or ephemeral) volumes that will only exist during the Pod’s execution, while data may persist using non-ephemeral volumes. All the volumes associated with a Pod can be mounted on any mount point (directories from containers’ filesystems) on all the containers running inside. Using these volumes, we can persist an <span class="No-Break">application’s data.</span></p>
<p>While the <strong class="source-inline">.spec.volumes</strong> key allows us to define the volumes to be included in the Pod’s mount namespace, we will use <strong class="source-inline">.spec.containers[*].volumeMounts</strong> to define in <a id="_idIndexMarker1178"/>each container how and where the volumes should <span class="No-Break">be used.</span></p>
<p>Let’s review <a id="_idIndexMarker1179"/>some of the most popular <span class="No-Break">volume types:</span></p>
<ul>
<li><strong class="source-inline">emptyDir</strong>: An <strong class="source-inline">emptyDir</strong> definition asks the kubelet component to create an empty temporary directory on your host that will follow the associated container’s life cycle. When the Pod is deleted, the containers free up this storage, and kubelet removes it. By default, <strong class="source-inline">emptyDir</strong> type volumes are created on a host’s filesystem but can use the <strong class="source-inline">medium</strong> subkey to define where the storage should be created. Size can also be limited by using the <strong class="source-inline">sizeLimit</strong> key. It is important to understand that these volumes are created on the hosts, hence you must be careful about their content and size. Never use them for storing unlimited logs, for example. And remember that they will be removed once the Pod <span class="No-Break">is deleted/recreated.</span></li>
<li><strong class="source-inline">hostPath</strong>: These volumes allow us to include a defined host’s storage inside the Pods. This is an important security breach that must be avoided unless your application needs to monitor or modify your host’s files. Different types of <strong class="source-inline">hostPath</strong> volumes can be used by setting the <strong class="source-inline">type</strong> key. By default, a directory will be created if doesn’t exist when the Pod starts, but we can create or use specific files, sockets, block devices, or even special types such as <strong class="bold">char devices</strong> (devices in which direct hardware access is required for interaction). Usage of <strong class="source-inline">hostPath</strong> volumes should be limited, and you must inform your Kubernetes administrators about their use in <span class="No-Break">your workloads.</span></li>
<li><strong class="source-inline">iscsi</strong>: If you <a id="_idIndexMarker1180"/>are already using <strong class="bold">Internet Small Computer Systems Interface</strong> (<strong class="bold">iSCSI</strong>) devices, you can expose them directly to your Pods. This allows us to include disks directly (similar to using block devices with <strong class="source-inline">hostPath</strong>). It is not very common to use <strong class="source-inline">iscsi</strong> volumes nowadays because it requires all the worker nodes to be completely equal (disk devices’ names must be completely equal in all cluster hosts). You can use node labels to specify where the workloads should run, but this makes them too fixed to the <span class="No-Break">underlying infrastructure.</span></li>
<li><strong class="source-inline">nfs</strong>: NFS volume types allow us to include a remote NFS filesystem in a Pod. The content of the mounted filesystem is maintained unless you remove it from your Pod’s processes. We specify the server and the exposed path, and we can mount it <a id="_idIndexMarker1181"/>in read-only mode by setting the <strong class="source-inline">readOnly</strong> key to <strong class="source-inline">true</strong>. The following screenshot shows a quick example displaying <a id="_idIndexMarker1182"/>the <span class="No-Break">required keys:</span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer104">
<img alt="Figure 10.6 – Manifest showing an NFS volume mounted in a Pod" height="422" src="image/B19845_10_06.jpg" width="446"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.6 – Manifest showing an NFS volume mounted in a Pod</p>
<ul>
<li><strong class="source-inline">PersistentVolumeClaim</strong>: This is the most advanced volume definition and requires a full section to describe its usage. We will learn how to use them in the <span class="No-Break">next subsection.</span></li>
<li><strong class="source-inline">ephemeral</strong>: These volumes may be considered similar to <strong class="source-inline">emptyDir</strong> because they are designed to provide ephemeral storage while a Pod is running, but they differ in that we can integrate PVC resources as ephemeral volumes or local storage. The volumes can be empty or they can already have some content when they are attached to <span class="No-Break">the Pod.</span></li>
</ul>
<p>A lot of cloud providers’ volumes have moved from Kubernetes core-based storage to modern PVC <a id="_idIndexMarker1183"/>management using external PV dynamic provisioners. Disassembling the storage provisioning from the Kubernetes code allows hardware <a id="_idIndexMarker1184"/>storage manufacturers, cloud providers, and middleware software creators to prepare their own solutions and evolve them out of the Kubernetes development cycle. We will now learn how PV and PVC resources allow us to improve storage management <span class="No-Break">on Kubernetes.</span></p>
<h1 id="_idParaDest-223"><a id="_idTextAnchor240"/>Enhancing storage management in Kubernetes with PV resources</h1>
<p>A PV resource presents a unit of storage that can be used within Kubernetes. PVs can be created <a id="_idIndexMarker1185"/>manually or dynamically by a storage <span class="No-Break">provisioning backend.</span></p>
<p>While the <a id="_idIndexMarker1186"/>volume definitions seen so far are declared namespace-wide, PV resources are defined cluster-wide, by Kubernetes administrators. We use them to define the storage capacity (size) using the <strong class="source-inline">capacity.storage</strong> key and the mode it will be consumed using the <strong class="source-inline">accessMode</strong> key. Let’s quickly review these modes, because our applications may need specific access to the data, especially when we run multiple replicas of <span class="No-Break">a process:</span></p>
<ul>
<li><strong class="source-inline">ReadWriteOnce</strong>: This mode presents the storage in write mode only for the first Pod that attaches it. Other Pods (replicas or even defined in other different workloads) can only have read access to <span class="No-Break">the data.</span></li>
<li><strong class="source-inline">ReadOnlyMany</strong>: In this mode, all the Pods will mount the volume in <span class="No-Break">read-only mode.</span></li>
<li><strong class="source-inline">ReadWriteMany</strong>: This is the option to use when processes running in different Pods need to write on a PV at the same time. You must ensure your application manages the locks for writing your data without <span class="No-Break">corrupting it.</span></li>
</ul>
<p>You have to be aware that <strong class="source-inline">accessMode</strong> does not enforce write protection once the volume is mounted. If you need to ensure that it is mounted in read-only mode in some Pods, you must use the <span class="No-Break"><strong class="source-inline">readOnly</strong></span><span class="No-Break"> key.</span></p>
<p>Multiple access modes can be defined in a PV resource but it only uses one when it is mounted. This helps the cluster to bind PVs, but it will fit the specifications in each <span class="No-Break">volume request.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">The mode also affects how applications will be updated by issuing a rolling update. By default, Deployment resources will start a new Pod instance before the old one is stopped to maintain the application working. But the <strong class="source-inline">ReadWriteOnce</strong> access mode will only allow the old Pod to access the storage while the new one will wait forever to attach it. In such situations, it may be interesting to change the default rolling update behavior to ensure that the old processes stop completely and free the volume before the new ones start with the <span class="No-Break">storage attached.</span></p>
<p>To use an <a id="_idIndexMarker1187"/>available PV, we will use a PVC resource that may be considered a request for storage. These resources are defined <a id="_idIndexMarker1188"/>namespace-wide because they will be used by our workloads. You, as a developer, will ask for storage for your application, defining a PVC with the required <strong class="source-inline">capacity.storage</strong> and <strong class="source-inline">accessMode</strong> keys. When both options match an already created and free PV resource, they are bound and the storage is attached to the Pod. In fact, the volumes are attached to the host that runs the Pod, and kubelet makes it available inside <span class="No-Break">the Pod.</span></p>
<p>Labels can be used to fix PVCs with a subset of PVs by using <strong class="source-inline">selector.matchLabels</strong> and an appropriate label. The following screenshot shows an example of <strong class="source-inline">PersistentVolume</strong> created as a local <span class="No-Break"><strong class="source-inline">hostPath</strong></span><span class="No-Break"> variable:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer105">
<img alt="Figure 10.7 – PV and PVC manifests" height="572" src="image/B19845_10_07.jpg" width="876"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.7 – PV and PVC manifests</p>
<p>If the <a id="_idIndexMarker1189"/>PVC is created, but there isn’t <a id="_idIndexMarker1190"/>a PV available matching the PVC’s defined requirements, it will stay unbound forever, waiting for a PV to be created or free in the <span class="No-Break">Kubernetes cluster.</span></p>
<p>When a Pod is using a PVC and it is bound to a PV, the storage can’t be removed until the Pod frees it when the Pod is removed. The following screenshot shows how a Pod uses <span class="No-Break">a PVC:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer106">
<img alt="Figure 10.8 – Pod manifest using a PVC associated with a PV" height="430" src="image/B19845_10_08.jpg" width="831"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.8 – Pod manifest using a PVC associated with a PV</p>
<p>PVs can be resized if the underlying filesystem is either <strong class="source-inline">xfs</strong>, <strong class="source-inline">ext3</strong>, or <strong class="source-inline">ext4</strong>. Depending <a id="_idIndexMarker1191"/>on the storage backend, we can clone the PV content or even create snapshots, which may be very interesting <a id="_idIndexMarker1192"/>for debugging purposes when a problem is occurring in your application with a set of data or <span class="No-Break">for backups.</span></p>
<p>Node affinity can be used to use specific cluster nodes with specific directories or even disk devices and mount the PVs wherever the directory is present. You, as a developer, should avoid node affinity unless your Kubernetes administrators ask you to use this feature as it makes your <span class="No-Break">workloads infrastructure-dependent.</span></p>
<p>PVs can be provisioned either manually by your Kubernetes administrator or dynamically, using a container storage interface integrated solution that will interact with a storage backend to create the volumes for you. Multiple storage solutions can coexist in your cluster, which may provide different storage capabilities. No matter whether your platform uses dynamic provisioning or manually created volumes, we may access faster backends, more resilient ones, or some with <span class="No-Break">specific housekeeping.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">It is important to understand that matching a PVC to an appropriate PV can lead to bad use of disk space. When a PVC asks for 5 Gi and a PV with a size of 10 Gi is available, they will be bound despite their size not matching. This means we’ll use only 50% of the available space. That’s why dynamic provisioning is so important, because it creates PVs with the exact size required and then they are bound, hence the data fits perfectly in the <span class="No-Break">provisioned storage.</span></p>
<p>We will <a id="_idIndexMarker1193"/>use StorageClass resources to classify the PVs by their capabilities. Kubernetes administrators will associate <a id="_idIndexMarker1194"/>created PV resources to any of the configured StorageClass resources. A default StorageClass may be defined to associate all PVs without a <strong class="source-inline">spec.storageClassName</strong> key. Whenever we create a PVC resource, we can either define a specific StorageClass or wait for the cluster to assign a PV from the default StorageClass to <span class="No-Break">our claim.</span></p>
<p>Now that we know about the basic concepts of storage management, we can take a quick look at the provisioning and decommissioning <span class="No-Break">of storage.</span></p>
<h2 id="_idParaDest-224"><a id="_idTextAnchor241"/>Provisioning and decommissioning storage</h2>
<p>Kubernetes does not manage how PVs are created or destroyed in storage backends. It just interacts <a id="_idIndexMarker1195"/>with their interfaces via a REST API to retrieve and follow the changes and states of <span class="No-Break">the storage.</span></p>
<p><strong class="bold">Dynamic provisioning</strong> requires <a id="_idIndexMarker1196"/>some Kubernetes administration <a id="_idIndexMarker1197"/>work. Kubernetes administrators will deploy <strong class="bold">Container Storage Interface</strong> (<strong class="bold">CSI</strong>) solutions and attach them to specific StorageClass resources, making them available for users. Each StorageClass resource includes its own parameters for invoking the provisioner, hence different PV resources will be created, depending on the mechanism used to <span class="No-Break">create them.</span></p>
<p>The following <a id="_idIndexMarker1198"/>screenshot shows two StorageClass resources <a id="_idIndexMarker1199"/>using a <strong class="bold">Google Compute Engine</strong> (<strong class="bold">GCE</strong>) storage backend with different parameters (appropriate provisioner software must be installed in your Kubernetes cluster to use it, via the <strong class="source-inline">kubernetes.io/gce-pd</strong> API endpoint) for creating standard and SSD (fast hard <span class="No-Break">drives) PVs:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer107">
<img alt="Figure 10.9 – StorageClass manifests for standard and SSD storage" height="379" src="image/B19845_10_09.jpg" width="805"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.9 – StorageClass manifests for standard and SSD storage</p>
<p>Notice <a id="_idIndexMarker1200"/>the <strong class="source-inline">reclaimPolicy</strong> key, which manages <a id="_idIndexMarker1201"/>the behavior of the provisioner when a Pod frees a PV and this <span class="No-Break">is reused:</span></p>
<ul>
<li>A <strong class="source-inline">Retain</strong> policy will not modify the content of the PV, therefore we need to remove it from the provisioner backend manually when the data isn’t <span class="No-Break">needed anymore.</span></li>
<li>A <strong class="source-inline">Recycle</strong> policy will basically delete all the content of the volume (such as issuing <strong class="source-inline">rm -rf /volumedata/*</strong> from a Pod mounting the PV). This is only supported in NFS and <span class="No-Break"><strong class="source-inline">hostPath</strong></span><span class="No-Break"> provisioners.</span></li>
<li>A <strong class="source-inline">Delete</strong> policy will completely delete the PV and its content by asking the provisioner API to delete the <span class="No-Break">associated volume.</span></li>
</ul>
<p class="callout-heading">Important note</p>
<p class="callout">Using PV and PVC resources allows us to prepare our application’s workloads to work on any Kubernetes infrastructure. We will just modify <strong class="source-inline">StorageClassName</strong> to fit any of the StorageClasses present in the <span class="No-Break">deployment platform.</span></p>
<p>We will now review some labs that will help us better understand some of the content of <span class="No-Break">this chapter.</span></p>
<h1 id="_idParaDest-225"><a id="_idTextAnchor242"/>Labs</h1>
<p>In this section, we will use some of the resources presented to improve our <strong class="source-inline">simplestlab</strong> application. We will include sensitive data in a Secret resource, NGINX configurations in a ConfigMap resource, and a simple StorageClass resource to implement a PV resource and a PVC resource to present storage for our <span class="No-Break">StatefulSet resource.</span></p>
<p>The code for <a id="_idIndexMarker1202"/>all the labs is available in this book’s GitHub repository at <a href="https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git">https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git</a>. Ensure you have the latest revision available by simply executing <strong class="source-inline">git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git</strong> to download all its content or <strong class="source-inline">git pull</strong> if you have already downloaded the repository. All the manifests and the steps required for adding storage to the <strong class="source-inline">simplestlab</strong> application are located inside the <span class="No-Break"><strong class="source-inline">Containers-for-Developers-Handbook/Chapter10</strong></span><span class="No-Break"> directory.</span></p>
<p>This section will show you how to implement different volume solutions on the <strong class="source-inline">simplestlab</strong> tier-three application, prepared for Kubernetes in <a href="B19845_09.xhtml#_idTextAnchor202"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, <em class="italic">Implementing </em><span class="No-Break"><em class="italic">Architecture Patterns</em></span><span class="No-Break">.</span></p>
<p>These are the tasks you will find in the <a href="B19845_10.xhtml#_idTextAnchor231"><span class="No-Break"><em class="italic">Chapter 10</em></span></a> <span class="No-Break">GitHub repository:</span></p>
<ul>
<li>We will improve the security of the <strong class="source-inline">simplestlab</strong> application by adding Secret resources on any sensitive data required by the application. We will review each application component, create the required Secret resources, and modify the component’s manifests to include the newly created resources. This includes some database initialization scripts required for the <span class="No-Break">database component.</span></li>
<li>We will also prepare different ConfigMap resources for the <strong class="source-inline">lb</strong> application’s component and verify how these changes impact the <span class="No-Break">application behavior.</span></li>
</ul>
<p>You can use one of the following Kubernetes <span class="No-Break">desktop environments:</span></p>
<ul>
<li><span class="No-Break">Docker Desktop</span></li>
<li><span class="No-Break">Rancher Desktop</span></li>
<li><span class="No-Break">Minikube</span></li>
</ul>
<p>The labs will work on any of them, and of course, on any other Kubernetes environment. You may find issues with their default storage class, but there are some comments on the files that may be changed. We’ll start with improving the <strong class="source-inline">simplestlab</strong> application <span class="No-Break">on Kubernetes:</span></p>
<ol>
<li>The <strong class="source-inline">simplestlab</strong> application is a very simple tier-3 application (a load balancer could present additional static content but it is not added for the purposes of the labs). To make it more secure, we’re going to add Secret resources for defining all the required <span class="No-Break">user authentications.</span><p class="list-inset">The application is composed of <span class="No-Break">three components:</span></p><ul><li>A <strong class="source-inline">db</strong> component: <span class="No-Break">Postgres database</span></li><li>An <strong class="source-inline">app</strong> component: Application backend <span class="No-Break">in Node.js</span></li><li>An <strong class="source-inline">lb</strong> component: NGINX fronted for <span class="No-Break">static content</span></li></ul><p class="list-inset">We have included in their manifests some of the storage solutions learned in <span class="No-Break">this chapter.</span></p></li>
<li>Let’s look at <a id="_idIndexMarker1203"/>the database component first. As we are already using a StatefulSet resource, a PVC resource is configured, but the <strong class="source-inline">postgres</strong> user password was presented in the database container in clear text. We added a Secret resource to include this password, and we also included a complete database initialization script that will allow us to prepare the database. In the previous labs, this component was initialized with the script included in the container image. In this case, we can manage how the database for the application will be created by modifying this script and replacing the Secret. You must know that we can’t use this mechanism to modify a previously initialized database. That’s why we expect to deploy this component <span class="No-Break">from scratch.</span><p class="list-inset">These are two Secret <span class="No-Break">manifests created:</span></p><ul><li><strong class="source-inline">dbcredentials.secret.yaml</strong>, the content of which is <span class="No-Break">shown here:</span><pre class="source-code">
apiVersion: v1
data:
  POSTGRES_PASSWORD: Y2hhbmdlbWU=
kind: Secret
metadata:
  name: dbcredentials</pre></li><li><strong class="source-inline">initdb.secret.yaml</strong>: This Secret <a id="_idIndexMarker1204"/>is created by including the content of <span class="No-Break"><strong class="source-inline">init-demo.sh</strong></span><span class="No-Break"> script:</span><pre class="source-code"><strong class="bold">$ cat init-demo.sh</strong>
<strong class="bold">#!/bin/bash</strong>
<strong class="bold">set -e</strong>
<strong class="bold">psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" &lt;&lt;-EOSQL</strong>
<strong class="bold">    CREATE USER demo with PASSWORD 'd3m0' ;</strong>
<strong class="bold">    CREATE DATABASE demo owner demo;</strong>
<strong class="bold">    GRANT ALL PRIVILEGES ON DATABASE demo TO demo;</strong>
<strong class="bold">    \connect demo;</strong>
<strong class="bold">    CREATE TABLE IF NOT EXISTS hits</strong>
<strong class="bold">    (</strong>
<strong class="bold">      hitid serial,</strong>
<strong class="bold">      serverip varchar(15) NOT NULL,</strong>
<strong class="bold">      clientip varchar(15) NOT NULL,</strong>
<strong class="bold">      date timestamp without time zone,</strong>
<strong class="bold">      PRIMARY KEY (hitid)</strong>
<strong class="bold">    );</strong>
<strong class="bold">    ALTER TABLE hits OWNER TO demo;</strong>
<strong class="bold">EOSQL</strong></pre></li></ul><p class="list-inset">We used the following command line to create an <strong class="source-inline">initdb.secret.yaml</strong> <span class="No-Break">Secret manifest:</span></p><pre class="source-code"><strong class="bold">$ kubectl create secret generic initdb \</strong>
<strong class="bold">--from-file=init-demo.sh --dry-run=client \</strong>
<strong class="bold">-o yaml |tee initdb.secret.yaml</strong>
<strong class="bold">apiVersion: v1</strong>
<strong class="bold">data:</strong>
<strong class="bold">  init-demo.sh: IyEvYmluL2Jhc2gKc2V0IC1lCgpwc3FsIC12IE9OX0VSUk9SX1NUT1A9MSAt....pZCkKICAgICk7CiAgICBBTFRFUiBUQUJMRSBoaXRzIE9XTkVSIFRPIGRlbW87CkVPU1FMCg==</strong>
<strong class="bold">kind: Secret</strong>
<strong class="bold">metadata:</strong>
<strong class="bold">  creationTimestamp: null</strong>
<strong class="bold">  name: initdb</strong></pre></li> <li>In both <a id="_idIndexMarker1205"/>cases, the values are encoded in Base64 format. They aren’t encrypted, as we <span class="No-Break">can verify:</span><pre class="source-code">
<strong class="bold">$ kubectl apply -f dbcredentials.secret.yaml</strong>
<strong class="bold">$ kubectl get secret dbcredentials \</strong>
<strong class="bold">-ojsonpath="{.data.POSTGRES_PASSWORD}"|base64 -d</strong>
<strong class="bold">changeme</strong></pre></li> <li>Let’s see now how the <strong class="source-inline">StatefulSet</strong> manifest <span class="No-Break">was modified:</span><pre class="source-code">
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: db
  labels:
    component: db
    app: simplestlab
spec:
  replicas: 1
...
      volumes:
      - name: initdb-secret
        secret:
          secretName: initdb
          optional: true
      containers:
      - name: database
        image: docker.io/frjaraur/simplestdb:1.0
...
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: dbcredentials
              key: POSTGRES_PASSWORD
        - name: PGDATA
          value: /data/postgres
        volumeMounts:
        - name: postgresdata
          mountPath: /data
        - name: initdb-secret
          mountPath: "/docker-entrypoint-initdb.d/"
          readOnly: true
...
  volumeClaimTemplates:
  - metadata:
      name: postgresdata
    spec:
      accessModes: [ "ReadWriteOnce" ]
      #storageClassName: "csi-hostpath-sc"
      resources:
        requests:
          storage: 1Gi</pre><p class="list-inset">The full <a id="_idIndexMarker1206"/>manifest file can be found in the <span class="No-Break"><strong class="source-inline">Chapter10/db.statefulset.yaml</strong></span><span class="No-Break"> file.</span></p></li> <li>We create all the components for <span class="No-Break">the database:</span><pre class="source-code">
<strong class="bold">$ kubectl create -f dbcredentials.secret.yaml \</strong>
<strong class="bold">-f initdb.secret.yaml</strong>
<strong class="bold">secret/dbcredentials created</strong>
<strong class="bold">secret/initdb created</strong>
<strong class="bold">$ kubectl create -f db.statefulset.yaml</strong>
<strong class="bold">statefulset.apps/db created</strong>
<strong class="bold">$ kubectl create -f db.service.yaml</strong>
<strong class="bold">service/db created</strong></pre><p class="list-inset">The service wasn’t modified <span class="No-Break">at all.</span></p></li> <li>We check if the user was created by connecting to the database server and showing <span class="No-Break">its users:</span><pre class="source-code">
<strong class="bold">$ kubectl exec -ti db-0 -- psql -U postgres</strong>
<strong class="bold">psql (15.3)</strong>
<strong class="bold">Type "help" for help.</strong>
<strong class="bold">postgres=# \du</strong>
<strong class="bold">                                   List of roles</strong>
<strong class="bold"> Role name |                         Attributes</strong>
<strong class="bold">| Member of</strong>
<strong class="bold">-----------+------------------------------------------------------------+-----------</strong>
<strong class="bold"> demo      |</strong>
<strong class="bold">| {}</strong>
<strong class="bold"> postgres  | Superuser, Create role, Create DB, Replication, Bypass RLS | {}</strong>
<strong class="bold">postgres=# \q</strong>
<strong class="bold">could not save history to file "//.psql_history": Permission denied</strong></pre><p class="list-inset">Notice that <a id="_idIndexMarker1207"/>we modified the content of the <strong class="source-inline">POSTGRES_PASSWORD</strong> variable, and now it’s taken from the Secret <span class="No-Break">we created.</span></p><p class="list-inset">We also included <strong class="source-inline">initdb-secre</strong>t as a volume, and it’s mounted in the <strong class="source-inline">/docker-entrypoint-initdb.d</strong> directory. Notice that we didn’t use <strong class="source-inline">subPath</strong> because this directory is empty. You can change the content of the Secret and it will be synced inside the containers, but this will not change the authentication values in the database because it is an initialization script. You can modify it to enforce the change of the password <span class="No-Break">via SQL.</span></p></li> <li>We can now review the PVC, created by using a template (because it is a StatefulSet) and the <span class="No-Break">associated PV:</span><pre class="source-code">
<strong class="bold">$ kubectl get pvc</strong>
<strong class="bold">NAME                STATUS   VOLUME</strong>
<strong class="bold">CAPACITY   ACCESS MODES   STORAGECLASS   AGE</strong>
<strong class="bold">postgresdata-db-0   Bound    pvc-4999f00b-deb3-4cec-97a0-3a289c4457d9   1Gi        RWO            hostpath</strong>
<strong class="bold">168m</strong>
<strong class="bold">$ kubectl get pv pvc-4999f00b-deb3-4cec-97a0-3a289c4457d9</strong>
<strong class="bold">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM      STORAGECLASS   REASON   AGE</strong>
<strong class="bold">pvc-4999f00b-deb3-4cec-97a03a289c4457d9   1Gi        RWO  Delete     Bound    default/postgresdata-db-0   hostpath                168m</strong></pre></li> <li>A StorageClass resource <a id="_idIndexMarker1208"/>is defined in Docker Desktop and we use it <span class="No-Break">by default:</span><pre class="source-code">
<strong class="bold">$ kubectl get sc</strong>
<strong class="bold">NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</strong>
<strong class="bold">hostpath (default)   docker.io/hostpath   Delete    Immediate           false                  12d</strong></pre><p class="list-inset">We can now continue and review the changes in the <span class="No-Break">app component.</span></p></li> <li>For the application backend component, we used the imperative method to create an <strong class="source-inline">appcredentials</strong> Secret. This method does not generate a YAML manifest, which may be a problem because you will need to store your passwords somewhere. If you need to store all your manifest in your code repository, which is always recommended, you must always encrypt your <span class="No-Break">Secret manifests:</span><pre class="source-code">
<strong class="bold">$ kubectl create secret generic appcredentials \</strong>
<strong class="bold">--from-literal=dbhost=db \</strong>
<strong class="bold">--from-literal=dbname=demo \</strong>
<strong class="bold">--from-literal=dbuser=demo \</strong>
<strong class="bold">--from-literal=dbpasswd=d3m0</strong>
<strong class="bold">secret/appcredentials created</strong></pre><p class="list-inset">The values for these variables must be the ones used in the <span class="No-Break">initialization script.</span></p></li> <li>Let’s review <a id="_idIndexMarker1209"/>the changes included to load the database authentication in <span class="No-Break">the application:</span><pre class="source-code">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
...
      containers:
      - name: app
        image: docker.io/frjaraur/simplestapp:1.0
        ports:
        - containerPort: 3000
        env:
        - name: dbhost
          valueFrom:
            secretKeyRef:
              name: appcredentials
              key: dbhost
        - name: dbname
          valueFrom:
            secretKeyRef:
              name: appcredentials
              key: dbname
...</pre><p class="list-inset">The full manifest file can be found in the <span class="No-Break"><strong class="source-inline">Chapter10/app.deployment.yaml</strong></span><span class="No-Break"> file.</span></p></li> <li>We have just <a id="_idIndexMarker1210"/>included all the required environment variables from the Secret created before. We deploy the <span class="No-Break">app manifests:</span><pre class="source-code">
<strong class="bold">$ kubectl create -f app.deployment.yaml</strong>
<strong class="bold">-f app.service.yaml</strong>
<strong class="bold">deployment.apps/app created</strong>
<strong class="bold">service/app created</strong></pre><p class="list-inset">We now verify the content included in <span class="No-Break">the containers:</span></p><pre class="source-code"><strong class="bold">$ kubectl exec -ti app-5f9797d755-2bgtt – env</strong>
<strong class="bold">...</strong>
<strong class="bold">dbhost=db</strong>
<strong class="bold">dbname=demo</strong>
<strong class="bold">dbuser=demo</strong>
<strong class="bold">dbpasswd=d3m0</strong>
<strong class="bold">...</strong>
<strong class="bold">$ kubectl get pods</strong>
<strong class="bold">NAME                   READY   STATUS    RESTARTS   AGE</strong>
<strong class="bold">app-5f9797d755-2bgtt   1/1     Running   0          100s</strong>
<strong class="bold">app-5f9797d755-gdpw7   1/1     Running   0          100s</strong>
<strong class="bold">app-5f9797d755-rzkqz   1/1     Running   0          100s</strong>
<strong class="bold">db-0                   1/1     Running   0          179m</strong></pre></li> <li>We can now <a id="_idIndexMarker1211"/>continue with the frontend component. In the previous versions of this application’s deployment, we were already using a ConfigMap resource for configuring the NGINX <span class="No-Break">load balancer.</span><p class="list-inset">This is the content of the ConfigMap resource with these special configurations for our NGINX <span class="No-Break">load balancer:</span></p><pre class="source-code">
apiVersion: v1
kind: ConfigMap
metadata:
  name: lb-config
  labels:
    component: lb
    app: simplestlab
data:
  nginx.conf: |
    user  nginx;
    worker_processes  auto;
    error_log  /tmp/nginx/error.log warn;
    pid        /tmp/nginx/nginx.pid;
    events {
      worker_connections  1024;
    }
    http {
      server {
        listen 8080; # specify a port higher than 1024 if running as non-root user
        location /healthz {
            add_header Content-Type text/plain;
            return 200 'OK';
        }
        location / {
          proxy_pass http://app:3000;
        }
      }
    }</pre></li> <li>We deploy <a id="_idIndexMarker1212"/>all the <span class="No-Break"><strong class="source-inline">lb</strong></span><span class="No-Break"> manifests:</span><pre class="source-code">
<strong class="bold">$ kubectl create -f lb.daemonset.yaml \</strong>
<strong class="bold">-f lb.configmap.yaml -f  lb.service.yaml</strong>
<strong class="bold">daemonset.apps/lb created</strong>
<strong class="bold">configmap/lb-config created</strong>
<strong class="bold">service/lb create</strong></pre></li> <li>We review the status of all the application’s components and the configuration applied to <a id="_idIndexMarker1213"/>the <span class="No-Break">NGINX component:</span><pre class="source-code">
<strong class="bold">$ kubectl get pods</strong>
<strong class="bold">NAME                   READY   STATUS    RESTARTS   AGE</strong>
<strong class="bold">app-5f9797d755-2bgtt   1/1     Running   0          5m52s</strong>
<strong class="bold">app-5f9797d755-gdpw7   1/1     Running   0          5m52s</strong>
<strong class="bold">app-5f9797d755-rzkqz   1/1     Running   0          5m52s</strong>
<strong class="bold">db-0                   1/1     Running   0          3h4m</strong>
<strong class="bold">lb-zcm6q               1/1     Running   0          2m2s</strong>
<strong class="bold">$ kubectl exec lb-zcm6q -- cat /etc/nginx/nginx.conf</strong>
<strong class="bold">user  nginx;</strong>
<strong class="bold">worker_processes  auto;</strong>
<strong class="bold">...    location / {</strong>
<strong class="bold">      proxy_pass http://app:3000;</strong>
<strong class="bold">    }</strong>
<strong class="bold">  }</strong>
<strong class="bold">}</strong>
<strong class="bold">$</strong></pre></li> <li>And now, we can reach our application in any Kubernetes cluster host’s port 32000. Your browser should access the application and show something like this (if you’re using Docker Desktop, you will need to <span class="No-Break">use </span><a href="http://localhost:32000"><span class="No-Break">http://localhost:32000</span></a><span class="No-Break">):</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer108">
<img alt="Figure 10.10 – simplestlab application web GUI" height="717" src="image/B19845_10_10.jpg" width="709"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.10 – simplestlab application web GUI</p>
<p>With this final step, you deployed completely the three components of the <strong class="source-inline">simplestlab</strong> application. You will find additional steps in the <strong class="source-inline">Chapter10</strong> folder in the GitHub repository <a id="_idIndexMarker1214"/>to add a new app component instance and modify the load balancer component to reach this <span class="No-Break">new backend.</span></p>
<p>These labs will help you understand how Secret resources improve the security of an application and how to implement different volume types for different <span class="No-Break">application needs.</span></p>
<h1 id="_idParaDest-226"><a id="_idTextAnchor243"/>Summary</h1>
<p>In this chapter, we reviewed how we can manage data in a Kubernetes cluster, which is currently the most popular container orchestrator, and you will probably use it for most of your projects. We learned how to include configurations and sensitive data in our application’s containers, and how we can manage stateless and stateful storage using different Kubernetes resources. At the end of the chapter, we learned how we can use dynamic provisioning of data volumes for our applications, which really fits in the microservices model, where automation is crucial for abstracting resources from the underlying infrastructure. This chapter is very important because it has taught you how to manage data in microservices and <span class="No-Break">container-based environments.</span></p>
<p>We will follow this up in the next chapter, in which we will learn how to publish our applications using best security practices, isolating all backend components from users and <span class="No-Break">other applications.</span></p>
</div>
</div></body></html>