<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Developing with Cloud Run for Anthos</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will discover how to leverage more sophisticated tools and services to deliver production-level management of the environment. Kubernetes is a wide and intriguing subject that is beyond the scope of this book. However, knowing some of the background and key elements will make the transition to this platform easier.</p>
<p>As per earlier chapters, an introduction to Cloud Run and Kubernetes will cover the key aspects of the technology. In that respect, working through the first section should act as a primer on <strong>Google Kubernetes Engine</strong> (<strong>GKE</strong>) if you are unfamiliar with the topic. Working with Cloud Run for Anthos provides the ability to utilize many of the benefits of Kubernetes. This chapter will deliver sufficient information to get you started. If you are already familiar with GKE, then feel free to skip the initial section and move on to the specifics of Cloud Run for Anthos. </p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Setting up identity and policy management</li>
<li>Working with environment monitoring</li>
<li>C<span>reating custom networking</span></li>
<li>E<span>stablishing domains</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="mce-root">To complete the hands-on exercises in this chapter, you will require a Google Cloud project.</p>
<p><span>You can find the code files used in this chapter in the GitHub repository for the book under the <kbd>ch09</kbd> sub-directory, at <a href="https://github.com/PacktPublishing/Hands-on-Serverless-Computing-with-Google-Cloud/tree/master/ch09">https://github.com/PacktPublishing/Hands-on-Serverless-Computing-with-Google-Cloud/tree/master/ch09</a></span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Identity and policy management</h1>
                </header>
            
            <article>
                
<p>Understanding the identity and policy arrangement on Google Cloud is a major learning curve for most users. Identity Access Management is a major component and could easily be the focus of its own book. In short, IAM provides a policy on a project to provide the relevant permissions associated with roles.</p>
<p class="mce-root">On Google Cloud, administrative management operations are typically performed using a service account. Working with the Google Cloud catalog, the IAM roles are defined to address the needs of users across a wide variety of scenarios.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IAM objects</h1>
                </header>
            
            <article>
                
<p class="mce-root">At a high level, Google Cloud uses a hierarchical structure made up of organizations, folders, projects, and resources to marshal access.</p>
<ul>
<li class="mce-root">The organization node is the root node for Google Cloud resources and containers all of the projects and resources.</li>
<li class="mce-root">Folders are optional, used to group projects under an organization. A folder may contain both projects and other folders. IAM policies can be used to control access to the resources a folder contains.</li>
<li class="mce-root">Google Cloud resources are always associated with a project. Google Cloud allows you to track resource and quota usage, enable billing, manage permissions and credentials, and enable services and APIs.</li>
</ul>
<p class="mce-root">The hierarchy defined in the preceding list is combined with members (that is, <strong>users</strong> or <strong>service accounts</strong>) and roles to constrict project access to specific groups based on defined access permissions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Members</h1>
                </header>
            
            <article>
                
<p>Member accounts are important as they provide access to the organization. Think of member accounts as providing domain access, that is used to determine the actions that can be performed when using the services available in Google Cloud. There are two types to consider when working with member accounts:</p>
<ul>
<li class="mce-root"><strong>Member roles</strong><em>:</em> Permissions given to members through the granting of roles. Roles define which permissions are granted. Google Cloud provides predefined roles, and also the ability to create custom roles.</li>
<li class="mce-root"><strong>Service accounts</strong>: These allow us to control server-to-server interaction. Typically used to authenticate one service to another and control the application actions that a service can perform, service accounts on Google are referenced by an email address in the <kbd>gserviceaccount.com</kbd> domain.</li>
</ul>
<p>Once a member account has been defined, the next step is to assign a role to the member. In effect, this is providing permissions to perform actions within the project.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Roles</h1>
                </header>
            
            <article>
                
<p>On Google Cloud, roles provide a very flexible way to give access to resources. Access in this context is provided as a spectrum in which the range is coarse (in Google Cloud terms, primitive) to fine-grained (in Google Cloud terms, custom) depending on the use case. The three role types are outlined in the following list. In most instances, a mixture of these role types will be used to deliver the type of access required:</p>
<ul>
<li class="mce-root"><strong>Primitive</strong>: The least granular roles that existed before the introduction of Cloud IAM. Defined at the project level, these offer a coarse-grained level of access, for example, the <span class="packt_screen">Owner</span>, <span class="packt_screen">Editor</span>, and <span class="packt_screen">Viewer roles</span>.</li>
<li class="mce-root"><strong>Predefined</strong>: Predefined IAM roles are used to provide finer-grained access control than primitive roles. Each Google Cloud service incorporates predefined roles. These are used to map to a job function, for example, <span class="packt_screen">Compute Network Admin</span>, <span class="packt_screen">Security Reviewer</span>.</li>
<li class="mce-root"><strong>Custom</strong>: Bespoke roles consisting of permissions and resources defined by the user.</li>
</ul>
<p class="mce-root">Learning the preceding role types will make working with Google Cloud significantly easier, as each project defined will adhere to the <span>structure </span>we've outlined. In the next section, we will look at GKE and see how this can be used in conjunction with Cloud Run.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of Google Kubernetes Engine</h1>
                </header>
            
            <article>
                
<p>Hopefully, you have heard about Kubernetes and understand how important this platform is for the deployment of technical environments. As an introduction for those not familiar with Kubernetes, this section will give you an overview of the key parts.</p>
<p>Kubernetes is an orchestration platform for containers that enables scheduling and maintenance to be performed in an automated fashion by the system, rather than manually by a user.</p>
<p>During the last couple of chapters on Cloud Run, we have discussed the importance of containers. What we haven't spoken about yet is what to do to coordinate this management, once you start to use it, in a more production-friendly way (that is, consistent and reliable). </p>
<p>As you might imagine, containers and Kubernetes are complementary technologies that establish an environment in which applications can be run at scale. The platform itself can be run on a range of Linux servers, including <strong>virtual machines</strong> (<strong>VMs</strong>), cloud instances, and even on bare metal. As an open source project, the pace of development is astounding, as are the quality of contributions. </p>
<p>To use Kubernetes on Google Cloud, we use GKE. This provides a managed environment for Kubernetes. To access the environment, we use a command called <kbd>kubectl</kbd>, also known as Kubernetes control. Provisioning and maintaining a Kubernetes cluster is beyond the scope of this book, but we will refer to the underlying constructs as we deploy our artifacts to the GKE cluster.</p>
<p>Knowing the use case for a product can save effort in terms of building solutions. At this point, it is worth outlining the key differences between Cloud Run and Cloud on GKE (apart from the need for Kubernetes).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Differentiating Cloud Run from Cloud Run for Anthos</h1>
                </header>
            
            <article>
                
<p class="mce-root">Cloud Run for Anthos provides many of the benefits of Cloud Run. In the following table, we illustrate some of the key differences that a user of the service should be aware of:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td/>
<td>
<p><strong>Cloud Run</strong></p>
</td>
<td>
<p><strong>Cloud Run for Anthos</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong>Billing</strong></p>
</td>
<td>
<p>Pay per use</p>
</td>
<td>
<p><span>Provisioned cluster resource</span></p>
</td>
</tr>
<tr>
<td>
<p><strong>Machine customization</strong></p>
</td>
<td>
<p>Memory</p>
</td>
<td>
<p>Memory, CPU, GPU, networking</p>
</td>
</tr>
<tr>
<td>
<p><strong>URL and SSL</strong></p>
</td>
<td>
<p>Automatic HTTPS URL</p>
</td>
<td>
<p>Manual SSL certificates</p>
</td>
</tr>
<tr>
<td>
<p><strong>Identity and Policy</strong></p>
</td>
<td>
<p>Public, invoker IAM role, CICP</p>
</td>
<td>
<p>Public or internal</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Despite the differences outlined in the preceding table, the services can actually be easily deployed without change via the simple deployment option. Development can be started on Cloud Run. Move to Cloud Run for Anthos where you need the platform resources associated with Kubernetes. There are also a number of features that are shared in common between the two: </p>
<ul>
<li style="font-weight: 400">Autoscaling (GKE limited by the cluster in use) for any service deployed.</li>
<li style="font-weight: 400">Run HTTP-based apps and services easily over TCP port <kbd>8080</kbd>.</li>
<li style="font-weight: 400">A simple developer experience based on containers using a manifest.</li>
<li style="font-weight: 400">Select any language, or any library that can be packaged within a container.</li>
<li style="font-weight: 400">Utilize custom domain names without the need to configure the environment.</li>
</ul>
<p>Now that we have a general appreciation of GKE, we can move on to apply our knowledge and use Cloud Run for Anthos in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Cloud Run for Anthos</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, w<span>orking with Cloud Run for Anthos provides the ability to utilize many of the benefits of Kubernetes. </span>In this section, we will explore some of these capabilities. Let's begin by creating (that is, provisioning)<span> a cluster with access to Cloud Run a GKE environment. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Provisioning GKE</h1>
                </header>
            
            <article>
                
<p>Cloud Run for Anthos requires a Kubernetes cluster. At a high level, Kubernetes provides a platform on which to manage (or <em>orchestrate</em>) containers. Outlining the value of Kubernetes is beyond the scope of this book, but it suffices to say it is something that is well worth the investment of time. </p>
<p>To deploy code to Cloud Run for Anthos, there is an assumption that there is a GKE cluster available. Cloud Run for Anthos requires some pre-existing infrastructure to be available prior to deployment taking place. In this section, we will spin up a cluster and then deploy our application to it to explore in what ways the process is different between Cloud Run for Anthos and Cloud Run.</p>
<p><span>The following example uses Cloud Shell to enter the command line and enable the services needed within a project.</span></p>
<ol>
<li>To provision a cluster, the <strong>Google Cloud Console</strong> or <strong>Cloud SDK</strong> (<strong>GCloud</strong>) can be used. For this example, the Cloud SDK will be used so the underlying commands can be seen. Many of the features accessed in this section will reference beta/alpha, as, at the time of writing, this is their current state. As Cloud Run uses Google Container Registry and Cloud Build APIs, these services will need to be enabled within your project. Enabling the relevant <kbd>googleapis</kbd> can be done via the Console or using Cloud SDK:</li>
</ol>
<pre style="padding-left: 60px"><strong><span>gcloud services enable container.googleapis.com containerregistry.googleapis.com cloudbuild.googleapis.com</span></strong></pre>
<ol start="2">
<li>Enabling Cloud Run on a cluster with beta status means the general format of the command may change once it moves to <strong>general availability</strong> (<strong>GA</strong>) status. If you are using Cloud Shell to run Cloud SDK commands, note this environment is automatically updated on a regular basis to incorporate the latest SDK changes. Other environments may need to be manually updated to ensure they have installed the correct components revisions. <span>Here, we are going to store the cluster name and zone to be used, as this information is needed by both the cluster creation and <kbd>build</kbd> command:</span></li>
</ol>
<pre style="padding-left: 60px">export CLUSTER_NAME="test-cluster"<br/>export ZONE="us-central1-a"</pre>
<div class="packt_tip"><span>Note that it is often useful to set some local environment variables to store common parameters as a convenience measure. Ensuring the environment variables are formatted in uppercase text makes them stand out in your command-line scripts. To access the value of a variable, append the <kbd>$</kbd> symbol in front of the variable name—for example, echo <kbd>$CLUSTER_NAME</kbd> will display the name associated with the cluster.</span></div>
<ol start="3">
<li>In the case of Cloud Run for Anthos, the element that is additionally required is the Cloud Run add-on. Our first use of the environment variable will be needed here. To reference this, we add the <kbd>$</kbd> to the front of the variable, for example, <kbd>$CLUSTER_NAME</kbd>. To provision the cluster, we use the following command to initiate the environment on which to deploy Cloud Run:</li>
</ol>
<pre style="padding-left: 60px"><strong>gcloud beta container clusters create $CLUSTER_NAME \</strong><br/><strong>--addons=HorizontalPodAutoscaling,HttpLoadBalancing,Istio,CloudRun \</strong><br/><strong>--machine-type=n1-standard-2 \</strong><br/><strong>--cluster-version=latest --zone=$ZONE \</strong><br/><strong>--enable-stackdriver-kubernetes \</strong><br/><strong>--scopes cloud-platform</strong></pre>
<p style="padding-left: 60px">Please be aware that there are restrictions on cluster names, so do check <span>prior to creation </span>that the details used conform. The following restrictions are applied; that is, they must be a match of regex <kbd>(?:[a-z](?:[-a-z0-9]{0,38}[a-z0-9])?)</kbd>, meaning the following:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li style="font-weight: 400">Only alphanumerics and <kbd>-</kbd> allowed </li>
<li style="font-weight: 400">Start with a letter and end with an alphanumeric</li>
<li style="font-weight: 400">No longer than 40 characters</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">When the cluster is created, there are a number of parameters we need to supply to the command that will be familiar if you have used GKE previously. A standard cluster requires the following:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li style="font-weight: 400">Machine size—compute reference indicating the type of machine to be allocated per node</li>
<li style="font-weight: 400">Cluster version—signifies the version to be allocated to the Kubernetes cluster</li>
<li style="font-weight: 400">Zone—the zone in which the compute resource will be created</li>
<li style="font-weight: 400">Addons—ancillary commands providing additional functionality</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">During the provisioning process, in the GKE Cloud Console option, there is a more interactive version of the command line that shows what is being performed. However, there is no need to use this over the command other than curiosity.</p>
<ol start="4">
<li>Once the cluster provisioning process completes, it will denote the configuration created. As an option, we can also set the <kbd>gcloud</kbd> command defaults for the project at this stage:</li>
</ol>
<pre style="padding-left: 60px"><strong>gcloud config set run/cluster $CLUSTER_NAME</strong><br/><strong>gcloud config set run/cluster_location $ZONE</strong></pre>
<ol start="5">
<li>To confirm the cluster has been successfully created, use the <kbd>kubectl</kbd> command to interact with GKE. Kubectl is the main way to interact directly with the cluster created. In order to check the nodes, we need to issue the following command:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong><span>kubectl get nodes</span></strong></pre>
<p>The output from the preceding command will display information such as the name, status, age, and version of the Kubernetes node deployed. In this context, a Kubernetes cluster is essentially our defined nodes working together as a unit.</p>
<p>In our GKE cluster, we now have the base platform on which to deploy Cloud Run. In the next section, we will take some time to explore how to deploy code to this environment. In addition, we will look at some workflow tips to aid development productivity.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Custom networking on GKE</h1>
                </header>
            
            <article>
                
<p>When using Kubernetes on GKE, it's useful to understand that it will create a custom network. The key emphasis to note is that Kubernetes will utilize IP addressing to assist with communication across all of its resources (such as pods, nodes, and services, and so on).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Internal networking</h1>
                </header>
            
            <article>
                
<p>The smallest element in a GKE cluster is called a <strong>pod</strong>. A pod is used to run containers and there can be just one or more, depending on the patterns used for a given application. Pods reside within the network namespace that is used to segregate access across the virtual network associated with Kubernetes.</p>
<p>Pods are scheduled to a node, and are able to communicate with any other pod, unless specifically restricted. Communication between pods is therefore taken as a given, even when they are removed and recreated dynamically. However, as pods are meant to be ephemeral, external access requires a separate mechanism called a service to provide a consistent point of access. Services use a label, which is basically a key-value pairing to a Kubernetes resource. Such a service retains a consistent IP address and port such that, externally, it can be used to access a grouping of pods as a logical unit.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">External networking</h1>
                </header>
            
            <article>
                
<p>For traffic outside of the cluster, the situation is managed in a different way. Kubernetes uses three distinct mechanisms to provide access to internal network resources.</p>
<p>NodePort and ClusterIP provide access using an HTTP load balancer. Ingress access to resources requires a service to be defined for the reasons <span>mentioned </span>previously. The communication then ensures traffic is directed to the logical group labeled for the service. </p>
<p>The main thing to note is that, as long as traffic remains within a cluster, communication between resources is enabled and supported. If external traffic is required, then a service and some form of load-balanced access should be made available.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying Cloud Run for Anthos</h1>
                </header>
            
            <article>
                
<p>Now that we have a cluster created, we can think about how to deploy an application. The main emphasis of this section is to cover the process to use in terms of deploying an application to the GKE cluster. Google has been very deliberate in terms of trying to keep the Cloud Run commands as similar as possible. As in the previous section, we will build a simple Node.js container and push this to GKE. </p>
<p>To demonstrate the capability of our new GKE cluster, we will deploy the <kbd>hello-node</kbd> Node.js application. Our <kbd>hello-node</kbd> application simply prints out a message to the screen, so there is no code complexity to worry about. In fact, we already have the code available in the repository, so let's clone that from the existing Cloud Shell environment:</p>
<ol>
<li>Clone the GitHub repository:</li>
</ol>
<pre style="padding-left: 60px"><strong><span>git clone [github repo]/ch09/hello-node</span></strong></pre>
<p style="padding-left: 60px">Again, the <kbd>hello-node</kbd> application doesn't do anything amazing, it just outputs <kbd>Hello World!</kbd> on port <kbd>8080</kbd>. It is all packaged up (that is, into a <kbd>cloudbuild.yaml</kbd> file and a Dockerfile) and ready for use to push an image to the container repository.</p>
<ol start="2">
<li>To begin the Cloud Build process, run the following command:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong><span>gcloud builds submit --config cloudbuild.yaml</span></strong></pre>
<p style="padding-left: 60px">In the build process, we will be using Google Container Registry, rather than the Docker Registry. A registry is essentially a storage location for images that can be used to push and pull stored images. The benefit of using a registry is that it provides a centralized storage area in which to share your images.</p>
<div class="packt_infobox">By default, the images stored in Container Registry are marked as private and require IAM permissions to access the content. Alternatively, images can also be marked as public, which means they can be shared outside of the project without requiring any additional authentication.</div>
<ol start="3">
<li>Once the build process has completed successfully, the image generated will be stored under the current Google Cloud project and given the tag specified in the <kbd>cloudbuild.yaml</kbd> file.</li>
</ol>
<p style="padding-left: 60px">The important thing to observe here is the tag associated with the image, as this is how the artifact will be referenced when pulling the image from the repository:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-843 image-border" src="assets/8fcbb888-a085-4a5f-a1c5-5ed05051ca0e.png" style=""/></div>
<p style="padding-left: 60px">Take a look in the Google Cloud Container Registry to see the image built in the previous step. Selecting the image in the registry will display further details, including the all-important tag reference.</p>
<p style="padding-left: 60px">From Container Registry, we can see the image, together with the hostname and level of visibility (that is, private/public) applied. The hostname provides the region for which the image is associated, outlined as follows:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li style="font-weight: 400"><kbd>gcr.io</kbd>: Currently located in the United States, but the location may change </li>
<li style="font-weight: 400"><kbd>us.gcr.io</kbd>: United States</li>
<li style="font-weight: 400"><kbd>eu.gcr.io</kbd>: European Union</li>
<li style="font-weight: 400"><kbd>asia.gcr.io</kbd>: Asia</li>
</ul>
</li>
</ul>
<div class="packt_tip"><br/>
When building images, it is advantageous to use a location closest to the data to maximize overall performance. The reason for this is that, when pulling the image (that is, the retrieval process), you want to minimize the distance between the registry source and destination host machine. </div>
<p style="padding-left: 60px">The visibility of an image is either private to the project or public (that is, accessible by everyone). By default, the images are set to private; however, the visibility can easily be changed if required.</p>
<p style="padding-left: 60px">At this point, as the image is present in the project registry, it will also be accessible to the cluster created earlier. Prior to deploying the image, let's take a moment to understand some of the terms used in the standard commands for deployment:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li style="font-weight: 400"><kbd>SERVICE</kbd>: Represents the name to be associated with the image to be deployed.</li>
<li style="font-weight: 400"><kbd>IMAGE</kbd>: An artifact available in Container Registry to be deployed as a service.</li>
<li style="font-weight: 400"><kbd>CLUSTER-NAME</kbd>: The name associated with the cluster created earlier; that is, <kbd>$CLUSTER_NAME</kbd>.</li>
<li style="font-weight: 400"><kbd>CLUSTER-LOCATION</kbd>: This is the zone allocated to the cluster; that is, <kbd>$ZONE</kbd>.</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">Take note that the <kbd>IMAGE</kbd> tag must exactly match what is available in Container Registry (including a version number, if applied). If you are unsure of the tag to use, visit the Cloud Console and select the image required to see the relevant tag detail. </p>
<p style="padding-left: 60px"><span>The deployed container will be displayed with a service name, a revision (that is, a unique reference), and a URL for serving traffic. </span>So far, we have created a placeholder for the service to be run. To make the container accessible as a named service, we need to deploy it.<span> In the real world, the prior activities are likely going to be a one-off task and can be easily automated. </span></p>
<ol start="4">
<li>To deploy the artifact to the GKE cluster, we use the <kbd>gcloud run deploy</kbd> command in the following way:</li>
</ol>
<pre style="padding-left: 60px"><strong><span>gcloud run deploy [SERVICE] --image [IMAGE] --platform gke --cluster [CLUSTER-NAME] --cluster-location [CLUSTER-LOCATION]</span></strong></pre>
<p>Now that the service has been deployed, there is a wealth of information suddenly available on the running of the application. There are two places of interest for information about the workloads running on GKE:</p>
<ul>
<li>The first is the Kubernetes Engine Workloads page, in which details of GKE deployments can be seen. If you are interested in the state of deployments or workloads sent to the cluster, this is a place to gather information. From here, it is possible to drill down into the various aspects of the deployment.</li>
<li>The second is Stackdriver. In the next section, we will update the application to see the impact this has on the data displayed and how to track information when things go wrong.</li>
</ul>
<p>Now that we have a base-level understanding of deployment, we can consider how to automate the process using the toolset available on Google Cloud.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Continuous deployment</h1>
                </header>
            
            <article>
                
<p>As we have seen, there is a lot of work to get a Cloud Run for Anthos up and running in comparison with Cloud Run. What happens if we want to deploy another revision of the code? Do we need to go through the whole process once again? Well no: the deployment of the service is the only aspect that needs to be repeated. Taking some time to explore this in more detail will be interesting and will provide an understanding of what is happening when multiple revisions are available to the cluster:</p>
<ol>
<li>Our previous image was version 0.1, so let's implement a small change (I added a <kbd>+1</kbd> to the response string) and see the impact this has on the deployment process and rollout to the cluster:</li>
</ol>
<pre style="padding-left: 60px">const express = require('express');<br/>const app = express();<br/>const port = process.env.PORT || 8080;<br/><strong>app.get('/', (req, res) =&gt; res.send('Hello World! +1'));</strong><br/>app.listen(port, () =&gt; console.log(`Example app listening on port ${port}!`));</pre>
<ol start="2">
<li>Next, update the stored image in Container Registry using the following command:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong><span>gcloud builds submit --config cloudbuild.yaml</span></strong></pre>
<ol start="3">
<li>Finally, we want to deploy the updated image in our cluster:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>gcloud beta run deploy [SERVICE] --image [IMAGE] --platform gke --cluster [CLUSTER-NAME] --cluster-location [CLUSTER-LOCATION]</strong></pre>
<p style="padding-left: 60px">The first this to do is confirm that the new service has been successfully deployed by looking at the command output. To get the status of a Cloud Run service, the Cloud console will always have an updated status in the workloads page and will show changes as they are initiated.</p>
<p style="padding-left: 60px">Unfortunately, it is a bit of a pain having to do these actions each time we want to deploy something. Never fear: there is a much more practical way of deploying our code that lets our trusty friends, the service account and Cloud Build, manage all the boring bits.</p>
<p class="mce-root" style="padding-left: 60px">In the <span class="packt_screen">Cloud Build</span> settings, amend the <span class="packt_screen">Cloud Run service account</span> <span class="packt_screen">(Cloud Run Admin)</span> and <span class="packt_screen">Service Accounts</span> <span class="packt_screen">(Service Account User)</span> to enabled. I<span>n the left-hand panel, </span>select the <span class="packt_screen">Triggers</span> option and connect to a valid repository.</p>
<div class="mce-root packt_infobox">Note that, if a connection to GitHub has already been established, this will need to be done to successfully complete this setup.</div>
<p class="mce-root" style="padding-left: 60px">Creating a push trigger can be set up for specific branches or for all pushes to the repository. Note the type of trigger will attempt to auto-detect the configuration file. In the case of the author, the <kbd>cloudbuild.yaml</kbd> file is renamed <kbd>cloudbuild.github</kbd>, so that it is patently obvious which environment file should be used.</p>
<p style="padding-left: 60px">Select the create button and the trigger will now be active for the selected repository.</p>
<ol start="4">
<li>Back with the source code, let's amend the source code once more with another simple change, so we have a visible way to discern the difference in deployed versions. Update the highlighted line so it reflects the change shown as follows:</li>
</ol>
<pre style="padding-left: 60px">const express = require('express')<br/>const app = express()<br/>const port = process.env.PORT || 8080;<br/><strong>app.get('/', (req, res) =&gt; res.send('Hello World! GitHub Build'))</strong><br/>app.listen(port, () =&gt; console.log(`Example app listening on port ${port}!`))</pre>
<ol start="5">
<li>Finally, we will need to amend the <kbd>cloudbuild.github.yaml</kbd> file to refine our build process. The updated configuration file will look similar to that shown as follows:</li>
</ol>
<pre style="padding-left: 60px">steps:<br/>  # Build the container image<br/>- name: 'gcr.io/cloud-builders/docker'<br/>  args: ['build', '-t', 'gcr.io/$PROJECT_ID/hello-node', '.']<br/>  # push the container image to Container Registry<br/>- name: 'gcr.io/cloud-builders/docker'<br/>  args: ['push', 'gcr.io/$PROJECT_ID/hello-node']<br/>  # Deploy container image to Cloud Run<br/>- name: 'gcr.io/cloud-builders/gcloud'<br/>  args: ['beta', 'run', 'deploy', 'hello-node', '--image', 'gcr.io/$PROJECT_ID/hello-node', '--platform', 'gke', '--cluster', 'test-cluster', '--cluster-location', 'us-central1-a']<br/>images:<br/>- 'gcr.io/$PROJECT_ID/hello-node'<br/>timeout: "600s"</pre>
<p style="padding-left: 60px">Taking a closer look at the build file outlined in the preceding code block, we can see the flexibility of Cloud Builds, as it allows commands to be directly initiated. A closer examination of the commands highlights the following activities:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li style="font-weight: 400"><strong>Build the container image</strong>: The <kbd>build</kbd> command is essentially a standard <kbd>docker build</kbd> command that tags the image with the appropriate naming convention. </li>
<li style="font-weight: 400"><strong>Push the container image to Container Registry</strong>: Once the <kbd>docker build</kbd> process is complete, the image built is then pushed to Google Container Registry with the specified tag. Again, the standard Docker command is used to send the image to the repository.</li>
<li style="font-weight: 400"><strong>Deploy the container to Cloud Run</strong>: The tagged image is deployed to the cluster. </li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">A layout such as this provides a common build pattern for Docker-based environments.</p>
<ol start="6">
<li>To initiate a build, once again, we would need to initiate the build process from the command line:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong><span>gcloud builds submit --config cloudbuild.github</span></strong></pre>
<p>However, the preceding manual step is no longer necessary! The repository has now been linked directly to GitHub, so each time a branch change is detected, the build process will be automatically initiated. Working with Cloud Build can save a lot of effort for very little configuration, and is worth the investment in time to understand how it works.</p>
<p>Having successfully built a service, in the next section we take a quick look at domains and how these are applied on Google Cloud when using Cloud Run.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying a domain</h1>
                </header>
            
            <article>
                
<p>Once a service has been deployed, Google Cloud provides a number of options to manage the associated domain name. In short, a domain name provides the ability to map a service IP address so that is accessible on the internet with a human-readable name. So, instead of accessing the IP <kbd>216.58.206.110</kbd>, we can enter <kbd>www.google.com</kbd> into the browser—I will leave it to you to consider which is more memorable.</p>
<p>Registering a domain name has become increasingly easy over the years and many companies provide an opportunity to purchase your own part of the internet. Once you have a domain name, you can actually map this to your Cloud Run service.</p>
<p>If you do not wish to purchase a domain name, Google Cloud incorporates three external wildcard <strong>domain name system</strong> (<strong>DNS</strong>) test sites that can be associated with a deployed Cloud Run service, as follows:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td style="width: 25.8478%">
<p><strong><span>DNS service</span></strong></p>
</td>
<td style="width: 32.2073%">
<p><strong><span>Information</span></strong></p>
</td>
</tr>
<tr>
<td style="width: 25.8478%">
<p><kbd><span>nip.io</span></kbd></p>
</td>
<td style="width: 32.2073%">
<p><a href="https://exentriquesolutions.com/">https://exentriquesolutions.com/</a></p>
</td>
</tr>
<tr>
<td style="width: 25.8478%">
<p><kbd><span>xip.io</span></kbd></p>
</td>
<td style="width: 32.2073%">
<p class="CDPAlignLeft CDPAlign"><a href="https://basecamp.com/">https://basecamp.com/</a></p>
</td>
</tr>
<tr>
<td style="width: 25.8478%">
<p><kbd><span>sslip.io</span></kbd></p>
</td>
<td style="width: 32.2073%">
<p class="mce-root"><a href="https://github.com/sstephenson">https://github.com/sstephenson</a></p>
<p class="mce-root"><a href="https://github.com/cunnie/sslip.io">https://github.com/cunnie/sslip.io</a></p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Alternatively, if you already own a domain, this can also be set up and used instead of the default domain. When you are not running a live service, having your own domain will likely be of little concern. However, once your product moves to production, having a domain looks much more professional.</p>
<p>The default domain name used by Cloud Run for Anthos is actually <kbd>example.com</kbd>. When you change the domain, for example, to a test site, the service deployed will be registered against the selected name system, for example, <kbd>xip.io</kbd>. Changing the DNS setting requires the use of a config map to tell Kubernetes how the domain is to be configured:</p>
<div class="packt_infobox"><br/>
In the following section, we capture the output into environment variables. Doing this means we do not have to continually keep posting API requests to confirm values.</div>
<ol>
<li>Get the service URL, currently using <kbd>default.com</kbd>, for example:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>SERVICE_URL=$(gcloud beta run services describe [SERVICE-NAME] --platform gke --cluster [CLUSTER-NAME] --cluster-location [ZONE] --format "value(status.url)")</strong></pre>
<ol start="2">
<li>Get the external IP of the deployed service:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>ISTIO_INGRESS=$(kubectl get svc istio-ingress -n gke-system -o json | jq -r '.status.loadBalancer.ingress[0].ip')</strong></pre>
<ol start="3">
<li>Apply a patch to the config map using the Istio Ingress IP as the external IP:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>kubectl patch configmap config-domain --namespace knative-serving --patch \</strong><br/><strong>'{"data": {"example.com": null, "[EXTERNAL-IP].[DNS-SERVICE]": ""}}'</strong></pre>
<ol start="4">
<li>Update the service URL environment variable:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>SERVICE_URL=$(gcloud beta run services describe [SERVICE-NAME] --platform gke --cluster [CLUSTER-NAME] --cluster-location [ZONE] --format "value(status.url)")</strong></pre>
<div class="packt_tip"><br/>
The <kbd>gcloud sdk</kbd> and <kbd>kubectl</kbd> commands provide information in a number of formats, including JSON. Learning how to parse JSON is a very handy skill to acquire when learning to develop command-line scripts.</div>
<p>Congratulations! You have enabled a custom domain on your service. Now rather than displaying <kbd>default.com</kbd>, the service will be registered against the selected domain.</p>
<p>In the next section, we will cover the monitoring of an application and give some insights into the helpful information available.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Troubleshooting with Stackdriver</h1>
                </header>
            
            <article>
                
<p>Earlier sections have discussed many of the key details of Cloud Run. So far, we have provisioned a cluster on GKE, deployed our application and utilized Cloud Build to make us more productive. At this point, we should probably also cover what to do when things go wrong. </p>
<p>Google Cloud provides a lot of environmental information, especially for compute-based resources such as GCE and GKE. For serverless workloads, fortunately, we can also take advantage of many of these key data points:</p>
<ol>
<li>To start, let's continue with our <kbd>hello-node</kbd> application and introduce an error into the code. Access the source code for <kbd>index.js</kbd> and save the following erroneous entry to the code:</li>
</ol>
<pre style="padding-left: 60px">const express = require('express')<br/>const app = express()<br/>const port = process.env.PORT || 8080;<br/><strong>oops</strong><br/>app.get('/', (req, res) =&gt; res.send('Hello World! GitHub Build'))<br/>app.listen(port, () =&gt; console.log(`Example app listening on port ${port}!`))</pre>
<ol start="2">
<li>In the preceding code, we have intentionally added a code defect so that we can track this in Stackdriver. Once again we can run our <kbd>cloudbuild.github</kbd> to do all the hard work for us. However, this time the deployment task will fail! To see the details of the failure, we should go to the Cloud Run interface and investigate the existing services.</li>
<li>From the Cloud Run dashboard view, we have a green circle with a ticket mark present indicating the <kbd>hello-node</kbd> service has been successfully deployed and is operating within expected parameters. Contrast this with our latest deployment of the <kbd>hello-node</kbd> service that has encountered an error, as indicated by the red circle with an exclamation mark in the center. Furthermore, neither the <span class="packt_screen">GKE Cluster</span> or <span class="packt_screen">Namespace</span> detail is present, meaning the image has not been deployed to its end destination.</li>
</ol>
<ol start="4">
<li>Select the application with the error to display further information on the <span class="packt_screen">Services</span> <span class="packt_screen">d</span><span class="packt_screen">etails</span> page, as follows:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-844 image-border" src="assets/b7ef7070-4707-4f60-939c-491a4b757528.png" style=""/></div>
<p>Before we get into how to explore further information about the error displayed, we should take a moment to highlight the Cloud Run <span class="packt_screen">Service details</span> page and the information accessible from there.</p>
<p>Whenever you deploy a service, there is a tremendous amount of information exchange taking place, much of it in the background. One of the important aspects of working with Google Cloud is the centralized management of resource-related data. Much of the information relating to services or resources deployed within your project will be captured in Stackdriver. Thankfully, the engineers at Google have taken the most common elements exposed in Stackdriver and added them to a handy dashboard covering <span class="packt_screen">METRICS</span>, <span class="packt_screen">REVISION</span>, <span class="packt_screen">LOGS</span>, <span class="packt_screen">DETAILS</span>, and <span class="packt_screen">YAML</span>, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-845 image-border" src="assets/4681cb86-eed2-43d2-a508-b64eef0d4c5d.png" style=""/></div>
<p class="mce-root">Let's explore these dashboard elements one by one: </p>
<ul>
<li><strong>METRICS</strong>: The metrics screen provides a range of data that is commonly used by an application, for example, a request count. In addition, the information presented can also be filtered by time period (such as 1 hour, 6 hours, 7 days, or 30 days). From this screen, an application state can easily be viewed and issues relating to the service performance can begin to be investigated. So, if you have an issue relating to the performance of a service, for example, such as latency or bottlenecking, this is the screen where the attributes of an application can be viewed to get a sense of what is happening.</li>
<li><strong>REVISIONS</strong>: A<span>n overview of the revisions deployed, including environment variables and Cloud SQL connectivity.</span></li>
<li class="mce-root"><strong>LOGS</strong>: Access the logged information for the service. The detail available is based on the system logs, so information captured by an application will be available here.</li>
<li><strong>DETAILS</strong>: <span>From this page, the service connectivity and authentication information are shared. </span></li>
<li><strong>YAML</strong>: <span>The last tab provides an overview of the YAML associated with the service being viewed.</span></li>
</ul>
<div class="mce-root packt_tip"><br/>
Remember that, at the time of writing this book, the dashboard capability was still being revised, so expect changes of a subtle (and not-so-subtle) nature in the feature set.</div>
<p class="mce-root">Now we have outlined the relative capabilities of the dashboard, we can move on to resolving our service error.</p>
<p>Earlier, you will remember that we updated our application and introduced an error. We can see in the main dashboard of Cloud Run that our service was unsuccessful. </p>
<p>Over the course of the chapter we have started with a simple application, and then incorporated it into a continuous integration build process. Traditionally, we use logs to get insight into applications that are not operating within standard procedures. Given that we have handed over much of the build process to an automated process, it makes sense that the logs for each stage of this process are also available centrally:</p>
<ol>
<li>Go to Stackdriver. The logs that would naturally be available locally to the developer are now present in a central repository. </li>
<li>In the Cloud Run dashboard, select the item indicating an error to once again go to the <span class="packt_screen">Service details</span> page.</li>
</ol>
<ol start="3">
<li>From here, select the <span class="packt_screen">LOGS</span> tab and take a closer look at what information has been captured by the logging process.</li>
</ol>
<div class="packt_infobox"><br/>
Note that each entry in Stackdriver is timestamped, and associated with this is some form of command that returned a status update. </div>
<p style="padding-left: 60px">Working through the content displayed on screen, we can see that our application is executed with the <kbd>index.js</kbd> <span>command node.</span> If you are unclear why, it is because this relates to the start command we entered into the <kbd>package.json</kbd> file.</p>
<p style="padding-left: 60px">Looking further down the list, we can see reference to <kbd>/usr/src/app/index.js:5</kbd>. This is telling us that something interesting occurred at the fifth line in <kbd>index.js</kbd>. In the following line, the logs indicate something curious: <kbd>oops</kbd> has been found in the source file. Well, that is clearly not meant to be there, so we have found our typo.</p>
<ol start="4">
<li>Now that we have explored the logs for valuable clues to correct our application defect, go back to the source code and remove the typo on line five of <kbd>index.js</kbd>.</li>
<li>Resubmit the changed code to a branch and see the code once again automatically update to take account of the changes made.</li>
<li>At this point, the code should be successfully working, based on the update made. Confirm the code is working by checking the text displayed is the same as that displayed in the current version of the source code.</li>
</ol>
<p>Hopefully, the process on which to debug an application has been made clearer with this preceding example. By incorporating the development workflow earlier into the Cloud process, it makes the overall integration more complete. Being able to utilize built-in tools such as Stackdriver provides an easier path to increased productivity. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deleting the cluster</h1>
                </header>
            
            <article>
                
<p>To complete the chapter, the final activity to cover is deleting the cluster. Removing a cluster is not a common activity; in fact, the only reason it is included here is to show the process. As we now know, the cluster incorporates all the base-level functionality associated with Kubernetes. On GKE, our cluster is managed; that is, you don't need to concern yourself with low-level activities such as node creation, TLS certification creation, and so on.</p>
<p>With that said, in order to remove the cluster created previously, use the following command:</p>
<pre class="mce-root"><strong><span>gcloud beta container clusters delete CLUSTER_NAME</span></strong></pre>
<div class="packt_tip packt_infobox"><br/>
Just to be clear, at the time of writing, the <kbd>cluster delete</kbd> command is in beta, so there may be some potential changes going forward.</div>
<p>Once we embark on deleting the cluster, it removes all the associated workloads, that is, the deployed containers. To restart, a new cluster would need to be created in order to deploy Cloud Run for Anthos.   </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we introduced the high-level concept of Kubernetes and then looked at how Cloud Run for Anthos can be used. If your platform of choice is Kubernetes, Cloud Run for Anthos is the path to follow. As we have seen, the migration between non-Kubernetes and Kubernetes environments requires no additional configuration as the delivery artifact is based on a container.</p>
<p>Through this chapter, we have discovered a more productive way to incorporate Cloud Build into our developer workflow. Utilizing the developer tools provided by Google is a sensible way to minimize the repetitive aspects that are integral to the build and deploy process. </p>
<p>In the next chapter, we develop a couple of Cloud Run examples to illustrate some key features. Working through some example use cases will help to illustrate how to utilize Cloud Run in your own projects.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li style="font-weight: 400">What type of machine customization is possible when using Cloud Run for Anthos?</li>
<li style="font-weight: 400">Are SSL certificates automatic or manual when using Cloud Run for Anthos?</li>
<li style="font-weight: 400">What platform flag is required when deploying to Cloud Run for Anthos?</li>
<li style="font-weight: 400">What port is used for service access when using Cloud Run for Anthos?</li>
</ol>
<ol start="5">
<li style="font-weight: 400">Is a pre-provisioned cluster required for Cloud Run for Anthos? (True or False)</li>
<li style="font-weight: 400">What addons are required for Cloud Run for Anthos?</li>
<li style="font-weight: 400">Which command is used to manage a GKE cluster from the command line?</li>
<li style="font-weight: 400">What is a pod?</li>
<li>How does GKE support external traffic?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li><strong>Istio</strong>: <a href="https://cloud.google.com/istio/">https://cloud.google.com/istio/</a></li>
<li><strong>Cloud Run Authentication</strong>: <a href="https://cloud.google.com/run/docs/authenticating/overview">https://cloud.google.com/run/docs/authenticating/overview</a></li>
<li><strong>Google Kubernetes Engine</strong>: <a href="https://cloud.google.com/kubernetes-engine/">https://cloud.google.com/kubernetes-engine/</a></li>
<li><strong>Mapping Custom Domains</strong>: <a href="https://cloud.google.com/appengine/docs/standard/python/mapping-custom-domains">https://cloud.google.com/appengine/docs/standard/python/mapping-custom-domains</a></li>
<li><strong>Filtering and formatting fun with gcloud, Google Cloud's command-line interface</strong>: <a href="https://cloud.google.com/blog/products/gcp/filtering-and-formatting-fun-with">https://cloud.google.com/blog/products/gcp/filtering-and-formatting-fun-with</a></li>
<li><strong>JQ tutorial</strong>: <a href="https://stedolan.github.io/jq/tutorial/">https://stedolan.github.io/jq/tutorial/</a></li>
</ul>


            </article>

            
        </section>
    </body></html>