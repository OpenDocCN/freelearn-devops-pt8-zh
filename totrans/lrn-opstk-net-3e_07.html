<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Attaching Instances to Networks</h1>
                </header>
            
            <article>
                
<p>In <em><a href="5a3df5cf-aebb-4c57-9f48-fa5419a5b2ae.xhtml">chapter 6</a>, Building Networks with Neutron</em>, we created multiple networks that can be utilized by projects in the cloud. In this chapter, we will create instances that reside in those networks.</p>
<p>I will guide you through the following tasks:</p>
<ul>
<li>Creating and attaching instances to networks</li>
<li>Adding additional interfaces to instances</li>
<li>Demonstrating DHCP and metadata services</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Attaching instances to networks </h1>
                </header>
            
            <article>
                
<p>Using the OpenStack command-line client, instances can be attached to networks in a couple of ways. When an instance is first created, it can be attached to one or more networks using the <kbd><span class="CodeInTextPACKT">openstack server create</span></kbd> command. Running instances can be attached to additional networks using the <kbd><span class="CodeInTextPACKT">openstack server add port</span></kbd> command. Both methods are explained in the following sections.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<div class="packt_infobox">If you're following along, the networks we created in the previous chapters have all been destroyed and recreated with similar names and segmentation IDs, but with new ID numbers.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Attaching instances to networks at creation</h1>
                </header>
            
            <article>
                
<p>Instances are created using the <kbd><span class="CodeInTextPACKT">openstack server create</span></kbd> command, as you can see here:</p>
<pre>openstack server create<br/>(--image &lt;image&gt; | --volume &lt;volume&gt;) --flavor &lt;flavor&gt;<br/>[--security-group &lt;security-group&gt;]<br/>[--key-name &lt;key-name&gt;]<br/>[--property &lt;key=value&gt;]<br/>[--file &lt;dest-filename=source-filename&gt;]<br/>[--user-data &lt;user-data&gt;]<br/>[--availability-zone &lt;zone-name&gt;]<br/>[--block-device-mapping &lt;dev-name=mapping&gt;]<br/>[--nic &lt;net-id=net-uuid,v4-fixed-ip=ip-addr,v6-fixed-ip=ip-addr,port-id=port-uuid,auto,none&gt;]<br/>[--network &lt;network&gt;] [--port &lt;port&gt;]<br/>[--hint &lt;key=value&gt;]<br/>[--config-drive &lt;config-drive-volume&gt; | True]<br/>[--min &lt;count&gt;] [--max &lt;count&gt;] [--wait]<br/>&lt;server-name&gt;   </pre>
<p><span>Nova attaches instances to virtual bridges and switches on the <kbd>compute</kbd> node via their <span class="KeyWordPACKT">virtual interfaces</span>, or VIFs. Each VIF has a corresponding Neutron port in the database.</span></p>
<p>When using the Open vSwitch mechanism driver and <span class="CodeInTextPACKT">Open vSwitch</span> firewall driver, each VIF plugs into the integration bridge on the respective <kbd>compute</kbd> node hosting the instance. The virtual switch port is configured with a local VLAN ID that corresponds to the network associated with the Neutron port and VIF. When the <kbd><span class="CodeInTextPACKT">iptables_hybrid</span></kbd> firewall driver is used, the VIF is connected to a Linux bridge where iptables rules are applied.</p>
<p>When using the Linux bridge mechanism driver, each VIF connects to a Linux bridge that corresponds to the associated network. Every network has a corresponding bridge that is used to segregate traffic at Layer 2.</p>
<p>For a refresher on these concepts, refer to <a href="05786c3c-b24e-40dc-82a7-ed6072eca14f.xhtml"><em><span class="ChapterrefPACKT">Chapter 4</span></em></a><span>, <em><span class="ItalicsPACKT">Virtual Switching Infrastructure Using Linux Bridges,</span></em> and</span> <a href="0763a131-4ab9-4b3e-8854-8646feae7937.xhtml"><em><span class="ChapterrefPACKT">Chapter 5</span></em></a><span>, <em><span class="ItalicsPACKT">Building a Virtual Switching Infrastructure Using Open vSwitch</span></em>.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Specifying a network</h1>
                </header>
            
            <article>
                
<p>The <span class="CodeInTextPACKT"><kbd>openstack server create</kbd> </span>command provides a <kbd><span class="CodeInTextPACKT">--nic</span></kbd> argument that specifies the network or port to be attached to the instance.</p>
<p>Users can specify a network identified by the network's ID by using the <kbd><span class="CodeInTextPACKT">net-id</span></kbd> key:</p>
<pre>--nic net-id=&lt;Network ID&gt; </pre>
<p>In the preceding example, Nova interfaces with the Neutron API to create a port using the network ID provided by the user. Neutron then returns details of the port back to Nova for use by the instance. Users can request a specific unused IPv4 or IPv6 address using the <kbd><span class="CodeInTextPACKT">v4-fixed-ip</span></kbd> and <span class="CodeInTextPACKT"><kbd>v6-fixed-ip</kbd> </span>keys, respectively, as shown here:</p>
<pre>--nic net-id=&lt;Network ID&gt;,v4-fixed-ip=&lt;ipv4 address&gt;<br/>--nic net-id=&lt;Network ID&gt;,v6-fixed-ip=&lt;ipv6 address&gt; </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Specifying a port</h1>
                </header>
            
            <article>
                
<p>Alternatively, users can specify a port that's been identified by the port's ID using the <kbd><span class="CodeInTextPACKT">port-id</span></kbd> key, as shown here:</p>
<pre>--nic port-id=&lt;Port ID&gt; </pre>
<p>In this example, Neutron associates the existing port with the instance and sets the port's <kbd><span class="CodeInTextPACKT">device_id</span></kbd> attribute accordingly. A port can later be detached from an instance and associated with a new instance using this method. Possible options include <span class="CodeInTextPACKT">auto</span>, <span class="CodeInTextPACKT">none</span>, or the ID of an existing port. The default is <span class="CodeInTextPACKT">auto</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Attaching multiple interfaces</h1>
                </header>
            
            <article>
                
<p>By passing the <kbd><span class="CodeInTextPACKT">--nic</span></kbd> argument multiple times, it is possible to attach multiple interfaces to an instance. The interfaces within the instance may then be enumerated as <kbd><span class="CodeInTextPACKT">eth0</span></kbd>, <kbd><span class="CodeInTextPACKT">eth1</span></kbd>, <kbd><span class="CodeInTextPACKT">eth2</span></kbd>, and so on, depending on the operating system.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>Attaching multiple network interfaces to an instance is referred to as</span> <strong>multihoming</strong><span>. When an instance is multihomed, neither Neutron nor the instance itself is aware of which network takes precedence over another. When attached networks and subnets have their own respective gateway addresses set, an instance's routing table can be populated with multiple default routes. This scenario can wreak havoc on the connectivity and routing behavior of an instance.</span> <span class="MsoCommentReference">T</span>his configuration is useful when connecting instances to multiple networks directly, however, care should be taken to avoid network issues in this type of design.</p>
<div class="packt_infobox">Para-virtualized devices, including network and storage devices that use the <span class="CodeInTextPACKT">virtio</span> drivers, are PCI devices. Virtual machine instances under KVM are currently limited to 32 total PCI devices. Some PCI devices are critical for operation, including the host bridge, the ISA/USB bridge, the graphics card, and the memory balloon device, leaving up to 28 PCI slots available for use. Every para-virtualized network or block device uses one slot. This means that users may have issues attempting to connect upwards of 20-25 networks to an instance depending on the characteristics of that instance.</div>
<p>The following <kbd><span class="CodeInTextPACKT">openstack server create</span></kbd> command demonstrates the basic procedure of connecting an instance to multiple networks when creating the instance:</p>
<pre>openstack server create --flavor FLAVOR --image IMAGE \<br/>--nic net-id=NETWORK1 \<br/>--nic net-id=NETWORK2 \<br/>--nic net-id=NETWORK3 \<br/>&lt;SERVER-NAME&gt; </pre>
<p>Inside the instance, the first attached NIC corresponds to <kbd><span class="CodeInTextPACKT">NETWORK1</span></kbd>, the second NIC corresponds to <kbd><span class="CodeInTextPACKT">NETWORK2</span></kbd>, and so on. For many cloud-ready images, a single interface within the instance is brought online automatically using DHCP. Modification of the network interface file(s) or use of the <kbd><span class="CodeInTextPACKT">dhclient</span></kbd> command within the instance may be required to activate and configure additional network interfaces once the instance is active.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Attaching network interfaces to running instances</h1>
                </header>
            
            <article>
                
<p>Using the <kbd><span class="CodeInTextPACKT">openstack server add port</span></kbd> or <kbd><span class="CodeInTextPACKT">openstack server add fixed ip</span></kbd> commands, you can attach an existing or new port to running instances.</p>
<p>The <kbd><span class="CodeInTextPACKT">openstack server add port</span></kbd> command can be used as follows:</p>
<pre>openstack server add port &lt;server&gt; &lt;port&gt;</pre>
<p class="mce-root"/>
<p>The <span class="CodeInTextPACKT">port</span> argument specifies the port to be attached to the given server. The port must be one that is not currently associated with any other instance or resource. Otherwise, the operation will fail.</p>
<p>The <kbd><span class="CodeInTextPACKT">openstack server add fixed ip</span></kbd> command can be used as follows:</p>
<pre>openstack server add fixed ip<br/>[--fixed-ip-address &lt;ip-address&gt;]<br/>&lt;server&gt; &lt;network&gt; </pre>
<p>The <span class="CodeInTextPACKT">network</span> argument specifies the network to be attached to the given server. A new port that has a unique MAC address and an IP from the specified network will be created automatically.</p>
<p>The <kbd><span class="CodeInTextPACKT">--fixed-ip-address</span></kbd> argument can be used to specify a particular IP address in the given network rather than relying on an automatic assignment from Neutron.</p>
<div class="packt_infobox">While additional network interfaces may be added to running instances using hot-plug technology, the interfaces themselves may need to be configured within the operating system before they can be used. You may use the <kbd><span class="CodeInTextPACKT">dhclient</span></kbd> command to configure the newly-connected interface using DHCP or configure the interface file manually.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Detaching network interfaces</h1>
                </header>
            
            <article>
                
<p>To detach an interface from an instance, use the <kbd><span class="CodeInTextPACKT">openstack server remove port</span></kbd> or <kbd><span class="CodeInTextPACKT">openstack server remove fixed ip</span></kbd> commands, as shown here:</p>
<pre>openstack server remove port &lt;server&gt; &lt;port&gt;<br/>openstack server remove fixed ip &lt;server&gt; &lt;ip-address&gt; </pre>
<p>Interfaces detached from instances are removed completely from the Neutron port database.</p>
<div class="packt_infobox">Take caution when removing interfaces from running instances, as it may cause unexpected behavior within the instance.</div>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring how instances get their addresses</h1>
                </header>
            
            <article>
                
<p>When a network is created and DHCP is enabled on a subnet within the network, the network is scheduled to one or more DHCP agents in the environment. In most environments, DHCP agents are configured on <kbd>controllers</kbd> or dedicated <kbd>network</kbd> nodes. In more advanced environments, such as those utilizing network segments and leaf/spine topologies, DHCP agents may be needed on <kbd>compute</kbd> nodes.</p>
<p>A DHCP agent is responsible for creating a local network namespace that corresponds to each network that has been scheduled to that agent. An IP address is then configured on a virtual interface inside the namespace, along with a <kbd>dnsmasq</kbd> process that listens for DHCP requests on the network. If a <kbd><span class="CodeInTextPACKT">dnsmasq</span></kbd> process already exists for the network and a new subnet is added, the existing process is updated to support the additional subnet.</p>
<div class="packt_infobox">When DHCP is not enabled on a subnet, a <kbd><span class="CodeInTextPACKT">dnsmasq</span></kbd> process is not spawned. An IP address is still associated with the Neutron port that corresponds to the interface within the instance, however. Without DHCP services, it is up to the user to manually configure the IP address on the interface within the guest operating system through a console connection.</div>
<p>Most instances rely on DHCP to obtain their associated IP address. DHCP follows the following stages:</p>
<ul>
<li> A DHCP client sends a <span class="CodeInTextPACKT"><kbd>DHCPDISCOVER</kbd> </span>broadcast packet that requests IP information from a DHCP server.</li>
<li>A DHCP server responds to the request with a <kbd><span class="CodeInTextPACKT">DHCPOFFER</span></kbd> packet. The packet contains the MAC address of the instance that makes the request, the IP address, the subnet mask, lease duration, and the IP address of the DHCP server. A Neutron network can be scheduled to multiple DHCP agents simultaneously, and each DHCP server may respond with a <kbd><span class="CodeInTextPACKT">DHCPOFFER</span></kbd> packet. However, the client will only accept the first one.</li>
<li>In response to the offer, the DHCP client sends a <kbd><span class="CodeInTextPACKT">DHCPREQUEST</span></kbd> packet back to the DHCP server, requesting the offered address.</li>
<li>In response to the request, the DHCP server will issue a <kbd><span class="CodeInTextPACKT">DHCPACK</span></kbd> packet or acknowledgement packet to the instance. At this point, the IP configuration is complete. The DHCP server sends other DHCP options such as name servers, routes, and so on to the instance.</li>
</ul>
<p>Network namespaces associated with DHCP servers are prefixed with <kbd><span class="CodeInTextPACKT">qdhcp</span></kbd>, followed by the entire network ID. DHCP namespaces will only reside on hosts running the <kbd><span class="CodeInTextPACKT">neutron-dhcp-agent</span></kbd> service. Even then, the network must be scheduled to the DHCP agent for the namespace to be created on that host. In this example, the DHCP agent runs on the <kbd>controller01</kbd> node.</p>
<p>To view a list of namespaces on the <kbd>controller01</kbd> node, use the <kbd><span class="CodeInTextPACKT">ip netns</span> list</kbd> command that's shown here:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/df747da2-8aea-46e2-b625-346260a53d5d.png" style="width:38.00em;height:5.58em;"/></div>
<p>The two namespaces listed in the output directly correspond to two networks for which a subnet exists and DHCP is enabled:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/4736f8c8-97d5-44f8-80ed-0a19c5af85b8.png" style="width:46.42em;height:8.00em;"/></div>
<p>An interface exists within the <span class="packt_screen">qdhcp</span> namespace for the network <span class="packt_screen">MyVLANNetwork</span>, which is used to connect the namespace to the virtual network infrastructure:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/1c8aa000-409b-4c15-a105-dd10ad620a97.png" style="width:55.17em;height:16.42em;"/></div>
<p>The interface <kbd><span class="CodeInTextPACKT">ns-6c15d7b8-87</span></kbd> within the namespace is one end of a <kbd>veth</kbd> interface. The IP address assigned to the <kbd><span class="CodeInTextPACKT">ns-6c15d7b8-87</span></kbd> interface, <kbd>192.168.206.2/24</kbd>, has been automatically assigned by Neutron and was procured from the subnet's allocation pool.</p>
<p>When using the Linux bridge driver, the other end of the interface, known as the peer, is connected to a bridge that corresponds to the network and is represented by the <span class="CodeInTextPACKT"><kbd>tap6c15d7b8-87</kbd> </span>interface, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/adb87c6a-32ef-4b46-9fa7-0ed4058371ce.png" style="width:33.17em;height:7.67em;"/></p>
<p>In the preceding screenshot, the bridge labeled <kbd><span class="CodeInTextPACKT">brq7745a4a9-68</span></kbd> corresponds to the network <kbd><span class="CodeInTextPACKT">MyFlatNetwork</span></kbd>, as evidenced by the <kbd>untagged</kbd> interface <kbd><span class="CodeInTextPACKT">eth2</span></kbd> connected to the bridge. The interface <span class="CodeInTextPACKT"><kbd>tapd1848f67-2e</kbd> </span>is the other end of the <kbd>veth</kbd> interface which is connected to the DHCP namespace for the network <span class="CodeInTextPACKT"><kbd>MyFlatNetwork</kbd>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Watching the DHCP lease cycle</h1>
                </header>
            
            <article>
                
<p>In this example, an instance will be created with the following characteristics:</p>
<ul>
<li><span class="KeyWordPACKT">Name:</span> <kbd>TestInstance1</kbd></li>
<li><span class="KeyWordPACKT">Flavor:</span> <kbd>tiny</kbd></li>
<li><span class="KeyWordPACKT">Image:</span> <kbd>cirros-0.4.0</kbd></li>
<li><span class="KeyWordPACKT">Network: </span><kbd>MyVLANNetwork</kbd></li>
<li><span class="KeyWordPACKT">Compute Node:</span> <kbd>compute01</kbd></li>
</ul>
<p>The command to create the instance is as follows:</p>
<pre>openstack server create \ <br/>--image cirros-0.4.0 \ <br/>--flavor tiny \<br/>--nic net-id=MyVLANNetwork \<br/>--availability-zone nova:compute01 \<br/>TestInstance1</pre>
<div class="packt_infobox">The tiny flavor may not exist in your environment, but can be created and defined with 1 vCPU, 1 MB RAM, and 1 GB disk.</div>
<p>To observe the instance requesting a DHCP lease, start a packet capture within the DHCP network namespace that corresponds to the instance's network using the following command:</p>
<pre><strong>ip netns exec &lt;namespace&gt; tcpdump -i any -ne port 67 or port 68</strong> </pre>
<p>As an instance starts up, it will send broadcast packets that will be answered by the DHCP server within the namespace:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/1c2a1f42-9a1b-40a3-82e0-428e6e690cbf.png"/></div>
<p>In the preceding screenshot, all four stages of the DHCP lease cycle can be observed. A similar output can be observed by performing the capture on the tap interface of the instance on the <kbd>compute</kbd> node:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/af5967ce-8b85-44fe-bd49-3d46fde58c35.png" style="width:68.83em;height:6.58em;"/></div>
<p>Using the <kbd><span class="CodeInTextPACKT">dhcpdump</span></kbd> utility, we can observe more verbose output of the DHCP lease cycle. To install <kbd><span class="CodeInTextPACKT">dhcpdump</span></kbd>, issue the following command on all nodes:</p>
<pre># apt install dhcpdump </pre>
<p>Within the network namespace hosting the DHCP server for the <kbd><span class="CodeInTextPACKT">MyVLANNetwork</span></kbd> network, run <kbd><span class="CodeInTextPACKT">dhcpdump</span></kbd>, as shown here:</p>
<pre>root@controller01:~# ip netns exec qdhcp-03327707-c369-4bd7-bd71-a42d9bcf49b8 dhcpdump -i ns-6c15d7b8-87 </pre>
<p>As the client makes its initial DHCP request, you will see a <kbd><span class="CodeInTextPACKT">DHCPDISCOVER</span></kbd> broadcast packet:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/7a817e4d-6fb2-41e6-b383-01adee525e0f.png" style="width:43.75em;height:41.17em;"/></div>
<p>Then, the <kbd>DHCP</kbd> server will send a <kbd><span class="CodeInTextPACKT">DHCPOFFER</span></kbd> unicast packet directly to the instance:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/09da7ac5-cf60-4cea-b5be-d98a3516876d.png" style="width:46.75em;height:38.58em;"/></p>
<p>Next, the client will send a <kbd><span class="CodeInTextPACKT">DHCPREQUEST</span></kbd> broadcast packet:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/cad43158-4284-4f8f-a199-0f68c1037ad8.png" style="width:42.92em;height:40.92em;"/></p>
<p>Lastly, the DHCP server will acknowledge the request with a <kbd><span class="CodeInTextPACKT">DHCPACK</span></kbd> unicast packet:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/cbd6712f-7a93-475c-9240-29962f5a362e.png" style="width:38.42em;height:32.75em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Troubleshooting DHCP</h1>
                </header>
            
            <article>
                
<p>If an instance is unable to procure its address from DHCP, it may be helpful to run a packet capture from various points in the network to see where the request or reply is failing.</p>
<p>Using <kbd><span class="CodeInTextPACKT">tcpdump</span></kbd> or <kbd><span class="CodeInTextPACKT">dhcpdump</span></kbd>, one can capture DHCP request and response packets on UDP ports <kbd>67</kbd> and <kbd>68</kbd> from the following locations:</p>
<ul>
<li>Within the DHCP namespace</li>
<li>On the physical interface of the <kbd>network</kbd> and/or <kbd>compute</kbd> nodes</li>
<li>On the tap interface of the instance</li>
<li>Within the guest operating system via the console</li>
</ul>
<p>Further investigation may be required once the node or interface responsible for dropping traffic has been identified.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring how instances retrieve their metadata</h1>
                </header>
            
            <article>
                
<p>In <a href="bf508e37-ce8a-4116-89db-e8f8a6abf0f4.xhtml"><em><span class="ChapterrefPACKT">Chapter 3</span></em></a><span>, <em><span class="ItalicsPACKT">Installing Neutron</span></em>, we briefly covered the process of instances accessing metadata over the network: either through a proxy in the router namespace or the DHCP namespace. The latter is described in the following section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The DHCP namespace</h1>
                </header>
            
            <article>
                
<p><span>Instances access metadata at <a href="http://169.254.169.254"><span class="URLPACKT">http://169.254.169.254</span></a>, followed by a URI that corresponds to the version of metadata, which is usually</span> <kbd><span class="URLPACKT">/latest</span></kbd><span>. When an instance is connected to a network that does <span class="ItalicsPACKT">not</span> utilize a Neutron router as the gateway, the instance must learn how to reach the metadata service. This can be accomplished in a few different ways, including the following:</span></p>
<ul>
<li>Setting a route manually on the instance</li>
<li>Allowing DHCP to provide a route</li>
</ul>
<p>When <span class="CodeInTextPACKT"><kbd>enable_isolated_metadata</kbd> </span>is set to <kbd><span class="CodeInTextPACKT">True</span></kbd> in the DHCP configuration file at <kbd><span class="CodeInTextPACKT">/etc/neutron/dhcp_agent.ini</span></kbd>, each DHCP namespace provides a proxy to the metadata service running on the <kbd>controller</kbd> node(s). The proxy service listens directly on port <kbd>80</kbd>, as shown in the following screenshot:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/c579967e-3cc1-47a4-9440-5b8eb585d3bd.png"/></div>
<p class="mce-root"/>
<p>Using the <kbd><span class="CodeInTextPACKT">ps</span></kbd> command within the namespace, you can see the process associated with this listener is the Neutron metadata proxy:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/75dc329b-811f-4b21-8948-0c96cfc0a299.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding a manual route to 169.254.169.254</h1>
                </header>
            
            <article>
                
<p>Before an instance can reach the metadata service in the DHCP namespace at <kbd>169.254.169.254</kbd>, a route must be configured to use the DHCP namespace interface as the next hop rather than at the default gateway of the instance.</p>
<p>Observe the IP addresses within the following DHCP namespace:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/43ee6750-ad7d-4551-8e30-433dad2e4893.png" style="width:66.33em;height:20.17em;"/></div>
<p><kbd>169.254.169.254/16</kbd> has been automatically configured as a secondary address on the interface inside the namespace. To reach <kbd>169.254.169.254</kbd> from an instance in the <kbd>192.168.206.0/24</kbd> network, the following <kbd><span class="CodeInTextPACKT">ip route</span></kbd> command can be used within the guest instance that sets <kbd>192.168.206.2</kbd> as the next hop:</p>
<pre># ip route add 169.254.169.254/32 via 192.168.206.2 </pre>
<p>While this method works, the process of adding a route to each instance does not scale well, especially when multiple DHCP agents exist in the environment. A single network can be scheduled to multiple agents that, in turn, have their own respective namespaces and IP addresses in the same subnet. Users will need prior knowledge of the IP to use in their route statement, and the address is subject to change. Allowing DHCP to inject the route automatically is the recommended method that will be discussed in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using DHCP to inject the route</h1>
                </header>
            
            <article>
                
<p>When <kbd><span class="CodeInTextPACKT">enable_isolated_metadata</span></kbd> is set to <kbd><span class="CodeInTextPACKT">True</span></kbd> <span>and the gateway for a subnet is <span class="ItalicsPACKT">not</span> set or is <span class="ItalicsPACKT">not</span> a Neutron router, the DHCP service is capable of injecting a route to the metadata service via the</span> <span class="CodeInTextPACKT">classless-static-route</span> DHCP option, also known as option 121.</p>
<div class="packt_tip">Possible DHCP options, including those leveraged by Neutron for various tasks, can be found on the IANA website at the following URL: <span class="URLPACKT"><a href="https://www.iana.org/assignments/bootp-dhcp-parameters/bootp-dhcp-parameters.xhtml">https://www.iana.org/assignments/bootp-dhcp-parameters/bootp-dhcp-parameters.xhtml</a>.</span></div>
<p>Once an instance connected to a subnet with the mentioned characteristics has been created, observe the following routes passed to the instance via DHCP:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/0080bbae-451a-4b8a-bc45-9afcac7b1547.png" style="width:25.67em;height:4.08em;"/></div>
<p>The next hop address for the metadata route is the IP address of the DHCP server that responded to the initial DHCP request from the client. If there were multiple DHCP agents in the environment and the same network was scheduled to all of them, it is possible that the next hop address would vary between instances, as any of the DHCP servers could have responded to the request.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, I demonstrated how to attach instances to networks and mapped out the process of an instance obtaining its IP address from an OpenStack-managed DHCP server. I also showed you how an instance reaches out to the metadata service when connected to a VLAN provider network. The same examples in this chapter can be applied to any recent OpenStack cloud and many different network topologies.</p>
<p>For additional details on deployment scenarios based on provider networks, refer to the following upstream documentation for the Pike release of OpenStack at the following locations:</p>
<p><strong><span class="BoldPACKT">Open vSwitch</span></strong>: <a href="https://docs.openstack.org/neutron/pike/admin/deploy-ovs-provider.html"><span class="URLPACKT">https://docs.openstack.org/neutron/pike/admin/deploy-ovs-provider.html</span></a></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span class="BoldPACKT"><strong>Linux bridge</strong>:</span> </p>
<p><a href="https://docs.openstack.org/neutron/pike/admin/deploy-lb-provider.html"><span class="URLPACKT">https://docs.openstack.org/neutron/pike/admin/deploy-lb-provider.html</span></a></p>
<p>In the next chapter, we will learn how to leverage Neutron security group functionality to provide network-level security to instances.</p>


            </article>

            
        </section>
    </body></html>