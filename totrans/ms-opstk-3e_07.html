<html><head></head><body>
  <div id="_idContainer135">
   <h1 class="chapter-number" id="_idParaDest-129">
    <a id="_idTextAnchor174">
    </a>
    <span class="koboSpan" id="kobo.1.1">
     7
    </span>
   </h1>
   <h1 id="_idParaDest-130">
    <a id="_idTextAnchor175">
    </a>
    <span class="koboSpan" id="kobo.2.1">
     Running a Highly Available Cloud – Meeting the SLA
    </span>
   </h1>
   <p class="author-quote">
    <span class="koboSpan" id="kobo.3.1">
     “The past resembles the future more than one drop of water resembles another.”
    </span>
   </p>
   <p class="author-quote">
    <span class="koboSpan" id="kobo.4.1">
     – Ibn Khaldun
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.5.1">
     One major aspect of successful cloud operating experiences is to prevent downtime and the failures of cloud resources and workloads.
    </span>
    <span class="koboSpan" id="kobo.5.2">
     In
    </span>
    <a href="B21716_01.xhtml#_idTextAnchor014">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.6.1">
        Chapter 1
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.7.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.8.1">
      Revisiting OpenStack – Design Consideration
     </span>
    </em>
    <span class="koboSpan" id="kobo.9.1">
     , we drafted an initial preparatory design to enable OpenStack services for redundancy.
    </span>
    <a href="B21716_03.xhtml#_idTextAnchor108">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.10.1">
        Chapter 3
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.11.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.12.1">
      OpenStack Control Plane – Shared Services
     </span>
    </em>
    <span class="koboSpan" id="kobo.13.1">
     , and
    </span>
    <a href="B21716_04.xhtml#_idTextAnchor125">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.14.1">
        Chapter 4
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.15.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.16.1">
      OpenStack Compute – Compute Capacity and Flavors
     </span>
    </em>
    <span class="koboSpan" id="kobo.17.1">
     , looked at some of the logical design patterns for OpenStack control plane deployments and various ways to segregate compute, such as cells and availability zones.
    </span>
    <span class="koboSpan" id="kobo.17.2">
     OpenStack is designed to scale massively and providing hardware for dedicated OpenStack services can help isolate failures, but this requires mechanisms to keep services running
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.18.1">
      during incidents.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.19.1">
     Ensuring
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.20.1">
      high availability
     </span>
    </strong>
    <span class="koboSpan" id="kobo.21.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.22.1">
      HA
     </span>
    </strong>
    <span class="koboSpan" id="kobo.23.1">
     ) in the
    </span>
    <a id="_idIndexMarker671">
    </a>
    <span class="koboSpan" id="kobo.24.1">
     OpenStack world does not differ too much from any other complex IT system.
    </span>
    <span class="koboSpan" id="kobo.24.2">
     One obligatory practice is to find and
    </span>
    <a id="_idIndexMarker672">
    </a>
    <span class="koboSpan" id="kobo.25.1">
     eliminate, through the logical OpenStack setup, any possible
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.26.1">
      single points of failure
     </span>
    </strong>
    <span class="koboSpan" id="kobo.27.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.28.1">
      SPOFs
     </span>
    </strong>
    <span class="koboSpan" id="kobo.29.1">
     ), which differ from one design to another.
    </span>
    <span class="koboSpan" id="kobo.29.2">
     Our goal in this chapter is to achieve HA in each layer of the private
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.30.1">
      cloud infrastructure.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.31.1">
     In this chapter, we will cover the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.32.1">
      following topics:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.33.1">
      Reviewing HA and failover strategies to ensure
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.34.1">
       business continuity
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.35.1">
      Iterating through OpenStack control plane HA
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.36.1">
       design patterns
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.37.1">
      Deploying an OpenStack environment with additional cloud controllers for fault tolerance and redundancy
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.38.1">
       using
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.39.1">
        kolla-ansible
       </span>
      </strong>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.40.1">
      Exploring different ways to achieve networking HA in Neutron with the latest OpenStack updates, including routing and distributed virtual
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.41.1">
       router mechanisms
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.42.1">
      Uncovering native OpenStack solutions to ensure instances failover using the Masakari
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.43.1">
       OpenStack project
      </span>
     </span>
    </li>
   </ul>
   <h1 id="_idParaDest-131">
    <a id="_idTextAnchor176">
    </a>
    <span class="koboSpan" id="kobo.44.1">
     Exploring HA strategies
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.45.1">
     A robust OpenStack cloud platform includes fault tolerance at every level of its architecture.
    </span>
    <span class="koboSpan" id="kobo.45.2">
     This can be very successful if it is planned in advance.
    </span>
    <span class="koboSpan" id="kobo.45.3">
     Starting with a small cluster is
    </span>
    <a id="_idIndexMarker673">
    </a>
    <span class="koboSpan" id="kobo.46.1">
     easy and achievable, but growing it is a challenge.
    </span>
    <span class="koboSpan" id="kobo.46.2">
     The hallmark of the basic OpenStack component is that it can run on commodity hardware.
    </span>
    <span class="koboSpan" id="kobo.46.3">
     OpenStack is designed to scale massively and provide HA by leveraging
    </span>
    <a id="_idIndexMarker674">
    </a>
    <span class="koboSpan" id="kobo.47.1">
     more advanced HA techniques at each level of the infrastructure.
    </span>
    <span class="koboSpan" id="kobo.47.2">
     This
    </span>
    <a id="_idIndexMarker675">
    </a>
    <span class="koboSpan" id="kobo.48.1">
     can include
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.49.1">
      automatic failover
     </span>
    </strong>
    <span class="koboSpan" id="kobo.50.1">
     and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.51.1">
      geo-redundancy
     </span>
    </strong>
    <span class="koboSpan" id="kobo.52.1">
     .
    </span>
    <a href="B21716_04.xhtml#_idTextAnchor125">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.53.1">
        Chapter 4
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.54.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.55.1">
      OpenStack Compute – Compute Capacity and Flavors
     </span>
    </em>
    <span class="koboSpan" id="kobo.56.1">
     , introduced the concepts of cells, regions, and availability zones, which provide more robust and advanced fault tolerance and availability capabilities for massive OpenStack deployment
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.57.1">
      at scale.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-132">
    <a id="_idTextAnchor177">
    </a>
    <span class="koboSpan" id="kobo.58.1">
     Measuring HA
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.59.1">
     Service availability
    </span>
    <a id="_idIndexMarker676">
    </a>
    <span class="koboSpan" id="kobo.60.1">
     should be measured and defined by standard metrics.
    </span>
    <span class="koboSpan" id="kobo.60.2">
     This can be summarized using the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.61.1">
      following formula:
     </span>
    </span>
   </p>
   <p>
    <em class="italic">
     <span class="koboSpan" id="kobo.62.1">
      Availability = MTTF/ (MTTF +
     </span>
    </em>
    <span class="No-Break">
     <em class="italic">
      <span class="koboSpan" id="kobo.63.1">
       MTTR)
      </span>
     </em>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.64.1">
     In the preceding equation, we can see
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.65.1">
      the following:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.66.1">
       Mean time to failure (MTTF)
      </span>
     </strong>
     <span class="koboSpan" id="kobo.67.1">
      : An
     </span>
     <a id="_idIndexMarker677">
     </a>
     <span class="koboSpan" id="kobo.68.1">
      estimate of the average time that a system is functional before
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.69.1">
       its failure
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.70.1">
       Mean time to repair (MTTR)
      </span>
     </strong>
     <span class="koboSpan" id="kobo.71.1">
      : An
     </span>
     <a id="_idIndexMarker678">
     </a>
     <span class="koboSpan" id="kobo.72.1">
      estimate of the average time to repair a part or component of
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.73.1">
       a system
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.74.1">
     Measuring HA in complex environments such as OpenStack would require a good understanding of the deployed cloud environment capabilities that can be tracked through
    </span>
    <a id="_idIndexMarker679">
    </a>
    <span class="koboSpan" id="kobo.75.1">
     performance metrics and KPIs, such as response time, system uptime, and downtime, for the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.76.1">
      Repair Time Objective
     </span>
    </strong>
    <span class="koboSpan" id="kobo.77.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.78.1">
      RTO
     </span>
    </strong>
    <span class="koboSpan" id="kobo.79.1">
     ) and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.80.1">
      Repair Point Objective
     </span>
    </strong>
    <span class="koboSpan" id="kobo.81.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.82.1">
      RPO
     </span>
    </strong>
    <span class="koboSpan" id="kobo.83.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.83.2">
     What’s more critical to end users is to expose a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.84.1">
      Service-Level Agreement
     </span>
    </strong>
    <span class="koboSpan" id="kobo.85.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.86.1">
      SLA
     </span>
    </strong>
    <span class="koboSpan" id="kobo.87.1">
     ) from the gathered metrics and KPIs and improve against
    </span>
    <a id="_idIndexMarker680">
    </a>
    <span class="koboSpan" id="kobo.88.1">
     them.
    </span>
    <span class="koboSpan" id="kobo.88.2">
     A SLA identifies areas of improvement based on
    </span>
    <a id="_idIndexMarker681">
    </a>
    <span class="koboSpan" id="kobo.89.1">
     routinely gathered metrics and will boost your business continuity strategy.
    </span>
    <span class="koboSpan" id="kobo.89.2">
     Availability management is an integral pillar of IT best practices that cannot be skipped, especially when operating a cloud environment running dozens of services, as with OpenStack.
    </span>
    <span class="koboSpan" id="kobo.89.3">
     Creating those SLAs for each service in more depth would fill an entire book.
    </span>
    <span class="koboSpan" id="kobo.89.4">
     For the sake of simplicity, make sure you engage in availability
    </span>
    <a id="_idIndexMarker682">
    </a>
    <span class="koboSpan" id="kobo.90.1">
     management practices and update the SLA per service by assigning an availability level and availability and downtime percentages, as shown in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.91.1">
      following table:
     </span>
    </span>
   </p>
   <table class="No-Table-Style _idGenTablePara-1" id="table001-4">
    <colgroup>
     <col/>
     <col/>
     <col/>
     <col/>
    </colgroup>
    <tbody>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.92.1">
           Service
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.93.1">
           Availability Level
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.94.1">
           Availability
          </span>
         </strong>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <strong class="bold">
          <span class="koboSpan" id="kobo.95.1">
           Downtime/Day
          </span>
         </strong>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.96.1">
          Compute
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.97.1">
          One 9
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.98.1">
          90
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.99.1">
         ~
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.100.1">
          2.4 hours
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.101.1">
          Network
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.102.1">
          Two 9s
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.103.1">
          99
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.104.1">
         ~
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.105.1">
          14 minutes
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.106.1">
          Compute
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.107.1">
          Three 9s
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.108.1">
          99.9
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.109.1">
         ~
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.110.1">
          86 seconds
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.111.1">
          Block storage
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.112.1">
          Four 9s
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.113.1">
          99.99
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.114.1">
         ~
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.115.1">
          8.6 seconds
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.116.1">
          Object storage
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.117.1">
          Five 9s
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.118.1">
          99.999
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.119.1">
         ~
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.120.1">
          0.86 seconds
         </span>
        </span>
       </p>
      </td>
     </tr>
     <tr class="No-Table-Style">
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.121.1">
          Image
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.122.1">
          Six 9s
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.123.1">
          99.9999
         </span>
        </span>
       </p>
      </td>
      <td class="No-Table-Style">
       <p>
        <span class="koboSpan" id="kobo.124.1">
         ~
        </span>
        <span class="No-Break">
         <span class="koboSpan" id="kobo.125.1">
          0.0086 seconds
         </span>
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.126.1">
     Table 7.1 – Example SLA with x-9s for OpenStack environment services
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.127.1">
     When designing the architecture for an HA OpenStack setup, failures should be planned for at every single layer of the cloud architecture.
    </span>
    <span class="koboSpan" id="kobo.127.2">
     This can be achieved thanks to advanced HA models and techniques.
    </span>
    <span class="koboSpan" id="kobo.127.3">
     The latest OpenStack releases are even richer, with built-in features that embrace availability not only for core components but also for user workloads.
    </span>
    <span class="koboSpan" id="kobo.127.4">
     For example, if a host fails, the application running on it will not be accessible anymore.
    </span>
    <span class="koboSpan" id="kobo.127.5">
     Nova supports the feature to recover a guest instance by relocating it to a new healthy host.
    </span>
    <span class="koboSpan" id="kobo.127.6">
     For an extended OpenStack setup, the cloud environment could scale even more domain failures by recalling availability zones under the Nova service.
    </span>
    <span class="koboSpan" id="kobo.127.7">
     The essence of the HA design patterns can be summarized in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.128.1">
      following points:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.129.1">
      Eliminate any SPOF for the control and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.130.1">
       data planes
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.131.1">
      Adopt a geo-replicated design
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.132.1">
       whenever possible
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.133.1">
      Automate monitoring and
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.134.1">
       anomaly detection
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.135.1">
      Plan and automate fast
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.136.1">
       disaster recovery
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.137.1">
      Decouple and isolate OpenStack components as much
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.138.1">
       as possible
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.139.1">
     In the
    </span>
    <a id="_idIndexMarker683">
    </a>
    <span class="koboSpan" id="kobo.140.1">
     world of OpenStack, different levels of HA can
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.141.1">
      be identified:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.142.1">
       L1
      </span>
     </strong>
     <span class="koboSpan" id="kobo.143.1">
      : This includes physical hosts, network and storage devices,
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.144.1">
       and hypervisors.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.145.1">
       L2
      </span>
     </strong>
     <span class="koboSpan" id="kobo.146.1">
      : This includes OpenStack services, including compute, network, and storage controllers, as well as databases and message
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.147.1">
       queuing systems.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.148.1">
       L3
      </span>
     </strong>
     <span class="koboSpan" id="kobo.149.1">
      : This includes the virtual machines running on hosts that are managed by
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.150.1">
       OpenStack services.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.151.1">
       L4
      </span>
     </strong>
     <span class="koboSpan" id="kobo.152.1">
      : This includes applications running in the virtual
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.153.1">
       machines themselves.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.154.1">
     The main focus of supporting HA in OpenStack is on L1, L2,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.155.1">
      and L3.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-133">
    <span class="koboSpan" id="kobo.156.1">
     Designing for HA
    </span>
    <a id="_idTextAnchor178">
    </a>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.157.1">
     One key aspect when designing systems is to take into account every possibility where an element
    </span>
    <a id="_idIndexMarker684">
    </a>
    <span class="koboSpan" id="kobo.158.1">
     of the system could fail.
    </span>
    <span class="koboSpan" id="kobo.158.2">
     Each element has limits of some kind and would not be able to recover within at least a short period, which would affect other parts of the system and lead to the whole system becoming unresponsive.
    </span>
    <span class="koboSpan" id="kobo.158.3">
     When looking at common design patterns aimed at maximizing scalability and availability, it is important to identify two main classes
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.159.1">
      of services:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.160.1">
       Stateful service
      </span>
     </strong>
     <span class="koboSpan" id="kobo.161.1">
      : A service
     </span>
     <a id="_idIndexMarker685">
     </a>
     <span class="koboSpan" id="kobo.162.1">
      that depends on data from a previous request and interacts synchronously to preserve consistency.
     </span>
     <span class="koboSpan" id="kobo.162.2">
      As such services rely on the state, a service failure can affect the whole system and require more backup and recovery mechanisms to maintain
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.163.1">
       state information.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.164.1">
       Stateless service
      </span>
     </strong>
     <span class="koboSpan" id="kobo.165.1">
      : A service
     </span>
     <a id="_idIndexMarker686">
     </a>
     <span class="koboSpan" id="kobo.166.1">
      that does not require data or needs to save information (state) from a previous request or event.
     </span>
     <span class="koboSpan" id="kobo.166.2">
      As such services do not store states across requests, a sudden failure won’t affect the rest of the system, which can operate in a different
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.167.1">
       handler instance.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.168.1">
     As discussed in
    </span>
    <a href="B21716_03.xhtml#_idTextAnchor108">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.169.1">
        Chapter 3
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.170.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.171.1">
      OpenStack Control Plane – Shared Services
     </span>
    </em>
    <span class="koboSpan" id="kobo.172.1">
     , the OpenStack control plane is mainly constructed of stateless services, including an API, scheduler, agents, and conductor components for all compute, network, image, monitoring, and storage services.
    </span>
    <span class="koboSpan" id="kobo.172.2">
     The database and queuing message count as stateful services.
    </span>
    <span class="koboSpan" id="kobo.172.3">
     This way, introducing HA into our initial setup would require verifying the right pattern for
    </span>
    <a id="_idIndexMarker687">
    </a>
    <span class="koboSpan" id="kobo.173.1">
     each service and component of the OpenStack deployment to ensure the continuity of the service during unexpected failures.
    </span>
    <span class="koboSpan" id="kobo.173.2">
     There are a multitude of ways to achieve OpenStack control plane HA.
    </span>
    <span class="koboSpan" id="kobo.173.3">
     This can be summarized in terms of the following design patterns, both of which were introduced in
    </span>
    <a href="B21716_03.xhtml#_idTextAnchor108">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.174.1">
        Chapter 3
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.175.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.176.1">
      OpenStack Control Plane –
     </span>
    </em>
    <span class="No-Break">
     <em class="italic">
      <span class="koboSpan" id="kobo.177.1">
       Shared Services
      </span>
     </em>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.178.1">
      :
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.179.1">
       Active/passive
      </span>
     </strong>
     <span class="koboSpan" id="kobo.180.1">
      : In the OpenStack control plane, failed services will be restarted
     </span>
     <a id="_idIndexMarker688">
     </a>
     <span class="koboSpan" id="kobo.181.1">
      on a second cloud controller node.
     </span>
     <span class="koboSpan" id="kobo.181.2">
      With stateful services such as the database, the master node handles all read and write operations and a second node acts as a listener until a failover occurs, upon which the data entry point will be switched to the second node.
     </span>
     <span class="koboSpan" id="kobo.181.3">
      This pattern is suitable for some stateful services but not for other stateless OpenStack services.
     </span>
     <span class="koboSpan" id="kobo.181.4">
      Additionally, it does not fully comply with horizontal scaling
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.182.1">
       in OpenStack.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.183.1">
       Active/active
      </span>
     </strong>
     <span class="koboSpan" id="kobo.184.1">
      : Here, the request load hitting the OpenStack control plane is distributed
     </span>
     <a id="_idIndexMarker689">
     </a>
     <span class="koboSpan" id="kobo.185.1">
      among active nodes that process in parallel.
     </span>
     <span class="koboSpan" id="kobo.185.2">
      This mode in an OpenStack deployment brings the highest level of fault tolerance for the control and data plane services.
     </span>
     <span class="koboSpan" id="kobo.185.3">
      In the event of one cloud controller failure, the rest of the load will be distributed to the second operational node, maintaining uninterrupted services.
     </span>
     <span class="koboSpan" id="kobo.185.4">
      It is also suited to horizontal scaling as it adds a new node to accommodate any increased load without compromising the function of the cluster.
     </span>
     <span class="koboSpan" id="kobo.185.5">
      As OpenStack core components are based on API calls and RPC to handle messages via the queue message system, performance is paramount.
     </span>
     <span class="koboSpan" id="kobo.185.6">
      In active/active mode, service recovery has a shorter MTTR than active/passive mode, where a potentially long delay to failover can occur, causing some OpenStack services to
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.186.1">
       time out.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.187.1">
     Most of the OpenStack reference architectures adopt an active/active ground setup for fault tolerance
    </span>
    <a id="_idIndexMarker690">
    </a>
    <span class="koboSpan" id="kobo.188.1">
     and failover, mainly due to the nature of the OpenStack services that can scale horizontally easily and do not require additional mechanisms.
    </span>
    <span class="koboSpan" id="kobo.188.2">
     On the other hand, some services can be configured in active/passive mode, depending on the nature of the service.
    </span>
    <span class="koboSpan" id="kobo.188.3">
     In the next section, we will look at the different services that can be used to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.189.1">
      enable HA.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-134">
    <a id="_idTextAnchor179">
    </a>
    <span class="koboSpan" id="kobo.190.1">
     Preparing for HA
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.191.1">
     Each OpenStack control plane layer requires separate analysis to identify the best approaches
    </span>
    <a id="_idIndexMarker691">
    </a>
    <span class="koboSpan" id="kobo.192.1">
     to ensure its availability.
    </span>
    <span class="koboSpan" id="kobo.192.2">
     Additional technical considerations will be taken into account when designing for fault tolerance in a production setup.
    </span>
    <span class="koboSpan" id="kobo.192.3">
     It is important to note that a major factor in the different choices comes from the given cloud service provider’s experience with tooling or hardware solutions.
    </span>
    <span class="koboSpan" id="kobo.192.4">
     In this section, we will go through some of the major adopted tools and design patterns to achieve a highly available and scalable OpenStack
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.193.1">
      control plane.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-135">
    <a id="_idTextAnchor180">
    </a>
    <span class="koboSpan" id="kobo.194.1">
     Designing with load balancing
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.195.1">
     Load balancing solution services can be found everywhere and can be used to efficiently distribute
    </span>
    <a id="_idIndexMarker692">
    </a>
    <span class="koboSpan" id="kobo.196.1">
     and serve incoming requests across a server pool.
    </span>
    <span class="koboSpan" id="kobo.196.2">
     HAProxy has been widely adopted on dozens of large OpenStack
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.197.1">
      production deployments.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.198.1">
     The HAProxy setup involves the following two types
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.199.1">
      of servers:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.200.1">
       Frontend server
      </span>
     </strong>
     <span class="koboSpan" id="kobo.201.1">
      : This
     </span>
     <a id="_idIndexMarker693">
     </a>
     <span class="koboSpan" id="kobo.202.1">
      server listens for requests coming from a specific IP and port, and determines where the connection or request should
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.203.1">
       be forwarded
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.204.1">
       Backend server
      </span>
     </strong>
     <span class="koboSpan" id="kobo.205.1">
      : A pool
     </span>
     <a id="_idIndexMarker694">
     </a>
     <span class="koboSpan" id="kobo.206.1">
      of servers in the cluster receiving the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.207.1">
       forwarded requests
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.208.1">
     It is also important to note the function layers that are involved in HAProxy
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.209.1">
      load balancing:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.210.1">
       Layer 4
      </span>
     </strong>
     <span class="koboSpan" id="kobo.211.1">
      : Load balancing is performed in the transport layer in the OSI model.
     </span>
     <span class="koboSpan" id="kobo.211.2">
      All the
     </span>
     <a id="_idIndexMarker695">
     </a>
     <span class="koboSpan" id="kobo.212.1">
      user traffic will be forwarded based on a specific IP address and port to the backend servers.
     </span>
     <span class="koboSpan" id="kobo.212.2">
      For example, a load balancer might forward the internal OpenStack system’s request to the Horizon web backend group of backend servers.
     </span>
     <span class="koboSpan" id="kobo.212.3">
      To do this, whichever backend Horizon is selected should respond to the request under scope.
     </span>
     <span class="koboSpan" id="kobo.212.4">
      This is true in the case of all the servers in the web backend serving
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.213.1">
       identical content.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.214.1">
       Layer 7
      </span>
     </strong>
     <span class="koboSpan" id="kobo.215.1">
      : The
     </span>
     <a id="_idIndexMarker696">
     </a>
     <span class="koboSpan" id="kobo.216.1">
      application layer will be used for load balancing.
     </span>
     <span class="koboSpan" id="kobo.216.2">
      This is a good way to load balance network traffic.
     </span>
     <span class="koboSpan" id="kobo.216.3">
      Simply put, this mode allows you to forward requests to different backend servers based on the content of the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.217.1">
       request itself.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.218.1">
     HAProxy supports several load balancing algorithms to dispatch a request to a server in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.219.1">
      backend pool:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.220.1">
       Round robin
      </span>
     </strong>
     <span class="koboSpan" id="kobo.221.1">
      : Each server is exploited in turn.
     </span>
     <span class="koboSpan" id="kobo.221.2">
      As a simple HAProxy setup, round
     </span>
     <a id="_idIndexMarker697">
     </a>
     <span class="koboSpan" id="kobo.222.1">
      robin is a dynamic algorithm that defines the server’s weight and adjusts it on the fly when the called instance hangs or
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.223.1">
       starts slowly.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.224.1">
       Leastconn
      </span>
     </strong>
     <span class="koboSpan" id="kobo.225.1">
      : The
     </span>
     <a id="_idIndexMarker698">
     </a>
     <span class="koboSpan" id="kobo.226.1">
      selection of the server is based on the node that has the lowest number
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.227.1">
       of connections.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.228.1">
       Source
      </span>
     </strong>
     <span class="koboSpan" id="kobo.229.1">
      : This
     </span>
     <a id="_idIndexMarker699">
     </a>
     <span class="koboSpan" id="kobo.230.1">
      algorithm ensures that the request will be forwarded to the same server based on a hash of the source IP, so long as the server is
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.231.1">
       still up.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.232.1">
       Uniform resource identifier
      </span>
     </strong>
     <span class="koboSpan" id="kobo.233.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.234.1">
       URI
      </span>
     </strong>
     <span class="koboSpan" id="kobo.235.1">
      ): This ensures that the request will be forwarded
     </span>
     <a id="_idIndexMarker700">
     </a>
     <span class="koboSpan" id="kobo.236.1">
      to the same server based on its URI.
     </span>
     <span class="koboSpan" id="kobo.236.2">
      It is ideal to increase the cache hit rate in the case of proxy
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.237.1">
       cache implementations.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.238.1">
     HAProxy keeps an eye on the nodes’ backend availability by running health checks on particular IP addresses and ports.
    </span>
    <span class="koboSpan" id="kobo.238.2">
     It disables any backend node that fails the health checks and discards it from the backend pool until it is healthy enough to start serving
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.239.1">
      requests again.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.240.1">
     Armed with a load balancer, an OpenStack service that is deployed in two or more nodes will be
    </span>
    <a id="_idIndexMarker701">
    </a>
    <span class="koboSpan" id="kobo.241.1">
     exposed by a
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.242.1">
      Virtual IP
     </span>
    </strong>
    <span class="koboSpan" id="kobo.243.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.244.1">
      VIP
     </span>
    </strong>
    <span class="koboSpan" id="kobo.245.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.245.2">
     In active/active mode, the VIP is managed by the load balancer, which makes sure that a node has sufficient availability before it forwards
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.246.1">
      the request.
     </span>
    </span>
   </p>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.247.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.248.1">
     If you consider separating the HAProxy deployment into its own physical setup, make sure that the VIPs can be reached over the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.249.1">
      public network.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.250.1">
     As the use of VIPs combined with HAProxy adds an extra layer to protect OpenStack services
    </span>
    <a id="_idIndexMarker702">
    </a>
    <span class="koboSpan" id="kobo.251.1">
     from failures, the load balancing layer should not present a single point of failure.
    </span>
    <span class="koboSpan" id="kobo.251.2">
     Depending on which software or hardware-based load balancing solution you adopt, make sure you increase its redundancy level.
    </span>
    <span class="koboSpan" id="kobo.251.3">
     That should be reviewed as a critical networking setup as it defines the first interface
    </span>
    <a id="_idIndexMarker703">
    </a>
    <span class="koboSpan" id="kobo.252.1">
     of the OpenStack environment.
    </span>
    <span class="koboSpan" id="kobo.252.2">
     This can be achieved by using a VIP software management tool such as
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.253.1">
      Keepalived
     </span>
    </strong>
    <span class="koboSpan" id="kobo.254.1">
     or
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.255.1">
      Pacemaker
     </span>
    </strong>
    <span class="koboSpan" id="kobo.256.1">
     to ensure
    </span>
    <a id="_idIndexMarker704">
    </a>
    <span class="koboSpan" id="kobo.257.1">
     a highly available load balancing
    </span>
    <a id="_idIndexMarker705">
    </a>
    <span class="koboSpan" id="kobo.258.1">
     layer.
    </span>
    <span class="koboSpan" id="kobo.258.2">
     Keepalived is free software and employs the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.259.1">
      Virtual Router Redundancy Protocol
     </span>
    </strong>
    <span class="koboSpan" id="kobo.260.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.261.1">
      VRRP
     </span>
    </strong>
    <span class="koboSpan" id="kobo.262.1">
     ) to eliminate SPOFs by making IPs highly available.
    </span>
    <span class="koboSpan" id="kobo.262.2">
     As shown in the following diagram, VRRP implements virtual routing to perform failover tasks between two or more servers in a static,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.263.1">
      default-routed environment:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer111">
     <span class="koboSpan" id="kobo.264.1">
      <img alt="Figure 7.1 – Load balancing and failover using HAProxy and Keepalived" src="image/B21716_07_01.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.265.1">
     Figure 7.1 – Load balancing and failover using HAProxy and Keepalived
    </span>
   </p>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.266.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.267.1">
     To ensure
    </span>
    <a id="_idIndexMarker706">
    </a>
    <span class="koboSpan" id="kobo.268.1">
     an easily determined quorum by Keepalived, we will empower our control plane with HA via three cloud controller nodes managed
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.269.1">
      by Keepalived.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-136">
    <a id="_idTextAnchor181">
    </a>
    <span class="koboSpan" id="kobo.270.1">
     HA for the database
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.271.1">
     Databases have always been a critical subject when it comes to dealing with the growth of data
    </span>
    <a id="_idIndexMarker707">
    </a>
    <span class="koboSpan" id="kobo.272.1">
     being stored, along with performance and resiliency.
    </span>
    <span class="koboSpan" id="kobo.272.2">
     This is because a database is not a simple service and does not scale as fast as a simple API.
    </span>
    <span class="koboSpan" id="kobo.272.3">
     Any request that reaches an OpenStack API service results in the database’s size growing incrementally.
    </span>
    <span class="koboSpan" id="kobo.272.4">
     In our deployment process, using a CI/CD pipeline will generate a few additional entries across several tables in each run.
    </span>
    <span class="koboSpan" id="kobo.272.5">
     If not designed to scale and monitored closely, the database could be subject to failure and quickly become a bottleneck.
    </span>
    <span class="koboSpan" id="kobo.272.6">
     Several open source and database vendors provide possible topologies to scale horizontally or vertically or both.
    </span>
    <span class="koboSpan" id="kobo.272.7">
     The other factor is the type of database engine supported by OpenStack and the required experience of the cloud operation team to build and architect a highly available and scalable database solution
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.273.1">
      in OpenStack.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.274.1">
     Since we’ve started our initial production draft with a single database based on MySQL, we can highlight the most commonly
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.275.1">
      clustering topologies:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.276.1">
       Master/slave replication
      </span>
     </strong>
     <span class="koboSpan" id="kobo.277.1">
      : A VIP will be switched to a slave node when the master
     </span>
     <a id="_idIndexMarker708">
     </a>
     <span class="koboSpan" id="kobo.278.1">
      node fails.
     </span>
     <span class="koboSpan" id="kobo.278.2">
      A delay in the health check on the master node at failover time and thus a delay in assigning the VIP to the slave node could potentially result in data inconsistencies, as
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.279.1">
       shown here:
      </span>
     </span>
    </li>
   </ul>
   <p class="IMG---Figure">
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer112">
     <span class="koboSpan" id="kobo.280.1">
      <img alt="Figure 7.2 – Database master-slave replication" src="image/B21716_07_02.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.281.1">
     Figure 7.2 – Database master-slave replication
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.282.1">
       Multi-master replication manager
      </span>
     </strong>
     <span class="koboSpan" id="kobo.283.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.284.1">
       MMM
      </span>
     </strong>
     <span class="koboSpan" id="kobo.285.1">
      ): By setting up two servers, both of
     </span>
     <a id="_idIndexMarker709">
     </a>
     <span class="koboSpan" id="kobo.286.1">
      them become masters by keeping only one acceptable write query at a given time.
     </span>
     <span class="koboSpan" id="kobo.286.2">
      This is still not a very reliable solution for OpenStack database HA because in the event of failure of the master, it might lose a certain number of transactions, as
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.287.1">
       illustrated here:
      </span>
     </span>
    </li>
   </ul>
   <div>
    <div class="IMG---Figure" id="_idContainer113">
     <span class="koboSpan" id="kobo.288.1">
      <img alt="Figure 7.3 – Database MMM replication" src="image/B21716_07_03.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.289.1">
     Figure 7.3 – Database MMM replication
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.290.1">
       MySQL shared storage
      </span>
     </strong>
     <span class="koboSpan" id="kobo.291.1">
      : In this topology, both servers depend on redundant shared storage.
     </span>
     <span class="koboSpan" id="kobo.291.2">
      As shown in the following figure, a separation is required between
     </span>
     <a id="_idIndexMarker710">
     </a>
     <span class="koboSpan" id="kobo.292.1">
      the servers processing the data and the storage devices.
     </span>
     <span class="koboSpan" id="kobo.292.2">
      Note that an active node may exist at any point in time.
     </span>
     <span class="koboSpan" id="kobo.292.3">
      If it fails, the other node will take over the VIP after checking the inactivity of the failed node, and turn it off.
     </span>
     <span class="koboSpan" id="kobo.292.4">
      Such a solution is excellent in terms of uptime but may require a powerful storage/hardware system, which can be extremely expensive.
     </span>
     <span class="koboSpan" id="kobo.292.5">
      The service will be resumed on a different node by mounting the shared storage within the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.293.1">
       taken VIP:
      </span>
     </span>
    </li>
   </ul>
   <div>
    <div class="IMG---Figure" id="_idContainer114">
     <span class="koboSpan" id="kobo.294.1">
      <img alt="Figure 7.4 – Database MySQL with shared storage" src="image/B21716_07_04.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.295.1">
     Figure 7.4 – Database MySQL with shared storage
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.296.1">
       Block-level replication
      </span>
     </strong>
     <span class="koboSpan" id="kobo.297.1">
      : One
     </span>
     <a id="_idIndexMarker711">
     </a>
     <span class="koboSpan" id="kobo.298.1">
      of the most adopted
     </span>
     <a id="_idIndexMarker712">
     </a>
     <span class="koboSpan" id="kobo.299.1">
      HA implementations is the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.300.1">
       Distributed Replicated Block Device
      </span>
     </strong>
     <span class="koboSpan" id="kobo.301.1">
      (
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.302.1">
       DRBD
      </span>
     </strong>
     <span class="koboSpan" id="kobo.303.1">
      ) replication.
     </span>
     <span class="koboSpan" id="kobo.303.2">
      Simply put, it replicates data in the block device, which is the physical hard drive that’s shared between OpenStack MySQL nodes.
     </span>
     <span class="koboSpan" id="kobo.303.3">
      DRBD can be a costless solution, but performance-wise, it is not sufficient when you’re relying on hundreds of nodes.
     </span>
     <span class="koboSpan" id="kobo.303.4">
      It can also
     </span>
     <a id="_idIndexMarker713">
     </a>
     <span class="koboSpan" id="kobo.304.1">
      affect the scalability of the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.305.1">
       replicated cluster:
      </span>
     </span>
    </li>
   </ul>
   <div>
    <div class="IMG---Figure" id="_idContainer115">
     <span class="koboSpan" id="kobo.306.1">
      <img alt="Figure 7.5 – Database block-level replication" src="image/B21716_07_05.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.307.1">
     Figure 7.5 – Database block-level replication
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.308.1">
       MySQL multi-master replication with Galera
      </span>
     </strong>
     <span class="koboSpan" id="kobo.309.1">
      : Based on
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.310.1">
       multi-master replication
      </span>
     </strong>
     <span class="koboSpan" id="kobo.311.1">
      , the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.312.1">
       Galera
      </span>
     </strong>
     <span class="koboSpan" id="kobo.313.1">
      solution
     </span>
     <a id="_idIndexMarker714">
     </a>
     <span class="koboSpan" id="kobo.314.1">
      has a few performance
     </span>
     <a id="_idIndexMarker715">
     </a>
     <span class="koboSpan" id="kobo.315.1">
      challenges within an MMM architecture for MySQL/InnoDB database clusters.
     </span>
     <span class="koboSpan" id="kobo.315.2">
      A requirement for the Galera setup to run properly
     </span>
     <a id="_idIndexMarker716">
     </a>
     <span class="koboSpan" id="kobo.316.1">
      is the presence of at least three nodes.
     </span>
     <span class="koboSpan" id="kobo.316.2">
      As shown in the following diagram, synchronous replication is managed by Galera, where data is replicated across the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.317.1">
       whole cluster:
      </span>
     </span>
    </li>
   </ul>
   <div>
    <div class="IMG---Figure" id="_idContainer116">
     <span class="koboSpan" id="kobo.318.1">
      <img alt="Figure 7.6 – Database multi-master with Galera replication" src="image/B21716_07_06.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.319.1">
     Figure 7.6 – Database multi-master with Galera replication
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.320.1">
     Regarding these topologies, any MySQL replication setup can be simple to set up and make HA-capable, but data can be lost during the failover process.
    </span>
    <span class="koboSpan" id="kobo.320.2">
     MySQL multi-master replication
    </span>
    <a id="_idIndexMarker717">
    </a>
    <span class="koboSpan" id="kobo.321.1">
     with Galera is tightly designed to resolve such a conflict in the multi-master database environment.
    </span>
    <span class="koboSpan" id="kobo.321.2">
     An issue you may face in a typical multi-master setup is that all the nodes try to update the same database with different data, especially when a synchronization problem occurs during the master
    </span>
    <a id="_idIndexMarker718">
    </a>
    <span class="koboSpan" id="kobo.322.1">
     failure.
    </span>
    <span class="koboSpan" id="kobo.322.2">
     This is why Galera uses
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.323.1">
      certification-based replication
     </span>
    </strong>
    <span class="koboSpan" id="kobo.324.1">
     (
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.325.1">
      CBR
     </span>
    </strong>
    <span class="koboSpan" id="kobo.326.1">
     ).
    </span>
    <span class="koboSpan" id="kobo.326.2">
     The main mechanism of CBR is to assume that the database can roll back uncommitted changes and is transactional, in addition to applying replicated events in the same order across all the instances.
    </span>
    <span class="koboSpan" id="kobo.326.3">
     Replication is truly parallel; each one has an ID check.
    </span>
    <span class="koboSpan" id="kobo.326.4">
     The added value that Galera can bring to our MySQL (MariaDB in OpenStack) HA is the ease of scalability, such as joining a node to Galera in an automated fashion in a production environment.
    </span>
    <span class="koboSpan" id="kobo.326.5">
     The end design brings an active/active multi-master topology with minimum latency and transaction losses.
    </span>
    <span class="koboSpan" id="kobo.326.6">
     A best practice to ensure data consistency when implementing Galera for MariaDB in OpenStack is to keep writes committed to only one node of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.327.1">
      the three.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-137">
    <a id="_idTextAnchor182">
    </a>
    <span class="koboSpan" id="kobo.328.1">
     HA for the message bus
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.329.1">
     RabbitMQ is
    </span>
    <a id="_idIndexMarker719">
    </a>
    <span class="koboSpan" id="kobo.330.1">
     mainly responsible for communication between different OpenStack
    </span>
    <a id="_idIndexMarker720">
    </a>
    <span class="koboSpan" id="kobo.331.1">
     services.
    </span>
    <span class="koboSpan" id="kobo.331.2">
     The issue is fairly simple: no queue, no OpenStack service intercommunication.
    </span>
    <span class="koboSpan" id="kobo.331.3">
     RabbitMQ should be considered another critical service that needs to be available and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.332.1">
      survive failures.
     </span>
    </span>
   </p>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.333.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.334.1">
     A variety of queuing
    </span>
    <a id="_idIndexMarker721">
    </a>
    <span class="koboSpan" id="kobo.335.1">
     messages systems such as Qpid or ZeroMQ are mature enough
    </span>
    <a id="_idIndexMarker722">
    </a>
    <span class="koboSpan" id="kobo.336.1">
     to support their own cluster setup without the need for you to run other resource managers or clustering software solutions
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.337.1">
      alongside them.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.338.1">
     RabbitMQ is
    </span>
    <a id="_idIndexMarker723">
    </a>
    <span class="koboSpan" id="kobo.339.1">
     a robust messaging system that can achieve scalability in an active/active way through one of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.340.1">
      following patterns:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.341.1">
       Clustering
      </span>
     </strong>
     <span class="koboSpan" id="kobo.342.1">
      : Any data or state needed for the RabbitMQ broker to be operational is replicated across
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.343.1">
       all nodes.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.344.1">
       Mirrored queues
      </span>
     </strong>
     <span class="koboSpan" id="kobo.345.1">
      : As the message queue cannot survive in the nodes in which it resides, RabbitMQ can act in active/active HA message queues.
     </span>
     <span class="koboSpan" id="kobo.345.2">
      Simply put, queues will be mirrored on other nodes within the same RabbitMQ cluster.
     </span>
     <span class="koboSpan" id="kobo.345.3">
      Thus, any node failure will lead to automatically switching to one of the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.346.1">
       queue mirrors.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.347.1">
       Quorum queues
      </span>
     </strong>
     <span class="koboSpan" id="kobo.348.1">
      : This is a modern version of queues using a variant of the
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.349.1">
       Raft
      </span>
     </strong>
     <span class="koboSpan" id="kobo.350.1">
      protocol (enabling members of a distributed system to agree on a set of values and
     </span>
     <a id="_idIndexMarker724">
     </a>
     <span class="koboSpan" id="kobo.351.1">
      share data in the event of failure) with a distributed consensus algorithm and implementing replicated FIFO.
     </span>
     <span class="koboSpan" id="kobo.351.2">
      Each quorum queue has a leader and multiple followers with replicated queues hosted in
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.352.1">
       different hosts.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.353.1">
     RabbitMQ has deprecated the implementation of mirrored queues in favor of quorum queues due to the problems of its predecessor that it solves.
    </span>
    <span class="koboSpan" id="kobo.353.2">
     This includes synchronization failing and performance issues.
    </span>
    <span class="koboSpan" id="kobo.353.3">
     With the huge message bus traffic in OpenStack, quorum queues can boost not just availability but also the consistency of the messages, as shown in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.354.1">
      following diagram:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer117">
     <span class="koboSpan" id="kobo.355.1">
      <img alt="Figure 7.7 – RabbitMQ broker quorum pattern" src="image/B21716_07_07.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.356.1">
     Figure 7.7 – RabbitMQ broker quorum pattern
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.357.1">
     In the
    </span>
    <a id="_idIndexMarker725">
    </a>
    <span class="koboSpan" id="kobo.358.1">
     next section, we will extend our deployment by introducing the aforementioned elements to enable HA and redundancy in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.359.1">
      OpenStack environment.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-138">
    <a id="_idTextAnchor183">
    </a>
    <span class="koboSpan" id="kobo.360.1">
     Deploying for HA
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.361.1">
     In this
    </span>
    <a id="_idIndexMarker726">
    </a>
    <span class="koboSpan" id="kobo.362.1">
     section, we will extend our initial production deployment by extending our OpenStack control plane with a highly available configuration composed of the following set
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.363.1">
      of nodes:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.364.1">
       Virtual
      </span>
     </strong>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.365.1">
        IP
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.366.1">
       :
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.367.1">
        10.0.0.47
       </span>
      </strong>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.368.1">
       HAProxy 01
      </span>
     </strong>
     <span class="koboSpan" id="kobo.369.1">
      (
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.370.1">
        hap1.os.packtpub
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.371.1">
       ):
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.372.1">
        10.0.0.20
       </span>
      </strong>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.373.1">
       HAProxy 02
      </span>
     </strong>
     <span class="koboSpan" id="kobo.374.1">
      (
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.375.1">
        hap2.os.packtpub
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.376.1">
       ):
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.377.1">
        10.0.0.21
       </span>
      </strong>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.378.1">
       Cloud Controller 01
      </span>
     </strong>
     <span class="koboSpan" id="kobo.379.1">
      (
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.380.1">
        cc01.os.packtpub
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.381.1">
       ):
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.382.1">
        10.0.0.100
       </span>
      </strong>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.383.1">
       Cloud Controller 02
      </span>
     </strong>
     <span class="koboSpan" id="kobo.384.1">
      (
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.385.1">
        cc02.os.packtpub
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.386.1">
       ):
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.387.1">
        10.0.0.101
       </span>
      </strong>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.388.1">
       Cloud Controller 03
      </span>
     </strong>
     <span class="koboSpan" id="kobo.389.1">
      (
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.390.1">
        cc03.os.packtpub
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.391.1">
       ):
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.392.1">
        10.0.0.102
       </span>
      </strong>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.393.1">
     The HA version of our OpenStack environment will require that we apply the following configurations in the
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.394.1">
       globals.yml
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.395.1">
      file:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.396.1">
      Enable HAProxy, which will use Keepalived by default for the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.397.1">
       HA settings:
      </span>
     </span>
     <pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.398.1">enable_haproxy: "yes"</span></strong></pre>
    </li>
    <li>
     <span class="koboSpan" id="kobo.399.1">
      Assign a VIP that is not used for the management network where the HAProxy hosts are connected and Keepalived is running.
     </span>
     <span class="koboSpan" id="kobo.399.2">
      Optionally, the external and internal VIPs can be separated.
     </span>
     <span class="koboSpan" id="kobo.399.3">
      The following setting will use the same internal
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.400.1">
       VIP address:
      </span>
     </span>
     <pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.401.1">kolla_external_vip_address: "10.0.0.47"</span></strong></pre>
    </li>
    <li>
     <span class="koboSpan" id="kobo.402.1">
      The RabbitMQ
     </span>
     <a id="_idIndexMarker727">
     </a>
     <span class="koboSpan" id="kobo.403.1">
      quorum is the default implementation for message-queue HA in OpenStack.
     </span>
     <span class="koboSpan" id="kobo.403.2">
      Some older versions in
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.404.1">
       kolla-ansible
      </span>
     </strong>
     <span class="koboSpan" id="kobo.405.1">
      use mirrored queues referenced with the
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.406.1">
       om_enable_rabbitmq_high_availability
      </span>
     </strong>
     <span class="koboSpan" id="kobo.407.1">
      setting.
     </span>
     <span class="koboSpan" id="kobo.407.2">
      Make sure this is disabled and uses quorum queues instead by checking the
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.408.1">
       ansible/group_vars/all.yml
      </span>
     </strong>
     <span class="koboSpan" id="kobo.409.1">
      file or adding the following variable set if it does not exist in the
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.410.1">
        globals.yml
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.411.1">
       file:
      </span>
     </span>
     <pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.412.1">om_enable_rabbitmq_quorum_queues: true</span></strong></pre>
    </li>
   </ul>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.413.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.414.1">
     Populating the quorum queues in a running environment requires manually restarting all OpenStack services using the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.415.1">
      kolla-ansible stop --tags &lt;service-tags&gt;
     </span>
    </strong>
    <span class="koboSpan" id="kobo.416.1">
     and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.417.1">
      kolla-ansible deploy --tags &lt;service-tags&gt;
     </span>
    </strong>
    <span class="koboSpan" id="kobo.418.1">
     command lines, where
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.419.1">
      &lt;service-tags&gt;
     </span>
    </strong>
    <span class="koboSpan" id="kobo.420.1">
     is the name of a given OpenStack service.
    </span>
    <span class="koboSpan" id="kobo.420.2">
     It is recommended to automate the service restart using the pipeline for consistent configuration and
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.421.1">
      durable queues.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.422.1">
     The next configuration update is to adjust the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.423.1">
      multi_packtpub_prod
     </span>
    </strong>
    <span class="koboSpan" id="kobo.424.1">
     file.
    </span>
    <span class="koboSpan" id="kobo.424.2">
     The following layout suggests the deployment of three cloud
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.425.1">
      controller nodes:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.426.1">
...
</span><span class="koboSpan" id="kobo.426.2">[control]
cc01.os.packtpub
cc02.os.packtpub
cc03.os.packtpub</span></pre>
   <p>
    <span class="koboSpan" id="kobo.427.1">
     A new host group of two load balancers will be added, running HAProxy
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.428.1">
      and Keepalived:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.429.1">
...
</span><span class="koboSpan" id="kobo.429.2">[haproxy]
hap1.os.packtpub
hap2.os.packtpub
[loadbalancer:children]
haproxy</span></pre>
   <p>
    <span class="koboSpan" id="kobo.430.1">
     As stated in
    </span>
    <a href="B21716_03.xhtml#_idTextAnchor108">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.431.1">
        Chapter 3
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.432.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.433.1">
      OpenStack Control Plane – Shared Services
     </span>
    </em>
    <span class="koboSpan" id="kobo.434.1">
     , one of the best practices regarding production environments is to start hosting workloads in the cloud environment only when it is configured with HA (at a minimum) within its core services.
    </span>
    <span class="koboSpan" id="kobo.434.2">
     As no
    </span>
    <a id="_idIndexMarker728">
    </a>
    <span class="koboSpan" id="kobo.435.1">
     production workload has been run yet, it is recommended to clean up the running environment by firing off the following
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.436.1">
      command line:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.437.1">
$ kolla-ansible -i ./multi_packtpub_prod destroy --yes-ireally-really-mean-it</span></pre>
   <p>
    <span class="koboSpan" id="kobo.438.1">
     This will clean up the OpenStack service containers and associated volumes.
    </span>
    <span class="koboSpan" id="kobo.438.2">
     The new pipeline run will deploy all containers from the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.439.1">
      same image.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.440.1">
     The database deployment for Galera InnoDB will run the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.441.1">
      wsrep
     </span>
    </strong>
    <span class="koboSpan" id="kobo.442.1">
     service across the three controller nodes.
    </span>
    <span class="koboSpan" id="kobo.442.2">
     One common issue when deploying additional nodes in a running environment is the failure of one or both nodes to read binary logs and update the replication status.
    </span>
    <span class="koboSpan" id="kobo.442.3">
     RabbitMQ quorum also requires additional manual tweaks to clean the existing exchanges and move to durable queues while using quorum across different cloud
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.443.1">
      controller nodes.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.444.1">
     Commit the changes before running the pipeline.
    </span>
    <span class="koboSpan" id="kobo.444.2">
     Rolling out the new multi-node infrastructure will take longer than the very first run as the new cloud controller nodes and load balancers will be deployed in addition to multi-master database quorum queues deployment across
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.445.1">
      different nodes.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.446.1">
     Once the pipeline finishes the multi-node deployment, observe the Docker images that have been loaded for HAProxy and Keepalived by running the following command line in any of the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.447.1">
      controller nodes:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.448.1">
$ sudo docker images</span></pre>
   <p>
    <span class="koboSpan" id="kobo.449.1">
     We will get
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.450.1">
      this output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer118">
     <span class="koboSpan" id="kobo.451.1">
      <img alt="Figure 7.8 – Listing the HAProxy and Keepalived Kolla images" src="image/B21716_07_08.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.452.1">
     Figure 7.8 – Listing the HAProxy and Keepalived Kolla images
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.453.1">
     In addition
    </span>
    <a id="_idIndexMarker729">
    </a>
    <span class="koboSpan" id="kobo.454.1">
     to the different containers for OpenStack services, observe the container running HAProxy
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.455.1">
      and Keepalived:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.456.1">
$ sudo docker ps</span></pre>
   <p>
    <span class="koboSpan" id="kobo.457.1">
     Here is
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.458.1">
      the output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer119">
     <span class="koboSpan" id="kobo.459.1">
      <img alt="Figure 7.9 – Listing the HAProxy and Keepalived Kolla containers" src="image/B21716_07_09.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.460.1">
     Figure 7.9 – Listing the HAProxy and Keepalived Kolla containers
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.461.1">
     Optionally, verify that all compute nodes can be listed as part of the OpenStack environment and check the service status,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.462.1">
      as follows:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.463.1">
$ openstack availability zone list --compute --long</span></pre>
   <p>
    <span class="koboSpan" id="kobo.464.1">
     The output is
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.465.1">
      as follows:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer120">
     <span class="koboSpan" id="kobo.466.1">
      <img alt="Figure 7.10 – Listing the enabled Nova services in all OpenStack environments" src="image/B21716_07_10.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.467.1">
     Figure 7.10 – Listing the enabled Nova services in all OpenStack environments
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.468.1">
     Each HAProxy instance that’s deployed in each cloud controller node is assigned a priority ID that’s used by Keepalived to refer to the elected master node.
    </span>
    <span class="koboSpan" id="kobo.468.2">
     The generated file in each controller node can be found in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.469.1">
      /etc/kolla/keepalived/keepalived.conf
     </span>
    </strong>
    <span class="koboSpan" id="kobo.470.1">
     file.
    </span>
    <span class="koboSpan" id="kobo.470.2">
     The following is a snippet of the Keepalived configuration that was generated on one of the cloud
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.471.1">
      controller nodes:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.472.1">
vrrp_instance kolla_internal_vip_51 {
    state BACKUP
    nopreempt
    interface br0
    virtual_router_id 51
    priority 40
    advert_int 1
    virtual_ipaddress {
        10.0.0.47 dev br0
    }
}
...</span></pre>
   <p>
    <span class="koboSpan" id="kobo.473.1">
     The
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.474.1">
      kolla_internal_vip_51
     </span>
    </strong>
    <span class="koboSpan" id="kobo.475.1">
     configuration block defines a random unique ID for the VIP
    </span>
    <a id="_idIndexMarker730">
    </a>
    <span class="koboSpan" id="kobo.476.1">
     that can be set in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.477.1">
      globals.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.478.1">
     file by changing the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.479.1">
      keepalived_virtual_router_id
     </span>
    </strong>
    <span class="koboSpan" id="kobo.480.1">
     variable.
    </span>
    <span class="koboSpan" id="kobo.480.2">
     The default value that’s shown is
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.481.1">
      51
     </span>
    </strong>
    <span class="koboSpan" id="kobo.482.1">
     , which refers to the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.483.1">
      virtual_router_id
     </span>
    </strong>
    <span class="koboSpan" id="kobo.484.1">
     value in the Keepalived configuration.
    </span>
    <span class="koboSpan" id="kobo.484.2">
     Once a cluster managed by Keepalived is launched, a priority number will be assigned for each node, where the higher priority is the most preferred node to hold the VIP and hence is elected as the master.
    </span>
    <span class="koboSpan" id="kobo.484.3">
     In this example, a priority of
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.485.1">
      40
     </span>
    </strong>
    <span class="koboSpan" id="kobo.486.1">
     has been assigned to the current cloud controller node.
    </span>
    <span class="koboSpan" id="kobo.486.2">
     A quick check on the Kolla Keepalived container log is used to validate each cloud controller state.
    </span>
    <span class="koboSpan" id="kobo.486.3">
     In the following example, the current cloud controller is assigned a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.487.1">
      master state:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.488.1">
$ docker logs -f keepalived</span></pre>
   <p>
    <span class="koboSpan" id="kobo.489.1">
     And we get the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.490.1">
      following output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer121">
     <span class="koboSpan" id="kobo.491.1">
      <img alt="Figure 7.11 – Validating the Keepalived master assignment" src="image/B21716_07_11.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.492.1">
     Figure 7.11 – Validating the Keepalived master assignment
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.493.1">
     Upon being
    </span>
    <a id="_idIndexMarker731">
    </a>
    <span class="koboSpan" id="kobo.494.1">
     elected as a master, Keepalived assigns a VIP of
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.495.1">
      10.0.0.47
     </span>
    </strong>
    <span class="koboSpan" id="kobo.496.1">
     to the cloud controller node.
    </span>
    <span class="koboSpan" id="kobo.496.2">
     In this example, cloud controller 02 (
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.497.1">
      10.0.0.101
     </span>
    </strong>
    <span class="koboSpan" id="kobo.498.1">
     ) has been assigned the VIP.
    </span>
    <span class="koboSpan" id="kobo.498.2">
     This can be checked by firing off the following command line in
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.499.1">
      the host:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.500.1">
$ ip a</span></pre>
   <p>
    <span class="koboSpan" id="kobo.501.1">
     It gives the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.502.1">
      following output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer122">
     <span class="koboSpan" id="kobo.503.1">
      <img alt="Figure 7.12 – Checking the Keepalived VIP" src="image/B21716_07_12.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.504.1">
     Figure 7.12 – Checking the Keepalived VIP
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.505.1">
     Enabling HAProxy and Keepalived in our OpenStack deployment ensures HA for most OpenStack services.
    </span>
    <span class="koboSpan" id="kobo.505.2">
     On the other hand, OpenStack networking may require additional hardening to enable the fault tolerance capability, as will be depicted in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.506.1">
      following subsection.
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-139">
    <a id="_idTextAnchor184">
    </a>
    <span class="koboSpan" id="kobo.507.1">
     HA for networking
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.508.1">
     The OpenStack
    </span>
    <a id="_idIndexMarker732">
    </a>
    <span class="koboSpan" id="kobo.509.1">
     network service involves different composites, including Neutron server L2, L3, metadata, and DHCP agents.
    </span>
    <span class="koboSpan" id="kobo.509.2">
     L2 agents are installed on every compute node and there is no need to maintain their HA setup.
    </span>
    <span class="koboSpan" id="kobo.509.3">
     The DHCP and metadata agents run across multiple nodes and support a highly available setup
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.510.1">
      by default.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.511.1">
     On the other hand, L3 agents require more tweaking to attain HA as they are the ones responsible for the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.512.1">
      following aspects:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <span class="koboSpan" id="kobo.513.1">
      Managing virtual routers
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.514.1">
       per tenant
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.515.1">
      Providing external connectivity
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.516.1">
       to instances
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.517.1">
      Managing floating IPs to instances for external
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.518.1">
       network access
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.519.1">
     Before the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.520.1">
      Icehouse
     </span>
    </strong>
    <span class="koboSpan" id="kobo.521.1">
     release, there was no built-in solution to resolve the L3 agent HA issue.
    </span>
    <span class="koboSpan" id="kobo.521.2">
     Some workarounds involve utilizing an external cluster solution using Pacemaker and
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.522.1">
      Corosync
     </span>
    </strong>
    <span class="koboSpan" id="kobo.523.1">
     .
    </span>
    <span class="koboSpan" id="kobo.523.2">
     New HA
    </span>
    <a id="_idIndexMarker733">
    </a>
    <span class="koboSpan" id="kobo.524.1">
     modes adopted for Neutron in OpenStack have been introduced
    </span>
    <a id="_idIndexMarker734">
    </a>
    <span class="koboSpan" id="kobo.525.1">
     since the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.526.1">
      Juno
     </span>
    </strong>
    <span class="koboSpan" id="kobo.527.1">
     release, including
    </span>
    <a id="_idIndexMarker735">
    </a>
    <span class="koboSpan" id="kobo.528.1">
     the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.529.1">
      following options:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.530.1">
       Virtual Router Redundancy
      </span>
     </strong>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.531.1">
        Protocol
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.532.1">
       (
      </span>
     </span>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.533.1">
        VRRP
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.534.1">
       )
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.535.1">
       Distributed Virtual
      </span>
     </strong>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.536.1">
        Routing
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.537.1">
       (
      </span>
     </span>
     <span class="No-Break">
      <strong class="bold">
       <span class="koboSpan" id="kobo.538.1">
        DVR
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.539.1">
       )
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.540.1">
     The next
    </span>
    <a id="_idIndexMarker736">
    </a>
    <span class="koboSpan" id="kobo.541.1">
     few sections will look at how a redundant Neutron router setup can be achieved using VRRP
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.542.1">
      and Keepalived.
     </span>
    </span>
   </p>
   <h3>
    <span class="koboSpan" id="kobo.543.1">
     Routing redundancy with VRRP
    </span>
   </h3>
   <p>
    <span class="koboSpan" id="kobo.544.1">
     We briefly introduced the concept of VRRP earlier in this chapter.
    </span>
    <span class="koboSpan" id="kobo.544.2">
     In the networking context, VRRP and Keepalived are configured in Neutron to fail over within a brief period
    </span>
    <a id="_idIndexMarker737">
    </a>
    <span class="koboSpan" id="kobo.545.1">
     between
    </span>
    <a id="_idIndexMarker738">
    </a>
    <span class="koboSpan" id="kobo.546.1">
     router namespaces.
    </span>
    <span class="koboSpan" id="kobo.546.2">
     As shown in the following diagram, routers can be seen in the form of groups, where each group presents an active router that is currently forwarding traffic
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.547.1">
      to instances:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer123">
     <span class="koboSpan" id="kobo.548.1">
      <img alt="Figure 7.13 – Routing redundancy with VRRP" src="image/B21716_07_13.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.549.1">
     Figure 7.13 – Routing redundancy with VRRP
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.550.1">
     Additionally, the instance traffic is spread among all network nodes based on the scheduling for the master and the rest of the backup routers.
    </span>
    <span class="koboSpan" id="kobo.550.2">
     Based on the same concept of the Keepalived mechanism, the master router configures its VIP internally and keeps informing the router group about its state
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.551.1">
      and priority.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.552.1">
     Each VRRP group elects a master router based on the assigned priorities, where the router with the highest ID will be selected as the master and the rest remain as backups.
    </span>
    <span class="koboSpan" id="kobo.552.2">
     A new election poll will only take place when the master router stops sending its VRRP advertisements to the assigned group and will be marked as a
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.553.1">
      failed master.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.554.1">
     Every
    </span>
    <a id="_idIndexMarker739">
    </a>
    <span class="koboSpan" id="kobo.555.1">
     newly created
    </span>
    <a id="_idIndexMarker740">
    </a>
    <span class="koboSpan" id="kobo.556.1">
     HA router will add a new router namespace where its L3 agent starts Keepalived.
    </span>
    <span class="koboSpan" id="kobo.556.2">
     Under the hood, routers configured in HA mode will be able to communicate via a specific HA network that is not visible to users.
    </span>
    <span class="koboSpan" id="kobo.556.3">
     The HA network interface is denoted
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.557.1">
      by
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.558.1">
       ha
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.559.1">
      .
     </span>
    </span>
   </p>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.560.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.561.1">
     The active
    </span>
    <a id="_idIndexMarker741">
    </a>
    <span class="koboSpan" id="kobo.562.1">
     router needs to periodically inform the standby ones about its state, determined by the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.563.1">
      advertisement interval timer
     </span>
    </strong>
    <span class="koboSpan" id="kobo.564.1">
     .
    </span>
    <span class="koboSpan" id="kobo.564.2">
     If a backup router does not receive such information, it will start a new master router election process based on the last advertised VRRP.
    </span>
    <span class="koboSpan" id="kobo.564.3">
     This election is based on priority, where the router with the highest value will be elected as the master.
    </span>
    <span class="koboSpan" id="kobo.564.4">
     Priorities range from
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.565.1">
      0
     </span>
    </strong>
    <span class="koboSpan" id="kobo.566.1">
     to
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.567.1">
      255
     </span>
    </strong>
    <span class="koboSpan" id="kobo.568.1">
     , with
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.569.1">
      255
     </span>
    </strong>
    <span class="koboSpan" id="kobo.570.1">
     being the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.571.1">
      highest priority.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.572.1">
     By default, Neutron automatically creates an HA pool range network of
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.573.1">
      169.254.192.0/18
     </span>
    </strong>
    <span class="koboSpan" id="kobo.574.1">
     , which is used by tenant routers with HA mode enabled.
    </span>
    <span class="koboSpan" id="kobo.574.2">
     The next configuration demonstrates a router resiliency setup in Neutron using VRRP and Keepalived.
    </span>
    <span class="koboSpan" id="kobo.574.3">
     Based on our initial design, a Neutron node will be added that runs an L3 agent and is configured with the Open vSwitch mechanism driver, which supports
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.575.1">
      HA routers.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.576.1">
     Add a second network node to the inventory file that runs an L3 agent and, optionally, the DHCP and metadata agents,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.577.1">
      as follows:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.578.1">
...
</span><span class="koboSpan" id="kobo.578.2">[network]
net02.os.packtpub
...</span></pre>
   <p>
    <span class="koboSpan" id="kobo.579.1">
     Run
    </span>
    <a id="_idIndexMarker742">
    </a>
    <span class="koboSpan" id="kobo.580.1">
     the pipeline
    </span>
    <a id="_idIndexMarker743">
    </a>
    <span class="koboSpan" id="kobo.581.1">
     and make sure the L3 agent is up and running by running the following command line on the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.582.1">
      controller node:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.583.1">
$ openstack network agent list --agent-type l3</span></pre>
   <p>
    <span class="koboSpan" id="kobo.584.1">
     The output will be
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.585.1">
      as shown:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer124">
     <span class="koboSpan" id="kobo.586.1">
      <img alt="Figure 7.14 – Listing the installed Neutron L3 agents" src="image/B21716_07_14.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.587.1">
     Figure 7.14 – Listing the installed Neutron L3 agents
    </span>
   </p>
   <p class="callout-heading">
    <span class="koboSpan" id="kobo.588.1">
     Important note
    </span>
   </p>
   <p class="callout">
    <span class="koboSpan" id="kobo.589.1">
     Make sure the new network node is connected to the same network segment as the first network node, as illustrated in
    </span>
    <a href="B21716_01.xhtml#_idTextAnchor014">
     <span class="No-Break">
      <em class="italic">
       <span class="koboSpan" id="kobo.590.1">
        Chapter 1
       </span>
      </em>
     </span>
    </a>
    <span class="koboSpan" id="kobo.591.1">
     ,
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.592.1">
      Revisiting OpenStack – Design Considerations
     </span>
    </em>
    <span class="koboSpan" id="kobo.593.1">
     .
    </span>
    <span class="koboSpan" id="kobo.593.2">
     The second node will use the same Neutron mechanism driver for Open vSwitch, as configured in the
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.594.1">
       globals.yml
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.595.1">
      file.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.596.1">
     Set the following configuration to
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.597.1">
      yes
     </span>
    </strong>
    <span class="koboSpan" id="kobo.598.1">
     in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.599.1">
      globals.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.600.1">
     file to enable the HA state for the Neutron
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.601.1">
      L3 agent:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.602.1">
enable_neutron_agent_ha: "yes"</span></pre>
   <p>
    <span class="koboSpan" id="kobo.603.1">
     Run the pipeline to apply the new changes in the Neutron configuration file.
    </span>
    <span class="koboSpan" id="kobo.603.2">
     The Neutron service should be restarted, with the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.604.1">
      l3_ha
     </span>
    </strong>
    <span class="koboSpan" id="kobo.605.1">
     setting being set to
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.606.1">
      True
     </span>
    </strong>
    <span class="koboSpan" id="kobo.607.1">
     in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.608.1">
      /etc/neutron/neutron.conf
     </span>
    </strong>
    <span class="koboSpan" id="kobo.609.1">
     file.
    </span>
    <span class="koboSpan" id="kobo.609.2">
     The default number of maximum L3 agents that will be scheduled on a virtual router is set to
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.610.1">
      3
     </span>
    </strong>
    <span class="koboSpan" id="kobo.611.1">
     to construct the VRRP virtual router.
    </span>
    <span class="koboSpan" id="kobo.611.2">
     This can be modified in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.612.1">
      roles/neutron/defaults/main.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.613.1">
     file by setting the value
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.614.1">
      of
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.615.1">
       max_l3_agents_per_router
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.616.1">
      .
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.617.1">
     With
    </span>
    <a id="_idIndexMarker744">
    </a>
    <span class="koboSpan" id="kobo.618.1">
     these new
    </span>
    <a id="_idIndexMarker745">
    </a>
    <span class="koboSpan" id="kobo.619.1">
     settings, any newly created router is considered an HA router and not a legacy one.
    </span>
    <span class="koboSpan" id="kobo.619.2">
     Create a new router by setting the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.620.1">
      –
     </span>
    </strong>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.621.1">
       ha
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.622.1">
      flag:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.623.1">
$ openstack router create --ha haRouter</span></pre>
   <p>
    <span class="koboSpan" id="kobo.624.1">
     Walking through the different network nodes running an L3 agent, the newly created router can be observed via its created namespace in the first
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.625.1">
      network node:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.626.1">
@net01.os:~#ip netns | grep router
qrouter-ba14211-22ae-3422-cda1-aeb623dacd11
And on the second network node:
@net02.os:~#ip netns | grep router
qrouter-ba14211-22ae-3422-cda1-aeb623dacd11</span></pre>
   <p>
    <span class="koboSpan" id="kobo.627.1">
     Once an HA router is created, the master router will be assigned a virtual IP of
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.628.1">
      169.254.0.1
     </span>
    </strong>
    <span class="koboSpan" id="kobo.629.1">
     at any
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.630.1">
      given time:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.631.1">
$ ip netns exec qrouter-ba14211-22ae-3422-cda1-aeb623dacd11 ip addr show</span></pre>
   <p>
    <span class="koboSpan" id="kobo.632.1">
     The output will be
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.633.1">
      as follows:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer125">
     <span class="koboSpan" id="kobo.634.1">
      <img alt="Figure 7.15 – Listing the router namespaces and HA scope for the master router" src="image/B21716_07_15.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.635.1">
     Figure 7.15 – Listing the router namespaces and HA scope for the master router
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.636.1">
     Let’s check the output in the second node running the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.637.1">
      backup router:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.638.1">
$ ip netns exec qrouter-ba14211-22ae-3422-cda1-aeb623dacd11 ip addr show</span></pre>
   <p>
    <span class="koboSpan" id="kobo.639.1">
     We get
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.640.1">
      the following:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer126">
     <span class="koboSpan" id="kobo.641.1">
      <img alt="Figure 7.16 – Listing the router namespaces and HA scope for the backup router" src="image/B21716_07_16.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.642.1">
     Figure 7.16 – Listing the router namespaces and HA scope for the backup router
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.643.1">
     Neutron
    </span>
    <a id="_idIndexMarker746">
    </a>
    <span class="koboSpan" id="kobo.644.1">
     automatically reserves a new dedicated HA network that is only visible to administrators
    </span>
    <a id="_idIndexMarker747">
    </a>
    <span class="koboSpan" id="kobo.645.1">
     and does not belong to any OpenStack project upon the creation of
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.646.1">
      HA routers:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.647.1">
$ openstack network list</span></pre>
   <p>
    <span class="koboSpan" id="kobo.648.1">
     The output is shown
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.649.1">
      as follows:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer127">
     <span class="koboSpan" id="kobo.650.1">
      <img alt="Figure 7.17 – Listing the reserved HA network" src="image/B21716_07_17.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.651.1">
     Figure 7.17 – Listing the reserved HA network
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.652.1">
     Keepalived is configured to run in each namespace by using a persistent configuration file located at
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.653.1">
      /var/lib/neutron/ha_confs/ROUTER_NETNS/keepalived.conf
     </span>
    </strong>
    <span class="koboSpan" id="kobo.654.1">
     , where
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.655.1">
      ROUTER_NETNS
     </span>
    </strong>
    <span class="koboSpan" id="kobo.656.1">
     is the router namespace of the HA router.
    </span>
    <span class="koboSpan" id="kobo.656.2">
     Failover events are also logged in
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.657.1">
      neutron-keepalived-state-change.log
     </span>
    </strong>
    <span class="koboSpan" id="kobo.658.1">
     under the same directory.
    </span>
    <span class="koboSpan" id="kobo.658.2">
     The following extract from a log shows a switch router during a failover event on the first
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.659.1">
      network node:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer128">
     <span class="koboSpan" id="kobo.660.1">
      <img alt="Figure 7.18 – Verifying router failover in log entries" src="image/B21716_07_18.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.661.1">
     Figure 7.18 – Verifying router failover in log entries
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.662.1">
     Neutron routing fault tolerance is a critical requirement to handle OpenStack networking availability.
    </span>
    <span class="koboSpan" id="kobo.662.2">
     The OpenStack Neutron design was not limited only to router redundancy using VRRP.
    </span>
    <span class="koboSpan" id="kobo.662.3">
     Later, Neutron introduced the DVR implementation.
    </span>
    <span class="koboSpan" id="kobo.662.4">
     We’ll explore this in the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.663.1">
      next subsection.
     </span>
    </span>
   </p>
   <h3>
    <span class="koboSpan" id="kobo.664.1">
     Routing redundancy with DVR
    </span>
   </h3>
   <p>
    <span class="koboSpan" id="kobo.665.1">
     Like HA routers, DVR operates across multiple compute nodes.
    </span>
    <span class="koboSpan" id="kobo.665.2">
     Using DVR, network load is distributed
    </span>
    <a id="_idIndexMarker748">
    </a>
    <span class="koboSpan" id="kobo.666.1">
     across operating routers, reducing the
    </span>
    <a id="_idIndexMarker749">
    </a>
    <span class="koboSpan" id="kobo.667.1">
     traffic load on the network node.
    </span>
    <span class="koboSpan" id="kobo.667.2">
     L3 agents run in compute nodes and traffic flows for
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.668.1">
      east-west
     </span>
    </em>
    <span class="koboSpan" id="kobo.669.1">
     (instance-to-instance) and
    </span>
    <em class="italic">
     <span class="koboSpan" id="kobo.670.1">
      north-south
     </span>
    </em>
    <span class="koboSpan" id="kobo.671.1">
     (from an instance to external networks with floating IPs or vice versa) are routed across them instead of a single centralized
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.672.1">
      network node.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.673.1">
     Configuring DVR in Neutron requires the usage of the Open vSwitch mechanism driver and the L3 agent to be installed on the compute nodes.
    </span>
    <span class="koboSpan" id="kobo.673.2">
     Update the inventory file by adding the L3 agent to the desired compute nodes,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.674.1">
      as follows:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.675.1">
...
</span><span class="koboSpan" id="kobo.675.2">[compute]
cn01.os.packtpub
cn02.os.packtpub
...
</span><span class="koboSpan" id="kobo.675.3">[neutron-l3-agent:children]
compute</span></pre>
   <p>
    <span class="koboSpan" id="kobo.676.1">
     Run the pipeline and verify that the L3 agent is up and running in the compute nodes by running the following command line on the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.677.1">
      controller node:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.678.1">
$ openstack network agent list --agent-type l3</span></pre>
   <p>
    <span class="koboSpan" id="kobo.679.1">
     We get the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.680.1">
      following output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer129">
     <span class="koboSpan" id="kobo.681.1">
      <img alt="Figure 7.19 – Listing the installed Neutron L3 agents" src="image/B21716_07_19.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.682.1">
     Figure 7.19 – Listing the installed Neutron L3 agents
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.683.1">
     Enable DVR routing in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.684.1">
      globals.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.685.1">
     file by setting the following
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.686.1">
      configuration line:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.687.1">
enable_neutron_dvr: "yes"</span></pre>
   <p>
    <span class="koboSpan" id="kobo.688.1">
     Run the pipeline and observe the configuration updates in the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.689.1">
      /etc/neutron/neutron.conf
     </span>
    </strong>
    <span class="koboSpan" id="kobo.690.1">
     Neutron configuration file,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.691.1">
      as follows:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.692.1">
...
</span><span class="koboSpan" id="kobo.692.2">router_distributed = True</span></pre>
   <p>
    <span class="koboSpan" id="kobo.693.1">
     Each
    </span>
    <a id="_idIndexMarker750">
    </a>
    <span class="koboSpan" id="kobo.694.1">
     compute node
    </span>
    <a id="_idIndexMarker751">
    </a>
    <span class="koboSpan" id="kobo.695.1">
     with an installed L3 agent should host the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.696.1">
      /etc/neutron/plugins/ml2/openvswitch_agent.ini
     </span>
    </strong>
    <span class="koboSpan" id="kobo.697.1">
     Open vSwitch agent configuration file with the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.698.1">
      following settings:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.699.1">
...
</span><span class="koboSpan" id="kobo.699.2">[agent]
l2_population = True
enable_distributed_routing = True</span></pre>
   <p>
    <span class="koboSpan" id="kobo.700.1">
     Run the pipeline to populate the DVR configuration in both the agent and Neutron server
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.701.1">
      configuration settings.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.702.1">
     As an admin, create a new router by specifying the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.703.1">
      --distributed
     </span>
    </strong>
    <span class="koboSpan" id="kobo.704.1">
     argument,
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.705.1">
      as follows:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.706.1">
$ openstack router create --distributed router_dvr</span></pre>
   <p>
    <span class="koboSpan" id="kobo.707.1">
     In each compute node, validate the existence of the same
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.708.1">
      qrouter
     </span>
    </strong>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.709.1">
      namespace ID:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.710.1">
root@cc01.os:~#ip netns | grep router
qrouter-a312143-ea11-3417-adc1-1eb513daeeda
root@cc02.os:~#ip netns | grep router
qrouter-a312143-ea11-3417-adc1-1eb513daeeda</span></pre>
   <p>
    <span class="koboSpan" id="kobo.711.1">
     The router connecting both networks to different compute nodes is the same router instance with the same namespace created in each compute node.
    </span>
    <span class="koboSpan" id="kobo.711.2">
     Typically, the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.712.1">
      qr
     </span>
    </strong>
    <span class="koboSpan" id="kobo.713.1">
     interfaces corresponding to the same namespace will have the same interface names and IP addresses in the compute nodes.
    </span>
    <span class="koboSpan" id="kobo.713.2">
     For
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.714.1">
      east-west
     </span>
    </strong>
    <span class="koboSpan" id="kobo.715.1">
     connectivity, the traffic flow between
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.716.1">
      instance01
     </span>
    </strong>
    <span class="koboSpan" id="kobo.717.1">
     hosted in
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.718.1">
      cn01.os
     </span>
    </strong>
    <span class="koboSpan" id="kobo.719.1">
     reaching
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.720.1">
      instance02
     </span>
    </strong>
    <span class="koboSpan" id="kobo.721.1">
     spawned in
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.722.1">
      cn02.os
     </span>
    </strong>
    <span class="koboSpan" id="kobo.723.1">
     can be visualized
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.724.1">
      as follows:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer130">
     <span class="koboSpan" id="kobo.725.1">
      <img alt="Figure 7.20 – East-west traffic in DVR mode" src="image/B21716_07_20.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.726.1">
     Figure 7.20 – East-west traffic in DVR mode
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.727.1">
     As
    </span>
    <a id="_idIndexMarker752">
    </a>
    <span class="koboSpan" id="kobo.728.1">
     shown in the preceding diagram, traffic flowing from
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.729.1">
      instance01
     </span>
    </strong>
    <span class="koboSpan" id="kobo.730.1">
     and
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.731.1">
      instance02
     </span>
    </strong>
    <span class="koboSpan" id="kobo.732.1">
     (east-west) takes the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.733.1">
      following path:
     </span>
    </span>
   </p>
   <ol>
    <li>
     <span class="koboSpan" id="kobo.734.1">
      Traffic
     </span>
     <a id="_idIndexMarker753">
     </a>
     <span class="koboSpan" id="kobo.735.1">
      from
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.736.1">
       instance01
      </span>
     </strong>
     <span class="koboSpan" id="kobo.737.1">
      is forwarded from its local gateway through the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.738.1">
       router namespace.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.739.1">
      The router in
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.740.1">
       cn01.os
      </span>
     </strong>
     <span class="koboSpan" id="kobo.741.1">
      replaces the source MAC address with its interface
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.742.1">
       MAC address.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.743.1">
      The router forwards the traffic to the integration bridge
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.744.1">
       in
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.745.1">
        cn01.os
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.746.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.747.1">
      Packets are then forwarded to the provider bridge
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.748.1">
       in
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.749.1">
        cn01.os
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.750.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.751.1">
      The source MAC address of the router interface in the packet is replaced by the MAC address of the compute
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.752.1">
       node,
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.753.1">
        cn01.os
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.754.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.755.1">
      Traffic is forwarded to the destination compute node,
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.756.1">
       cn02.os
      </span>
     </strong>
     <span class="koboSpan" id="kobo.757.1">
      , through the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.758.1">
       physical network.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.759.1">
      Traffic reaches the
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.760.1">
       cn02.os
      </span>
     </strong>
     <span class="koboSpan" id="kobo.761.1">
      host via the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.762.1">
       provider bridge.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.763.1">
      Traffic is forwarded to the integration bridge in the
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.764.1">
        cn02.os
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.765.1">
       host.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.766.1">
      At the integration bridge level, the source MAC address is replaced by the router MAC interface in
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.767.1">
       cn02.os
      </span>
     </strong>
     <span class="koboSpan" id="kobo.768.1">
      , as dictated in the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.769.1">
       router namespace.
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.770.1">
      Traffic is forwarded to the
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.771.1">
       destination,
      </span>
     </span>
     <span class="No-Break">
      <strong class="source-inline">
       <span class="koboSpan" id="kobo.772.1">
        instance02
       </span>
      </strong>
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.773.1">
       .
      </span>
     </span>
    </li>
    <li>
     <span class="koboSpan" id="kobo.774.1">
      Return traffic from
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.775.1">
       instance02
      </span>
     </strong>
     <span class="koboSpan" id="kobo.776.1">
      follows the routing path from
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.777.1">
       cn02.os
      </span>
     </strong>
     <span class="koboSpan" id="kobo.778.1">
      through its respective bridges
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.779.1">
       and routers.
      </span>
     </span>
    </li>
   </ol>
   <p>
    <span class="koboSpan" id="kobo.780.1">
     The
    </span>
    <a id="_idIndexMarker754">
    </a>
    <span class="koboSpan" id="kobo.781.1">
     DVR implementation, much like using VRRP, is simple
    </span>
    <a id="_idIndexMarker755">
    </a>
    <span class="koboSpan" id="kobo.782.1">
     as it comes with Neutron’s
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.783.1">
      built-in features.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.784.1">
     This section outlined the building blocks of enabling HA in the underlying OpenStack infrastructure and control plane services.
    </span>
    <span class="koboSpan" id="kobo.784.2">
     In the following section, we will deep dive into the different options to implement fault tolerance for workloads running
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.785.1">
      in OpenStack.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-140">
    <a id="_idTextAnchor185">
    </a>
    <span class="koboSpan" id="kobo.786.1">
     Managing instance failover
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.787.1">
     Providing HA to cloud resources is a critical topic that OpenStackers have had to handle since the early releases of OpenStack.
    </span>
    <span class="koboSpan" id="kobo.787.2">
     Workload users seek different ways to increase the availability of their virtual machines through manual tooling and scripting, which can be overlooked if
    </span>
    <a id="_idIndexMarker756">
    </a>
    <span class="koboSpan" id="kobo.788.1">
     not efficiently managed.
    </span>
    <span class="koboSpan" id="kobo.788.2">
     With the introduction of the
    </span>
    <strong class="bold">
     <span class="koboSpan" id="kobo.789.1">
      Masakari
     </span>
    </strong>
    <span class="koboSpan" id="kobo.790.1">
     project in OpenStack, cloud operators can offer workload users an automated
    </span>
    <a id="_idIndexMarker757">
    </a>
    <span class="koboSpan" id="kobo.791.1">
     service that ensures HA for KVM-based instances, reducing the need for manual scripting and seamlessly integrating within the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.792.1">
      OpenStack ecosystem.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.793.1">
     Masakari also uses Corosync and Pacemaker.
    </span>
    <span class="koboSpan" id="kobo.793.2">
     As a native HA load balancing stack solution for the Linux platform, Pacemaker is a cluster resource manager that depends on Corosync to control and organize HA across the hosts in OpenStack.
    </span>
    <span class="koboSpan" id="kobo.793.3">
     Corosync ensures that cluster communication is based on the messaging layer and manages the VIP assignment to one of the nodes.
    </span>
    <span class="koboSpan" id="kobo.793.4">
     Once a cluster of workload instances is created, Masakari provides failure detection of the hosts running the instances, which is where Corosync comes into play by making sure a virtual IP is assigned to a functional host.
    </span>
    <span class="koboSpan" id="kobo.793.5">
     Masakari is composed of an API that deals with REST requests and an engine component that executes recovery requests to the Nova service.
    </span>
    <span class="koboSpan" id="kobo.793.6">
     As shown in the following figure, Masakari primarily provides instance HA via three forms
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.794.1">
      of monitors:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer131">
     <span class="koboSpan" id="kobo.795.1">
      <img alt="Figure 7.21 – Instance HA monitors using Masakari" src="image/B21716_07_21.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.796.1">
     Figure 7.21 – Instance HA monitors using Masakari
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.797.1">
     The
    </span>
    <a id="_idIndexMarker758">
    </a>
    <span class="koboSpan" id="kobo.798.1">
     main Masakari components can be summarized
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.799.1">
      as follows:
     </span>
    </span>
   </p>
   <ul>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.800.1">
       Instance restart
      </span>
     </strong>
     <span class="koboSpan" id="kobo.801.1">
      : An instance failure detected by an agent running in the compute node will be restarted.
     </span>
     <span class="koboSpan" id="kobo.801.2">
      Instance restart is managed by the
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.802.1">
       masakari-instancemonitor
      </span>
     </strong>
     <span class="koboSpan" id="kobo.803.1">
      Masakari
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.804.1">
       monitor process.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.805.1">
       Instance evacuation
      </span>
     </strong>
     <span class="koboSpan" id="kobo.806.1">
      : Instances will be evacuated to another healthy compute node upon detection of hypervisor failure.
     </span>
     <span class="koboSpan" id="kobo.806.2">
      The Masakari glossary defines a
     </span>
     <strong class="bold">
      <span class="koboSpan" id="kobo.807.1">
       failover segment
      </span>
     </strong>
     <span class="koboSpan" id="kobo.808.1">
      as a group of compute nodes that hosts evacuated instances if one of the compute nodes in the same segment goes down.
     </span>
     <span class="koboSpan" id="kobo.808.2">
      Instance evacuation is managed by the
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.809.1">
       masakari-hostmonitor
      </span>
     </strong>
     <span class="koboSpan" id="kobo.810.1">
      Masakari
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.811.1">
       process monitor.
      </span>
     </span>
    </li>
    <li>
     <strong class="bold">
      <span class="koboSpan" id="kobo.812.1">
       Process monitor
      </span>
     </strong>
     <span class="koboSpan" id="kobo.813.1">
      : This is managed by the
     </span>
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.814.1">
       masakari-processmonitor
      </span>
     </strong>
     <span class="koboSpan" id="kobo.815.1">
      service, which runs on the compute node to collect the status of the different processes
     </span>
     <a id="_idIndexMarker759">
     </a>
     <span class="koboSpan" id="kobo.816.1">
      running on the hypervisor machine, including libvirtd and the Nova compute service.
     </span>
     <span class="koboSpan" id="kobo.816.2">
      The monitor makes sure that, during the failure of one process, no more instances are scheduled to run on the affected compute node and will instead be handled by
     </span>
     <span class="No-Break">
      <span class="koboSpan" id="kobo.817.1">
       other nodes.
      </span>
     </span>
    </li>
   </ul>
   <p>
    <span class="koboSpan" id="kobo.818.1">
     The next section describes how to deploy the Masakari service in OpenStack
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.819.1">
      using
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.820.1">
       kolla-ansible
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.821.1">
      .
     </span>
    </span>
   </p>
   <h2 id="_idParaDest-141">
    <a id="_idTextAnchor186">
    </a>
    <span class="koboSpan" id="kobo.822.1">
     Deploying Masakari
    </span>
   </h2>
   <p>
    <span class="koboSpan" id="kobo.823.1">
     Masakari is composed of its API, monitors, and engine, all of which are installed across the cloud
    </span>
    <a id="_idIndexMarker760">
    </a>
    <span class="koboSpan" id="kobo.824.1">
     controller and compute nodes.
    </span>
    <span class="koboSpan" id="kobo.824.2">
     Starting with the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.825.1">
      globals.yml
     </span>
    </strong>
    <span class="koboSpan" id="kobo.826.1">
     file, enable the Masakari service by editing the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.827.1">
      following variable:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.828.1">
enable_masakari: "yes"</span></pre>
   <p>
    <span class="koboSpan" id="kobo.829.1">
     To control the instances’ HA using the instance evacuation option, enable the following setting in the
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.830.1">
       globals.yml
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.831.1">
      file:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.832.1">
enable_hacluster: "yes"</span></pre>
   <p>
    <span class="koboSpan" id="kobo.833.1">
     In the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.834.1">
      multi_packtpub_prod
     </span>
    </strong>
    <span class="koboSpan" id="kobo.835.1">
     inventory file, assign the Masakari services to run the API and engine services in the cloud
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.836.1">
      controller nodes:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.837.1">
...
</span><span class="koboSpan" id="kobo.837.2">[masakari-api:children]
control
[masakari-engine:children]
control</span></pre>
   <p>
    <span class="koboSpan" id="kobo.838.1">
     At the cloud controller level, the instance evacuation monitor requires that the compute nodes that will deploy Peacemaker and Corosync under the hood to
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.839.1">
      be monitored:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.840.1">
[masakari-hostmonitor:children]
control</span></pre>
   <p>
    <span class="koboSpan" id="kobo.841.1">
     Here,
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.842.1">
      hacluster
     </span>
    </strong>
    <span class="koboSpan" id="kobo.843.1">
     is an extra Ansible role that provides support to Masakari for compute node failure monitoring and recovering instances on a healthy hypervisor node, as required for Pacemaker
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.844.1">
      and Corosync:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.845.1">
[hacluster:children]
control
[hacluster-remote:children]
compute</span></pre>
   <p>
    <span class="koboSpan" id="kobo.846.1">
     The instance
    </span>
    <a id="_idIndexMarker761">
    </a>
    <span class="koboSpan" id="kobo.847.1">
     restart monitor requires the instance status to be monitored by the compute
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.848.1">
      nodes themselves:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.849.1">
[masakari-instancemonitor:children]
compute</span></pre>
   <p>
    <span class="koboSpan" id="kobo.850.1">
     Run the pipeline and make sure the Masakari containers are up and running by checking the new Masakari containers.
    </span>
    <span class="koboSpan" id="kobo.850.2">
     To do so, run the following command line in a cloud
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.851.1">
      controller node:
     </span>
    </span>
   </p>
   <pre class="source-code"><span class="koboSpan" id="kobo.852.1">
$ sudo docker ps</span></pre>
   <p>
    <span class="koboSpan" id="kobo.853.1">
     We will get the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.854.1">
      following output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer132">
     <span class="koboSpan" id="kobo.855.1">
      <img alt="Figure 7.22 – Listing Masakari Kolla containers" src="image/B21716_07_22.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.856.1">
     Figure 7.22 – Listing Masakari Kolla containers
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.857.1">
     To simulate a VM HA scenario, we will spawn an instance in one compute node and use the Masakari instance restart
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.858.1">
      monitor mode:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.859.1">
$ openstack server create --image cirros-5.1 --flavor m1.tiny --network priv_net vm-ha</span></pre>
   <p>
    <span class="koboSpan" id="kobo.860.1">
     Set the
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.861.1">
      HA_Enabled
     </span>
    </strong>
    <span class="koboSpan" id="kobo.862.1">
     flag property of the created instance
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.863.1">
      to
     </span>
    </span>
    <span class="No-Break">
     <strong class="source-inline">
      <span class="koboSpan" id="kobo.864.1">
       True
      </span>
     </strong>
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.865.1">
      :
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.866.1">
$ openstack server set --property HA_Enabled=True vm-ha</span></pre>
   <p>
    <span class="koboSpan" id="kobo.867.1">
     Check which compute node the instance is running and kill the instance process ID to simulate an
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.868.1">
      instance failure:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.869.1">
$ openstack server show vm-ha</span></pre>
   <p>
    <span class="koboSpan" id="kobo.870.1">
     Here is
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.871.1">
      the output:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer133">
     <span class="koboSpan" id="kobo.872.1">
      <img alt="Figure 7.23 – Listing the virtual machines for the HA test" src="image/B21716_07_23.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.873.1">
     Figure 7.23 – Listing the virtual machines for the HA test
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.874.1">
     Log in to
    </span>
    <a id="_idIndexMarker762">
    </a>
    <span class="koboSpan" id="kobo.875.1">
     the compute node and kill the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.876.1">
      instance PID:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.877.1">
$ pgrep -f guest=instance-00000003
12652
$ kill –9 12652</span></pre>
   <p>
    <span class="koboSpan" id="kobo.878.1">
     By watching the Masakari log file outputs in
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.879.1">
      /var/log/kolla/masakari
     </span>
    </strong>
    <span class="koboSpan" id="kobo.880.1">
     , observe the status of the instance reboot in the same
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.881.1">
      hypervisor host:
     </span>
    </span>
   </p>
   <div>
    <div class="IMG---Figure" id="_idContainer134">
     <span class="koboSpan" id="kobo.882.1">
      <img alt="Figure 7.24 – Validating the Masakari instance respawning process in the log entries" src="image/B21716_07_24.jpg"/>
     </span>
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    <span class="koboSpan" id="kobo.883.1">
     Figure 7.24 – Validating the Masakari instance respawning process in the log entries
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.884.1">
     Within a few seconds, the killed instance will be spawned in the same compute node.
    </span>
    <span class="koboSpan" id="kobo.884.2">
     This can be checked via the newly created
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.885.1">
      instance PID:
     </span>
    </span>
   </p>
   <pre class="console"><span class="koboSpan" id="kobo.886.1">
$ pgrep -f guest=instance-00000003
13442</span></pre>
   <p>
    <span class="koboSpan" id="kobo.887.1">
     As we can see, Masakari can be a great addition to ensure workload fault tolerance without the
    </span>
    <a id="_idIndexMarker763">
    </a>
    <span class="koboSpan" id="kobo.888.1">
     need to operate the HA capability separately for each instance, thus avoiding heavy manual effort.
    </span>
    <span class="koboSpan" id="kobo.888.2">
     Masakari is getting more popular, and several production deployments have proven its advantages in helping workload administrators and cloud developers tackle failover challenges at the
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.889.1">
      instance level.
     </span>
    </span>
   </p>
   <h1 id="_idParaDest-142">
    <a id="_idTextAnchor187">
    </a>
    <span class="koboSpan" id="kobo.890.1">
     Summary
    </span>
   </h1>
   <p>
    <span class="koboSpan" id="kobo.891.1">
     In this chapter, we enabled a critical architectural safeguard design in our OpenStack environment by covering the HA pillar across the control and data planes.
    </span>
    <span class="koboSpan" id="kobo.891.2">
     We now have numerous ways to construct a highly available OpenStack environment, depending on which HA strategy is preferred.
    </span>
    <span class="koboSpan" id="kobo.891.3">
     In this chapter, we empowered the control plane services using HAProxy and Keepalived.
    </span>
    <span class="koboSpan" id="kobo.891.4">
     Other deployments could employ Corosync, Pacemaker, and a selection of vendor solutions for load balancing.
    </span>
    <span class="koboSpan" id="kobo.891.5">
     As demonstrated in this chapter, more than a single design pattern can be applied for common infrastructure services, such as databases and message queues, to achieve failover at best.
    </span>
    <span class="koboSpan" id="kobo.891.6">
     Networking HA in OpenStack has achieved another level of maturity that enables cloud operators to choose between two options to minimize any potential risks of connectivity loss for the tenant networks: routing with VRRP
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.892.1">
      and DVR.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.893.1">
     This chapter also explored an attractive capability for cloud users to achieve failover with native OpenStack services for their workloads running in instances using Masakari.
    </span>
    <span class="koboSpan" id="kobo.893.2">
     We also showed some additional snippets for managing HA in OpenStack layers using
    </span>
    <strong class="source-inline">
     <span class="koboSpan" id="kobo.894.1">
      kolla-ansible
     </span>
    </strong>
    <span class="koboSpan" id="kobo.895.1">
     .
    </span>
    <span class="koboSpan" id="kobo.895.2">
     There is still some ongoing amelioration on the infrastructure code using Kolla to automate cell and region deployments for compute services in OpenStack that was not covered in this chapter.
    </span>
    <span class="koboSpan" id="kobo.895.3">
     HA and redundancy are critical elements that are required for you to start welcoming production workloads in your OpenStack environment and with this chapter, you should be ready to get started.
    </span>
    <span class="koboSpan" id="kobo.895.4">
     Alongside ensuring the HA of services, we need to keep an eye on them and act proactively when things start
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.896.1">
      to boil.
     </span>
    </span>
   </p>
   <p>
    <span class="koboSpan" id="kobo.897.1">
     The next chapter will discuss the next operational excellence pillar of the OpenStack journey.
    </span>
    <span class="koboSpan" id="kobo.897.2">
     It will explore ways you can monitor your cloud environment for the early detection of anomalies and deep dive into more fine-grained options for introspection and the analysis of collected OpenStack
    </span>
    <span class="No-Break">
     <span class="koboSpan" id="kobo.898.1">
      services logs.
     </span>
    </span>
   </p>
  </div>
 </body></html>