- en: Chapter 10. Controlling containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '|   | *The inside of a computer is as dumb as hell but it goes like mad!* |
      |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*Richard Feynman* |'
  prefs: []
  type: TYPE_TB
- en: In this chapter, we'll look at the emerging topic of **containers** and see
    how it relates to configuration management. We'll see how to use Puppet to manage
    the Docker daemon, as well as images and containers, and explore some different
    strategies for managing configuration within containers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Controlling containers](img/8880_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Understanding containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the technology behind containers is at least thirty years old, it's
    only in the last few years that containers have really taken off (to mix a metaphor).
    This is largely thanks to the rise of Docker, a software platform which makes
    it easier to create and manage containers.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The problem that Docker solves is principally one of **software deployment**:
    that is, making it possible to install and run your software in a wide variety
    of environments with minimal effort. Let''s take a typical PHP web application,
    for example. To run the application you need at least the following to be present
    on a node:'
  prefs: []
  type: TYPE_NORMAL
- en: PHP source code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PHP interpreter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Its associated dependencies and libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PHP modules required by your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compiler and build tools for building native binaries for PHP modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web server (for example Apache)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Module for serving PHP apps (for example, `mod_php`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Config files for your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User to run the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directories for things such as log files, images, and uploaded data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do you manage all of this stuff? You can use a system package format, such
    as RPM or DEB, which uses metadata to describe its dependencies in terms of other
    packages, and scripts which can do much of the system configuration required.
  prefs: []
  type: TYPE_NORMAL
- en: However, this packaging is specific to a particular version of a particular
    operating system, and a package intended for Ubuntu 18.04, for example, will not
    be installable on Ubuntu 16.04 or on Red Hat Enterprise Linux. Maintaining multiple
    packages for several popular operating systems is a large workload on top of maintaining
    the application itself.
  prefs: []
  type: TYPE_NORMAL
- en: Options for deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One way to address this problem is for the author to provide **configuration
    management** **manifests** for the software, such as a Puppet module or a Chef
    recipe to install the software. However, if the intended user of the software
    does not use a CM tool, or uses a different tool, then this is no help. Even if
    they use exactly the same version of the same tool on the same operating system,
    they may have problems integrating the third-party module with it, and the module
    itself will depend on other modules and so on. It's certainly not a turnkey solution.
  prefs: []
  type: TYPE_NORMAL
- en: Another option is the **omnibus package**, a package which contains everything
    the software needs to run. An omnibus package for our example PHP application
    might contain the PHP binaries and all dependencies, plus anything else the application
    needs. These are necessarily quite large packages, however, and omnibus packages
    are still specific to a particular operating system and version, and involve a
    lot of maintenance effort.
  prefs: []
  type: TYPE_NORMAL
- en: Most package managers do not provide an efficient binary update facility, so
    even the smallest update requires re-downloading the entire package. Some omnibus
    packages even include their own config management tool!
  prefs: []
  type: TYPE_NORMAL
- en: Yet another solution is to provide an entire **virtual machine image**, such
    as a Vagrant box (the Vagrant box we've been using throughout the book is a good
    example). This contains not only the application plus dependencies and configuration,
    but the entire operating system as well. This is a fairly portable solution, since
    any platform which can run the virtual machine host software (for example, VirtualBox
    or VMware) can run the VM itself.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is a performance penalty with virtual machines, and they also
    consume a lot of resources, such as memory and disk space, and the VM images themselves
    are large and unwieldy to move around a network.
  prefs: []
  type: TYPE_NORMAL
- en: While in theory you could deploy your application by building a VM image and
    pushing it to a production VM host, and some people do this, it's far from an
    efficient method of distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the container
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years many operating systems have added facilities for self-contained
    execution environments, more concisely called **containers**, in which programs
    can run natively on the CPU, but with very limited access to the rest of the machine.
    A container is like a security sandbox, where anything running inside it can access
    files and programs inside the container, but nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: This is similar in principle to a virtual machine, except that the underlying
    technology is quite different. Instead of running on a virtual processor, via
    a software emulation layer, programs in a container run directly on the underlying
    physical hardware. This makes containers a great deal more efficient than VMs.
    To put it another way, you need much less powerful hardware to run containers
    than you do for virtual machines of the same performance.
  prefs: []
  type: TYPE_NORMAL
- en: A single virtual machine consumes a large amount of its host's resources, which
    means that running more than one VM on the same host can be quite demanding. By
    contrast, running a process inside a container uses no more resources than running
    the same process natively.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, you can run a very large number of containers on a single host, and
    each is completely self-contained and has no access to either the host, or any
    other container (unless you specifically allow it). A container, at the kernel
    level, is really just a namespace. Processes running in that namespace cannot
    access anything outside it, and vice versa. All the containers on a machine use
    the host operating system's kernel, so although containers are portable across
    different Linux distributions, for example, a Linux container cannot run directly
    on a Windows host. Linux containers can, however, run on Windows using a virtualization
    layer provided by Docker for Windows.
  prefs: []
  type: TYPE_NORMAL
- en: What Docker does for containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So if containers themselves are provided by the kernel, what is Docker for?
    It turns out that having an engine is not quite the same thing as having a car.
    The operating system kernel may provide the basic facilities for containerization,
    but you also need:'
  prefs: []
  type: TYPE_NORMAL
- en: A specification for how to build containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A standard file format for container images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A protocol for storing, versioning, organizing, and retrieving container images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software to start, run, and manage containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drivers to allow network traffic to and from containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ways of communicating between containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facilities for getting data into containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These need to be provided by additional software. There are in fact many software
    frontends which allow you to manage containers: Docker, OCID, CoreOS/rkt, Apache
    Mesos, LXD, VMware Photon, Windows Server Containers, and so on. However, Docker
    is by far the market leader, and currently the majority of containers in production
    are running under Docker (a recent survey put the proportion at over 90%).'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The principle of deploying software with containers is very simple: the software,
    plus everything it needs to run, is inside the container **image**, which is like
    a package file, but is executable directly by the container runtime.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the software, all you need to do is execute a command like the following
    (if you have Docker installed, try it!):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Docker will download the specified image from your configured **registry** (this
    could be the public registry, called Docker Hub, or your own private Docker registry)
    and execute it. There are thousands of Docker images available for you to use,
    and many software companies are increasingly using Docker images as their primary
    way to deploy products.
  prefs: []
  type: TYPE_NORMAL
- en: Building Docker containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: But where do these Docker images come from? Docker images are like an archive
    or a package file, containing the file and directory layout of all the files inside
    the container, including executable binaries, shared libraries, and config files.
    To create this image file, you use the `docker build` command.
  prefs: []
  type: TYPE_NORMAL
- en: '`docker build` takes a special text file called a **Dockerfile**, which specifies
    what should be in the container. Usually, a new Docker image is based on an existing
    image with a few modifications. For example, there is a Docker image for Ubuntu
    Linux, which contains a fully-installed operating system ready to run.'
  prefs: []
  type: TYPE_NORMAL
- en: Your Dockerfile might specify that you use the Ubuntu Docker image as a starting
    point, and then install the package `nginx`. The resulting Docker container contains
    everything that was in the stock Ubuntu image, plus the `nginx` package. You can
    now upload this image to a registry and run it anywhere using `docker run`.
  prefs: []
  type: TYPE_NORMAL
- en: If you wanted to package your own software with Docker, you could choose a suitable
    base image (such as Ubuntu) and write a Dockerfile which installs your software
    onto that base image. When you build the container image with `docker build`,
    the result will be a container with your software inside it, which anyone can
    run using `docker run`. The only thing they need to install is Docker.
  prefs: []
  type: TYPE_NORMAL
- en: This makes Docker a great way both for software vendors to package their products
    in an easy-installable format, and for users to try out different software quickly
    to see if it meets their needs.
  prefs: []
  type: TYPE_NORMAL
- en: The layered filesystem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Docker filesystem has a feature called **layering**. Containers are built
    up in layers, so that if something changes, only the affected layer and those
    above it need to be rebuilt. This makes it much more efficient to update container
    images once they've been built and deployed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you change one line of code in your app and rebuild the container,
    only the layer that contains your app needs to be rebuilt, along with any layers
    above it. The base image and other layers below the affected layer remain the
    same and can be re-used for the new container.
  prefs: []
  type: TYPE_NORMAL
- en: Managing containers with Puppet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are a few things you need to be able to do to package and run software
    with Docker:'
  prefs: []
  type: TYPE_NORMAL
- en: Install, configure, and manage the Docker service itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build your images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rebuild images when the Dockerfile changes, or a dependency is updated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage the running images, their data storage, and their configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unless you want to make your images public, you will also need to host an image
    registry for your own images.
  prefs: []
  type: TYPE_NORMAL
- en: These sound like the kinds of problems that configuration management tools can
    solve, and luckily, we have a great configuration management tool available. Oddly
    enough, while most people recognize that traditional servers need to be built
    and managed automatically by a tool such as Puppet, the same does not seem to
    be true (yet) of containers.
  prefs: []
  type: TYPE_NORMAL
- en: The trouble is, it's so easy to make a simple container and run it that many
    people think configuration management for containers is overkill. That may be
    so when you're first trying out Docker and experimenting with simple containers,
    but when you're running complex, multi-container services in production, at scale,
    things get more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: First, containerizing non-trivial applications is non-trivial. They need dependencies
    and configuration settings and data, and ways to communicate with other applications
    and services, and while Docker provides you with tools to do this, it doesn't
    do the work for you.
  prefs: []
  type: TYPE_NORMAL
- en: Second, you need an infrastructure to build your containers, update them, store
    and retrieve the resulting images, and deploy and manage them in production. Configuration
    management for containers is very much like configuration management for traditional
    server-based applications, except that it's happening at a slightly higher level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Containers are great, but they don''t do away with the need for configuration
    management tools (remember the *Law of Conservation of Pain* from [Chapter 1](ch01.html
    "Chapter 1. Getting started with Puppet"), *Getting started with Puppet*?):'
  prefs: []
  type: TYPE_NORMAL
- en: '*"If you save yourself pain in one place, it pops up again in another. Whatever
    cool new technology comes along, it won''t solve all our problems; at best, it
    will replace them with refreshingly different problems."*'
  prefs: []
  type: TYPE_NORMAL
- en: Managing Docker with Puppet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Puppet can certainly install and manage the Docker service for you, just as
    it can any other software, but it can also do a lot more. It can download and
    run Docker images, build images from Dockerfiles, mount files and directories
    on the container, and manage Docker volumes and networks. We'll see how to do
    all these things in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we do anything else, we'll need to install Docker on our node (using
    Puppet, of course). The `puppetlabs/docker_platform` module is ideal for this.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''ve already installed and run the `r10k` module management tool, as
    shown in [Chapter 7](ch07.html "Chapter 7. Mastering modules"), *Mastering modules*,
    in the *Using r10k* section, the required module will already be installed. If
    not, run the following commands to install it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the module is installed, all you need to do to install Docker on your
    node is to apply a manifest like the following (`docker_install.pp`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following command to apply the manifest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To check that Docker is installed, run the following command (you may see a
    different version number, but that''s OK):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Running a Docker container
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to run a Docker container, we first of all have to download it from
    a Docker registry, which is a server that stores container images. The default
    registry is Docker Hub, the official public Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this with Puppet, you can use the `docker::image` resource (`docker_image.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As with the `package` resource, if you specify `ensure => latest`, Puppet will
    check the registry every time it runs and make sure you have the latest available
    version of the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the image you''ve just downloaded, add a `docker::run` resource to your
    manifest (`docker_run.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply this manifest with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `docker::run` resource tells Docker to fetch the image `bitfield/hello`
    from the local image cache and run it with the specified command, which in this
    case just loops forever printing `Hello, world`. (I told you containers were useful.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The container is now running on your node, and you can check this with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker ps` command shows all currently running containers (`docker ps
    -a` will show stopped containers too), with the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: The container ID, Docker's internal identifier for the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The image name (`bitfield/hello` in our example)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The currently executing command in the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The creation time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current status
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any ports mapped by the container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The human-readable name of the container (which is the title we gave the `docker::run`
    resource in our manifest)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The container is running as a service, and we can check that with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Stopping a container
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: According to the Docker documentation, you can stop a container by running `sudo
    docker stop NAME`. However, if you try this, and then run `sudo docker ps` again,
    you'll see that the container is still running. What's that about?
  prefs: []
  type: TYPE_NORMAL
- en: The Puppet module assumes by default that you want to run all containers as
    services; that is, to configure `systemd` to keep the container running, and to
    start it at boot time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, if you want to stop a container which is running as a service, you
    will need to do this with Puppet, by setting the `ensure` parameter on the `docker::run`
    resource to `absent`, as in the following example (`docker_absent.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, on the command line, you can use the `systemctl` command to
    stop the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you don't want your container to be managed as a service by `systemd`, specify
    the parameter `restart => always` to the `docker::run` resource. This tells Docker
    to restart the container automatically when it exits; so therefore Puppet does
    not need to create a `systemd` service to manage it.
  prefs: []
  type: TYPE_NORMAL
- en: Running multiple instances of a container
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Of course, the true power of automation is the ability to scale. We're not limited
    to running a single instance of a given container; Puppet will happily start as
    many as you like.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each `docker::run` resource must have a unique name, as with any other Puppet
    resource, so you can create them in an `each` loop, as in the following example
    (`docker_run_many.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `range()` function comes from the `stdlib` module, and, as you might expect,
    `range(1,20)` returns the sequence of integers between 1 and 20 inclusive. We
    iterate over this sequence with the `each` function, and each time through the
    loop `$instance` is set to the next integer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker::run` resource title includes the value of `$instance` on each
    iteration, so each container will be uniquely named: `hello-1`, `hello-2`,...
    `hello-20`. I''ve chosen the number 20 at random, just as an example; you could
    compute the number of instances to run based on the resources available, for example
    the number of system CPUs or available memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Don't forget to stop these containers afterward (edit the example manifest to
    add `ensure => absent` to the `docker::run` resource and re-apply it).
  prefs: []
  type: TYPE_NORMAL
- en: Managing Docker images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, it's very useful to be able to download and run public images from
    Docker Hub or other registries, but to unlock the real power of Docker we need
    to be able to build and manage our own images too.
  prefs: []
  type: TYPE_NORMAL
- en: Building images from Dockerfiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in the previous examples, if you don't already have the specified
    container image on your system, Puppet's `docker::image` resource will pull it
    from Docker Hub for you and save it locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `docker::image` resource is most useful, however, for actually **building**
    Docker images. This is usually done using a Dockerfile, so here is an example
    Dockerfile we can use to build an image (`Dockerfile.hello`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `FROM` statement tells Docker what base image to start from, of the many
    public images available. `FROM scratch` would start with a completely empty container.
    `FROM library/ubuntu` would use the official Ubuntu Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, one of the key advantages of containers is that they can be as small
    or as large as they need to be, so downloading a 188 MB image containing all of
    Ubuntu is unnecessary if you simply want to run `/bin/echo`.
  prefs: []
  type: TYPE_NORMAL
- en: Alpine is another Linux distribution designed to be as small and lightweight
    as possible, which makes it ideal for containers. The `library/alpine` image is
    only 4 MB, forty times smaller than `ubuntu`; quite a saving. Also, if you build
    all your containers from the same base image, Docker's layer system means it only
    has to download and store the base image once.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Dockerfiles can be fairly simple, as in the example, or quite complex. You
    can find out more about the Dockerfile format and commands from the Docker documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how to create a Docker image from this file (`docker_build_hello.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the `docker::image` resource has been applied, the resulting `pbg-hello`
    image will be available for you to run as a container (`docker_run_hello.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Managing Dockerfiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you run your own apps in containers, or third-party apps in your own containers,
    you can manage the associated Dockerfiles with Puppet. Here''s an example of a
    simple Dockerfile which builds a container using Nginx to serve a web page with
    a friendly greeting message (`Dockerfile.nginx`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the Puppet manifest which manages this Dockerfile, and builds an image
    from it (`docker_build_nginx.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following command to apply this manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Whenever the contents of the Dockerfile change, applying this manifest will
    cause the image to be rebuilt.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the purposes of this example we are building and running the container on
    the same node. In practice, though, you should build your containers on a dedicated
    build node and upload the resulting images to the registry, so that your production
    nodes can download and run them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the manifest to run the container we just built (`docker_run_nginx.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note the `pull_on_start` attribute, which tells Puppet to always download the
    latest available version of the container when starting or restarting it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you worked through [Chapter 7](ch07.html "Chapter 7. Mastering modules"),
    *Mastering modules*, the Apache web server will be running and listening on port
    `80`, so you will need to run the following commands to remove it before applying
    this manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You can check that the container is working by browsing to the following URL
    on your local machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://localhost:8080`'
  prefs: []
  type: TYPE_NORMAL
- en: You should see the text `Hello, world`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you''re using the Vagrant box, port `8080` on your local machine is automatically
    mapped to port `80` on the VM, which is then mapped by Docker to port `80` on
    the `pbg-nginx` container. If for some reason you need to change this port mapping,
    edit your Vagrantfile (in the Puppet Beginner''s Guide repo) and look for the
    following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Change these settings as required, and run the following command on your local
    machine in the PBG repo directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'If you''re not using the Vagrant box, the container''s port `80` will be exposed
    at your local port `80`, so the URL will simply appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`http://localhost`'
  prefs: []
  type: TYPE_NORMAL
- en: Building dynamic containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although Dockerfiles are a fairly powerful and flexible way of building containers,
    they are only static text files, and very often you will need to pass information
    into the container to tell it what to do. We might call such containers—whose
    configuration is flexible and based on data available at build time—**dynamic
    containers**.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring containers with templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One way to configure containers dynamically is to use Puppet to manage the Dockerfile
    as an EPP template (see [Chapter 9](ch09.html "Chapter 9. Managing files with
    templates"), *Managing files with templates*), and interpolate the required data
    (which could come from Hiera, Facter, or directly from Puppet code).
  prefs: []
  type: TYPE_NORMAL
- en: Let's upgrade our previous `Hello, world` example to have Nginx serve any arbitrary
    text string, supplied by Puppet at build time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the manifest to generate the Dockerfile from a template and run the
    resulting image (`docker_template.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply this manifest with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: When you have applied the manifest and built the container, you will find that
    if you change the value of `message` and reapply, the container will be rebuilt
    with the updated text. The `docker::image` resource uses `notify` to tell the
    `docker::run` resource to restart the container when the image changes.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Templating the Dockerfile like this is a powerful technique. Since you can
    have Puppet put any arbitrary data into a Dockerfile, you can configure anything
    about the container and its build process: the base image, the list of packages
    to install, files and data that should be added to the container, and even the
    command entry point for the container.'
  prefs: []
  type: TYPE_NORMAL
- en: Self-configuring containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's take this idea even further and use Puppet to dynamically configure a
    container which can fetch its data from Git. Instead of serving static text supplied
    at build time, we will have the container itself check out a Git repo for the
    website.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the code from the previous example remains unchanged, except for the
    Dockerfile resource (`docker_website.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The Dockerfile itself is a little more complicated, because we need to install
    Git in the container and use it to check out the supplied Git repo (`Dockerfile.website.epp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'When you apply this manifest and browse to `http://localhost:8080`, you should
    see the text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Although we supplied the `git_url` parameter directly to the Dockerfile template,
    that data could of course come from anywhere, including Hiera. With this technique,
    you can build a container to serve any website simply by changing the Git URL
    passed to it.
  prefs: []
  type: TYPE_NORMAL
- en: Using the iteration pattern we saw in the `docker_run_many` example earlier
    in this chapter, you could build a set of containers like this from an array of
    `git_url` values, each serving a different website. Now we're really starting
    to exploit the power of Docker-plus-Puppet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to stop the container before going on to the next
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: There's one slight problem with this idea. Although it's good to have the container
    be able to serve content from a Git repo determined at build time, every time
    the container is started or restarted, it will have to run the `git clone` process
    again. This takes time, and if the repo or the network is unavailable for some
    reason, it can stop the container from working.
  prefs: []
  type: TYPE_NORMAL
- en: A better solution would be to serve the content from persistent storage, and
    we'll see how to do that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Persistent storage for containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containers are designed to be transient; they run for a while, and then disappear.
    Anything inside the container disappears with it, including files and data created
    during the container's run. This isn't always what we want, of course. If you're
    running a database inside a container, for example, you usually want that data
    to persist when the container goes away.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways of persisting data in a container: the first is to mount
    a directory from the host machine inside the container, known as a **host-mounted
    volume**, and the second is to use what''s called a **Docker volume**. We''ll
    look at both of these in the following sections.'
  prefs: []
  type: TYPE_NORMAL
- en: Host-mounted volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you want a container to be able to access files on the host machine''s filesystem
    (such as application code that you''re working on and you want to test, for example),
    the easiest way to do that is to mount a directory from the host on the container.
    The following example shows how to do this (`docker_mount.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `volumes` attribute specifies an array of volumes to attach to the container.
    If the volume is of the form `HOST_PATH:CONTAINER_PATH`, Docker will assume you
    want to mount the directory `HOST_PATH` on the container. The path inside the
    container will be `CONTAINER_PATH`. Any files which already exist in the mounted
    directory will be accessible to the container, and anything the container writes
    to the directory will still be available once the container has stopped.
  prefs: []
  type: TYPE_NORMAL
- en: If you apply this example manifest, the container will mount the host machine's
    `/tmp/container_data/` directory (this will be created if it doesn't exist) as
    `/mnt/data/` in the container.
  prefs: []
  type: TYPE_NORMAL
- en: The `command` attribute tells the container to write the string `Hello, world`
    to the file `/mnt/data/hello.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to apply this manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The container will start, write the data, and then exit. If all has gone well,
    you''ll see that the file `/tmp/container_data/hello.txt` is now present and contains
    the data written by the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Host-mounted volumes are very useful when a container needs to access or share
    data with applications running on the host machine. For example, you could use
    a host-mounted volume with a container which runs syntax checks, lint, or continuous
    integration tests on your source code directory.
  prefs: []
  type: TYPE_NORMAL
- en: However, containers using host-mounted volumes are not portable, and they rely
    on a specific directory being present on the host machine. You can't specify a
    host-mounted volume in a Dockerfile, so you can't publish a container which relies
    on one. While host-mounted volumes can be useful for testing and development,
    a better solution in production is to use Docker volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Docker volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A more portable way of adding persistent storage to containers is to use a **Docker
    volume**. This is a persistent data object which lives in Docker's storage area
    and can be attached to one or more containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how to use `docker::run` to start a container with
    a Docker volume (`docker_volume.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `volumes` attribute is a little different from the previous example. It
    has the form `VOLUME_NAME:CONTAINER_PATH`, which tells Docker that this is not
    a host-mounted volume, but a Docker volume named `VOLUME_NAME`. If the value before
    the colon is a path, Docker assumes you want to mount that path from the host
    machine, but otherwise, it assumes you want to mount a Docker volume with the
    specified name.
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous example, the container's `command` argument writes a message
    to a file on the mounted volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you apply this manifest, once the container has exited, you can see that
    the volume is still present by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: A Docker volume is a good way to store data that you need to keep even when
    the container is not running (a database, for example). It's also a good way to
    make data available to containers without having to load it into each container
    every time it starts.
  prefs: []
  type: TYPE_NORMAL
- en: In the website example earlier in the chapter, instead of each container checking
    out its own copy of the Git repo, you could check out the repo into a Docker volume,
    and then have each container mount this volume when it starts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test that idea with the following manifest (`docker_volume2.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This is the same `nginx` container we used earlier in the chapter, which serves
    whatever is in its `/usr/share/nginx/html` directory as a website.
  prefs: []
  type: TYPE_NORMAL
- en: The `volumes` attribute tells the container to mount the `pbg-volume` volume
    on `/usr/share/nginx/html`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following commands to apply this manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything works as we expect, we should able to browse to the following
    URL on the local machine: `http://localhost:8080/`'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should see the following text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This is a very powerful feature of containers. They can read, write, and modify
    data created by other containers, maintain persistent storage of their own, and
    share data with other running containers, all using volumes.
  prefs: []
  type: TYPE_NORMAL
- en: A common pattern for running applications in Docker is to use multiple, communicating
    containers, each providing a single specific service. For example, a web application
    might use an Nginx container to serve an application to users, while storing its
    session data in a MySQL container mounting a persistent volume. It could also
    use a linked Redis container as an in-memory key-value store.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from sharing data via volumes, though, how do these containers actually
    communicate over the network? We'll see the answer to that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Networking and orchestration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We started off the chapter by saying that containers are completely self-contained,
    and have no access to each other, even if they''re running on the same host. But
    to run real applications, we need containers to communicate. Fortunately, there
    is a way to do this: the **Docker network**.'
  prefs: []
  type: TYPE_NORMAL
- en: Connecting containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A Docker network is like a private chat room for containers: all the containers
    inside the network can talk to each other, but they can''t talk to containers
    outside it or in other networks, and vice versa. All you need to do is have Docker
    create a network, give it a name, and then you can start containers inside that
    network and they will be able to talk to each other.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's develop an example to try this out. Suppose we want to run the Redis database
    inside a container, and send data to it from another container. This is a common
    pattern for many applications.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we're going to create a Docker network, and start two containers
    inside it. The first container is a public Docker Hub image that will run the
    Redis database server. The second container will install the Redis client tool,
    and write some data to the Redis server container. Then, to check it worked, we
    can try to read the data back from the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to apply the Docker network example manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: If everything worked as it should, our Redis database should now contain a piece
    of data named `message` containing a friendly greeting, proving that we've passed
    data from one container to another over the Docker network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to connect to the client container and check that
    this is the case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'So how does it all work? Let''s take a look at the example manifest. First
    of all, we create the network for the two containers to run in, using the `docker_network`
    resource in Puppet (`docker_network.pp`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Now, we run the Redis server container, using the public `redis:4.0.1-alpine`
    image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Did you notice that we supplied the `net` attribute to the `docker::run` resource?
    This specifies the Docker network that the container should run in.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we build a container which has the Redis client (`redis-cli`) installed
    so that we can use it to write some data to the Redis container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the Dockerfile for the client container (`Dockerfile.pbg-demo`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We build this container in the usual way using `docker::image`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we run an instance of the client container with `docker::run`, passing
    in a command to `redis-cli` to write some data to the other container.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this container also has the attribute `net => 'pbg-net'`. It
    will therefore run in the same Docker network as the `pbg-redis` container, so
    the two containers will be able to talk to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the container starts, the `command` attribute calls `redis-cli` with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The `-h pbg-redis` argument tells Redis to connect to the host `pbg-redis`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How does using the `pbg-redis` name connect to the right container? When you
    start a container inside a network, Docker automagically configures DNS lookups
    within the container to find other containers in the network by name. When you
    reference a container name (the title of the container's `docker::run` resource,
    which in our example is `pbg-redis`), Docker will route the network connection
    to the right place.
  prefs: []
  type: TYPE_NORMAL
- en: The command `set message "Hello, world"` creates a Redis key named `message`,
    and gives it the value `"Hello, world"`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now have all the necessary techniques to containerize a real application:
    using Puppet to manage multiple containers, built from dynamic data, pushed to
    a registry, updated on demand, communicating over the network, listening on ports
    to the outside world, and persisting and sharing data via volumes.'
  prefs: []
  type: TYPE_NORMAL
- en: Container orchestration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We've seen a number of ways to manage individual containers in this chapter,
    but the question of how to provision and manage containers at scale, and across
    multiple hosts—what we call container **orchestration**—remains.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if your app runs in a container, you probably won''t be running
    just one instance of the container: you need to run multiple instances, and route
    and load-balance traffic to them. You also need to be able to distribute your
    containers across multiple hosts, so that the application is resilient against
    the failure of any individual container host.'
  prefs: []
  type: TYPE_NORMAL
- en: What is orchestration?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When running containers across a distributed cluster, you also need to be able
    to deal with issues such as networking between containers and hosts, failover,
    health monitoring, rolling out updates, service discovery, and sharing configuration
    data between containers via a key-value database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although container orchestration is a broad task, and different tools and frameworks
    focus on different aspects of it, the core requirements of orchestration include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scheduling**: Running a container on the cluster and deciding which containers
    to run on which hosts to provide a given service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster management**: Monitoring and marshalling the activity of containers
    and hosts across the cluster, and adding or removing hosts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service discovery**: Giving containers the ability to find and connect to
    the services and data they need to operate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What orchestration tools are available?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google's Kubernetes and Docker's Swarm are both designed to orchestrate containers.
    Another product, Apache Mesos, is a cluster management framework which can operate
    on different kinds of resources, including containers.
  prefs: []
  type: TYPE_NORMAL
- en: Most containers in production today are running under one of these three orchestration
    systems. Kubernetes has been around the longest and has the biggest user base,
    but Swarm, though a relatively new arrival, is part of the official Docker stack,
    so it is being rapidly adopted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because all these products are necessarily rather complicated to set up and
    operate, there is also the option of **Platform-as-a-Service** (**PaaS**) orchestration:
    essentially, running your containers on a managed cloud platform. **Google Container
    Engine** (**GKE**) is Kubernetes as a service; Amazon''s **EC2 Container Service**
    (**ECS**) is a proprietary, Kubernetes-like system.'
  prefs: []
  type: TYPE_NORMAL
- en: As yet, Puppet integration with container orchestrators is somewhat limited
    and at an early stage, though, given the popularity of containers, this is likely
    to advance rapidly. There is some elementary support for generating Kubernetes
    configuration from Puppet resources, and some for managing Amazon ECS resources,
    but it's fair to say that automating container orchestration at scale with Puppet
    is so far still in its infancy. Watch this space, however.
  prefs: []
  type: TYPE_NORMAL
- en: Running Puppet inside containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If a container can contain a whole operating system, such as Ubuntu, you might
    be wondering: "can''t I just run Puppet inside the container?"'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can, and some people do take this approach to managing containers. It also
    has a number of advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: You can use your existing Puppet manifests, or Forge modules; no need to write
    complex Dockerfiles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet will keep the container continuously updated; no need to rebuild when
    something changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Of course, there are a few disadvantages too:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Puppet inflates the image size considerably, and pulls in all sorts
    of dependencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Puppet slows down the build process, and also consumes resources in
    the running container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are also some hybrid options, such as running Puppet in the container
    during the build stage, and then removing Puppet and its dependencies, plus any
    intermediate build artifacts, before saving the final image.
  prefs: []
  type: TYPE_NORMAL
- en: Puppet's `image_build` module is a promising new way of building containers
    directly from Puppet manifests, and I expect to see rapid progress in this space
    in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: Are containers mini VMs or single processes?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Which option you favor probably depends on your basic approach to containers.
    Do you see them as mini-virtual machines, not too different from the servers you're
    already managing? Or do you see them as transient, lightweight, single-process
    wrappers?
  prefs: []
  type: TYPE_NORMAL
- en: If you treat containers as mini-VMs, you'll probably want to run Puppet in your
    containers, in the same way as you do on your physical and virtual servers. On
    the other hand, if you think a container should just run a single process, it
    doesn't seem appropriate to run Puppet in it. With single-process containers there's
    very little to configure.
  prefs: []
  type: TYPE_NORMAL
- en: I can see arguments in favor of the mini-VM approach. For one thing, it makes
    it much easier to transition your existing applications and services to containers;
    instead of running them in a VM, you just move the whole thing (application, support
    services, and database) into a container, along with all your current management
    and monitoring tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, while this is a valid approach, it doesn''t really make the most of
    the inherent advantages of containers: small image sizes, quick deployment, efficient
    rebuilding, and portability.'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring containers with Puppet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Personally, I''m a container minimalist: I think the container should contain
    only what it needs to do the job. Therefore, I prefer to use Puppet to manage,
    configure, and build my containers from the outside, rather than from the inside,
    and that''s why I''ve used that approach in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: That means generating Dockerfiles from templates and Hiera data, as we've seen
    in the examples, as well as templating config files which the container needs.
    You can have the Dockerfile copy these files into the container during the build,
    or mount individual files and directories from the host onto the container.
  prefs: []
  type: TYPE_NORMAL
- en: As we've seen, a good way to handle shared data is to have Puppet write it into
    a Docker volume or a file on the host which is then mounted (usually read-only)
    by all running containers.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of this is that you don't need to rebuild all your containers
    following a config change. You can simply have Puppet write the changes to the
    config volume, and trigger each container to reload its configuration using a
    `docker::exec` resource, which executes a specified command on a running container.
  prefs: []
  type: TYPE_NORMAL
- en: Containers need Puppet too
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the risk of laboring a point, containerization is not an alternative to
    using configuration management tools such as Puppet. In fact, the need for configuration
    management is even greater, because you not only have to build and configure the
    containers themselves, but also store, deploy, and run them: all of which requires
    an infrastructure.'
  prefs: []
  type: TYPE_NORMAL
- en: As usual, Puppet makes this sort of task easier, more pleasant, and—most importantly—more
    scalable.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've examined some of the problems associated with software
    deployment, some of the options for solving them, and the advantages of the container
    solution. We've briefly introduced the basics of container technology and Docker,
    in particular, and seen that containers are another kind of configuration management
    problem which Puppet can help solve.
  prefs: []
  type: TYPE_NORMAL
- en: We've installed the `docker_platform` module, and used it to set up Docker on
    our VM, and build and run simple Docker containers. We've seen how to automatically
    rebuild the container image when the underlying Dockerfile changes, and how to
    use Puppet to configure a Dockerfile dynamically at build time.
  prefs: []
  type: TYPE_NORMAL
- en: We've introduced the topic of persistent storage for containers, including host-mounted
    volumes and Docker volumes, and how to manage these with Puppet. We've set up
    a Docker network with two communicating containers exchanging data over network
    ports.
  prefs: []
  type: TYPE_NORMAL
- en: We've looked at the advantages and disadvantages of running Puppet inside containers,
    as opposed to using Puppet to configure and build containers from the outside,
    and also suggested a hybrid strategy where Puppet manages configuration data on
    a volume attached to running containers.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we've covered some of the issues involved in container orchestration,
    and introduced some of the most popular platforms and frameworks available.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll learn how to use Puppet to manage cloud computing
    resources, with an in-depth example developing a software-defined Amazon EC2 infrastructure.
  prefs: []
  type: TYPE_NORMAL
