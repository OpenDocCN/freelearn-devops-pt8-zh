<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Troubleshooting and Profiling</h1>
                </header>
            
            <article>
                
<p class="mce-root">Sometimes, our Puppet infrastructure and code don't seem like they're cooperating with us. In this chapter, we'll focus on troubleshooting some common issues.</p>
<p class="mce-root">The main topics that we'll cover in this chapter are as follows:</p>
<ul>
<li>Puppet infrastructure component errors</li>
<li>Common catalog compilation errors</li>
<li>Logging</li>
</ul>
<p>Although this is not always the most exciting topic, knowing how to work with these issues is the key to success with any system and language, including Puppet. Before we dive into our code, we'll make sure that our Puppet infrastructure is ready to go.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Common component errors</h1>
                </header>
            
            <article>
                
<p>This section will be all about a healthy Puppet installation. We'll primarily focus on the common issues that we see on agents, and what they may mean for your Puppet system. We'll tackle this for the times that we most commonly see errors: while writing, testing, and deploying code to our servers. We will be troubleshooting primarily from the perspective of the Puppet agent, so you will see the most common issues that team members encounter while working on a Puppet deployment.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Puppet agents and Puppetserver</h1>
                </header>
            
            <article>
                
<p>All of the nodes in a Puppet infrastructure contain a Puppet agent. In a split installation, each component checks in with a Puppetserver, just like any other node managed in the infrastructure. In a monolithic installation, the Puppet agent checks in with itself. Every other node managed by Puppet must use the agent to retrieve a configuration. Because the agent is everywhere, understanding some of the common errors with the agent will be universally useful for troubleshooting. Some of the common causes of a malfunctioning agent are as follows:</p>
<ul>
<li>Certificate reuse</li>
<li>Wrong user context when connecting to the master</li>
<li>Network connectivity</li>
<li>DNS alternate name</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Waiting on certificate signing</h1>
                </header>
            
            <article>
                
<p>One of the simplest errors that you will see when running the agent for the first time is a message stating, <kbd>failed to retrieve certificate and waitforcert is disabled</kbd>:</p>
<pre>Exiting; failed to retrieve certificate and waitforcert is disabled</pre>
<p>This particular message is easy to fix. Our agent is informing us that it has not received a signed certificate back from the master. We can solve this problem by simply logging in to the Puppet Master as the root user and signing our certificate. We can view any pending certificates on our Puppet Master with the command <kbd>puppet cert list</kbd>, as follows:</p>
<pre><strong>[root@wordpress puppetlabs]# puppet agent -t</strong><br/><strong>Exiting; no certificate found and waitforcert is disabled</strong></pre>
<p>In the preceding code, we can see that our <kbd>wordpress</kbd> node hasn't been signed, and we can simply approve this node for use with <kbd>puppet cert sign</kbd>:</p>
<pre><strong>[root@pe-puppet-master ~]# puppet cert list</strong><br/><strong>  "wordpress" (SHA256) F4:9E:56:9E:07:3F:66:B3:B4:CE:81:9E:1E:ED:FC:43:B9:A2:CC:88:78:8D:C5:30:CA:B0:B7:6D:0F:77:86:20</strong><br/><br/><strong>[root@pe-puppet-master ~]# puppet cert sign wordpress</strong><br/><strong>Signing Certificate Request for:</strong><br/><strong>  "wordpress" (SHA256) F4:9E:56:9E:07:3F:66:B3:B4:CE:81:9E:1E:ED:FC:43:B9:A2:CC:88:78:8D:C5:30:CA:B0:B7:6D:0F:77:86:20</strong><br/><strong>Notice: Signed certificate request for wordpress</strong><br/><strong>Notice: Removing file Puppet::SSL::CertificateRequest wordpress at '/etc/puppetlabs/puppet/ssl/ca/requests/wordpress.pem'</strong></pre>
<p>If we're not auto-signing our certificates through our <kbd>autosign.conf</kbd> or using an ENC that provides automatic signing for us, we'll always need to remember to sign certificates for new nodes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Certificate reuse</h1>
                </header>
            
            <article>
                
<p>Sometimes, we spin up a new node by using a <kbd>cert</kbd> name previously known to the Puppet Master, especially in immutable infrastructures. Our Puppet infrastructure is designed with certificate security in mind, so having a new node with a name already known by the Puppet Master will present a message like the following:</p>
<pre><strong>[root@wordpress puppet]# puppet agent -t</strong><br/><strong>Error: Could not request certificate: The certificate retrieved from the master does not match the agent's private key. Did you forget to run as root?</strong><br/><strong>Certificate fingerprint: 88:7F:B2:88:15:20:0A:55:3F:DE:2A:36:2C:B1:52:50:F1:77:96:EA:79:75:A1:00:B9:D6:3E:0B:93:45:D8:1C</strong><br/><strong>To fix this, remove the certificate from both the master and the agent and then start a puppet run, which will automatically regenerate a certificate.</strong><br/><strong>On the master:</strong><br/><strong>  puppet cert clean wordpress</strong><br/><strong>On the agent:</strong><br/><strong>  1a. On most platforms: find /etc/puppetlabs/puppet/ssl -name wordpress.pem -delete</strong><br/><strong>  1b. On Windows: del "\etc\puppetlabs\puppet\ssl\certs\wordpress.pem" /f</strong><br/><strong>  2. puppet agent -t</strong><br/><br/><strong>Exiting; failed to retrieve certificate and waitforcert is disabled</strong></pre>
<p>The simple fix for this error is to simply clean the certificate on our Puppet Master before running the agent again, and also signing the certificate again, as follows:</p>
<pre><strong>[root@pe-puppet-master manifests]# puppet cert clean wordpress</strong><br/><strong>Notice: Revoked certificate with serial 18</strong><br/><strong>Notice: Removing file Puppet::SSL::Certificate wordpress at '/etc/puppetlabs/puppet/ssl/ca/signed/wordpress.pem'</strong><br/><strong>Notice: Removing file Puppet::SSL::Certificate wordpress at '/etc/puppetlabs/puppet/ssl/certs/wordpress.pem'</strong></pre>
<p>Additionally, Puppet will not let us rerun the agent until we delete the certificate that was recently generated. The message provided by the error provides the best command to remove the certificate, so it can be regenerated on our agents: <kbd>find /etc/puppetlabs/puppet/ssl -name &lt;fqdn&gt;.pem -delete</kbd>. On most agents, it is actually safer to delete the entire SSL directory, with <kbd>rm -rf /etc/puppetlabs/puppet/ssl</kbd>. </p>
<div class="packt_tip">Deleting the SSL directory on the Puppet Master will delete the entire certificate chain, causing a need for a whole new set of certificates. This problem was more difficult to resolve in older versions of Puppet; we can now resolve it by following the directions at <a href="https://puppet.com/docs/puppet/latest/ssl_regenerate_certificates.html">https://puppet.com/docs/puppet/latest/ssl_regenerate_certificates.html</a>. Ensure that you don't accidentally delete the SSL certificates on the master, rather than the agent.</div>
<p>Preventing this error is as simple as running <kbd>puppet cert clean &lt;nodename&gt;</kbd> on the Puppet Master, after decommissioning any node attached to the Puppet Master.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Wrong Puppet user</h1>
                </header>
            
            <article>
                
<p>When we're writing code, we often log in to a test machine to run our agent manually and get a sense of what's going on. We rarely log in directly as the root, and it's easy to forget to switch our user to root. This problem can be particularly frustrating, because it appears as a certificate error. Our individual user generates a new certificate, and cannot connect to the Master using the SSL error. The key difference that you'll notice in the error log is the recommendation to remove the local certificate.</p>
<p>This happens primarily when doing testing and running the agent as the wrong user on a Puppet agent. Take note of the generating new key, and the user context user in line 1, and in the certificate clean message:In the following example, notice a new SSL key being generated, and that I'm running this command as my own users instead of root:</p>
<pre><strong>[rary@wordpress ~]$ puppet agent -t</strong><br/><strong>Info: Creating a new SSL key for wordpress</strong><br/><strong>Info: Caching certificate for ca</strong><br/><strong>Info: Caching certificate for wordpress</strong><br/><strong>Error: Could not request certificate: The certificate retrieved from the master does not match the agent's private key. Did you forget to run as root?</strong><br/><strong>Certificate fingerprint: 0C:10:48:BB:F9:F4:12:4A:66:52:FD:BB:33:DF:54:67:98:B4:D1:01:96:DE:6B:A4:D1:29:19:3C:C8:83:15:8C</strong><br/><strong>To fix this, remove the certificate from both the master and the agent and then start a puppet run, which will automatically regenerate a certificate.</strong><br/><strong>On the master:</strong><br/><strong>  puppet cert clean wordpress</strong><br/><strong>On the agent:</strong><br/><strong>  1a. On most platforms: find /home/rary/.puppetlabs/etc/puppet/ssl -name wordpress.packt.com.pem -delete</strong><br/><strong>  1b. On Windows: del "\home\rary\.puppetlabs\etc\puppet\ssl\certs\wordpress.packt.com.pem" /f</strong><br/><strong>  2. puppet agent -t</strong><br/><br/><strong>Exiting; failed to retrieve certificate and waitforcert is disabled</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network connectivity</h1>
                </header>
            
            <article>
                
<p>Network connectivity issues can be pretty noisy in Puppet. The agent in the following code sample does not have the ability to talk to the master, due to either a bad networking route or a firewall stopping traffic to our Puppet Master. In the following example, a firewall is blocking the agent from connecting to the master:</p>
<pre><strong>[root@wordpress ~]# puppet agent -t</strong><br/><strong>Warning: Unable to fetch my node definition, but the agent run will continue:</strong><br/><strong>Warning: Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong><br/><strong>Warning: Not using cache on failed catalog</strong><br/><strong>Error: Could not retrieve catalog; skipping run</strong><br/><strong>Error: Could not send report: Failed to open TCP connection to pe-puppet-master:8140 (No route to host - connect(2) for "pe-puppet-master" port 8140)</strong></pre>
<p>You may notice recurring themes in the preceding examples: <kbd>No route to host</kbd> and <kbd>Failed to open TCP Connection</kbd>. Each component of our catalog compilation will individually print a message back, alerting us to a connection failure. When we see no route to the host, we know that a firewall is between our agent and master, or that there is no network route to the host. This can also be caused by an improper DNS or <kbd>/etc/hosts</kbd> entry on the agent attempting to connect to the master.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DNS alt name</h1>
                </header>
            
            <article>
                
<p>DNS alt names are very convenient in larger Puppet infrastructures. They allow us to effectively nickname our servers individually, or as a group. A common DNS alt name might be <kbd>puppet</kbd>, so that you can use a load balancer to serve all of your individual Puppetservers. </p>
<p>In the following example, we're trying to connect to our Puppetserver using the name <kbd>alt-name.puppet.net</kbd>, which was never baked in to the certificate on the original signing of our Puppet server:</p>
<pre><strong>[root@wordpress puppet]# puppet agent -t --server=alt-name.puppet.net</strong><br/><strong>Warning: Unable to fetch my node definition, but the agent run will continue:</strong><br/><strong>Warning: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong><br/><strong>Warning: Not using cache on failed catalog</strong><br/><strong>Error: Could not retrieve catalog; skipping run</strong><br/><strong>Error: Could not send report: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [ok for /CN=pe-puppet-master]</strong></pre>
<p>There are two possible fixes for this: either set your agent to call the master by a known DNS name, or rebuild the certificate on your Puppetserver with the new DNS alt name. This can be done by removing the SSL cert with <span><kbd>find /etc/puppetlabs/puppet/ssl -name &lt;fqdn&gt;.pem -delete</kbd> on the offending master, and running <kbd>puppet agent -t --dns-alt-names=&lt;name1&gt;,&lt;name2&gt;,&lt;etc&gt;</kbd> on the master, connecting to the master of masters, and building a new certificate. This certificate has to be signed via the command line on the CA (usually the Master of Masters), and cannot be signed in the PE console, due to the DNS alt names.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Date and time</h1>
                </header>
            
            <article>
                
<p>Time is an important factor in maintaining integrity between SSL connections. <kbd>puppetlabs/ntp</kbd> is usually the module most curated by Puppet, due to the fact that Puppet needs an accurate date and time on each node during a transaction. If you receive a message stating that the certificate revocation list (CRL) is not yet valid on your runs, ensure that NTP is properly configured across your nodes:</p>
<pre><strong>[root@wordpress puppet]# puppet agent -t</strong><br/><strong>Warning: Unable to fetch my node definition, but the agent run will continue:</strong><br/><strong>Warning: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong><br/><strong>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong><br/><strong>Warning: Not using cache on failed catalog</strong><br/><strong>Error: Could not retrieve catalog; skipping run</strong><br/><strong>Error: Could not send report: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [CRL is not yet valid for /CN=Puppet Enterprise CA generated on pe-puppet-master at +2018-06-15 02:28:12 +0000]</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">PE console service is down</h1>
                </header>
            
            <article>
                
<p>If the Puppet Enterprise console is overloaded, it can trigger an <kbd>OutOfMemory</kbd> error and crash. I see this most often when spinning up small Puppet Enterprise installations on a virtual machine or container on my local laptop. When the console is down, Puppet Enterprise users will receive an error, letting them know that the node manager service isn't running. Users should check the status of the PE console and the relevant logs if this message starts to come up in agent runs:</p>
<pre><strong>[root@wordpress ~]# puppet agent -t</strong><br/><strong>Warning: Unable to fetch my node definition, but the agent run will continue:</strong><br/><strong>Warning: Error 500 on SERVER: Server Error: Classification of wordpress failed due to a Node Manager service error. Please check /var/log/puppetlabs/console-services/console-services.log on the node(s) running the Node Manager service for more details.</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: Error 500 on SERVER: Server Error: Failed when searching for node wordpress: Classification of wordpress failed due to a Node Manager service error. Please check /var/log/puppetlabs/console-services/console-services.log on the node(s) running the Node Manager service for more details.<br/></strong><br/><strong>Warning: Not using cache on failed catalog</strong><br/><strong>Error: Could not retrieve catalog; skipping run</strong></pre>
<div class="packt_infobox"><span>This section only applies to Puppet Enterprise users.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Catalog errors</h1>
                </header>
            
            <article>
                
<p>When a catalog compilation error is triggered, the Puppet Parser is alerting us that it cannot build a catalog from the provided code. A puppet run will fail and the agent will not configure anything on a node that fails catalog compilation. These errors trigger when Puppet cannot read the code, or cannot determine how to apply the resources supplied in the catalog. In the next sections, we'll cover the following common failures:</p>
<ul>
<li>Syntax errors</li>
<li>Duplicate resource declarations</li>
<li>Missing resources</li>
<li>Autoload format</li>
<li>Circular dependencies</li>
</ul>
<div class="packt_infobox"><span class="packt_screen">Enterprise Users</span>: The configuration tab in the classification group will not be able to read classes that contain syntax errors, missing classes, or classes not found in autoload format.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Syntax errors</h1>
                </header>
            
            <article>
                
<p>Syntax errors are the most common errors that we see when we develop code. It's easy to miss simple syntax when typing code, and to push failing code to a test environment. In the following example, the closing bracket to the class at the end of the file is missing:</p>
<pre><strong>[root@wordpress puppet]# puppet agent -t</strong><br/><strong>Info: Using configured environment 'production'</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: Error 500 on SERVER:</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<pre><strong> Server Error: Syntax error at end of input (file: /etc/puppetlabs/code/environments/production/modules/profile/manifests/baseline.pp) on node wordpress</strong></pre>
<p>We can test for this failure long before it is deployed to our Puppet Master. The command <kbd>puppet parser validate</kbd> will give us the exact same message as the agent if we run it against the manifest. Users of the PDK will find that <kbd>pdk validate</kbd> runs this as one of the checks in the suite. The error from the agent run is replicated by Puppet parser validate in the following code:</p>
<pre><strong>[root@pe-puppet-master manifests]# puppet parser validate baseline.pp</strong><br/><strong>Error: Could not parse for environment production: Syntax error at end of input (file: /etc/puppetlabs/code/environments/production/modules/profile/manifests/baseline.pp)</strong></pre>
<p>This is one of the simplest examples of a good practice to put into your CI/CD pipelines. You can find more good examples of adding this simple check in <a href="683ff898-d0ea-47e0-bbc7-b3458e300904.xhtml">Chapter 8</a>, <em>Extending Puppet with Tasks and Discovery</em>.</p>
<div class="packt_tip">Syntax error checkers like Puppet parser validate scan through the code until they find a line that they cannot resolve. Often, these errors are on the line above the reported failure! Always check the line above the reported line. The following error was actually a missing comma on line 4 of the <kbd>example.pp</kbd>: <kbd>Error: Could not parse for environment production: Syntax error at 'source' (file: /Users/rary/workspace/packt/manifests/example.pp, line: 5, column: 5)</kbd>. </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Duplicate resource declaration</h1>
                </header>
            
            <article>
                
<p>Puppet builds our catalogs based on every resource declared in our manifests. In good Puppet code design, we have classes that include or contain other classes. During development, it's not uncommon to sometimes attempt to declare a resource that has been declared in a class that's already applied on the system. By design, Puppet will fail on a duplicate resource declaration, and for a good reason: How can the catalog decide which resource is the right resource to apply? In the following example, a resource is declared in two separate classes being applied to my node:</p>
<pre><strong>[root@pe-puppet-master production]# puppet agent -t</strong><br/><strong>Info: Using configured environment 'production'</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: Error 500 on SERVER: Server Error: Evaluation Error: Error while evaluating a Resource Statement, Duplicate declaration: File[/var/log/custom] is already declared at (file: /etc/puppetlabs/code/environments/production/modules/profile/manifests/baseline.pp, line: 6); cannot redeclare (file: /etc/puppetlabs/code/environments/production/modules/profile/manifests/logging.pp, line: 3) (file: /etc/puppetlabs/code/environments/production/modules/profile/manifests/logging.pp, line: 3, column: 3) on node pe-puppet-master</strong><br/><strong>Warning: Not using cache on failed catalog</strong><br/><strong>Error: Could not retrieve catalog; skipping run</strong></pre>
<p>In the preceding case, I had my logging directory set in my baseline profile. I iterated and designed a whole profile around logging, and included my directory in the logging profile. To fix this error, I'll simply remove the custom logging directory resource from my baseline profile.</p>
<div class="packt_tip"><span>If you need to declare a resource, and potentially use it in multiple manifests, you may want to use a virtual resource.</span>. <a href="036a4b96-b91a-4c72-83dc-e5505efc26cd.xhtml">Chapter 9</a>, <em>Exported Resources</em> covers virtual resources, as well. </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Missing resources</h1>
                </header>
            
            <article>
                
<p>When we attempt to use a resource that is not available to our Puppet Master or Puppet environment, we can trigger a missing resource error, causing the catalog compilation to fail. While these are commonly caused by misspelling a resource type, they can also be caused by missing modules in an environment. In the following example, I'm attempting to use the NTP module with <kbd>include ntp</kbd>. Remember, classes are resources, too:</p>
<pre><strong>[root@wordpress puppet]# puppet agent -t</strong><br/><strong>Info: Using configured environment 'production'</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: Error 500 on SERVER: Server Error: Evaluation Error: Error while evaluating a Function Call, Could not find class ::ntp for wordpress (file: /etc/puppetlabs/code/environments/production/modules/profile/manifests/baseline.pp, line: 3, column: 3) on node wordpress<br/><br/></strong><br/><strong>Warning: Not using cache on failed catalog</strong><br/><strong>Error: Could not retrieve catalog; skipping run</strong></pre>
<p>I'm simply missing the NTP class in my environment. I could resolve this by hand with <kbd>puppet module install</kbd>, but, if you're using r10k or Code Manager, enter the module entry and all of the dependencies into your environment Puppetfile:</p>
<pre>mod 'puppetlabs/ntp'<br/>mod 'puppetlabs/stdlib'</pre>
<p>Using the Puppet module <kbd>install</kbd> method does make a module available to all environments, but I can only recommend using it on temporary Puppet Masters that are used to test code:</p>
<pre><strong>[root@pe-puppet-master manifests]# puppet module install puppetlabs/ntp</strong><br/><strong>Notice: Preparing to install into /etc/puppetlabs/code/environments/production/modules ...</strong><br/><strong>Notice: Downloading from https://forgeapi.puppet.com ...</strong><br/><strong>Notice: Installing -- do not interrupt ...</strong><br/><strong>/etc/puppetlabs/code/environments/production/modules</strong><br/><strong>└─┬ puppetlabs-ntp (v7.2.0)</strong><br/><strong> └── puppetlabs-stdlib (v4.25.1)</strong></pre>
<div class="packt_tip">The Puppet module <kbd>install</kbd> grabs all of the dependencies for us, by default. R10k and Code Manager do not, so make sure that you include all of the dependencies in your Puppetfile.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoload format</h1>
                </header>
            
            <article>
                
<p>If our manifests containing classes and defined types aren't in the right directories, our master won't be able to find them. In the following example, I'm attempting to use a new class:</p>
<div>
<pre><strong>[root@wordpress puppet]# puppet agent -t</strong><br/><strong>Info: Using configured environment 'production'</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Notice: /File[/opt/puppetlabs/puppet/cache/locales/ja/puppetlabs-ntp.po]/ensure: defined content as '{md5}7265ff57e178feb7a65835f7cf271e2c'</strong><br/><strong>Info: Loading facts</strong><br/><strong>Error: Could not retrieve catalog from remote server: Error 500 on SERVER: Server Error: Evaluation Error: Error while evaluating a Function Call, Could not find class ::profile::baseline::linux for wordpress</strong></pre>
<pre><strong>(file:</strong><strong>/etc/puppetlabs/code/environments/production/modules/profile/manifests/baseline.pp, line: 4, column: 3) on node wordpress</strong></pre>
<p>I know that I wrote my <kbd>linux.pp</kbd> manifest, but the master can't find it. If I run <kbd>tree</kbd> in the directory, I'll see that <kbd>profile::baseline::linux</kbd> is actually in the autoload directory for <kbd>profile::linux</kbd>. Remember, directories are what provide us with extra layers in our namespace:</p>
<pre>profile/<br/>└── manifests<br/>    ├── baseline.pp # profile::baseline<br/>    └── linux.pp # profile::baseline::linux &lt;-- Can't find this</pre>
<p>By simply moving my Linux baseline into the <kbd>baseline</kbd> folder, the master will be able to find this manifest:</p>
<pre>profile/<br/>└── manifests<br/>    ├── baseline<br/>    │   └── linux.pp # profile::baseline::linux &lt;-- Found!<br/>    └── baseline.pp # profile::baseline</pre></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Circular dependencies</h1>
                </header>
            
            <article>
                
<p>Circular dependencies don't happen often in Puppet development, but when they do, they can be a major pain to troubleshoot. Circular dependencies happen when we create dependency chains with arrow indicators (<kbd>-&gt;</kbd>) or ordering metaparameters. In the following example, my three notify statements require each other in a circular chain - <kbd>a -&gt; b -&gt; c -&gt; a</kbd>:</p>
<pre>class profile::baseline::linux {<br/><br/># notify {'baseline': message =&gt; 'Applying the Linux Baseline!' }<br/><br/>  notify {'a':<br/>    message =&gt; 'Resource A',<br/>    require =&gt; Notify['b']<br/>  }<br/><br/>  notify {'b':<br/>    message =&gt; 'Resource B',<br/>    require =&gt; Notify['c']<br/>  }<br/><br/>  notify {'c':<br/>    message =&gt; 'Resource C',<br/>    require =&gt; Notify['a']<br/>  }<br/><br/>}</pre>
<p>When this catalog is applied on the node, we'll get a statement letting us know which resources are in a dependency chain:</p>
<pre><strong>[root@wordpress puppet]# puppet agent -t</strong><br/><strong>Info: Using configured environment 'production'</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Info: Loading facts</strong><br/><strong>Info: Caching catalog for wordpress</strong><br/><strong>Info: Applying configuration version '1535603400'</strong><br/><strong>Error: Found 1 dependency cycle:</strong><br/><strong>(Notify[a] =&gt; Notify[c] =&gt; Notify[b] =&gt; Notify[a])\nTry the '--graph' option and opening the resulting '.dot' file in OmniGraffle or GraphViz</strong><br/><strong>Error: Failed to apply catalog: One or more resource dependency cycles detected in graph</strong></pre>
<p>Notice the <kbd>--graph</kbd> flag that is indicated in the agent. If we run our agent again, with <kbd>puppet agent -t --graph</kbd>, we'll get a dot file back that details our ordering, and we will be able to highlight our dependency cycles. This file is written out to <kbd>/opt/puppetlabs/puppet/cache/stage/graphs/cycles.dot</kbd>. I can open this file in GraphViz (open source) or OmniGraffle and view my chain in a graph. The following diagram shows this notification cycle represented in OmniGraffle:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4e89c9ec-916f-4dd6-b830-fa6f330e47ff.png" style="width:18.92em;height:11.00em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Debug mode – catalog</h1>
                </header>
            
            <article>
                
<p>Sometimes, Puppet throws an error that isn't immediately obvious. In the next example, I'm attempting to install <kbd>apache httpd</kbd>, but I have misspelled the name of the package. If you haven't spent a lot of time working on a system that uses Yum, the error <kbd>Nothing to do</kbd> isn't exactly a very clear error:</p>
<pre><strong>[root@pe-puppet-master manifests]# puppet agent -t</strong><br/><strong>Info: Using configured environment 'production'</strong><br/><strong>Info: Retrieving pluginfacts</strong><br/><strong>Info: Retrieving plugin</strong><br/><strong>Info: Retrieving locales</strong><br/><strong>Info: Loading facts</strong><br/><strong>Info: Caching catalog for pe-puppet-master</strong><br/><strong>Info: Applying configuration version '1535778801'</strong><br/><strong>Notice: Applying the Linux Baseline!</strong><br/><strong>Notice: /Stage[main]/Profile::Baseline::Linux/Notify[baseline]/message: defined 'message' as 'Applying the Linux Baseline!'</strong><br/><strong>Error: Execution of '/usr/bin/yum -d 0 -e 0 -y install http' returned 1: Error: Nothing to do</strong><br/><strong>Error: /Stage[main]/Profile::Baseline/Package[http]/ensure: change from 'purged' to 'present' failed: Execution of '/usr/bin/yum -d 0 -e 0 -y install http' returned 1: Error: Nothing to do</strong><br/><strong>https://yum.puppet.com/puppet5/puppet5-release-el-7.noarch.rpm' returned 1: Error: Nothing to do</strong><br/><strong>Info: Stage[main]: Unscheduling all events on Stage[main]</strong></pre>
<p>I may want to inspect exactly what Puppet is trying to get my system to do. I can use the <kbd>--debug</kbd> flag on the agent to inspect all of the actions that Puppet is taking underneath the system. I can see that Puppet uses <kbd>rpm -q</kbd> to check whether the package is already installed on the system. When it's not found, it executes a specific Yum command: run Yum without an error log (<kbd>-e 0</kbd>) or debugging (<kbd>-d 0</kbd>), and assume yes (<kbd>-y</kbd>) to install <kbd>http</kbd>. Finally, because this resource has failed, any resources requiring it will fail to install:</p>
<pre><strong>Debug: Executing: '/usr/bin/rpm -q http --nosignature --nodigest --qf '%{NAME} %|EPOCH?{%{EPOCH}}:{0}| %{VERSION} %{RELEASE} %{ARCH}\n''</strong><br/><strong>Debug: Executing: '/usr/bin/rpm -q http --nosignature --nodigest --qf '%{NAME} %|EPOCH?{%{EPOCH}}:{0}| %{VERSION} %{RELEASE} %{ARCH}\n' --whatprovides'</strong><br/><strong>Debug: Package[http](provider=yum): Ensuring =&gt; present</strong><br/><strong>Debug: Executing: '/usr/bin/yum -d 0 -e 0 -y install http'</strong><br/><strong>Error: Execution of '/usr/bin/yum -d 0 -e 0 -y install http' returned 1: Error: Nothing to do</strong><br/><strong>Error: /Stage[main]/Profile::Baseline/Package[http]/ensure: change from</strong><strong>'purged' to 'present' failed: Execution of '/usr/bin/yum -d 0 -e 0 -y</strong></pre>
<p class="mce-root"/>
<pre><strong> install http' returned 1: Error: Nothing to do</strong><br/><strong>Debug: Class[Profile::Baseline]: Resource is being skipped, unscheduling all events</strong></pre>
<div class="packt_tip">The error <kbd>Nothing to do</kbd> wasn't actually solved. A quick search of your favorite forums will indicate some likely culprits, and in this case, <kbd>http</kbd> isn't a package in Yum. <kbd>httpd</kbd> , which is the Apache web server, is what I was looking to install.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging</h1>
                </header>
            
            <article>
                
<p>Logging is one of the most useful forms of troubleshooting, if actively monitored. We can often identify problems in our infrastructure before they become problems that users report. By understanding the logging available to Puppet, you will know where to look for indicators of system degradation. In this section, we'll explore the log files available to Puppet and its sub components, and we will configure the log level in the Puppetserver.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The logback.xml file</h1>
                </header>
            
            <article>
                
<p>Each component that we'll be logging on, other than the Puppet agent, will use Logback. Although this isn't a book on <kbd>logback</kbd>, we'll look at a few existing sections of <kbd>logback.xml</kbd> and some common settings that we can alter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Main configuration</h1>
                </header>
            
            <article>
                
<p>The main configuration includes the first and last line of the following XML file:</p>
<pre>&lt;configuration scan="true" scanPeriod="60 seconds"&gt;</pre>
<p>The <kbd>scan</kbd> setting tells <kbd>logback</kbd> to rescan the configuration for changes and reload the service if changes are detected. The <kbd>scanPeriod</kbd> setting lets the configuration know how often to scan. We use these settings so that our log configuration is updated dynamically with the file; no service restart is needed.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Appender</h1>
                </header>
            
            <article>
                
<p>The appender configuration section is what manages the log file. I've added comments to the appender for <kbd>puppetserver.log</kbd>, concerning what the individual lines are doing:</p>
<pre>&lt;!-- Setting the name for future reference and making a Rolling Log File --&gt;<br/>    &lt;appender name="F1" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;<br/><br/>&lt;!-- Logging to /var/log/puppetlabs/puppetserver/puppetserver.log --&gt;<br/>        &lt;file&gt;/var/log/puppetlabs/puppetserver/puppetserver.log&lt;/file&gt;<br/><br/>&lt;!-- Appending to, not replacing the log --&gt;<br/>        &lt;append&gt;true&lt;/append&gt;<br/><br/>&lt;!-- Roll the file over based on Size and Time --&gt;<br/>        &lt;rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"&gt;<br/><br/>&lt;!-- What to name the file as it's rolled over, with date variables --&gt;<br/>            &lt;fileNamePattern&gt;/var/log/puppetlabs/puppetserver/puppetserver-%d{yyyy-MM-dd}.%i.log.gz&lt;/fileNamePattern&gt;<br/><br/>&lt;!-- Maximum size of log file before rolling over --&gt;<br/>            &lt;maxFileSize&gt;200MB&lt;/maxFileSize&gt;<br/><br/>&lt;!-- Maximum Number of Files to keep - 90 logs --&gt;<br/>            &lt;maxHistory&gt;90&lt;/maxHistory&gt;<br/><br/>&lt;!-- Maximum Filesize of all files that will be kept. Up to 5 files with 200 MB --&gt;<br/>            &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;<br/>        &lt;/rollingPolicy&gt;<br/>&lt;!-- What to print for date and time with the message --&gt;<br/>        &lt;encoder&gt;<br/>            &lt;pattern&gt;%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} %-5p [%t] [%c{2}] %m%n&lt;/pattern&gt;<br/>        &lt;/encoder&gt;<br/>    &lt;/appender&gt;</pre>
<p>In the preceding example, we're creating <kbd>puppetserver.log</kbd> with a rollover strategy. We'll keep up to 90 logs, but we'll rotate whenever a log reaches 200 MB in size, and we will delete logs if we have more than 1 GB of logs. We'll append the date to logs that we roll over, and we will print the timestamp from the log.</p>
<div class="packt_tip">You may see an appender to <kbd>STDOUT</kbd>. This actually prints to <kbd>System.out</kbd> and <kbd>System.error</kbd>, essentially appending to the Terminal.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loggers</h1>
                </header>
            
            <article>
                
<p>A logger in the <kbd>logback.xml</kbd> acts as a pointer for the logs produced by the application:</p>
<pre>    &lt;logger name="puppetlabs.pcp" level="info" additivity="false"&gt;<br/>      &lt;appender-ref ref="PCP"/&gt;<br/>    &lt;/logger&gt;</pre>
<p>This example connects to the <kbd>puppetlabs.pcp</kbd> log in the Puppetserver application, and collects the info-level logs. The <kbd>additivity=false</kbd> flag tells the log to replace the file, rather than append to it. Finally, the <kbd>appender-ref</kbd> tag tells the logger which appender to use for the logging configuration.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Root logger</h1>
                </header>
            
            <article>
                
<p>There is also a special type of logger, called the root logger:</p>
<pre>    &lt;root level="info"&gt;<br/>        &lt;appender-ref ref="${logappender:-DUMMY}" /&gt;<br/>        &lt;appender-ref ref="F1" /&gt;<br/>    &lt;/root&gt;</pre>
<p>The root logger acts as a default, allowing you to select the logging level and provide a list of <kbd>appender-refs</kbd> to apply the default settings to. Think of it as a default group policy logger, rather than a single configuration being applied to a log. All other loggers override the root logger for each value.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Puppet agent</h1>
                </header>
            
            <article>
                
<p>The Puppet agent is on every node, and the log for the Puppet agent is stored locally on that node. This is the only log file that we work with that does not use logback, but uses system messaging, instead. The Puppet agent logs to the <kbd>syslog</kbd> of the operating system it runs on. Each operating system uses a different location, as follows:</p>
<ul>
<li>Linux: <kbd>/var/log/messages</kbd></li>
<li>macOS X: <kbd>/var/log/system.log</kbd></li>
<li>Solaris: <kbd>/var/adm/messages</kbd></li>
<li>Windows: Event Viewer</li>
</ul>
<p>The information logged here is the same information that is output during a Puppet run. You can check on successful and failed resources being applied to the node in this log file.</p>
<div class="packt_infobox">Enterprise Users: You also have agent logging available to view in the Puppet Enterprise console, which can be provided with filters, to help narrow down problems or statuses. You can find this log in the reports section of each node page.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">PuppetDB</h1>
                </header>
            
            <article>
                
<p>PuppetDB logging is managed by the config file located at <kbd>/etc/puppetlabs/puppetdb/logback.xml</kbd> on the PuppetDB server. This <kbd>logback</kbd> file contains entries for the following logs, which are in <kbd>/var/log/puppetlabs/puppetdb/</kbd>, by default:</p>
<ul>
<li><kbd>puppetdb.log</kbd>: Information on the PuppetDB application</li>
<li><kbd>puppetdb-access.log</kbd>: Information on user and machine access to PuppetDB</li>
<li><kbd>puppetdb-status.log</kbd>: Current status of PuppetDB</li>
</ul>
<div class="packt_tip">If you're looking for postgresql logs, they're contained in <kbd>/var/log/puppetlabs/postgresql</kbd>. This is standard postgresql logging.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Puppetserver</h1>
                </header>
            
            <article>
                
<p><span>Puppetserver logging is managed by the config file located at <kbd>/etc/puppetlabs/puppetserver/logback.xml</kbd> on the PuppetDB server. This <kbd>logback</kbd> file contains entries for the following logs, which are in <kbd>/var/log/puppetlabs/puppetserver</kbd>, by default:</span></p>
<ul class="ul">
<li class="li"><kbd>puppetserver.log</kbd><span>: Application activity with compilation errors</span></li>
<li class="li"><kbd>pcp-broker.log</kbd><span>: The log file for PCP broker activity on Puppet</span></li>
<li class="li"><kbd>pcp-broker-access.log</kbd>: The log file for users accessing PCP brokers on Puppet</li>
<li class="li"><kbd>puppetserver-status.log</kbd>: Status indicator for Puppetserver</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Puppet Enterprise console</h1>
                </header>
            
            <article>
                
<p><span>Console logging is managed by the config file located at <kbd>/etc/puppetlabs/console-services/logback.xml</kbd> on the PuppetDB server. This <kbd>logback</kbd> file contains entries for the following logs, which are in <kbd>/var/log/puppetlabs/console-services</kbd>, by default:</span></p>
<ul class="ul">
<li class="li"><kbd>console-services.log</kbd>: Logging for Puppet Enterprise console</li>
<li><kbd>console-services-status.log</kbd>: Status indicator for the console</li>
</ul>
<div class="packt_infobox"><span>This section is only useful to Puppet Enterprise users.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we discussed troubleshooting Puppet. We went over common errors seen in connections between the Puppetserver and Puppet agents. We looked at common catalog compilation failures, and how to debug them. We also covered <kbd>logback</kbd> and the log files on the master.</p>


            </article>

            
        </section>
    </body></html>