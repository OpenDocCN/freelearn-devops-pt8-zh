- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Already Provisioned? Strategies for Importing Existing Environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous nine chapters of this book have focused on implementing new cloud
    architectures across multiple clouds using multiple cloud computing paradigms.
    Now, we’re going to shift gears a bit and focus on how to work with existing environments.
    Unfortunately, sometimes (actually, a lot of the time), the cloud environments
    that you will manage weren’t originally provisioned using **Infrastructure-as-Code**
    (**IaC**) using via Terraform. They could’ve been provisioned using other tools,
    or even manually provisioned, and now you’re trying to consolidate your cloud
    operations using Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Importing individual resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying resources to import
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Importing existing environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Importing individual resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Terraform supports two ways of importing resources into state. One is inherently
    imperative and procedural and is typically executed outside of a GitOps process
    using Terraform’s **Command Line Interface** (**CLI**). There is also another,
    newer option that allows us to declare import operations in code and follow our
    standard GitFlow process to shepherd these changes into production.
  prefs: []
  type: TYPE_NORMAL
- en: The import command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `import` command allows you to import an existing resource that has already
    been provisioned outside of Terraform by some other means:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `Terraform import` command ([https://developer.hashicorp.com/terraform/cli/commands/import](https://developer.hashicorp.com/terraform/cli/commands/import))
    takes two key parameters. The various options fall outside of the scope of this
    book. I recommend that you check the documentation for more details on all of
    the available options.
  prefs: []
  type: TYPE_NORMAL
- en: The first parameter, the address of the resource within the Terraform code base,
    is crucial. It’s the same reference that we use to access resources in our Terraform
    workspace. Unlike when we’re in the HashiCorp Configuration Language code base,
    we’re not limited by the current Terraform module’s scope. The address follows
    your Terraform provider’s naming convention. For instance, you’d need the resource
    type and object reference to import a virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: The second parameter is the resource’s unique identifier on the target cloud
    platform. This unique identifier will look very different between different clouds.
    In the next section, we’ll look at how this differs for each cloud platform.
  prefs: []
  type: TYPE_NORMAL
- en: The `import` command is great for individual resources that might have failed
    due to transient issues during a `terraform apply`. If you had to import an entire
    solution, it would be extremely tedious to put together an `import` command for
    every resource. Even a simple virtual machine might consist of a dozen or so resources.
  prefs: []
  type: TYPE_NORMAL
- en: Import block
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `import` command is useful and available, but it requires you to introduce
    change to your IaC code base through outside influence from a human operator through
    the command line. The import block was introduced in version 1.5.0 of Terraform
    to allow these changes to be made through source code changes, which is important
    to maintaining a GitFlow process. This, in turn, is a key component of a GitOps
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather than executing a command using the Terraform CLI, you’ll need to embed
    an import block in your code base that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: It looks very similar to the parameters of the `import` command but it utilizes
    the existing context in which you execute Terraform. It also uses HashiCorp Configuration
    Language to define the import action.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique not only allows us to perform state management operations as
    part of our GitOps process but also streamlines the process. Importing resources
    only requires two pull requests: the first to introduce the import blocks for
    the resources we wish to import, and the second to remove the import blocks after
    a successful `Terraform Apply`, when the resources are imported into Terraform
    state.'
  prefs: []
  type: TYPE_NORMAL
- en: Importing multiple resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Import` command and the import block support importing resources using
    the `for_each` and `count` meta-arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To import resources provisioned with a `for_each` block, you simply need to
    define a `map` with the unique identifiers for the resources you wish to import:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The import block’s unique identifier will come from this `map` that you define.
    Then, use a matching `for_each` in the import block, which references your resource
    block using the same `map` and references the corresponding resource using `each.key`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, when importing resources provisioned using the `count` meta-argument,
    we must declare an array with unique identifiers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can use the `count` meta-argument on the import block and iterate
    across it just as we do with the resource block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `import` command is a bit more difficult. You’ll need to execute
    a `terraform import` command for each item within the map, referencing the correct
    `key` and mapping it to the corresponding value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'A similar technique is used for importing resources that are provisioned using
    `count`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: When working with `for_each` provisioned resources, we need to execute the `terraform
    import` command for each item within the array and manually correlate the index
    with the correct unique identifier.
  prefs: []
  type: TYPE_NORMAL
- en: Although it is technically possible through some pretty advanced bash scripting,
    the recommended approach is to use the import block within the HashiCorp Configuration
    Language, as this is much easier and less error-prone to implement.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have examined the imperative and declarative ways of importing existing
    resources into Terraform using the `import` command and the import block, respectively.
    Now, let’s examine how to identify the correct unique identifier for each of our
    existing resources across the three cloud platforms we have covered in this book:
    **Amazon Web Services** (**AWS**), Microsoft Azure, and Google Cloud Platform.'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying resources to import
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as there were subtle differences in each of the cloud architectures we
    developed in the previous chapters of this book, the way in which existing resources
    are imported into Terraform is affected by the structural and not-so-subtle differences
    between the cloud platforms.
  prefs: []
  type: TYPE_NORMAL
- en: AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The naming convention used by AWS for EC2 instances tends to look like this:
    `i-abcd1234`. It typically consists of two components: the prefix and the identifier,
    with the prefix varying across AWS services.'
  prefs: []
  type: TYPE_NORMAL
- en: The `i-` prefix indicates that this is an `vol-` for volumes or `sg-` for security
    groups.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the `abcd1234` identifier is a unique identifier for the instance.
    AWS usually assigns a hexadecimal string to each instance to differentiate it
    from other resources. This naming convention helps users and AWS services identify
    and reference resources within the AWS ecosystem. You’ll need to recognize the
    correct unique identifier for whatever resource you are trying to import into
    Terraform from AWS and the other cloud platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using the import command on AWS, it would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding import block would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: It’s important to understand the distinction between the address, which is the
    internal object reference within Terraform, and the unique identifier, which is
    the external reference to the resource on the target cloud platform. This understanding
    will help you navigate the import process more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Azure, the unique identifier is called the **Azure resource ID**. It takes
    on a radically different format that is composed using several different landmarks
    in a cloud resource’s location within Azure. It follows a structured format that
    includes several components: the subscription, the resource group, the resource
    provider, a resource type, and a localized resource name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, the Azure resource ID for an Azure virtual machine would look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we can see the concrete values for each component of the resource
    ID’s path:'
  prefs: []
  type: TYPE_NORMAL
- en: '`00000000-0000-0000-0000-000000000000` GUID for the subscription.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rg-foo`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft.Compute` is the resource provider for Azure compute services, which
    includes Azure virtual machines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`virtualMachines` is used for an Azure virtual machine. Together, the resource
    provider and the resource type create a fully qualified Azure resource type: `Microsoft.Compute\virtualMachines`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vmfoo001`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each resource type within a resource provider has subtypes as well. These are
    delimited with additional slashes (such as a virtual machine extension: `Microsoft.Compute/virtualMachines/{vm-name}/extensions/{extension-name}`).
    This naming convention for Azure resource ID uses a resource path strategy instead
    of AWS’s prefix and unique identifier strategy. As a result, Azure resource IDs
    can get rather long, but they do have a sensible way in which they can be deconstructed
    to gather valuable information about the deployment context of a particular resource,
    making additional lookups unnecessary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When using the import command on Azure, it would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding import block would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: It’s important to remember that the address is the internal object reference
    within Terraform. The unique identifier is the external reference to the resource
    on the target cloud platform.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Google Cloud, the unique identifier for a resource is called the **resource
    path**, and like Azure, it is composed of some important landmarks in the cloud
    resource’s location within Google Cloud. These landmarks differ from Azure’s due
    to the structural differences between the two platforms and other design considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, the Google resource path for a Google compute instance would look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we see the concrete values for each component of the resource
    path:'
  prefs: []
  type: TYPE_NORMAL
- en: '`proj-foo`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Zone**: This indicates the physical location of the resource within a Google
    Cloud region and zone.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vmfoo001`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While Google Cloud does have higher-level organizational structures, such as
    the Google Cloud organization and the folders within that organization, a resource
    path only includes the Google Cloud project ID. This is similar to Azure’s resource
    ID, which includes the Azure subscription and resource group, as these are logical
    containers of the resource within the platform. Google opted for a more simplistic
    path by only including the project ID. A major difference between Google Cloud’s
    resource path and Azure’s resource ID is the inclusion of the zone within the
    resource path. The zone indicates the resource’s physical location within one
    of Google Cloud’s regions. Azure’s resource ID only includes logical structures
    such as subscription, resource group, resource provider, and type, not physical
    locations such as Azure regions or availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using the import command on Google Cloud Platform, it would look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding import block would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: It’s important to remember that the address is the internal object reference
    within Terraform and the unique identifier is the external reference to the resource
    on the target cloud platform.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know a bit about how to identify the existing resources and the
    unique identifiers that we need to map to the resources defined within our code
    base, we are fully equipped to start manually importing resources into our Terraform
    code. However, is this the only way? Is there potentially a more cost-effective
    or time-sensitive approach that would allow us to import resources en masse? In
    the next section, we’ll explore some tools that allow us to find and import existing
    resources and generate their corresponding Terraform code.
  prefs: []
  type: TYPE_NORMAL
- en: Importing existing environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in the previous sections of this chapter, Terraform contains extensive
    import mechanisms that allow us to import individuals and a multitude of existing
    resources into our Terraform code base. These tools can help us overcome transient
    errors that result in orphaned resources that need to be managed with an existing
    Terraform code base and Terraform state file.
  prefs: []
  type: TYPE_NORMAL
- en: However, what happens when we don’t have any Terraform code written and many
    existing resources already provisioned within our cloud landscape? Manually reverse
    engineering all the Terraform code from scratch doesn’t seem like a useful way
    to spend our days. That’s why there are tools that help automate this process!
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll examine a couple of the most popular open-source tools
    for solving this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Terraformer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Terraformer** is an open-source tool developed by Google that helps with
    the process of importing existing cloud infrastructure into Terraform configuration
    and state. It supports various cloud providers, including the ones we’ve explored
    in this book. Naturally, Google Cloud is well-supported, including its main competitors
    (AWS and Azure), but a myriad of other Terraform providers also have support.
    Unlike the built-in capabilities of Terraform, this tool was designed to generate
    Terraform code and state based on the existing resources spread across your cloud
    landscape.'
  prefs: []
  type: TYPE_NORMAL
- en: This tool, and others like it, works by leveraging the cloud provider’s REST
    APIs in order to gather information about the various resources that have already
    been provisioned. You just need to point it in the right direction and give it
    some guardrails in order to narrow its field of vision. You simply pick up the
    resources that you want to bundle together into the same Terraform workspace and
    state file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key command line arguments that allow you to scope Terraformer to just
    the resources you are interested in are resource types, regions, and tags. Depending
    on the provider, there may be limitations in resource type support, so it is best
    to check the current list of supported resources by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This will help you inform how you will query the particular cloud platform.
    For example, when importing resources from AWS, we can determine that `s3` and
    `ec2_instance` are supported resource types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'On Azure, we’ll be using Azure-specific resource types and will often use the
    `--resource-group` argument to specify this Azure-specific logical structure to
    import resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, on Google Cloud, we’ll use the Google Cloud Project, which is the
    logical structure that corresponds to Azure resource groups, to narrow the field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Tags play an important role, as they provide a very fine-grained way to import
    exactly what we want into our Terraform workspaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can specify a very specific collection of tags that we pre-seed in our environments
    to get the most efficiency during the import process.
  prefs: []
  type: TYPE_NORMAL
- en: The Azure Export Tool
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are other commercial and platform-specific tools that might do a better
    job than general-purpose tools like Google’s Terraformer. One example of this
    is the `azurerm` provider and the `azapi` provider, which are two Terraform providers
    that can be used to provision and manage Azure resources.
  prefs: []
  type: TYPE_NORMAL
- en: Like Terraformer, the Azure Export Tool has several mechanisms for querying
    existing resources that should be included in the code generation process. It
    supports additional import options, such as a subscription-wide import, and eliminates
    the need to specify resource types. This can help speed up the process for Azure
    code generation by using a combination of `azurerm` and `azapi` providers. Since
    the `azapi` provider enables full support of every Azure resource, there are no
    resource type-based compatibility concerns that can’t be filled by using the `azapi`
    provider as a poly-fill when the `azurerm` resources are unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The command to import all the resources within a given Azure resource group
    would simply be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: It can be run in an interactive or non-interactive mode. The interactive mode
    allows the end user to review the resources that will be imported and mapped to
    their corresponding references in the Terraform code.
  prefs: []
  type: TYPE_NORMAL
- en: While the Azure Export Tool isn’t as widely known as the Terraformer project,
    it does have some interesting features that are useful within the context of Azure
    and the broader Terraform community as well. One example is the **append** feature
    that allows you to perform targeted code generation and append existing resources
    into an existing Terraform workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The allure of an efficient code generation tool for IaC and Terraform is very
    real. However, it is not without its limitations and common pitfalls that you
    should be aware of when venturing into this territory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest challenges with code generation tools for Terraform are not unique
    problems within the realm of Terraform and IaC, but ones that affect the approach
    of reverse engineering or code generation in general. Code that is generated using
    reverse engineering tools often lacks the craftsmanship that handwritten code
    has engrained within it from day one. This can result in not only functional defects
    that need to be ferreted out but also countless occurrences of code quality and
    readability issues that need to be resolved before the code base can really be
    used for its intended purpose: to maintain cloud environments via IaC.'
  prefs: []
  type: TYPE_NORMAL
- en: One functional problem that often crops up in imported Terraform code bases
    is over-zealously defined explicit dependencies using the `depends_on` meta-argument.
    The `depends_on` clause is a valuable tool for resolving implicit dependencies
    between resources that Terraform can’t otherwise pick up automatically. However,
    in most cases, an explicit definition of these dependencies between resources
    is unnecessary, adds additional bloat and complexity to the code base, and can
    be detrimental to readability.
  prefs: []
  type: TYPE_NORMAL
- en: Another example is that when the resource configuration is extracted from the
    cloud platform, its values are largely imported as hard-coded values that are
    scattered across all the resources declared. This creates an immediate backlog
    of technical debt to rationalize related constant values and extract a sane and
    then desirable set of input variables that can be used to define relevant configuration
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, there are often write-only attributes on Terraform resources that will
    not be returned by the cloud platform’s REST APIs because they contain sensitive
    or secret information. This is by design to protect against secret leakage and
    would not be a problem if the resource was originally provisioned from Terraform,
    as those sensitive values would be stored in the state. However, this creates
    a bit of a refactoring process because it means that in most cases, your Terraform
    code base will not pass `terraform validate`, let alone `terraform plan`, without
    errors that need to be resolved.
  prefs: []
  type: TYPE_NORMAL
- en: Running `plan` immediately after you generate the code and import the resources
    can help you pick up on subtle differences and irregularities in the import process.
    This can happen, as the terraform code generation is far from 100% accurate.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there are some pretty good options in the realm of tools that
    can automate the code generation and terraform state file creation of large landscapes
    of cloud resources across the multitude of Terraform providers available, including
    the three major cloud platforms that we focused on in this book. However, while
    code generation can expedite some parts of the process, it can also bring its
    own challenges that need to be addressed. In the next section, we’ll weigh the
    tradeoffs and discuss some best practices and alternatives for bringing existing
    environments under Terraform management.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve looked at the built-in capabilities within Terraform to import individual
    resources and at how we can identify the existing resources that we want to import
    on different cloud platforms. We recognized some of the limitations of the built-in
    capabilities and looked at 3rd party alternatives that offer options of importing
    entire environments en masse, as well as the current limitations of such options.
    Now, we’ll look at best practices for how and when to use these different approaches
    to import existing resources and environments to bring them under the management
    of Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: Blast radius
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When importing existing resources and bringing them under management using Terraform,
    it’s important to think carefully about the organization of those resources and
    how you want to compartmentalize them into working IaC solutions in the long term.
    This is the design principle of minimizing the **blast radius** of your Terraform
    modules. When we are importing resources, we are essentially establishing the
    boundaries of our root modules or Terraform workspaces.
  prefs: []
  type: TYPE_NORMAL
- en: This is the ideal time to perform this design, as the workspaces have yet to
    be organized. It’s important to think this through, as it will affect how easy
    it is to manage, update, and replicate parts of your infrastructure, depending
    on how you group resources together.
  prefs: []
  type: TYPE_NORMAL
- en: You should consider the function that the resources will play and who will be
    responsible for managing them. Suppose a central team is responsible for maintaining
    a certain part of the architecture. In that case, you may want to consider organizing
    these resources together within the same Terraform workspace to make it easier
    to control access and reduce friction between teams.
  prefs: []
  type: TYPE_NORMAL
- en: Use tags to narrow your resource filter as you use Terraformer or other tools
    to generate code within your Terraform workspaces. Pre-seeding the cloud resources
    with tags that are fit for purpose will help you maximize the effectiveness of
    the Terraform import tools you use. This is especially important in AWS, where
    you lack logical containers for resources like those that are present on Azure
    and Google Cloud with resource groups and projects, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes moving slowly is moving fast
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As an alternative to using an import tool to import resources on masse, you
    could use a lightweight technique using built-in import tools. This process is
    a bit tedious, but moving slowly sometimes allows you to be more purposeful and
    thoughtful. This process involves simply using querying techniques to identify
    the resources that you plan on importing and then scaffolding them using the most
    bare-bones Terraform resource definition. This resource definition is merely a
    placeholder and is very unlikely to match the configuration of the previously
    provisioned resource—but that’s not the point.
  prefs: []
  type: TYPE_NORMAL
- en: The point is to import the existing resource into the state and then run a `terraform
    plan` to determine the configuration differences. You can then use the resulting
    plan to adjust the resource definition’s configuration in code to match the output
    from the plan until there are no more changes required.
  prefs: []
  type: TYPE_NORMAL
- en: With this approach, you are taking the opposite approach to bulk tool-based
    import. Rather than wielding a machete and traipsing through the jungle, you wield
    a scalpel and make extremely thoughtful cuts. You will have to manually configure
    it, but it will give you a more systematic and step-by-step understanding of the
    components you are importing and bringing under management. This deeper understanding
    can help you identify dependencies and flaws in your design that might get swept
    under the rug when following a bulk import process.
  prefs: []
  type: TYPE_NORMAL
- en: Blue/green deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another option is to consider alternatives to importation. Importing is a messy
    and very error-prone business. If you have critical infrastructure that was manually
    provisioned, you might want to consider replacing it with newly provisioned environments
    that are already under Terraform management.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is called a **blue/green deployment**. It is a well-known release
    management strategy whereby the existing **blue** environment is replaced through
    the construction of a new **green** environment. After the green environment is
    fully tested and ready to go, we perform a cutover operation to transition from
    the blue environment to the green environment.
  prefs: []
  type: TYPE_NORMAL
- en: You can set up new environments and transition workloads and applications into
    those. This will allow you to have a clean separation between environments that
    were provisioned manually without proper governance in place and those for which
    you followed best practices. Slowly transition your workloads, a piece at a time,
    to the new well-organized environment until the legacy environment is simply shut
    off.
  prefs: []
  type: TYPE_NORMAL
- en: Using code generators will likely produce code of extremely poor quality that
    will require extensive refactoring. While some of this will be simple input variable
    extraction, moving resources into modules will become extremely tedious as the
    complexity of the environment increases. The effort to perform an import, refactor,
    and transform process might actually be greater than writing from scratch and
    cutting over gradually.
  prefs: []
  type: TYPE_NORMAL
- en: When you weigh the cost of putting the legacy environment into a “keep the lights
    on” mode while you build out the new world order, this allows your organization
    to maintain some normalcy and slowly adapt to the change of using IaC-managed
    environments over time rather than in one fell swoop.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discussed some important rules of thumb for importing existing
    resources and environments under Terraform management. If you plan on performing
    bulk imports, first recognize the limitations of the tool that you will use and
    build in ample time for refactoring. Most importantly, make sure that you narrow
    the focus by defining a focused blast radius around your deployments.
  prefs: []
  type: TYPE_NORMAL
- en: If combing through a mountain of junk code and cleaning it all up through extensive
    refactoring doesn’t sound like your cup of tea, consider moving slowly by either
    reconstructing the environment through a highly focused step-by-step import process
    or going all the way and planning a blue/green deployment. My preferred method
    is blue/green, but you must carefully assess the impact on production environments
    to determine whether this is the best option for you.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at Terraform’s built-in capabilities for importing
    existing resources into Terraform state using imperative and declarative approaches.
    While the built-in import capabilities lack any sort of code generation, we looked
    at a few open source tools that analyzed existing environments and generated HashiCorp
    Configuration Language code to manage the resources and provide for them to be
    imported into the state. We discussed the relevant trade-offs between these different
    import techniques and when to consider each, which should help you decide the
    best course of action for your organization and teams. In the next chapter, we’ll
    look at how to manage and operate existing environments using Terraform.
  prefs: []
  type: TYPE_NORMAL
