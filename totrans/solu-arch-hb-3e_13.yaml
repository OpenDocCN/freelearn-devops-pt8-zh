- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Machine Learning Architecture
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习架构
- en: In the previous chapter, you learned about ingesting and processing big data
    and getting insights to understand your business. In the traditional way of running
    a business, the organization’s decision maker looks at past data and uses their
    experience to plot the future course of the company’s direction. It’s not just
    about setting up the business vision but also improving the end user experience
    by predicting and fulfilling their needs or automating day-to-day decision-making
    activities such as loan approval.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你了解了如何摄取和处理大数据，并通过洞察数据来理解你的业务。在传统的商业运营方式中，组织的决策者会查看过去的数据，并通过他们的经验来规划公司未来的发展方向。这不仅仅是设定商业愿景的问题，还包括通过预测和满足最终用户的需求或自动化日常决策活动（例如贷款审批）来改善用户体验。
- en: However, with the sheer amount of data available now, it’s become difficult
    for the human brain to process all data and predict the future. That’s where **artificial
    intelligence (AI)** and **machine learning** (**ML**) come in. AI is the broader
    concept of machines carrying out tasks in smart ways like Siri and Alexa to understand
    your questions and give answers, and ML is a specific subset of AI that involves
    teaching computers to learn and make decisions based on data. They help us to
    predict future courses of action by looking at a large amount of historical data.
    Most enterprises are investing in ML today, primarily because of the acceleration
    brought by generative AI (GenAI). ML is fast becoming the technology that helps
    companies differentiate themselves—through the creation of new products, services,
    and business models, allowing them to innovate and gain a competitive advantage.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着如今可用数据量的庞大，人类大脑已经很难处理所有数据并预测未来。正是因为这样，**人工智能（AI）**和**机器学习（ML）**才应运而生。人工智能是机器以智能方式执行任务的更广泛概念，比如Siri和Alexa能够理解你的问题并给出答案；而机器学习是人工智能的一个特定子集，涉及让计算机通过数据学习并做出决策。它们帮助我们通过查看大量的历史数据来预测未来的行动方向。如今，大多数企业正在投资机器学习，主要是因为生成式人工智能（GenAI）带来的加速发展。机器学习正迅速成为帮助企业脱颖而出的技术——通过创造新产品、服务和商业模式，使企业能够创新并获得竞争优势。
- en: AI and ML are excellent for solving business problems because they present countless
    use cases in different lines of business across a company, and the high degree
    of impact these use cases can make. For example, with ML you can build a new level
    of customer service with call center intelligence or help marketing teams deliver
    on their personalization objectives by using an ML-based personalized marketing
    campaign.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）和机器学习（ML）非常适合解决商业问题，因为它们在公司不同业务领域中提供了无数的应用场景，并且这些应用场景所带来的影响程度也很高。例如，通过机器学习，你可以通过呼叫中心智能化提升客户服务水平，或者帮助市场营销团队通过使用基于机器学习的个性化营销活动实现个性化目标。
- en: 'Within the scope of this chapter, we’ll cover the following topics to handle
    and manage your ML needs:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的范围内，我们将涵盖以下主题来处理和管理你的机器学习需求：
- en: What is machine learning?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Working with data science and machine learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与数据科学和机器学习的合作
- en: Machine learning in the cloud
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云中的机器学习
- en: Building machine learning architecture
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建机器学习架构
- en: Design principles for machine learning architecture
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习架构的设计原则
- en: MLOps
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLOps
- en: Deep learning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习
- en: '**Natural language processing** (**NLP**)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理**（**NLP**）'
- en: By the end of this chapter, you will have an understanding of ML architecture.
    You will learn about the various ML models and the ML workflow. You will understand
    the process of creating an ML model pipeline through feature engineering, model
    training, inference, and model evaluation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将对机器学习架构有一定的了解。你将学习各种机器学习模型以及机器学习工作流。你将理解通过特征工程、模型训练、推断和模型评估等过程创建机器学习模型管道的过程。
- en: What is machine learning?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Machine learning drives better customer experiences, more efficient business
    operations, and faster, more accurate decision making. With the rise in compute
    power and the proliferation of data, ML has moved from the periphery to become
    a core differentiator for businesses and organizations across industries. ML use
    cases can apply to most businesses, like personalized product and content recommendations,
    contact center intelligence, virtual identity verification, and intelligent document
    processing. There are also customized use cases built for specific industries—like
    clinical trials in pharma or assembly line quality control in manufacturing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习推动了更好的客户体验、更高效的业务运作以及更快速、更准确的决策制定。随着计算能力的提升和数据的泛滥，机器学习已从外围技术发展为各行业企业和组织的核心竞争力。机器学习的应用场景可以涵盖大多数企业，例如个性化产品和内容推荐、呼叫中心智能化、虚拟身份验证和智能文档处理等。也有为特定行业量身定制的应用场景，如制药行业的临床试验或制造业的生产线质量控制。
- en: 'ML uses technology in order to find new trends and inculcate mathematical predictive
    models based on past factual data. ML can help to solve complex problems such
    as the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习通过技术来发现新趋势，并基于过去的事实数据建立数学预测模型。机器学习能够帮助解决一些复杂问题，诸如以下问题：
- en: You may need to learn how to create complex code rules to make a decision; for
    example, if you want to recognize people’s emotions in images and speech, there
    are no easy ways to code the logic to achieve that.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可能需要学习如何创建复杂的代码规则来做出决策；例如，如果您想识别图像和语音中的人类情感，目前没有简单的方式编写逻辑来实现这一目标。
- en: When you need to analyze a large amount of data for decision making and the
    volume of data is too large for a human to do this efficiently. For example, while
    a human can do it with spam detection, the amount of data makes it impractical
    to do this quickly.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当需要分析大量数据以做出决策，而数据量过大，人类无法高效处理时。例如，虽然人类可以进行垃圾邮件检测，但数据量大到使得快速完成这一任务变得不切实际。
- en: Relevant information may only become available dynamically when you need to
    adapt and personalize user behavior based on individual data; for example, with
    individualized product recommendations or website personalization.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关信息可能仅在您需要时动态生成，此时需要根据个人数据调整和个性化用户行为；例如，个性化的产品推荐或网站个性化。
- en: When many tasks with a lot of data are available, you cannot track the information
    fast enough to make a rule-based decision—for example, fraud detection and NLP.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当有大量数据任务需要处理时，无法足够迅速地跟踪信息以做出基于规则的决策——例如，欺诈检测和自然语言处理（NLP）。
- en: 'Humans handle data prediction based on the results of their analyses and their
    experiences. Using ML, you can train a computer to provide expertise based on
    available data and get a prediction based on new data. Here are some prevalent
    use cases for ML across various industries:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 人类基于分析结果和经验进行数据预测。通过机器学习，可以训练计算机根据可用数据提供专业知识，并基于新数据进行预测。以下是机器学习在各行各业的几种普遍应用场景：
- en: '**Predictive maintenance**: Predict whether a component will fail in advance
    based on sensor data. This is commonly applied in estimating the **remaining useful
    life** (**RUL**) of automotive fleets, manufacturing equipment, and IoT sensors.
    Its primary benefits are increased vehicle and equipment uptime and significant
    cost savings. This application is widespread in the automotive and manufacturing
    industries.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测性维护**：根据传感器数据预测组件是否会提前发生故障。常用于估算**剩余使用寿命**（**RUL**）的预测，适用于汽车车队、制造设备和物联网传感器。其主要好处是提高车辆和设备的正常运行时间，显著节省成本。这一应用广泛存在于汽车和制造行业。'
- en: '**Demand forecasting**: Use historical data to project key demand metrics quicker
    and more accurately, aiding in making more accurate business decisions about production,
    pricing, inventory management, and purchasing/restocking. The main advantages
    include meeting customer demand, minimizing inventory carrying costs by reducing
    surplus inventory, and decreasing waste. Industries like financial services, manufacturing,
    retail, and, **consumer packaged goods** (**CPG**) frequently employ this use
    case.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需求预测**：利用历史数据更快速、准确地预测关键需求指标，从而帮助做出关于生产、定价、库存管理以及采购/补货的更准确商业决策。其主要优势包括满足客户需求、通过减少多余库存来最小化库存持有成本，以及减少浪费。金融服务、制造业、零售业以及**消费品包装商品**（**CPG**）等行业经常使用这一应用场景。'
- en: '**Fraud detection**: Automate the identification of potentially fraudulent
    activities and flag them for further review. The primary benefit of this is the
    reduction of costs related to fraud and the maintenance of customer trust. This
    use case is implemented in the financial services and online retail sectors.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欺诈检测**：自动识别潜在的欺诈活动并标记以供进一步审查。其主要好处是减少与欺诈相关的成本，并保持客户信任。这个用例在金融服务和在线零售行业得到了应用。'
- en: '**Credit risk prediction**: Explain individual predictions from credit applications
    to predict the likelihood of whether credit will be paid back or not (often called
    a *credit default*). The benefit lies in identifying bias and complying with regulatory
    requirements. This use case is predominantly used in the financial services and
    online retail industries.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信用风险预测**：解释信用申请中的个体预测，以预测是否会按时还款的可能性（通常称为*信用违约*）。其好处在于识别偏见并遵守监管要求。这个用例主要用于金融服务和在线零售行业。'
- en: '**Data extraction and analysis from documents**: Understand text in handwritten
    and digital documents, extracting information for classification, and decision-making
    purposes. This use case is widespread in sectors like healthcare, financial services,
    legal, mechanical, electrical, and education industries.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从文档中提取和分析数据**：理解手写和数字文档中的文本，提取信息用于分类和决策。这种用例在医疗、金融服务、法律、机械、电气和教育等行业中广泛应用。'
- en: '**Personalized recommendations**: Make customized recommendations based on
    historical data. This approach is common in the retail and education sectors.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化推荐**：基于历史数据做出定制化推荐。这种方法在零售和教育行业中很常见。'
- en: '**Churn prediction**: Estimate the probability of customers discontinuing their
    services. This is often utilized in industries such as retail, education, and
    **software as a service** (**SaaS**) providers.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流失预测**：估算客户停止使用服务的概率。这通常应用于零售、教育和**软件即服务**（**SaaS**）提供商等行业。'
- en: The main idea behind ML is to make available a training dataset to an ML algorithm
    and have it predict something from a new dataset, for example, feeding some historical
    stock market trend data to an ML model and having it predict how the market will
    fluctuate in the next six months to one year.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的主要思想是为机器学习算法提供一个训练数据集，让其从新的数据集中进行预测，例如，将一些历史股市趋势数据提供给机器学习模型，并让其预测市场在未来六个月到一年的波动情况。
- en: When developing ML systems, it’s important to carefully combine data and code.
    Both must come together in an organized manner and should evolve in a controlled
    way to build toward the common goal of a robust and scalable ML system.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发机器学习系统时，重要的是要谨慎地结合数据和代码。两者必须有组织地结合在一起，并且应该以受控的方式发展，以朝着构建一个强大且可扩展的机器学习系统的共同目标迈进。
- en: The data you use for training, testing, and making decisions with the ML system
    inference will change over time as data comes from different places. Your code
    also needs to change with data to accommodate data from various sources. Without
    a systematic approach, there can be divergence in how code and data change. This
    mismatch can cause problems when you try to use your ML system for real tasks.
    It can also get in the way of smooth deployment, and lead to results that are
    hard to understand, trace, or repeat later. There are various types of ML; let’s
    explore them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你用来训练、测试和进行机器学习系统推断决策的数据会随着时间的推移发生变化，因为数据来自不同的地方。你的代码也需要随着数据的变化而改变，以适应来自不同来源的数据。如果没有系统的方法，代码和数据的变化可能会发生偏离。这种不匹配可能会在你尝试将机器学习系统应用于实际任务时引发问题。它还可能妨碍平稳部署，并导致难以理解、追溯或后续重现的结果。机器学习有多种类型，让我们来探索一下。
- en: Types of machine learning
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: 'ML helps computers learn things without us needing to program every detail.
    It is like teaching computers to learn from experience. Imagine teaching your
    dog a trick: you show it what to do, and then it learns and does it! With ML,
    computers can learn from data and then use this learning to make decisions. Let’s
    look at the different ways computers can learn.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习帮助计算机无需我们编写每个细节就能学会某些东西。就像教狗狗一个新动作：你展示给它看，之后它学会了并且做出来！通过机器学习，计算机可以从数据中学习，然后利用这些学习做出决策。让我们来看看计算机学习的不同方式。
- en: Supervised learning
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: In supervised learning, the algorithm is given a set of training examples where
    the data and target decisions are known. It can then predict the target value
    for new datasets containing the same attributes. With this type of learning, the
    algorithm is taught using a dataset where input data comes with the correct answer
    or target. The algorithm learns to connect inputs with their correct outputs using
    these examples.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，算法被提供一组训练示例，其中数据和目标决策是已知的。然后，它可以预测包含相同属性的新数据集的目标值。在这种学习类型中，算法通过一个输入数据附带正确答案或目标的数据集进行学习。算法通过这些示例学习将输入与其正确输出关联起来。
- en: This type of learning is often used for tasks where you need to classify things
    into categories or predict numbers, like in classification and regression tasks.
    For example, it can be used to classify emails as spam or not spam or to predict
    the price of a house based on its features.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种学习类型通常用于需要将事物分类到不同类别或预测数字的任务，例如分类和回归任务。例如，它可以用来将电子邮件分类为垃圾邮件或非垃圾邮件，或根据房屋的特征预测房价。
- en: Unsupervised learning
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: In unsupervised learning, the algorithm is provided with a massive volume of
    data and should discover patterns and relationships among the data. It can then
    draw inferences from datasets.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，算法会提供大量数据，并应在数据中发现模式和关系。然后，它可以从数据集中推断出结论。
- en: Human intervention is not required in unsupervised learning, for example, auto-classification
    of documents based on context. It addresses the problem where correct output is
    unavailable for training examples, and the algorithm must find patterns in data
    using clustering.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，不需要人工干预，例如根据上下文进行文档的自动分类。它解决了正确输出无法用于训练示例的问题，算法必须通过聚类在数据中发现模式。
- en: In unsupervised learning, a model is trained using an unlabeled dataset. The
    algorithm works on its own to discover patterns, structures, or relationships
    in the data without any specific guidance or labeled examples to follow. This
    type of learning is often applied to clustering, dimensionality reduction, and
    density estimation tasks. News agencies or legal firms often deal with massive
    data. Using unsupervised learning, they can automate document categorization,
    efficiently manage their digital repositories, and improve information retrieval
    processes, such as recommending similar articles or cases to readers or researchers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，模型使用未标记的数据集进行训练。算法自主工作，发现数据中的模式、结构或关系，而无需任何特定的指导或标记示例。此类学习常应用于聚类、降维和密度估计任务。新闻机构或法律事务所通常处理大量数据。通过无监督学习，它们可以实现文档自动分类，高效管理数字存储库，并改进信息检索过程，例如向读者或研究人员推荐相似的文章或案例。
- en: Semi-supervised learning
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 半监督学习
- en: This approach mixes elements of both supervised and unsupervised learning. It
    involves using a small amount of labeled data along with a more significant amount
    of unlabeled data to improve model performance. Semi-supervised learning is particularly
    useful when obtaining labeled data is either costly or takes a lot of time. It’s
    often used in scenarios where there’s a limited amount of labeled data, but plenty
    of unlabeled data. Within the biomedical field, for example, semi-supervised learning
    can be very advantageous. For instance, annotating medical images requires a lot
    of time and resources, making semi-supervised learning a practical solution. Models
    can be initially trained on a small set of labeled images and then fine-tuned
    using a more extensive set of unlabeled images, maximizing utility while minimizing
    costs and resources.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法结合了监督学习和无监督学习的元素。它涉及使用少量标记数据与大量未标记数据一起使用，以提高模型性能。半监督学习特别有用，尤其是在获取标记数据既昂贵又耗时的情况下。通常应用于标记数据有限但未标记数据充足的场景。例如，在生物医学领域，半监督学习可以非常有利。例如，标注医学图像需要大量时间和资源，这使得半监督学习成为一种实用的解决方案。模型可以先在一小部分标记图像上进行训练，然后使用更多未标记的图像进行微调，从而最大化效用并最小化成本和资源消耗。
- en: Reinforcement learning
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习
- en: This type of learning involves training agents (or computer programs) to make
    a series of sequential decisions in a certain setting. The goal is for the agent
    to learn the best actions to take in order to maximize a cumulative reward over
    time. Agents learn by taking action, receiving feedback (rewards or punishments),
    and adjusting their strategies. Reinforcement learning is used in autonomous robotics,
    game playing (e.g., AlphaGo), and recommendation systems. Autonomous vehicles
    employ reinforcement learning by navigating through traffic and adjusting actions
    based on the environment, thus ensuring optimal decision making in diverse scenarios.
    The vehicle makes sequences of decisions (like changing lanes, adjusting speed,
    etc.), receiving positive reinforcement for safe, efficient actions and negative
    reinforcement for undesirable actions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种学习类型涉及训练代理（或计算机程序）在特定环境中做出一系列顺序决策。目标是让代理学会采取最佳行动，以便在时间推移中最大化累积奖励。代理通过采取行动、接收反馈（奖励或惩罚）并调整策略来学习。强化学习广泛应用于自主机器人、游戏对抗（例如
    AlphaGo）和推荐系统。自动驾驶车辆通过在交通中导航，并根据环境调整行动，来应用强化学习，从而确保在各种情境下做出最优决策。车辆会做出一系列决策（如变换车道、调整车速等），对于安全高效的行动给予正向强化，而对于不良行为给予负向强化。
- en: Self-supervised learning
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自监督学习
- en: This is a type of unsupervised learning where the algorithm generates labels
    or targets from the data. It often involves tasks like predicting missing parts
    of data. Self-supervised learning has gained popularity in NLP and computer vision
    for pre-training models on large datasets before fine-tuning specific tasks. In
    image processing or computer vision, self-supervised learning can be employed
    to predict the next frame in a video sequence, thus facilitating models that understand
    movement and development within visual data. Pre-training models in this manner
    and then fine-tuning them for specific tasks, like object detection, can yield
    impressive results.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种无监督学习类型，其中算法从数据中生成标签或目标。它通常涉及预测数据中的缺失部分等任务。自监督学习在自然语言处理（NLP）和计算机视觉中广受欢迎，常用于在大规模数据集上预训练模型，然后对特定任务进行微调。在图像处理或计算机视觉中，自监督学习可以用于预测视频序列中的下一个帧，从而帮助模型理解视觉数据中的运动和发展。通过这种方式对模型进行预训练，再针对具体任务（如物体检测）进行微调，能够获得令人印象深刻的结果。
- en: Multi-instance learning
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多实例学习
- en: In multi-instance learning, each data point is a bag containing multiple instances
    (sub-data points). The goal is to learn from bags of data while only having access
    to bag-level labels. Multi-instance learning has applications in drug discovery,
    image classification, and content-based image retrieval. Considering e-commerce
    platforms, multi-instance learning could be employed to predict whether a user
    will purchase a product within a session (a bag), using various instances like
    page views, clicked products, and time spent on pages. The bag-level label might
    indicate whether a purchase was made during that session, providing a robust basis
    for predictions and personalized content delivery.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在多实例学习中，每个数据点是一个包含多个实例（子数据点）的袋。目标是从数据袋中学习，同时仅能访问袋级别的标签。多实例学习在药物发现、图像分类和基于内容的图像检索中有应用。在电子商务平台中，多实例学习可以用于预测用户在一次会话（一个数据袋）中是否会购买产品，使用的不同实例如页面浏览量、点击的产品以及在页面上的停留时间。袋级标签可能会指示该会话期间是否发生了购买，从而为预测和个性化内容推荐提供了坚实的基础。
- en: These diverse learning paradigms, each with its own specialty and application
    area, make ML a versatile field, adaptable to various scenarios and challenges
    across industries and domains. By choosing a paradigm tailored to the specificities
    and available data of a given problem, ML practitioners can derive insightful
    models and facilitate intelligent, automated decision-making across applications.
    The key is to select a learning type that aligns best with the available data
    and the problem at hand, ensuring that models are both robust and applicable.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些多样的学习范式，每种都有其专长和应用领域，使得机器学习成为一个多才多艺的领域，能够适应各个行业和领域中的不同场景与挑战。通过选择一个与特定问题的特点和可用数据相匹配的范式，机器学习从业者能够推导出有洞察力的模型，并推动智能化、自动化决策的应用。关键在于选择最适合现有数据和问题的学习类型，确保模型既强健又具有可应用性。
- en: In the next section, let’s learn how data science goes hand in hand with ML.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将学习数据科学是如何与机器学习（ML）紧密结合的。
- en: Working with data science and machine learning
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与数据科学和机器学习合作
- en: ML is all about working with data. The quality of the training data is crucial
    to the success of an ML model. High-quality data leads to a more accurate ML model
    and the right prediction.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）完全是关于数据的工作。训练数据的质量对 ML 模型的成功至关重要。高质量的数据可以带来更准确的 ML 模型和正确的预测。
- en: Data often has multiple issues, such as missing values, noise, bias, outliers,
    and so on. Exploring the data makes us aware of this, providing us with necessary
    information on data quality and cleanliness, interesting patterns in the data,
    and likely paths forward once you start modeling. Data science includes data collection,
    data preparation, analysis, preprocessing, and feature engineering.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 数据常常存在多个问题，如缺失值、噪声、偏差、离群值等。探索数据使我们意识到这些问题，为我们提供有关数据质量和清洁度的信息，揭示数据中的有趣模式，并在开始建模后指引可能的前进路径。数据科学包括数据收集、数据准备、分析、预处理和特征工程。
- en: Data preparation is the first step in building an ML model. It is time consuming
    and constitutes up to 80% of the time spent on ML development. Data preparation
    has always been considered tedious and resource intensive due to the inherent
    nature of data being “dirty” and not ready for ML in its raw form. “Dirty” data
    could include missing or erroneous values and outliers. Feature engineering is
    often needed to transform the inputs to deliver more accurate and efficient ML
    models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备是构建 ML 模型的第一步。它耗时且占据了 ML 开发中高达 80% 的时间。由于数据本身“脏”且未经处理，数据准备一直被认为是繁琐且资源密集型的。“脏”数据可能包括缺失值、错误值和离群值。通常需要进行特征工程来转换输入数据，从而提供更准确和高效的
    ML 模型。
- en: The first step in data preparation is to understand the business problem. Data
    scientists are often eager to jump into the data directly, start coding, and produce
    insights. However, without a clear understanding of the business problem, any
    insights you develop have a high chance of becoming a solution that cannot address
    the problem at hand. It makes much more sense to start with a straightforward
    user story and business objectives before getting lost in the data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备的第一步是理解业务问题。数据科学家通常急于直接跳入数据中，开始编写代码并产生洞见。然而，如果没有清楚地理解业务问题，任何产生的洞见都有很大的可能变成无法解决实际问题的方案。比起陷入数据的细节，先从简单的用户故事和业务目标出发显得更有意义。
- en: After building a solid understanding of the business problem, you can narrow
    down the ML problem categories and determine whether ML will be suitable to solve
    your business problem.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入理解业务问题之后，你可以缩小 ML 问题的类别，并确定 ML 是否适合用来解决你的业务问题。
- en: Data preparation often involves multiple steps such as data cleaning, dealing
    with missing values, data normalization/standardization, and data labeling. You
    will learn about these steps in detail in the upcoming *Building machine learning
    architecture* section later in this chapter. Most standalone data preparation
    tools are equipped with functionalities for data transformation, feature engineering,
    and visualization. Data transformation might include tasks like converting currencies
    (for example, from dollars to euros) or changing measurement units (such as from
    kilograms to pounds). Feature engineering involves creating new data columns (features)
    from existing ones to enhance the dataset’s utility for ML models; for instance,
    extracting the day of the week or the month from a date column can help the model
    discern time-related patterns. While these tools excel in preparing data, they
    often lack built-in capabilities for model validation, a critical step in assessing
    an ML model’s performance. What’s needed is a framework that provides all these
    capabilities in one place and is tightly integrated with the rest of the ML pipeline.
    Data preparation modules therefore need curation and integration before they are
    deployed in production.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备通常包括多个步骤，如数据清理、处理缺失值、数据规范化/标准化和数据标注。在本章后续的*构建机器学习架构*部分，你将详细学习这些步骤。大多数独立的数据准备工具都配备了数据转换、特征工程和可视化功能。数据转换可能包括诸如货币转换（例如，从美元转换为欧元）或单位转换（例如，从千克转换为磅）等任务。特征工程则涉及从现有数据中创建新的数据列（特征），以增强数据集在
    ML 模型中的有效性；例如，从日期列中提取星期几或月份信息可以帮助模型识别与时间相关的模式。尽管这些工具在数据准备上表现出色，但它们通常缺乏内置的模型验证功能，而模型验证是评估
    ML 模型性能的关键步骤。所需的是一个能够提供所有这些功能，并且与 ML 流水线其他部分紧密集成的框架。因此，数据准备模块在部署到生产环境之前需要经过整理和整合。
- en: 'As shown in the following diagram, data preprocessing and learning to create
    an ML model are interconnected—your data preparation will heavily influence your
    model, while the model you choose heavily influences the type of data preparation
    you will do. Finding the correct balance is highly iterative and is very much
    an art (or trial and error):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，数据预处理和学习以创建机器学习模型是相互关联的——数据准备将深刻影响你的模型，而你选择的模型也将深刻影响你将进行的类型的数据准备。找到正确的平衡是一个高度迭代的过程，实际上非常像一门艺术（或试错法）：
- en: '![](img/B21336_13_01.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21336_13_01.png)'
- en: 'Figure 13.1: ML workflow'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：机器学习工作流
- en: 'As shown in the preceding diagram, the ML workflow includes the following phases:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，机器学习工作流包括以下几个阶段：
- en: '**Preprocessing**: In this phase, the data scientist preprocesses the data
    and divides it into training (70% of the data), validation (10% of the data),
    and testing (20% of the data) datasets. Your ML model is trained using the training
    dataset, which helps it learn and give the right prediction. Once training is
    complete, the model is then evaluated with a separate validation dataset to assess
    its performance and generalization capabilities. Once the model is ready, you
    can test it using a testing dataset. Features are independent attributes of your
    dataset that may or may not influence the outcome. Feature engineering involves
    finding the right feature, which can help to achieve model accuracy. The label
    is your target outcome, which is dependent on feature selection. You can apply
    dimensionality reduction to choose the right feature, which filters and extracts
    the most compelling feature for your data.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理**：在这一阶段，数据科学家会对数据进行预处理，并将其划分为训练集（占数据的70%）、验证集（占数据的10%）和测试集（占数据的20%）。你的机器学习模型将使用训练集进行训练，这有助于它学习并给出正确的预测。一旦训练完成，模型将使用单独的验证数据集进行评估，以评估其性能和泛化能力。模型准备好后，你可以使用测试数据集对其进行测试。特征是数据集中的独立属性，可能会影响结果，也可能不会。特征工程包括寻找正确的特征，这可以帮助实现模型的准确性。标签是你的目标结果，依赖于特征选择。你可以应用降维方法来选择正确的特征，从而筛选和提取出最有力的特征。'
- en: '**Learning**: You select the appropriate ML algorithm per the business use
    case and data in this phase. This is the core of the ML workflow, where you train
    your ML model on your training dataset. To achieve model accuracy, you need to
    experiment with various hyperparameters and perform model selection. Hyperparameters
    are the configuration settings used to control the learning process in ML algorithms.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习**：在这一阶段，你根据业务用例和数据选择合适的机器学习算法。这是机器学习工作流的核心，你将在训练数据集上训练你的机器学习模型。为了实现模型的准确性，你需要尝试各种超参数并进行模型选择。超参数是用来控制机器学习算法学习过程的配置设置。'
- en: '**Evaluation**: Once your ML model has been trained in the learning phase,
    you want to evaluate its accuracy with a known dataset. To assess your model,
    you use the validation dataset kept aside during the preprocessing step. Required
    model tuning needs to be performed per the evaluation result if your model prediction
    accuracy needs to be revised to the exceptions determined by validation data.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估**：一旦你的机器学习模型在学习阶段完成训练，你需要使用已知数据集来评估其准确性。为了评估你的模型，你将使用在预处理步骤中保留的验证数据集。如果模型预测的准确性需要根据验证数据的预期进行修订，则需要根据评估结果进行必要的模型调优。'
- en: '**Prediction**: Prediction is also known as inference. In this phase, you deploy
    your model and start making a prediction. These predictions can be made in real
    time or in batches.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**：预测也叫做推理。在这一阶段，你将部署模型并开始进行预测。这些预测可以是实时进行的，也可以是批量进行的。'
- en: GenAI has led a paradigm shift in the landscape of ML and AI. At its core are
    **foundational models** (**FMs**) like GPT-4, which have been trained on vast,
    internet-scale datasets, redefining the conventional norms of data labeling and
    model customization. This groundbreaking technology empowers organizations to
    fine-tune FMs with limited data tokens, thereby significantly reducing the manual
    effort and time traditionally associated with data preparation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI引领了机器学习和人工智能领域的范式转变。其核心是**基础模型**（**FMs**），如GPT-4，这些模型已经在庞大的互联网级数据集上进行了训练，重新定义了数据标注和模型定制的传统规范。这项开创性技术使得组织能够在有限的数据令牌下微调基础模型，从而大大减少了传统数据准备过程中所需的人工努力和时间。
- en: However, it is vital to recognize that GenAI is not a silver bullet because
    it is not designed to address all AI and ML problems. Also, the development of
    FMs is a resource-intensive endeavor, demanding substantial computational power
    and access to extensive datasets. As such, many enterprises opt to leverage FMs
    provided by renowned third-party companies, such as OpenAI, Google, Meta, and
    Anthropic, who have pioneered the development of these models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须认识到，生成式人工智能（GenAI）并非灵丹妙药，因为它并非设计来解决所有的人工智能和机器学习问题。此外，生成式模型（FM）的开发是一项资源密集型的工作，需要大量的计算能力和广泛的数据集。因此，许多企业选择利用由知名第三方公司提供的生成式模型，例如
    OpenAI、谷歌、Meta 和 Anthropic，这些公司在这些模型的开发中处于领先地位。
- en: Nonetheless, the story does not end there. Custom model training remains a compelling
    option, especially when specific, tailored solutions are required. While GenAI
    provides an innovative approach to problem solving, the strategic decision to
    adopt it should align with an organization’s unique goals, resources, and constraints.
    You will learn more about GenAI in *Chapter 14*, *Generative AI Architecture*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，故事并不止于此。定制化模型训练仍然是一个有吸引力的选择，特别是当需要特定的定制解决方案时。尽管生成式人工智能提供了一种创新的问题解决方法，但采纳它的战略决策应与组织的独特目标、资源和约束相一致。您将在*第14章*《生成式人工智能架构》中了解更多关于生成式人工智能的内容。
- en: As per your data input, the ML model often has overfitting or underfitting issues,
    which you must consider to get the right outcome. Let’s learn more about this.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的数据输入，机器学习模型常常会出现过拟合或欠拟合问题，您必须考虑这些问题以获得正确的结果。让我们深入了解一下这个问题。
- en: Evaluating ML models—overfitting versus underfitting
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估机器学习模型——过拟合与欠拟合
- en: In overfitting, your model needs to generalize, which means it should perform
    well not just on the data it was trained on (the training set) but also on new,
    unseen data (the test set or validation set). If a model is overfitting, it has
    essentially memorized the training data, capturing noise along with the underlying
    pattern, which leads to poor performance on any new data. If a model shows high
    performance metrics on the training data but significantly lower metrics on the
    test data, it’s a sign of overfitting.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在过拟合中，模型需要进行泛化，这意味着它不仅要在其训练过的数据（训练集）上表现良好，还要在新的、未见过的数据（测试集或验证集）上也能表现出色。如果模型发生过拟合，实际上它已经记住了训练数据，捕捉了噪声和底层模式，这会导致在任何新数据上的表现较差。如果模型在训练数据上的表现指标很高，但在测试数据上的指标显著较低，这就是过拟合的标志。
- en: This typically indicates that the model is too flexible for the amount of training
    data, allowing it to *memorize* the data, including noise. Overfitting corresponds
    to high variance, where small changes in the training data result in significant
    changes to the results.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常表示模型对训练数据的灵活性过高，使其能够*记住*数据，包括噪声。过拟合对应于高方差，在这种情况下，训练数据的微小变化会导致结果的显著变化。
- en: In underfitting, your model fails to capture essential patterns in the training
    dataset. Typically, underfitting indicates that the model is too simple or has
    too few explanatory variables. An underfitting model needs to be more flexible
    to model real patterns and corresponds to high bias, indicating that the results
    show a systematic lack of fit in a certain region.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在欠拟合中，模型未能捕捉训练数据集中的重要模式。通常，欠拟合表示模型过于简单或解释变量过少。欠拟合模型需要更加灵活，以便能够建模真实的模式，并对应于高偏差，表明结果在某个区域系统性地缺乏拟合。
- en: 'The following graphs illustrate the clear difference between overfitting and
    underfitting, as they correspond to a model with a good fit:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表清晰地展示了过拟合与欠拟合之间的区别，因为它们对应于一个拟合良好的模型：
- en: '![A diagram of good compromise  Description automatically generated with low
    confidence](img/B21336_13_02.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![良好折衷的图示，描述自动生成且置信度较低](img/B21336_13_02.png)'
- en: 'Figure 13.2: ML model overfitting versus underfitting'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2：机器学习模型的过拟合与欠拟合
- en: The ML model categorizes two data point categories, illustrated by the preceding
    graphs’ rings and crosses. The ML model tries to determine whether a customer
    will buy a given product or not. The chart shows predictions from three different
    ML models. You can see an overfitted model (on the right) traversing through all
    ringed data points in training and failing to generalize the algorithm for real-world
    data outside of the training dataset. On the other hand, the underfitted model
    (on the left) leaves out several data points and needs to be more accurate. A
    good model (shown in the middle) usually provides clear data point predictions.
    Creating a good ML model is like creating art; you can find the right fit with
    model tuning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Popular machine learning algorithms
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The popularity of an algorithm often depends on its applicability and performance
    in diverse use cases, ease of understanding, and implementation, as well as its
    ability to scale and adapt to different types of data. Let’s look at some popular
    ML algorithms.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Linear regression tries to understand how one thing (let’s say, *X*) can help
    predict another thing (*Y*) by finding a linear relationship between them. Imagine
    you’re at a farmer’s market. When you observe the prices of pumpkins, you notice
    that as the size of the pumpkin increases, so does its price. Linear regression
    acts like drawing a straight line through all the price points of pumpkins, ensuring
    the line is as close to all points as possible.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Real estate is a sector where linear regression plays a vital role. For instance,
    if a company wants to predict the selling price of a house, it will look at features
    like the number of rooms, location, and age of the property. If houses with more
    rooms have typically been sold for higher prices in the past, the model will predict
    a higher price for houses with more rooms in the future. It’s like predicting
    the price of our pumpkin based on its size.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logistic regression tells you the probability or chance of something happening,
    with “yes” or “no” answers. Imagine you are trying to predict whether a book will
    be a bestseller or not. Logistic regression will look at features like the number
    of pages, the popularity of the author, and the genre to predict the likelihood
    (between `0` and `1`) of it becoming a bestseller.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: In healthcare, logistic regression can predict the likelihood of a patient having
    a disease based on various symptoms and test results. For example, by considering
    factors like age, blood pressure, and cholesterol levels, it can predict the probability
    of a person having heart disease. Doctors might conduct further tests if the probability
    is high, ensuring early and proactive management of potential health risks.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Decision trees help you make a series of decisions by asking questions. Imagine
    you want to decide what to wear. The decision tree might ask: “Is it raining?”
    If “yes,” it might suggest a raincoat. If “no,” it might ask another question,
    like “Is it hot?”, and suggest clothes accordingly, helping you navigate through
    various options until you find the best answer.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树通过提问的方式帮助你做出一系列决策。想象你想决定穿什么。决策树可能会问：“下雨吗？”如果回答是“是”，它可能会建议穿雨衣。如果回答是“否”，它可能会问下一个问题，比如“天气热吗？”，然后根据回答建议合适的衣服，帮助你在各种选项中做出最佳选择。
- en: 'Decision trees can help predict whether a customer will buy a product in the
    retail sector. For instance, it might ask: “Has the customer bought something
    in the last month?” If “yes,” they might likely buy again soon. If “no,” it might
    consider other factors like recent website visits or clicked promotions to predict
    their purchasing behavior, helping retailers target customers with relevant ads
    and offers.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树可以帮助预测零售行业中顾客是否会购买某个产品。例如，它可能会问：“顾客在过去一个月内是否购买过商品？”如果回答是“是”，他们可能很快会再次购买。如果回答是“否”，它可能会考虑其他因素，比如最近的网站访问或点击的促销活动，以预测顾客的购买行为，从而帮助零售商通过相关广告和优惠来精准地锁定顾客。
- en: Random forests
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机森林
- en: As its name implies, a random forest is like creating a forest where each tree
    is a decision tree that casts a vote to decide on the outcome. Each tree is given
    a random subset of the data and makes its best decision. Then, all trees “vote”
    to provide a final answer. This approach often results in better, more stable
    predictions than a single decision tree.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，随机森林就像是创建了一片森林，每棵树都是一棵决策树，它们通过投票来决定结果。每棵树会得到一个数据的随机子集并做出最佳决策。然后，所有的树“投票”得出最终答案。这种方法通常比单一决策树产生更好、更稳定的预测。
- en: In finance, random forests can be used for predicting whether to approve or
    deny loan applications. For example, trees might consider different aspects like
    credit score, income, and debt to make individual decisions. The final decision,
    made through a majority vote of all trees, is more accurate and robust than relying
    on a single model, thereby reducing the risk of lousy loan approval.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，随机森林可以用来预测是否批准或拒绝贷款申请。例如，树可能会考虑不同的因素，如信用评分、收入和债务，做出各自的决策。通过所有树的多数投票，最终的决策比依赖单一模型更准确和稳健，从而减少了糟糕贷款审批的风险。
- en: K-Nearest Neighbours (k-NNs)
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K-最近邻（k-NN）
- en: Using **k**-NNs is like looking at a new thing and trying to understand it by
    comparing it to similar things we already know. If you find a fruit you’ve never
    seen before, you might decide whether it’s likely to taste sweet or sour by comparing
    it to similar-looking fruits whose taste you’re familiar with. If it looks like
    other sweet fruits, you might guess it’s sweet.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**k**-NN就像是观察一个新事物并尝试通过将它与我们已经知道的相似事物进行比较来理解它。如果你发现了一种以前从未见过的水果，你可能会通过与其他你熟悉的口味相似的水果进行比较，来判断它是甜的还是酸的。如果它看起来像其他甜的水果，你可能会猜它是甜的。
- en: K-NN is widely utilized in recommendation systems, like those in e-commerce
    websites. If a user has bought a particular product, k-NN finds similar products
    that other similar users have bought and recommends them to the user. For example,
    suppose a user buys a detective novel. In that case, k-NN looks for other users
    who bought the same novel and then recommends other books that those users have
    bought, enhancing the user’s shopping experience by showing relevant products.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: K-NN广泛应用于推荐系统，如电子商务网站中的推荐系统。如果用户购买了某个特定产品，k-NN会找到其他相似用户也购买过的类似产品，并将它们推荐给该用户。例如，假设某个用户购买了一本侦探小说，那么k-NN会寻找其他也购买了这本小说的用户，并推荐这些用户购买的其他书籍，从而通过展示相关产品增强用户的购物体验。
- en: Support vector machines (SVMs)
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: SVMs are decisive algorithms that aim to keep things clear and separate. Imagine
    you have a big table and put apples on one side and bananas on the other. SVMs
    try to find the broadest possible line (or gap) to separate these two fruits so
    that all apples are on one side and all bananas are on the other, causing no mix-ups.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）是一种决定性的算法，旨在保持事物的清晰和分离。想象你有一张大桌子，把苹果放在一边，香蕉放在另一边。SVM会尝试找到一条最宽的线（或空隙）来分开这两种水果，以确保所有苹果都在一边，所有香蕉都在另一边，避免混淆。
- en: In the field of handwriting recognition, SVMs are helpful. For instance, if
    you write a number, say “4,” SVMs help the computer decide whether it’s indeed
    a “4” or maybe a “9” by looking at many examples of how people write these numbers
    and finding the best boundary that separates “4” from “9,” thus helping in accurately
    reading handwritten numbers.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Think of neural networks like a mini-brain inside the computer that learns from
    lots of examples to make decisions. When you learn to ride a bike, you might initially
    fall, but gradually, you learn how to balance and pedal by understanding what
    went wrong in the previous attempts. Neural networks learn similarly, adjusting
    from errors to make better decisions next time.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: For example, social media platforms use neural networks to identify and tag
    people in photos in image recognition. The network learns by looking at many pictures
    of a person and noticing features like nose shape and eye color. When a new photo
    is uploaded, it compares these features with its learned knowledge, making the
    best guess on who’s in it.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: K-means clustering is a means of grouping similar data points together. It’s
    like organizing a big party where you want to create groups (or clusters) of friends
    who share similar interests so that they enjoy each other’s company. You repeatedly
    try different ways to group individuals, trying to ensure that everyone in a group
    is as similar to each other as possible, ensuring a fun time for all.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: A popular application of k-means is customer segmentation for marketing strategies.
    Businesses can use k-means to group customers into clusters based on their purchasing
    behavior. For instance, one cluster might be customers who buy frequently but
    spend little each time, while another might be customers who buy infrequently
    but make big purchases. Each group can be targeted with different marketing strategies
    to maximize sales.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: XGBoost learns from past mistakes and becomes wiser and wiser with each decision.
    If you were solving math problems and you solved one incorrectly, XGBoost would
    look at it, understand where you went wrong, and remember this mistake so that
    the next time it faces a similar problem, it doesn’t repeat the same error.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: In the credit industry, XGBoost is widely used to predict whether a customer
    will default on a loan. Looking at many factors like income, age, and previous
    loan history predicts the probability of a customer defaulting. If an applicant
    is predicted to have a high risk of default, the loan might be denied, thereby
    minimizing the risk for the bank.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: These algorithms are the foundation of many ML projects, chosen based on the
    specific problem and data types (e.g., text, images, numerical data) with which
    one works. Some of them, like neural networks, require more computational resources
    and data, while others, like decision trees or k-NN, might be applicable even
    with smaller datasets.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: We continue our exploration of ML by next looking at popular ML tools and frameworks.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续探索机器学习，接下来将介绍流行的机器学习工具和框架。
- en: Popular machine learning tools and frameworks
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流行的机器学习工具和框架
- en: ML is accomplished using various tools and frameworks, each designed to aid
    different aspects of developing ML models – from data processing and algorithm
    design to model training and deployment. Here are some of the popular ones.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习使用各种工具和框架来完成，每种工具和框架都旨在帮助开发机器学习模型的不同方面——从数据处理、算法设计到模型训练和部署。以下是一些流行的工具和框架。
- en: 'Popular tools and frameworks for data preparation and exploration include:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备和探索的流行工具和框架包括：
- en: '**NumPy**: The core Python library for scientific computing. Numerical Python,
    or NumPy, is a library of multi-dimensional array objects and a set of operations
    for manipulating such arrays.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy**：核心的 Python 科学计算库。数值 Python，或称 NumPy，是一个多维数组对象库，并提供一组用于操作这些数组的运算。'
- en: An array is a collection of data items of the same type, stored in contiguous
    memory locations.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组是相同类型的数据项集合，存储在连续的内存位置中。
- en: NumPy facilitates easier and more efficient numerical and logical operations
    on large datasets. Imagine a retail company that wants to calculate the monthly
    average sales to analyze the performance and decide the future strategy. They
    have daily sales data stored in a numerical format. Using NumPy, they can easily
    calculate monthly average sales by organizing the daily sales data into an array,
    summing it, and dividing it by the number of days.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NumPy 使在大数据集上进行数值和逻辑操作变得更加容易和高效。假设某零售公司希望计算月度平均销售额，以分析业绩并决定未来的策略。他们拥有以数字格式存储的每日销售数据。使用
    NumPy，他们可以轻松通过将每日销售数据组织成数组、求和并除以天数来计算月度平均销售额。
- en: '**Pandas**: A library offering Python users simple, high-performance data structures
    and data analysis capabilities, allowing users to analyze and manipulate data.
    It presents Series and DataFrames, two essential data structures for Python that
    are constructed on top of NumPy.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pandas**：一个为 Python 用户提供简单、高性能数据结构和数据分析能力的库，使用户能够分析和操作数据。它呈现了 Series 和 DataFrame
    两个基础数据结构，它们是构建在 NumPy 之上的。'
- en: A Series is a column, and a DataFrame is a multi-dimensional table comprising
    a series collection.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Series 是一列，DataFrame 是由多个 Series 组成的多维表格。
- en: Pandas functionalities make it easy to clean, analyze, and visualize data. For
    example, imagine a grocery store wanting to analyze its sales data to understand
    which products are the best selling and which ones are not doing well. They have
    a large dataset with information about every transaction, including the product
    name, quantity sold, and price. Using pandas, they can easily manipulate this
    data, finding the total sales for each product, sorting them, and identifying
    the top-selling items.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Pandas 的功能使数据清洗、分析和可视化变得简单。例如，假设某个超市希望分析其销售数据，以了解哪些产品销量最好，哪些产品销量不佳。他们拥有一个包含每笔交易信息的大数据集，其中包括产品名称、销售数量和价格。使用
    pandas，他们可以轻松操作这些数据，计算每个产品的总销售额，对其进行排序，并找出最畅销的商品。
- en: '**Scikit-learn**: A straightforward and effective predictive data analysis
    tool that works with pandas and NumPy. Numerous supervised and unsupervised learning
    techniques are supported by scikit-learn. It is extensively utilized in ML, data
    mining, and data analysis. Scikit-learn has many built-in tools for model selection,
    evaluation, data import, and improvement. Imagine a bank wants to predict whether
    a customer will default on their loan. They have historical data on previous customers,
    including age, salary, marital status, and whether they defaulted. Using scikit-learn,
    they can build a model (like a decision tree, logistic regression, or another
    appropriate algorithm) that learns from this data, and then use this model to
    predict the likelihood of new customers defaulting on their loans.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**：一个简单有效的预测数据分析工具，支持与 pandas 和 NumPy 一起使用。scikit-learn 支持许多监督学习和无监督学习技术。它在机器学习（ML）、数据挖掘和数据分析中得到了广泛应用。Scikit-learn
    拥有许多内置工具，用于模型选择、评估、数据导入和改进。假设某银行希望预测客户是否会违约。他们拥有关于以前客户的历史数据，包括年龄、薪水、婚姻状况以及是否违约。使用
    scikit-learn，他们可以建立一个模型（如决策树、逻辑回归或其他合适的算法），从这些数据中学习，然后利用该模型预测新客户违约的可能性。'
- en: 'Popular tools and frameworks for data visualization include:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化的流行工具和框架包括：
- en: '**Matplotlib**: A popular and feature-rich Python library for making static,
    interactive, and animated visualizations. In addition to line, scatter, error
    bar, histogram, bar, pie, box, and 3D plots, Matplotlib offers an incredibly versatile
    foundation for creating a vast array of visualizations. This tool allows developers
    and data scientists to visualize their data in various forms of plots, which can
    be very useful for understanding the data distribution and patterns, debugging
    issues, or visualizing the relationships among the data. Let’s say a teacher wants
    to visually present the scores of students in a class to highlight overall performance
    and outliers quickly. Using Matplotlib, the teacher can create a variety of charts,
    like bar charts, scatter plots, or histograms, to represent the distribution of
    scores in an easily interpretable visual format.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**：一个流行且功能丰富的 Python 库，用于制作静态、互动和动画可视化图表。除了线图、散点图、误差条图、直方图、条形图、饼图、箱形图和
    3D 图表外，Matplotlib 还提供了一个极为多功能的基础，能够创建各种各样的可视化图表。这个工具使开发者和数据科学家能够以多种图表形式可视化他们的数据，这对理解数据分布和模式、调试问题或可视化数据之间的关系非常有用。假设一位老师希望直观地展示班级学生的成绩，以便快速突出总体表现和异常值。使用
    Matplotlib，老师可以创建多种图表，如条形图、散点图或直方图，以易于理解的可视化格式表示成绩分布。'
- en: '**Seaborn**: A Matplotlib-based statistical data visualization library that
    offers a high-level interface for designing appealing graphs. Seaborn has several
    built-in themes and color palettes to make creating aesthetically pleasing and
    visually informative charts easy. It is particularly well suited for visualizing
    complex datasets with multiple variables, thanks to its support for creating multi-plot
    layouts and functionalities to visualize the relationship between multiple variables.
    Imagine a retail business that wants to understand its customer purchasing behavior
    across different product categories over a period of time. With Seaborn, analysts
    can create a heatmap to visually represent purchasing frequency across various
    product categories in different months, allowing quick insights into trends and
    customer preferences.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seaborn**：一个基于 Matplotlib 的统计数据可视化库，提供了一个高层接口，用于设计美观的图表。Seaborn 具有多个内置主题和配色方案，使得创建美观且信息丰富的图表变得容易。由于它支持创建多图布局并能够可视化多个变量之间的关系，因此特别适合用于可视化具有多个变量的复杂数据集。假设一家零售公司希望了解其在不同时间段内在不同产品类别中的客户购买行为。通过
    Seaborn，分析师可以创建热力图，以可视化表示各月不同产品类别的购买频率，从而快速洞察趋势和客户偏好。'
- en: '**Business intelligence (BI) tools**: BI tools such as Tableau, Microsoft Power
    BI, Amazon QuickSight, and MicroStrategy are used for converting raw data into
    an understandable format. These tools help people visualize, understand, and make
    decisions with their data. Unlike other mentioned tools, these tools come with
    a graphical user interface that allows users to drag and drop items to analyze
    data, making it particularly accessible to individuals without a coding background.
    BI tools can connect to numerous data sources, providing real-time data insights.
    You can create and share dashboards, which provide interactive visualizations
    with embedded analytics. Consider a restaurant chain that wants to optimize its
    supply chain and menu based on customer purchasing behavior and seasonal trends.
    Using a BI tool, the company can visualize sales data across various dimensions,
    such as time, customer demographics, and product categories, to identify patterns
    and inform decision-making processes.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**商业智能（BI）工具**：如 Tableau、Microsoft Power BI、Amazon QuickSight 和 MicroStrategy
    等 BI 工具用于将原始数据转换为易于理解的格式。这些工具帮助人们可视化、理解并基于数据做出决策。与其他工具不同，这些工具提供图形用户界面，允许用户通过拖放项目来分析数据，使得没有编程背景的人也能轻松使用。BI
    工具可以连接多个数据源，提供实时的数据洞察。你可以创建并分享仪表板，提供嵌入分析的互动式可视化图表。假设一家餐饮连锁企业希望根据客户购买行为和季节性趋势优化供应链和菜单。通过使用
    BI 工具，公司可以在不同维度（如时间、客户人口统计和产品类别）上可视化销售数据，从而识别模式并为决策过程提供支持。'
- en: 'Popular tools and frameworks for model development and training include:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发和训练的流行工具和框架包括：
- en: '**TensorFlow:** A comprehensive open-source platform designed to manage a range
    of ML tasks. TensorFlow supports a range of APIs for building, training, and deploying
    AI models. A key feature of TensorFlow is its ability to create dataflow graphs.
    These graphs show how data moves through a series of processing steps or nodes.
    In these graphs, each node stands for a mathematical operation, and the connections
    between nodes, known as edges, represent tensors, which are multi-dimensional
    data arrays. TensorFlow provides tools for developers to use large-scale ML and
    nurtures an extensive library that makes it convenient to learn and develop AI
    models, ranging from beginners to experts. Imagine a healthcare start-up wanting
    to leverage ML to predict the onset of diseases based on various patient metrics
    like age, genetics, weight, and lifestyle habits. They could utilize TensorFlow
    to build a neural network model that considers all these factors to predict the
    likelihood of disease occurrence.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow**：一个全面的开源平台，旨在管理各种机器学习任务。TensorFlow支持一系列API，用于构建、训练和部署AI模型。TensorFlow的一个关键特点是其创建数据流图的能力。这些图展示了数据如何在一系列处理步骤或节点中流动。在这些图中，每个节点代表一个数学操作，节点之间的连接，称为边，表示张量，张量是多维数据数组。TensorFlow为开发者提供了工具，支持大规模机器学习，并拥有广泛的库，方便不同水平的学习者和开发者构建AI模型。假设一个医疗初创公司想要利用机器学习，根据患者的年龄、基因、体重和生活习惯等多项指标预测疾病的发生。他们可以利用TensorFlow构建一个神经网络模型，综合考虑这些因素，预测疾病发生的可能性。'
- en: '**PyTorch**: A popular ML library due to its flexibility, ease of use, and
    dynamic computational graph, which is particularly useful for deep learning. Developers,
    researchers, and data scientists favor it for both research and production due
    to its flexibility and extensive functionality. The dynamic computation graph
    enables users to change network behavior on the go, and the library provides a
    rich API for application in various ML tasks like classification, regression,
    and reinforcement learning, to name a few. Imagine an e-commerce company that
    wants to develop a chatbot to enhance customer experience. Using PyTorch, they
    could develop a deep learning model that understands the customer’s language and
    provides useful and accurate responses to customer queries in real time.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyTorch**：一个流行的机器学习库，因其灵活性、易用性和动态计算图而广受欢迎，特别适用于深度学习。开发者、研究人员和数据科学家都因其灵活性和广泛的功能在研究和生产中青睐它。动态计算图使用户能够随时更改网络行为，而该库提供了丰富的API，适用于分类、回归、强化学习等各种机器学习任务。比如，一个电商公司想要开发一个聊天机器人来提升客户体验。使用PyTorch，他们可以开发一个深度学习模型，理解客户语言，并实时提供有用且准确的响应。'
- en: '**Keras**: An open-source software library that serves as an easy-to-use API
    for building and training deep learning models. It can run atop other popular
    ML libraries like TensorFlow, making it highly versatile. Keras is particularly
    favored for its simplicity and ease of use in experimentation. With Keras, data
    scientists and developers can turn their ideas into results with minimal delay,
    which is vital in innovative projects. Let’s consider a retail company trying
    to recommend products to customers based on their past purchase history. The company
    could use Keras to create a recommendation system that analyzes customer buying
    patterns and suggests products they are likely to buy.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Keras**：一个开源软件库，作为构建和训练深度学习模型的易用API。它可以运行在其他流行的机器学习库如TensorFlow之上，使其具有高度的灵活性。Keras特别因其简洁性和易于实验而受到青睐。借助Keras，数据科学家和开发者可以在最短的时间内将想法转化为成果，这在创新项目中至关重要。假设一家零售公司试图根据客户的历史购买记录向其推荐产品。该公司可以使用Keras创建一个推荐系统，分析客户的购买模式，建议他们可能会购买的产品。'
- en: '**Apache Spark’s MLlib:** An ML library that’s part of Apache Spark, designed
    to scale up to meet the demands of big data. MLlib provides various ML algorithms
    including classification, regression, clustering, and collaborative filtering,
    as well as tools for model selection and evaluation. It also provides APIs for
    saving models for later use. MLlib is designed to handle large-scale ML tasks
    efficiently. Given its distributed computing capability, MLlib can quickly handle
    vast datasets, making it particularly valuable for scenarios where large-scale
    data analysis and model training are essential. Moreover, MLlib can be utilized
    with different data sources and formats, offering flexibility in dealing with
    various data types. Imagine a financial institution that wants to identify fraudulent
    credit card transactions as they occur. Using MLlib, data scientists can utilize
    vast amounts of transaction data to train models that identify unusual purchase
    patterns or anomalous transactions indicative of fraud, allowing for real-time
    detection and mitigation of fraudulent activities.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Popular tools and frameworks for model deployment include:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker**: A platform designed to make creating, deploying, and running applications
    using containers easier. Docker is not an ML tool per se, but it plays a crucial
    role in deploying ML models and applications efficiently and consistently. Docker
    allows developers and data scientists to package an application along with all
    of its dependencies (libraries, tools, and scripts) into a “container.” This container
    can be transferred and run consistently across various computing environments,
    which means the application will work the same way regardless of where it’s being
    run. Imagine a software development team that is creating an ML application to
    predict stock prices. They have data scientists who use various tools and libraries
    for model creation and software engineers who build the application using different
    technologies. Using Docker, they can create a cohesive workflow where everyone
    can work in a consistent environment, ensuring that the model and application
    behave the same way during development, testing, and deployment despite being
    developed with different tools.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flask**: A micro web framework written in Python. It’s simple to learn and
    simple to utilize, making it great for beginners, but it doesn’t include additional
    features (like form validation or database abstraction layers) that a full-stack
    framework might offer. However, its simplicity and ease of use make it popular
    for deploying lightweight web applications and APIs, especially in the data science
    and ML community. Imagine a scenario where a data scientist has developed an ML
    model to predict whether an email message is spam or not. This model could be
    utilized by a web application where users submit their emails, and in return,
    the application tells them whether the email is spam. Using Flask, the data scientist
    can create a simple web server that accepts email text, uses the ML model to predict
    if it’s spam, and then returns the result to the user, all through a web interface.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Popular integrated development environments (IDEs) include:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '**Jupyter** **Notebook:** An open-source web application that enables the creation
    and sharing of interactive documents. These documents can contain live code, equations,
    visualizations, and explanatory text, making them versatile tools for data analysis,
    scientific research, and educational purposes. It supports various languages,
    like Python, R, and Julia, and is extensively used in data cleaning, statistical
    modeling, ML, and much more due to its interactive computational environment.
    Jupyter is crucial in data science, academic research, and scientific computing
    for enabling users to create reproducible analyses and compellingly communicate
    their results through visualization and narrative text. Let’s consider a scenario
    where a biologist wants to analyze data on bird species and their migrations.
    The biologist could use a Jupyter notebook to write Python code that loads the
    data, visualizes migration patterns, and perhaps even uses ML to predict future
    migration timings or paths based on historical data.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RStudio**: An open-source IDE for R, a statistical computing and graphics
    programming language, that works with the standard version of R and can also work
    with the version of R available in the cloud. RStudio provides a robust set of
    capabilities for script development, data visualization, and statistical analysis,
    supporting the comprehensive utilization of the R language. Imagine a retail company
    wanting to understand the purchasing behaviors of its customers. Using RStudio,
    a data analyst could input sales data, apply statistical analysis, and create
    visualizations (like scatter plots, histograms, or bar charts) to identify buying
    trends, popular items, and peak shopping periods, potentially employing ML to
    forecast future sales trends.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Zeppelin**: An open-source notebook-based environment similar to Jupyter,
    which allows data engineers, data analysts, and data scientists to develop, organize,
    execute, and share data workflows and collaboratively execute code. Zeppelin supports
    various data processing backends like Apache Spark, Python, and JDBC. Users can
    create data-driven, interactive, and collaborative documents with Scala, Python,
    SQL, and so on. A particular strength of Zeppelin lies in its built-in data visualization
    and some integrations that aren’t as out-of-the-box for Jupyter users. Consider
    a scenario in the healthcare sector where analysts want to explore patient data
    to understand patterns in disease outbreaks. Using Zeppelin, they can interactively
    explore datasets, integrate various data processing backends, and create visualizations
    like heatmaps or line charts to represent outbreaks over geographic regions or
    timelines visually.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeppelin, RStudio, and Jupyter notebooks are the most common environments for
    data engineers doing data discovery, cleansing, enrichment, labeling, and preparation
    for ML model training.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: As the cloud is becoming a go-to platform for ML model training, let’s learn
    about some available ML cloud platforms.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning in the cloud
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML development is a complex and costly process. There are barriers to adoption
    at each step of the ML workflow, from collecting and preparing data, which is
    time consuming and undifferentiated, to choosing the right ML algorithm, which
    is often done by trial and error, and lengthy training times, which leads to higher
    costs. Then there is model tuning, which can be a very long cycle and requires
    adjusting thousands of different combinations. Once you’ve deployed a model, you
    must monitor it and then scale and manage its production.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: To solve these challenges, all major public cloud vendors provide an ML platform
    that facilitates ease of training, tuning, and deploying ML models anywhere at
    a low cost. For example, Amazon SageMaker is one of the most popular platforms
    that provides end-to-end ML services. SageMaker provides users with an integrated
    workbench of tools brought together in one place through SageMaker Studio. Users
    can launch Jupyter Notebook and JupyterLab environments instantly through SageMaker
    Studio. SageMaker also provides complete experiment management, data preparation,
    and pipeline automation and orchestration to help make data scientists more productive.
    SageMaker also provides the fully managed RStudio platform, which is one of the
    most popular IDEs among R developers for ML and data science projects. SageMaker
    provides fully managed servers in the cloud. Beyond notebooks, SageMaker provides
    other managed infrastructure capabilities as well. From distributed training jobs,
    data processing jobs, and even model hosting, SageMaker takes care of all of the
    scaling, patching, high availability, and so on associated with building, training,
    and hosting models.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, GCP provides the Google Cloud AI platform, with different services
    to perform ML experiments, and Microsoft Azure offers Azure ML Studio.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: In addition to managed ML platforms, cloud vendors also provide ready-to-use
    AI services. AI services allow developers to easily add intelligence to any application
    without needing ML skills. The pre-trained models provide ready-made intelligence
    for your applications and workflows to help you personalize the customer experience,
    forecast business metrics, translate conversations, extract meaning from documents,
    and more. For example, AWS provides the Amazon Comprehend AI service, which has
    pre-trained models that support keyphrase detection and sentiment analysis natively
    in multiple languages.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: The cloud is increasingly serving as a primary platform for accessing and utilizing
    GenAI FMs, offering a cost-effective and scalable environment for testing and
    deploying these advanced AI systems. These FMs are trained on vast datasets and
    can be fine-tuned for specific tasks, making them versatile tools for a wide range
    of applications. The cloud’s scalability and resource availability make it an
    ideal environment for working with these large, resource-intensive models. Both
    open-source and commercial GenAI FMs are available, offering options for different
    needs and budgets.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: This accessibility of GenAI FMs via the cloud democratizes advanced AI capabilities,
    enabling businesses and developers to leverage cutting-edge AI technology without
    the need for significant upfront investment in computational infrastructure. For
    example, using an API, Amazon Bedrock allows you to access multiple third-party
    foundation models from companies like stability.ai, Meta, Mistral, Anthropic,
    Amazon, and AI21\. Similarly, Azure provides API access to OpenAI’s GPT-4, and
    GCP provides access to their FM model Gemini. You will learn more about them in
    Chapter 14, *Generative AI Architecture*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Data scientists can leverage managed cloud environments to accelerate data preparation
    and model training. When complete, they can one-click deploy the model and begin
    serving inferences over HTTP.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Let’s learn more about some of the essential things to consider when you are
    designing ML architecture.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Building machine learning architecture
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building a robust and scalable workflow from a loose collection of code is a
    complex and time-consuming process, and many data scientists need to gain experience
    building workflows. An ML workflow can be defined as an orchestrated sequence
    that involves multiple steps. Data scientists and ML developers first need to
    package numerous code recipes and then specify the order in which they should
    execute, keeping track of code, data, and model parameter dependencies between
    each step.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Added complexity in ML workflows warrants monitoring changes in data used for
    training and predictions because changes in the data could introduce bias, leading
    to inaccurate predictions. In addition to monitoring the data, data scientists
    and ML developers also need to monitor model predictions to ensure they are accurate
    and don’t become skewed toward particular results over time. As a result, it can
    take several months of custom coding to get the individual code recipes to execute
    in the correct sequence and as expected.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: ML architectures need to protect model artifacts and provide self-service capabilities
    for model development and training. It’s essential for your ML architecture to
    facilitate automated, comprehensive documentation of the entire model development
    life cycle, encompassing stages from across development, training, and deployment.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: ML applications should also employ a continuous integration and continuous deployment
    (CI/CD) pipeline that is seamlessly integrated with change control systems. This
    integration is crucial for model management and deployment. Additionally, the
    environments require pre-defined security configurations.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: The following are the ML architecture components from the **AWS** ML platform
    to help you understand ML architecture.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Other ML platforms are Azure ML Studio, H2O.ai, SAS, Databricks, and the Google
    AI platform.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Prepare and label
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To prepare data for ML, you need to run your data processing workloads, such
    as feature engineering, data validation, model evaluation, and model interpretation.
    Feature engineering also preprocesses datasets to convert the input datasets into
    a format expected by your ML algorithm. For example, if you’re working with a
    dataset that includes dates, you might extract the day of the week, the month,
    and the time of the year as separate features, as these could have predictive
    value for your model. You can use the various tools and techniques mentioned in
    the previous section to wrangle data as per your ML needs. A managed ML platform
    like Amazon SageMaker also provides a data wrangler and feature store capability
    to simplify the data processing job. SageMaker Data Wrangler allows you to easily
    prepare your data for ML by providing a visual interface to access, combine, clean,
    and transform data. This tool helps you perform common data preparation tasks
    without writing code, speeding up the process and reducing the chance of errors.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, SageMaker Feature Store is a centralized repository to store,
    share, and manage curated features for ML models. This ensures consistency across
    different models and reduces redundancy in feature engineering efforts. Feature
    Store helps in maintaining a consistent set of features for training and inference,
    facilitating better model performance and easier model maintenance.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: During the data processing phase, labeling your data is a crucial step. This
    process helps in organizing and constructing accurate datasets for ML. To facilitate
    this, you can engage third-party services specializing in data labeling, like
    Labelbox, CrowdAI, Docugami, and Scale, which offer expertise in image labeling
    and other types of data annotation. Additionally, platforms like Amazon SageMaker
    Ground Truth provide an automated solution for image data labeling.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Once your data is ready, the next step is to select a suitable algorithm and
    build the model.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Select and build
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before creating an ML model, you first want to understand business problems
    clearly, which will help you select the suitable algorithm. As explained in the
    previous section, you can choose from a list of algorithms and ML frameworks,
    broadly both *supervised* and *unsupervised* ML algorithms. This may be dictated
    by the data available. Once you select the suitable algorithm for your use case
    to build an ML model, you need a platform to train and develop your model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter Notebook and RStudio are the most popular platforms among data scientists
    to build ML models. You can use cloud platforms such as Amazon SageMaker to spin
    up Jupyter Notebook or RStudio Workbench. AWS provides SageMaker Studio and RStudio,
    a web-based visual interface, in a place where all the developmental steps of
    ML will be performed by you.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: To select your model, you can choose several built-in ML algorithms that you
    can use for various problem types, or get a number of models and algorithms available
    in the cloud market, making it easy to get started quickly.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to train and tune the model. Let’s learn more about it.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Train and tune
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To accelerate the training process, it’s advisable to utilize a distributed
    compute cluster. This setup allows you to distribute the training workload across
    multiple computing resources, significantly speeding up the training phase. By
    employing such a cluster, you can parallelize the computation, which means different
    parts of the training data can be processed simultaneously. As a result, the model
    training completes faster, and the output, which your applications can utilize,
    becomes available sooner. This approach not only enhances efficiency but also
    enables the handling of larger datasets, contributing to the development of more
    accurate and robust ML models. Model tuning is also known as hyperparameter tuning,
    which is critical to achieving result accuracy.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: You need to find the most effective version of a model by running multiple training
    jobs on your dataset using the chosen algorithm and varying ranges of hyperparameters.
    Following this, choose the correct hyperparameter values that yield a model that
    performs the best, as determined by a metric of your choice.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: While you are tuning the model, it’s crucial to have debugging capabilities
    that help capture real-time metrics during the training phase, such as training
    and validation accuracy, confusion matrices, and learning gradients. These metrics
    are essential for enhancing the accuracy of your model. Additionally, it’s important
    to produce documentation to help improve model accuracy. You need to capture the
    input parameters, configurations, and results and categorize them as different
    experiments. This organization allows you to efficiently search for previous experiments
    by their characteristics, review previous experiments with their outcomes, and
    visually compare the results of various experiments to inform further adjustments
    and improvements. Most managed ML platforms, such as Amazon SageMaker, provide
    these features for you.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker also provides Autopilot, a feature that automates several aspects
    of model development. Autopilot examines raw data and applies feature processing
    techniques. It then picks the most suitable algorithms, conducts training, tunes
    multiple models, and monitors their performance. The models are ranked based on
    their performance metrics.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: After finalizing your model, you need to deploy it and manage it in a production
    environment to gain valuable insights and achieve your desired outcomes.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Deploy and manage
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You must deploy your trained ML model into a production environment to enable
    real-time or batch data predictions. Implement auto-scaling for your ML instances
    across various locations to ensure high redundancy and establish a RESTful HTTPS
    endpoint for your application. The application should be configured to have an
    API call to an ML endpoint to achieve low latency and high data processing speeds.
    This architectural approach facilitates rapid integration of your new models into
    your application, streamlining the process because changes to the model do not
    necessitate modifications in the application’s code.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Data is subject to rapid changes due to factors like seasonality or unforeseen
    events, making it essential to continuously monitor your model for both accuracy
    and ongoing relevance to your business. A significant factor that can affect the
    accuracy of deployed models is if the data that is used for generating predictions
    differs from the training data used to train the model. For instance, changing
    economic conditions could drive new interest rates, which in turn could impact
    home purchasing predictions. This phenomenon is known as concept drift, whereby
    the patterns and correlations a model was trained on no longer hold true in the
    current data environment. To address this, you need to automatically detect concept
    drift in deployed models, with detailed alerts that assist in pinpointing the
    exact source of the problem.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Model compatibility is another crucial factor during deployment. Once a model
    has been built and trained using MXNet, TensorFlow, PyTorch, or XGBoost, for example,
    you can choose your target hardware platform from Intel, NVIDIA, or ARM. You need
    to compile your trained ML models to run optimally and efficiently in deploying
    compiled models to edge devices. This step ensures that your models not only deliver
    and provide high-performance and low-cost inference but also maintain cost effectiveness.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: You should be able to run large-scale ML inference applications, which can include
    tasks like image recognition, speech recognition, NLP, personalization, and fraud
    detection. As you progress through the different stages of building and deploying
    ML models, understanding how to fine-tune and adapt them for efficient deployment
    and operation becomes key, particularly for applications that require real-time
    processing and responsiveness. Let’s look at a reference architecture to connect
    all components.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: ML reference architecture
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following example architecture depicts a bank loan approval workflow based
    on customer data built on the AWS cloud platform.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Customer data is ingested in the cloud and the ML framework decides on the customer
    loan application.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, screenshot, diagram  Description automatically
    generated](img/B21336_13_03.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.3: ML architecture in the AWS cloud'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'In designing the preceding architecture, some fundamental design principles
    to consider as a guide are:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '**Training workflow**:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets enter the process flow using S3\. This data may be raw input data or
    preprocessed from on-premises datasets.
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ground Truth is used to build a high-quality, labeled training dataset for ML
    models. If required, the Ground Truth service can label the data.
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Lambda can be used for data integration, preparation, and cleaning before
    datasets are passed to SageMaker.
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Data scientists will interface with SageMaker to train and test their models.
    The Docker images used by SageMaker are stored in ECR and can be custom images
    with custom toolsets created through the build flow steps or use one of the pre-built
    Amazon images.
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Model artifacts to be used as part of the deployment phase are output to S3\.
    The output from the SageMaker model can also be used to label data using Ground
    Truth. Models that have been pre-built and trained on-premises or other platforms
    can be deposited into the model artifacts S3 bucket and deployed using SageMaker.
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Lambda can trigger an approval workflow based on a new model artifact being
    deposited into the S3 bucket.
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Simple Notification Service (SNS) can be used to provide an automatic
    or manual approval workflow based on human intervention to deploy the final model.
    The supporting Lambda function takes the output from SNS to deploy the model.
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: DynamoDB stores all model metadata, actions, and other associated data for audit
    tracking.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To host the final model, we deploy the endpoint with the associated configuration
    as part of the final step in the workflow.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Build workflow**:'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SageMaker notebook instances are used to prepare and process data and to train
    and deploy ML models. These notebooks can be accessed via a VPC endpoint for the
    SageMaker service.
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CodeCommit provides the repository for the source code to trigger the build
    jobs required for any custom Docker images used by SageMaker.
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The CodePipeline service manages the end-to-end build pipeline for the custom
    Docker images and uses the CodeBuild service for the build/test phase.
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CodeBuild will build and perform unit testing of the custom Docker image and
    push it to Amazon ECR (this process can be managed centrally or by business functions
    requiring the tools).
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Deploy workflow**:'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As SageMaker endpoints are private, Amazon API Gateway exposes the model endpoint
    to end users for inference.
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Batch transform jobs are typically utilized to obtain inferences for an entire
    dataset. By employing a trained model and a dataset, the output from the batch
    job is stored in S3\. Additionally, you can utilize SageMaker Model Monitor to
    oversee production models and send alerts in case of any quality issues.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: This section taught you about ML architecture with a CI/CD pipeline. We look
    at ML architecture design principles next.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Design principles for machine learning architecture
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Designing an effective ML architecture requires a strategic approach, prioritizing
    scalability, maintainability, efficiency, and robustness. Here are some design
    principles that professionals typically adhere to when developing ML architectures.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Organizing the machine learning system into modules
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Modularity** breaks down the ML system into separate, interchangeable components
    or modules, each responsible for a distinct function. In an ML model, for instance,
    you could have one module for data ingestion, another for preprocessing, one for
    model training, and yet another for prediction serving. Consider a retail recommendation
    system: the data ingestion module might be responsible for collecting user interaction
    and purchase history, while another module uses that data to train a model that
    recommends products. The advantage is that if a better recommendation algorithm
    is developed, the training module can be replaced or updated without disrupting
    the data ingestion module.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: In a **financial fraud detection system**, as another example, modularity allows
    the development team to isolate and update the prediction model whenever new fraud
    patterns are identified without altering the data collection or transaction monitoring
    modules. This compartmentalized approach promotes streamlined troubleshooting,
    targeted upgrades, and generally enhanced system manageability.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring scalability
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Scalability** refers to the ML architecture’s capacity to gracefully handle
    increases in workload or demand, ensuring consistent performance. This is pivotal
    when managing larger datasets or when user requests grow significantly. For instance,
    in a streaming service like Netflix, the recommendation system must scale to accommodate
    the growing number of users and their viewing histories without compromising on
    the speed or accuracy of the recommendations. Scalability ensures that the service
    remains uninterrupted and consistently high-performing even as data and demand
    grow.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Another real-world example would be an **e-commerce platform** during a Black
    Friday sale. The system must scale to process and analyze exponentially higher
    transaction and user data.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring reproducibility
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is vital to ensure that ML models can reliably reproduce outcomes. This means
    that if the model is retrained with the same data, code, and parameters, it should
    produce the same results. An e-learning platform may use an ML model to personalize
    learning content for each user. If a particular model version yields impressive
    results, being able to reproduce it ensures a consistent user experience and facilitates
    future debugging and development.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Consider an ML model used for **diagnosing medical conditions** from imaging
    data in healthcare. Ensuring reproducibility means that the diagnoses remain consistent
    and reliable across different instances of the model, reinforcing trust in the
    automated system among healthcare professionals and patients and ensuring that
    scientific studies using the model are valid and verifiable.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Implementing data quality assurance
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Data quality assurance** means implementing mechanisms to validate and ensure
    the data’s accuracy, completeness, and reliability, fed into ML models. For a
    system like a voice-activated virtual assistant, which is continually learning
    from user interactions to improve response accuracy, ensuring that the incoming
    data is accurate and relevant is paramount to train the model effectively. Faulty
    or low-quality data could lead the model to learn incorrect patterns, diminishing
    the user experience.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Take an **autonomous vehicle navigation system** as another example. Ensuring
    data quality is crucial because the decisions made by the ML model based on this
    data directly impact the safety and efficacy of the vehicle.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring flexibility
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Flexibility** in ML architecture refers to the ability to easily modify and
    adapt the system to accommodate changes or enhancements in data, technology, and
    requirements. A flexible system can integrate new data sources, manage different
    data types, and adapt to different algorithms or technologies as needed. Imagine
    a news aggregator app that uses ML to personalize content for users. Flexibility
    allows this app to easily adapt its model to new data sources (like a new news
    website) or to integrate new types of data (like video news or podcasts) without
    requiring a comprehensive architecture redesign.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: With **customer support chatbots**, as another example, having flexibility allows
    the chatbot to adapt its responses and interaction style based on evolving user
    expectations and linguistic trends. Suppose the model identifies a shift in user
    interaction style or a surge in specific inquiries. A flexible architecture enables
    it to integrate new data or adjust its algorithms to enhance user interactions
    and satisfaction.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring robustness and reliability
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring **robustness and reliability** means that the ML architecture should
    produce consistent, dependable results and be resilient to variations in the input
    data or system disturbances. For instance, a robust ML model for an email provider
    should consistently filter spam messages irrespective of the variety of spam techniques
    or message content. It should reliably protect the user’s inbox even if spammers
    change their strategies or use different languages and terminologies.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: In **automated stock trading**, the robustness and reliability of the ML models
    are vital to ensure that trading decisions are consistent and protected from volatile
    market conditions or deceptive trading activities. An ML system must recognize
    and navigate through market noise, erroneous data, or manipulative trading activities
    to safeguard investments and maintain investors’ trust.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring privacy and security
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Privacy and security** involve safeguarding the data and the ML model from
    unauthorized access and ensuring that personal or sensitive data is handled ethically
    and complies with regulations. In a personal finance app that uses ML to provide
    financial advice, for example, it’s imperative to protect the user’s financial
    data and ensure that the model’s predictions are secure from malicious attacks
    to preserve both user privacy and model integrity.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Considering **personalized marketing** as a use case, handling user data, such
    as shopping history, preferences, and personal details, with utmost privacy and
    security is essential. Ensuring the ML model, which curates personalized marketing
    content, adheres to data protection regulations and is resilient against data
    breaches protects the end users. It preserves the brand’s reputation and legal
    compliance.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring efficiency
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Efficiency** is about maximizing the performance of the ML system while minimizing
    the resources used. An efficient ML model ensures that the computational, data
    storage, and other resource usages are optimized without compromising the model’s
    output quality. In the case of mobile apps that use ML for features like image
    recognition or language translation, an efficient model will provide quick and
    accurate results without excessively draining the device’s battery or utilizing
    intensive computational resources.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: An example of **real-time fraud detection** in online transactions highlights
    the necessity of efficiency. The ML model must rapidly analyze transaction data
    and accurately identify fraudulent activities to provide immediate alerts or actions,
    all while managing computational resources to handle countless transactions happening
    every second. Efficiency ensures swift, accurate fraud detection without imposing
    unsustainable computational costs or latency in transaction processing.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring interpretability
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring **interpretability** in ML architecture means the model outputs are
    understandable and explainable to humans. For instance, a healthcare platform
    that employs ML to assist doctors in diagnosing diseases should offer interpretations
    of its predictions, enabling doctors to understand the reasoning behind the diagnostic
    suggestions and, thereby, make informed decisions for patient care.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Consider an ML application in **credit scoring**. Interpretability is paramount
    to both the end users, who might want to understand the factors influencing their
    credit score, and the regulators, ensuring that the scoring model is not biased
    and is compliant with legal standards. An interpretable ML model can elucidate
    which factors (e.g., transaction history, loan repayments, etc.) influence the
    credit score, providing transparency and facilitating trust among users and regulatory
    bodies.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Implementing real-time capability
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Real-time capability** refers to the ML architecture’s ability to process
    data and produce outputs in real time or near real time, which is crucial in scenarios
    that require instant decision making. An autonomous vehicle, for instance, utilizes
    ML to make immediate decisions based on real-time inputs from various sensors
    and cameras, such as identifying obstacles and deciding the optimal path. The
    architecture must process, evaluate, and act upon real-time data to navigate dynamic
    environments safely.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: In **customer support** provided by virtual assistants and chatbots, real-time
    capability ensures customer queries are addressed immediately and accurately,
    enhancing user experience and satisfaction. The ML model must comprehend user
    inputs, process the relevant data, and generate real-time responses to facilitate
    smooth and coherent interactions, even as user inquiries and conversations diversify
    and escalate.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring fault tolerance
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Fault tolerance** implies that the ML architecture should maintain its functionality
    and produce reasonable outputs even when some system components fail or it encounters
    unexpected input data. For instance, an e-commerce recommendation system should
    continue to provide product suggestions to users even if specific data sources
    (like recent browsing history) are temporarily unavailable, ensuring continuous
    user engagement and potential sales.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: In **industrial equipment monitoring** using ML to predict maintenance needs
    and detect failures, fault tolerance ensures that the system can still provide
    valuable insights even when some sensors fail or provide erratic data. The ML
    model should identify and manage such anomalies, providing reliable equipment
    health assessments and ensuring safe and continuous operations in the industrial
    setup.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Through adherence to these principles in ML architecture, models can robustly
    navigate through various real-world applications, from ensuring safe and efficient
    operations in industries to providing real-time, insightful interactions in customer
    support.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: ML is applicable everywhere; for example, it can be applied in solving customer
    problems such as predictive maintenance, providing accurate forecasting for businesses,
    or building personalized recommendations for end users. ML use cases are not only
    limited to customer problems but also help you to handle your IT applications
    by optimizing your workload with predictive scaling, identifying log patterns,
    fixing errors before they cause issues in production, or budget forecasting for
    IT infrastructure. So, solutions architects must know about ML use cases and associated
    technology.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in this book, you learned about DevOps to automate and operationalize
    your development workload. As ML is becoming mainstream, MLOps has become essential
    to learning ML at scale in production. Let’s explore more details on operationalizing
    the ML workload with MLOps.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: MLOps
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An ML workflow is a set of operations developed and executed to produce a mathematical
    model, which eventually is designed to solve a real-world problem. But these models
    have no value until they are deployed in production other than proofs of concept.
    ML models almost always require deployment to a production environment to provide
    business value.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: At its core, MLOps fundamentally focuses on transitioning an experimental ML
    model into a fully operational production system. MLOps is an emerging practice,
    different from traditional DevOps due to the unique nature of the ML development
    life cycle and the specific ML artifacts it produces. The ML life cycle revolves
    around discerning patterns from training data, making the MLOps workflow particularly
    sensitive to changes in data, as well as variations in data volumes and quality.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: A well-developed MLOps practice should support the monitoring of ML life cycle
    activities as well as the ongoing supervision of models once they are operational
    in production environments. This dual focus ensures both the efficiency of the
    development process and the effectiveness of the deployed models.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: MLOps implementation makes it simple for organizations to feel confident in
    building a mature MLOps framework, eliminating extensive coding. Like any other
    workload, you want to develop MLOps by applying best practices such as security,
    reliability, high availability, and performance, and considering the cost for
    the deployment phase of the ML life cycle. Let’s have a look at a few MLOps principles.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: MLOps principles
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Any changes in the code, training data, or model should trigger the build process
    in the ML development pipeline to make sure your model is performing well by accommodating
    changes immediately.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'An ML pipeline should follow these MLOps principles while developing ML systems:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '**Automation**: The deployment of ML models in production should be automated.
    The MLOps team should automate the end-to-end ML workflow from data engineering
    to model interference in production without any manual intervention. This automation
    makes sure that there is no lapse in the production model where there are changes
    in training data and your model stays relevant. The MLOps pipeline can trigger
    model training and deployment based on events such as calendar scheduling, messaging,
    monitoring, data changes, model training code changes, and application code changes.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Versioning**: Versioning is an essential aspect of MLOps. Every ML model
    and related script version should be maintained in a version control system such
    as GitHub to make the models reproducible and auditable.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing**: ML systems require extensive testing and monitoring. Each ML system
    should have at least the following three scopes for testing:'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature and data tests, which include validating data quality and selecting
    the right features for your ML model
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Model development tests, which include business metric tests, model staleness
    tests, and model performance validation tests
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: ML infrastructure tests, which include ML API usage tests, complete ML pipeline
    integration tests, and training and production server availability tests
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reproducibility**: Every phase of an ML workflow should be reproducible,
    which means that ML model training, processing of data, and emplacement of the
    ML model must deduce similar results for similar input. It will ensure a robust
    ML system.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment**: MLOps integrates the principles of ML with the culture of DevOps,
    emphasizing CI/CD and **continuous training**/**continuous monitoring** (**CT/CM**).
    Through automated deployment and testing, MLOps facilitates the early detection
    of issues, enabling quick rectifications and iterative learning. This approach
    streamlines the process of deploying ML models into production, ensuring they
    remain effective and up to date.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring**: Over time, the performance of a model may degrade in production
    due to factors such as data drift. This scenario necessitates the continuous deployment
    of new or updated models to counteract any decline; they must be shipped into
    production constantly to address performance decline or to enhance model fairness.
    After deploying an ML model, it’s critical that a monitoring system is implemented
    to ensure that the ML model performs according to expectations and maintains its
    effectiveness in providing accurate and reliable outputs, which is essential for
    maintaining the overall quality and trustworthiness of the ML application as expected.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having learned about MLOps design principles in this section, let’s consider
    some best practices to apply MLOps in your ML workload.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: MLOps best practices
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to many moving parts (data, model, or code) and challenges in solving business
    problems using ML, MLOps can be a challenging task.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the principles outlined in the previous section, the following are
    the best practices that ML engineers/full-stack data scientists should practice
    while deploying ML solutions in production, which will help reduce technical debt
    and maintenance overhead in ML projects and drive the most business value out
    of them:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '**Design considerations:** To develop a maintainable ML system, the architecture/system
    design should be modular and, as much as possible, loosely coupled. Implementing
    a loosely coupled architecture enables different teams within an organization
    to operate independently. This means they don’t have to depend on other teams
    for support or services. As a result, each team can work more swiftly and efficiently,
    contributing to the overall value and productivity of the organization.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data validation**: Data validation is crucial for a successful ML system.
    In a production environment, data can present several challenges. One such issue
    arises if the statistical properties of the production data are different from
    those of the training data, indicating potential problems with properties, the
    training data itself, or the data sampling process. Additionally, data drift can
    occur, which might cause the statistical properties of data over time to change
    for successive batches. This drift can impact the model’s performance, as it was
    trained on data with different statistical characteristics.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model validation**: Reusing models is different from reusing software. It’s
    best to tune models to fit each new scenario. Ensuring that models are thoroughly
    validated before they are moved into production is very important. To confirm
    that the model performs effectively on live data, it’s important to conduct both
    online and offline data validation. This process helps to establish that the model’s
    predictions are accurate and reliable under actual operating conditions.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model experiment tracking:** It’s essential to meticulously document all
    experiments conducted with your ML models. Experimentation in ML may involve trying
    out different combinations of code (encompassing preprocessing, training, and
    evaluation methods), datasets, and hyperparameters. Each unique combination of
    these elements produces metrics, which you should compare against the outcomes
    of your other experiments. This comparison is key to understanding which approaches
    are most effective and optimizing your ML models accordingly.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code quality check**: Every ML model specification (ML training code that
    creates an ML model) should undergo a code review phase. Checking the quality
    of the code as the initial path of a pipeline activated by a pull request is a
    nice practice in general.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Naming conventions**: Following a standard naming convention (like *PEP8*
    for Python programming) in your ML coding practices is an effective strategy to
    help mitigate the challenges posed by the **Changing Anything Changes Everything**
    (**CACE**) principle. Consistent and clear naming conventions facilitate easier
    understanding and modification of the code. This not only helps in maintaining
    the integrity of the project when changes are made but also enables new team members
    to establish familiarity with your project quickly.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model predictive service performance monitoring**: Other than project metrics
    (such as **root mean square error** (**RMSE**)) that calculate the behavior of
    a model with reference to the aim of the business, operational metrics such as
    latency, scalability, and service updates are also crucial to monitor to avoid
    business losses.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The CT/CM process:** In a production environment, model performance can deteriorate
    due to factors such as data drift. This necessitates the ongoing deployment of
    updated models to enhance or maintain the model’s fairness and accuracy. To effectively
    manage this, a CT/CM process is essential. CT ensures that models are regularly
    updated and trained with the latest data, while CM keeps track of the model’s
    performance in real time, identifying any issues or deviations that might occur
    due to changing data patterns. Together, CT and CM form a robust framework for
    ensuring the long-term reliability and effectiveness of ML models in production.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource utilization**: Understanding the requirements of your system during
    both the training and deployment phases is crucial for efficient operations. This
    insight helps your team effectively optimize the resources used for your experiments,
    which in turn can lead to significant cost savings. Proper resource management
    ensures that you allocate just the right amount of computational power, memory,
    and other resources necessary for the tasks at hand, without underutilizing or
    over-committing resources. This balance is key to maintaining both the performance
    and the cost effectiveness of your ML projects.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLOps plays a crucial role in the industrialization of AI. MLOps collaborates
    ML, data engineering, and DevOps to effectively build, deploy, and maintain ML
    systems in production.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning is now the go-to mechanism to solve complex ML problems. Let’s
    learn more about deep learning.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML is about forecasting and solving complex problems using NLP, enabling computers
    to understand, interpret, and generate human language in a valuable and meaningful
    way. NLP is used in numerous applications, including language translation, sentiment
    analysis, chatbots, and voice assistants, allowing for more intuitive, human-like
    interaction with machines. While ML needs a pre-defined set of labeled data for
    supervised learning, **deep learning** uses a neural network for unsupervised
    learning to simulate human brain behaviors, using a large amount of data to develop
    ML capabilities. A neural network is a series of algorithms that recognize underlying
    relationships in a set of data through a process that mimics the way the human
    brain operates.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep learning involves a neural network of multiple layers where you don’t
    need to do data labeling upfront. However, depending on your use case, you can
    use both labeled and unlabeled data with deep learning. The following diagram
    shows a simple deep learning model:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21336_13_04.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.4: An overview of deep learning layers'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, a deep learning model has interconnected nodes where
    input layers provide data input through various nodes. This data goes through
    multiple hidden layers to calculate the output and deliver the final model inference
    through the output node layer. The input and output layers are visible layers,
    and learning happens in the middle layer through weights and bias, as shown in
    the following diagram:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21336_13_05.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.5: Deep learning neural network model'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, you can see a series of hidden layers between where
    each layer applies some weight functions to the interconnected nodes to learn
    the pattern, in the same way as a human brain. You can see **label** data coming
    in as input and going through neural network nodes with their weight (**0.2**,
    **0.4**, **0.3**, and **0.9**) indicated between vertices.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Weight is a neural network parameter that plays a role in transforming input
    data as it passes through the hidden layers. Essentially, the weight determines
    the extent to which a given input will influence the output. It can be thought
    of as representing the strength or intensity of the connection between nodes in
    the network.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if the weight from node A to node B is high, it implies that neuron
    A has a more significant influence over neuron B. Weights that are close to zero
    indicate that changing this particular input will have minimal or no impact on
    the output. Conversely, if the weights are negative, it suggests an inverse relationship
    – this means increasing the input will decrease the output and vice versa. This
    mechanism of weights is fundamental to how neural networks process and learn from
    data.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: The preceding learning method is called **forward propagation**, where data
    flows from the input layer all the way to the output layer. Here, the output of
    one layer is fed as the input to the next, leading up to the final output.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: On the other side, there’s another technique known as **backpropagation**. This
    involves calculating the error in the network’s predictions (the discrepancy between
    what the network predicts and the actual outcome). The network uses algorithms
    to calculate prediction errors and then adjusts its internal parameters—the weights
    and biases—based on this error. This adjustment happens in reverse, starting from
    the output layer and moving backward through the layers, which is why it’s called
    “backpropagation.”
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Through the combined use of forward and backward propagation, a neural network
    is able to learn and improve. It processes data (forward propagation), identifies
    any inaccuracies in its predictions (backpropagation), and then tweaks its parameters
    to reduce these errors. This cycle is key to training the neural network to gradually
    become more efficient and accurate at its task with the training algorithm.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep learning encompasses different types of neural networks, each suited for
    different applications. The two most frequently used are:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional neural networks** **(CNNs)**: These are adept at processing
    data with a grid-like topology, such as images, making them highly effective for
    tasks involving visual input, such as computer vision and image classification
    tasks.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent neural networks** **(RNNs)**: RNNs excel in handling sequential
    data, making them ideal for tasks that involve understanding language and speech,
    such as NLP and speech recognition.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of the most popular frameworks for building these neural network models
    are TensorFlow, which has built-in support for various neural network architectures,
    and MXNet, which also supports a range of network architectures and is known for
    its efficiency and scalability, particularly in the context of high-performance
    deep learning applications. In addition to this, other popular deep learning frameworks
    are PyTorch, Chainer, Caffe2, ONNX, Keras, and Gluon.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: This section has provided you with a high-level view of deep learning. It is
    a complex topic and requires an entire book to cover the basics. You will find
    multiple books available on each of the frameworks. Deep learning model training
    requires a lot of processing power and could be very costly. However, public cloud
    providers such as AWS, GCP, and Azure make it easy to use high-powered GPU-based
    instances to train these models with the pay-as-you-go method.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning in the real world
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning is widely popular, and there are multiple use cases of deep learning
    across various industries. Let’s take a look at some of the examples.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Healthcare: diagnosis and prognosis'
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning models assist professionals in healthcare by providing a second
    opinion and sometimes even spotting details humans might miss. These models are
    trained on vast datasets of medical images, learning to identify features associated
    with diseases and conditions, and they can predict the probability of a patient
    having a particular disease. For instance, Google’s DeepMind has developed a model
    to spot eye diseases in scans. By analyzing 3D scans of patients’ eyes, the deep
    learning system can recommend how patients should be referred for treatment.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: 'Autonomous vehicles: navigation and safety'
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning models assist autonomous vehicles in understanding their surroundings,
    making decisions, and navigating the world. They are trained on extensive datasets
    of various driving scenarios and learn to recognize objects (like pedestrians
    and other vehicles), understand road signs, and make safe driving decisions (like
    when to brake or steer). Deep learning essentially allows these vehicles to interpret
    and understand the world around them, making automated driving possible and progressively
    safer as the technology evolves.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Tesla, Waymo, and other companies utilize deep learning for their autonomous
    vehicles. These vehicles are equipped with many sensors that feed data into deep
    learning models, enabling them to make real-time decisions.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'Manufacturing: quality control and predictive maintenance'
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In manufacturing, deep learning models optimize operations and enhance quality
    control. By analyzing data from manufacturing processes, models can identify manufacturing
    anomalies or defects in products early in the production chain, ensuring high-quality
    output. General Electric employs deep learning for predictive equipment maintenance,
    using models that analyze data from machinery to predict when they might fail
    or need maintenance, thereby reducing downtime.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: With its capacity to derive insights from vast, complex datasets, deep learning
    finds applications across diverse real-world scenarios, driving innovations and
    optimizing operations in various industries. From healthcare, where it aids in
    diagnostics, to manufacturing, where it ensures optimal operations and quality,
    deep learning is an integral part of technological advancements in numerous sectors.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: NLP
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NLP aims to understand and read, as well as utilize, the human language well.
    It combines AI and computational linguistics so that computers can process human
    language through spoken words or text. Let’s look at some of the use cases of
    NLP.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots and virtual assistants
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the common applications of NLP is in creating chatbots and virtual assistants
    like Siri, Alexa, or customer service chatbots on various websites.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots engage in interactive conversations with users, often assisting them
    in finding information, answering queries, or facilitating transactions. They
    leverage NLP to understand user inputs (questions or commands) and generate relevant
    responses. By analyzing the text, NLP models discern the intent behind the user’s
    message and respond accordingly. This application is widely utilized across industries
    like retail, banking, and customer service to enhance user experience and provide
    immediate responses to customer inquiries.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Companies use sentiment analysis, also known as opinion mining, to gauge sentiment
    toward their brand, products, or service by analyzing written or spoken words
    from customers, such as customer reviews and social media comments.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis models, developed with NLP, examine text data to determine
    the emotional tone behind them, categorizing sentiments as positive, negative,
    or neutral. For instance, a company could analyze product reviews to identify
    whether customers are generally satisfied or dissatisfied. This information is
    crucial for businesses to understand customer perception and strategically adjust
    their products or services accordingly. Modern contact center solutions, such
    as Amazon Connect, have revolutionized customer service by incorporating real-time
    analysis of customer conversations. These systems can analyze voice interactions
    to determine the customer’s sentiment, which can assist customer support representatives
    during calls to drive customer engagement.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Text summarization
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automated summarization tools that generate concise summaries of lengthy documents
    or articles employ NLP to understand and condense the content effectively.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Text summarization involves reducing a text document without losing its critical
    information and presenting it in a shortened form. NLP models extract essential
    details and key points from the document, providing a summarized version that
    retains the core message. This can be particularly useful in sectors like law
    or research, where professionals must review vast documents and extract pertinent
    information efficiently.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google Translate, which can translate text into different languages, heavily
    relies on NLP to understand and translate the text accurately.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation models utilize NLP to comprehend the text and its context
    in the source language and generate equivalent text in the target language. NLP
    ensures that the translation adheres to grammatical and syntactical rules and
    maintains the original message’s meaning and context. This has global implications,
    breaking down language barriers and facilitating international communication and
    information exchange.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: By enabling machines to understand and process human language, NLP opens up
    many applications that enhance communication, provide insights, and streamline
    processes across numerous domains, including customer service, marketing, and
    global communication.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '**Large language models** (**LLMs**), such as **generative pretrained transformer**
    (**GPT**) models, have emerged as transformative tools in NLP, showcasing impressive
    capabilities across various NLP tasks. These models are designed to understand,
    generate, and work with human-like text, enabling them to engage in activities
    like text completion, summarization, and translation. You will learn more about
    various LLMs in the next chapter.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Overall, ML and AI are vast topics and warrant multiple books to understand
    them more thoroughly. In this chapter, you were just given an overview of ML models,
    types, and workflows.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this comprehensive chapter, you journeyed through the fundamental concepts
    and practical applications of ML. You began by understanding the core principles
    of ML and its close relationship with data science, emphasizing the pivotal role
    of data in training and evaluating ML models. You explored different types of
    ML, ranging from supervised and unsupervised learning to reinforcement learning
    and deep learning. Each type was elucidated with real-world examples and common
    algorithms, providing you with an understanding of when and how to apply them.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Next, you delved into the critical concepts of model overfitting and underfitting,
    exploring the delicate balance required to achieve model generalization. You examined
    various strategies and techniques to address these challenges effectively.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Popular AI tools and frameworks were covered and the chapter also ventured into
    cloud-based ML, demonstrating the advantages and capabilities of harnessing cloud
    platforms for ML projects. The role of data in ML was expounded, with an emphasis
    on feature engineering and selection, as well as the meticulous process of building,
    training, tuning, deploying, and managing ML models. We discussed the design principles
    for ML architecture, providing best practices for architecting scalable and efficient
    ML systems.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: MLOps was explored as anessential component of ML project development, providing
    a structured framework for designing and implementing robust ML systems.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning took center stage, revealing its profound impact on various industries,
    from image recognition to NLP. We dissected the architecture of deep learning
    models and explored practical applications in the real world.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: The chapter culminated in exploring NLP and LLMs, demonstrating how these models
    transform communication, translation, and content generation. Taking a step further,
    GenAI is a key technology for the next evolution. In the next chapter, you will
    learn about GenAI architecture, various FMs, and available offerings that will
    help you gain expertise in GenAI.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace to ask questions and interact with the authors
    and other solution architecture professionals: [https://packt.link/SAHandbook](Chapter_13.xhtml)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code930022060277868125.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
