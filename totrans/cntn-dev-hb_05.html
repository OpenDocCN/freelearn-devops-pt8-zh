<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer062">
<h1 class="chapter-number" id="_idParaDest-102"><a id="_idTextAnchor118"/>5</h1>
<h1 id="_idParaDest-103"><a id="_idTextAnchor119"/>Creating Multi-Container Applications</h1>
<p>This book guides you step by step along the path of developing your applications using containers. In previous chapters, we learned how to create container images, how to share them, and, finally, how to run application processes within containers. In this chapter, we will go a step further by running applications using multiple containers. This is the method you would probably use for developing your applications, running different interconnected components, sharing information, and publishing only the frontend processes to users. By the end of this chapter, you will be able to build, deliver, and run applications by using a composition of multiple containers managed all at once with a newly learned <span class="No-Break">command line.</span></p>
<p>This chapter will cover the <span class="No-Break">following topics:</span></p>
<ul>
<li>Installing and using <span class="No-Break">Docker Compose</span></li>
<li>Introducing the Docker Compose <span class="No-Break">file syntax</span></li>
<li>Building and sharing <span class="No-Break">multi-container applications</span></li>
<li>Running and debugging <span class="No-Break">multi-container applications</span></li>
<li>Managing multiple environments with <span class="No-Break">Docker Compose</span></li>
</ul>
<h1 id="_idParaDest-104"><a id="_idTextAnchor120"/>Technical requirements</h1>
<p>We will use open source tools for building, sharing, and running an application composed of multiple containers. The labs for this chapter will help you understand the content presented, and they are published at <a href="https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter5">https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter5</a>. The <em class="italic">Code In Action</em> video for this chapter can be found <span class="No-Break">at </span><a href="https://packt.link/JdOIY"><span class="No-Break">https://packt.link/JdOIY</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-105"><a id="_idTextAnchor121"/>Installing and using Docker Compose</h1>
<p><strong class="bold">Docker Compose</strong> is a tool developed by Docker Inc. to help developers create, deliver, and run <a id="_idIndexMarker560"/>applications with multiple components running within containers. This tool may come with your Docker container runtime distribution or have to be installed separately. If you are <a id="_idIndexMarker561"/>using tools such as <strong class="bold">Podman</strong>, you will also have available equivalent <span class="No-Break">command-line tools.</span></p>
<p>Docker Compose, developed in 2014 as an open source project, aims to manage multiple containers <a id="_idIndexMarker562"/>based on YAML definitions. This command line will talk directly with the Docker container runtime API. This means that all containers <a id="_idIndexMarker563"/>managed by a <strong class="source-inline">docker-compose</strong> file will run together on top of the same container runtime, hence on the same host. Understanding this is key because you will need third-party tools and configurations if you need to provide high availability for your applications. We can think of Docker Compose as a single-node <span class="No-Break">container orchestrator.</span></p>
<p>If you are using Docker Desktop, you will notice that Docker Compose is already available for you. It should be integrated into your WSL environment if you checked the <strong class="bold">Enable integration</strong> option in your Docker Desktop (this option should be already checked for all previous chapters’ labs and examples in your environment). You can verify this by quickly accessing your Docker Desktop’s settings by navigating to <strong class="bold">Settings</strong> | <strong class="bold">Resources</strong> | <span class="No-Break"><strong class="bold">WSL Integration</strong></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<img alt="Figure 5.1 – Docker Desktop WSL Integration settings" height="775" src="image/B19845_05_01.jpg" width="1477"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Docker Desktop WSL Integration settings</p>
<p>Then, you can <a id="_idIndexMarker564"/>open a terminal in your WSL environment and <a id="_idIndexMarker565"/>simply execute <span class="No-Break"><strong class="source-inline">which docker-compose</strong></span><span class="No-Break">:</span></p>
<pre class="console">
$ which docker-compose
/usr/bin/docker-compose</pre> <p>Docker Desktop installs a modern Docker CLI environment, and this includes a <strong class="source-inline">docker-compose</strong> built-in link. You can verify this by simply retrieving the related information <span class="No-Break">as follows:</span></p>
<pre class="source-code">
$ docker compose --help
Usage:  docker compose [OPTIONS] COMMAND
Docker Compose
Options:
...
Commands:
  build       Build or rebuild services
…
  version     Show the Docker Compose version information
Run 'docker compose COMMAND --help' for more information on a command.</pre> <p>Therefore, we can use either <strong class="source-inline">docker-compose</strong> or <strong class="source-inline">docker compose</strong> for running <strong class="source-inline">compose</strong> <span class="No-Break">commands.</span></p>
<p>If you are using <a id="_idIndexMarker566"/>the Docker container runtime directly on your <a id="_idIndexMarker567"/>computer and your client environment does not include this built-in link, you will need to properly install <strong class="source-inline">docker-compose</strong> binaries. You can use any of the <span class="No-Break">following procedures:</span></p>
<ul>
<li><strong class="bold">As a Python module</strong>: You can install the <strong class="source-inline">docker-compose</strong> module by using the Python package installer (<strong class="source-inline">pip install docker-compose</strong>). This will install the latest Python-based <strong class="source-inline">docker-compose</strong> <span class="No-Break">release (1.29.2):</span><pre class="source-code">
$ pip install docker-compose
Defaulting to user installation because normal site-packages is not writeable
Collecting docker-compose
  Downloading docker_compose-1.29.2-py2.py3-none-any.whl (114 kB) ——— 114.8/114.8 KB 3.9 MB/s eta 0:00:00
...
Successfully installed attrs-22.2.0 bcrypt-4.0.1 certifi-2022.12.7 cffi-1.15.1 charset-normalizer-3.1.0 docker-6.0.1 docker-compose-1.29.2 dockerpty-0.4.1 docopt-0.6.2 idna-3.4 jsonschema-3.2.0 packaging-23.0 paramiko-3.1.0 pycparser-2.21 pynacl-1.5.0 pyrsistent-0.19.3 python-dotenv-0.21.1 requests-2.28.2 texttable-1.6.7 urllib3-1.26.15 websocket-client-0.59.0</pre><p class="list-inset">However, this method will be deprecated as newer <strong class="source-inline">docker-compose</strong> binaries are built using the Go language. We can check the version currently installed by using the <strong class="source-inline">–</strong><span class="No-Break"><strong class="source-inline">version</strong></span><span class="No-Break"> argument:</span></p><pre class="source-code">$ docker-compose --version
docker-compose version 1.29.2, build unknown</pre></li> <li><strong class="bold">As a system package</strong>: Depending on your client’s operating system, you will find different <a id="_idIndexMarker568"/>options for installing the <strong class="source-inline">docker-compose</strong> package. We will show you the steps for Ubuntu 22.04, which provides <a id="_idIndexMarker569"/>the required package and <span class="No-Break">its dependencies:</span><pre class="source-code">
$ sudo apt-get install -qq docker-compose
Preconfiguring packages ...
Selecting previously unselected package pigz.
…
Setting up docker-compose (1.29.2-1) ...
Processing triggers for dbus (1.12.20-2ubuntu4.1) ...
Processing triggers for man-db (2.10.2-1) .</pre><p class="list-inset">As you can see, this method also installs the latest Python-based version <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break">:</span></p><pre class="source-code">$ file /usr/bin/docker-compose
/usr/bin/docker-compose: Python script, ASCII text executable</pre><p class="list-inset">Docker Compose v1 will be deprecated in June, 2023. We should use at least Docker Compose v2 and an appropriate command-line release based on Go. This release may be installed automatically with Docker Desktop, as mentioned at the beginning of this section, or by using Docker Compose as a Docker <span class="No-Break">client plugin.</span></p></li> <li><strong class="bold">As a plugin</strong>: This method is preferred if you are not using Docker Desktop. You will need to configure the package report for your operating system (this may be already <a id="_idIndexMarker570"/>configured in your environment if you installed <a id="_idIndexMarker571"/>the Docker container runtime and its client). You can follow the specific instructions for your Linux distribution published at <a href="https://docs.docker.com/engine/install">https://docs.docker.com/engine/install</a>. Having configured the Docker Inc. repository, we can use the distribution-specific package manager to install <strong class="source-inline">docker-compose-plugin</strong>. We will show you the following Ubuntu process as <span class="No-Break">an example:</span><pre class="source-code">
<strong class="bold">$ sudo apt-get install docker-compose-plugin -qq</strong>
<strong class="bold">Selecting previously unselected package docker-compose-plugin</strong>
<strong class="bold">...</strong>
<strong class="bold">Unpacking docker-compose-plugin (2.17.2-1~ubuntu.22.04~jammy) ...</strong>
<strong class="bold">Setting up docker-compose-plugin (2.17.2-1~ubuntu.22.04~jammy) ...</strong>
<strong class="bold">$ docker compose version</strong>
<strong class="bold">Docker Compose version v2.17.2</strong></pre><p class="list-inset">As you may have noticed, this method installs a modern <strong class="source-inline">docker-compose</strong> version compatible with both Docker Compose v2 <span class="No-Break">and v3.</span></p></li> </ul>
<p class="callout-heading">Important note</p>
<p class="callout">It is possible to install <strong class="source-inline">docker-compose</strong> directly by downloading its binary from the project’s GitHub repository. You can use the following link for further <span class="No-Break">instructions: </span><a href="https://docs.docker.com/compose/install/linux/#install-the-plugin-manually"><span class="No-Break">https://docs.docker.com/compose/install/linux/#install-the-plugin-manually</span></a><span class="No-Break">.</span></p>
<p>Once we <a id="_idIndexMarker572"/>install <strong class="source-inline">docker-compose</strong> by following any of the methods described, we are ready to quickly review the main <span class="No-Break">features available:</span></p>
<ul>
<li>We can build multiple images, code blocks, and Dockerfiles, which may be separated into different folders. This is very useful for automating the construction of all application components <span class="No-Break">at once.</span></li>
<li>Sharing the applications’ container image components is easier with <strong class="source-inline">docker-compose</strong>, as all images will be pushed <span class="No-Break">at once.</span></li>
<li>We can start and stop applications based on multiple containers with <strong class="source-inline">docker-compose</strong>. All components will run at the same time by default, although we can define dependencies <span class="No-Break">between components.</span></li>
<li>All applications’ standard errors and output will be available from a single command, which means that we can access all application logs at once. This will be very useful <a id="_idIndexMarker573"/>when debugging interactions between multiple components at the <span class="No-Break">same time.</span></li>
<li>Provisioning and decommissioning environments are very easy using <strong class="source-inline">docker-compose</strong>, as all required application components will be created and removed by using simple actions such as <strong class="source-inline">docker compose create</strong> and <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">compose rm</strong></span><span class="No-Break">.</span></li>
<li><strong class="bold">Volumes</strong> and <strong class="bold">networks</strong> will be managed for all application containers. This makes the use of <strong class="source-inline">docker-compose</strong> perfect for easily sharing data and isolating inter-process communication. We will publish only specific application processes, while others will be kept internal, hidden from <span class="No-Break">the users.</span></li>
<li>We will use <strong class="bold">projects</strong> to isolate one application from another. Therefore, projects will allow us to run the same application multiple times (with its own set of container objects, such as processes, volumes, networks, and configurations). By default, the name of the current directory will be used as the project name if none is specified. The project name will be used as a prefix for all the objects created. Therefore, container names created for a project, for example, will follow the <strong class="source-inline">&lt;PROJECT&gt;-&lt;SERVICE_NAME&gt;</strong> syntax. We can retrieve the list of running projects by using <strong class="source-inline">docker-compose ls</strong>. This command will show you all running <strong class="source-inline">docker-compose</strong> projects with their Compose YAML <span class="No-Break">file definitions.</span></li>
<li>By using <strong class="bold">profiles</strong>, we will be able to define which objects should be created and managed. This can be very useful under certain circumstances – for example, we can define one <a id="_idIndexMarker574"/>profile for production and another for <a id="_idIndexMarker575"/>debugging. In this situation, we will execute <strong class="source-inline">docker-compose --profile prod up --detach</strong> to launch our application in production, while using <strong class="source-inline">--profile debug</strong> will run some additional components/services for debugging. We will use the <strong class="source-inline">profile</strong> key in our Compose YAML file to group services, which can be added to multiple profiles. We will use a string to define these profiles and we will use it later in the <strong class="source-inline">docker-compose</strong> command line. If no profile is specified, <strong class="source-inline">docker-compose</strong> will execute the actions without using any profile (objects with no profile will <span class="No-Break">be used).</span></li>
</ul>
<p>The following list shows the main actions available <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break">:</span></p>
<ul>
<li><strong class="source-inline">config</strong>: This action will check and show a review of the Compose YAML file. It can be <a id="_idIndexMarker576"/>used in combination with <strong class="source-inline">--services</strong> or <strong class="source-inline">--volumes</strong> arguments to retrieve only these objects. As mentioned before, <strong class="source-inline">--profile</strong> can be used to specifically retrieve information about a certain set or group <span class="No-Break">of objects.</span></li>
<li><strong class="source-inline">images</strong>: This shows the images defined in our Compose YAML file. This will be useful if <a id="_idIndexMarker577"/>you are wondering whether images will need to be built or may already be present in <span class="No-Break">your environment.</span></li>
<li><strong class="source-inline">build</strong>: This action makes <strong class="source-inline">docker-compose</strong> a great tool, even if you are planning to <a id="_idIndexMarker578"/>deploy your applications on a container orchestration cluster such as Kubernetes, as we are able to build all our application components’ container images with just one command. Images created using <strong class="source-inline">docker-compose</strong> will include the project’s name in its name; hence, they will be identified as <strong class="source-inline">&lt;PROJECT_NAME&gt;-&lt;SERVICE_NAME&gt;</strong>. A Dockerfile should be included in all component directories, although we can override the building of certain images by specifying an image repository directly. Remember all the content we learned about tagging images in <a href="B19845_03.xhtml#_idTextAnchor082"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Shipping Docker Images</em>. We can modify the build context and the Dockerfile filename using the <strong class="source-inline">context</strong> and <strong class="source-inline">dockerfile</strong> keys, respectively. If our Dockerfile contains <a id="_idIndexMarker579"/>various targets, we can define which one will be used for building the service’s image by using the <strong class="source-inline">target</strong> key. Arguments can also be passed to the build process to modify the environment by using the <strong class="source-inline">args</strong> key with a list of the key-value pairs that should <span class="No-Break">be included.</span></li>
<li><strong class="source-inline">pull</strong>/<strong class="source-inline">push</strong>: The images defined can be downloaded all at once and the build definitions <a id="_idIndexMarker580"/>can also be pushed to remote registries once your images <span class="No-Break">are created.</span></li>
<li><strong class="source-inline">up</strong>: This action <a id="_idIndexMarker581"/>is equivalent to executing <strong class="source-inline">docker run</strong> for each component/service defined in our Compose YAML file. By default, <strong class="source-inline">docker compose up</strong> will start all the containers at once and our terminal will attach to all containers’ outputs, which may be interesting for testing but not for production (our terminal will be stuck attached to the processes, and we must use <em class="italic">Ctrl </em>+ <em class="italic">P</em> + <em class="italic">Q</em> to detach from them). To avoid this situation, we should use the <strong class="source-inline">-d</strong> or <strong class="source-inline">--detach</strong> argument to launch our containers in the background. <strong class="source-inline">docker-compose</strong> also supports the <strong class="source-inline">run</strong> action, but this is generally used for running specific services one at <span class="No-Break">a time.</span></li>
<li><strong class="source-inline">down</strong>: This action, as expected, does the opposite of <strong class="source-inline">up</strong>; it will stop and remove all the containers <a id="_idIndexMarker582"/>that are running. It is important to understand that new containers will be created if they were previously removed by using this action. Any persistent data must be stored outside of the container’s life cycle. To completely remove your application, remember to always remove the associated volumes. We can add the <strong class="source-inline">--volumes</strong> argument to force the removal of any <span class="No-Break">associated volume.</span></li>
<li><strong class="source-inline">create</strong>/<strong class="source-inline">run</strong>/<strong class="source-inline">start</strong>/<strong class="source-inline">stop</strong>/<strong class="source-inline">rm</strong>: All <a id="_idIndexMarker583"/>these <a id="_idIndexMarker584"/>actions <a id="_idIndexMarker585"/>are <a id="_idIndexMarker586"/>equivalent <a id="_idIndexMarker587"/>to the ones we learned about in <a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Running Docker Containers</em>, but in this case, they will apply to multiple containers <span class="No-Break">at once.</span></li>
<li><strong class="source-inline">ps</strong>: As we <a id="_idIndexMarker588"/>are running multiple containers for a project, this action will list all associated containers. Containers’ performances can be reviewed by using <strong class="source-inline">docker-compose top</strong>, which is an extension of the <strong class="source-inline">docker stats</strong> command we learned in <a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Running </em><span class="No-Break"><em class="italic">Docker Containers</em></span><span class="No-Break">.</span></li>
<li><strong class="source-inline">exec</strong>: This option <a id="_idIndexMarker589"/>allows us to execute a command attached to one of the containers (in this case, a <span class="No-Break">project’s service).</span></li>
<li><strong class="source-inline">logs</strong>: We can use <strong class="source-inline">docker-compose logs</strong> to retrieve all the project’s container logs. This is <a id="_idIndexMarker590"/>very useful for retrieving all application logs by using a single point of view and just one command. The container output will be separated by colors and all the filter options learned about in <a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Running Docker Containers</em>, as well as by <strong class="source-inline">--follow</strong>, which continuously follows all of them. We can retrieve just one service log by adding the service name as <span class="No-Break">an argument.</span></li>
</ul>
<p class="callout-heading">Important note</p>
<p class="callout">Although you will usually execute <strong class="source-inline">docker-compose</strong> actions against all containers, it is possible to specify one service at a time by adding the specific service name, <strong class="source-inline">docker-compose &lt;ACTION&gt; &lt;SERVICE&gt;</strong>. This option is extensible to almost all commands and very useful for debugging purposes when things go wrong with <span class="No-Break">some containers.</span></p>
<p>Now that we know how to install <strong class="source-inline">docker-compose</strong> and what features we may expect, we can learn how to create applications <span class="No-Break">using it.</span></p>
<h1 id="_idParaDest-106"><a id="_idTextAnchor122"/>Introducing the Docker Compose file syntax</h1>
<p>We will <a id="_idIndexMarker591"/>use <strong class="source-inline">docker-compose</strong> with a YAML file, in which we will define all the services, volumes, and networks that will run together and be managed <a id="_idIndexMarker592"/>as components of an application. The YAML file used should follow the <strong class="bold">Compose application model</strong> (more information is available at <a href="https://github.com/compose-spec/compose-spec/blob/master/spec.md">https://github.com/compose-spec/compose-spec/blob/master/spec.md</a>). This model will distribute application components in <strong class="bold">services</strong> and their intercommunication with each other using <strong class="bold">networks</strong>. These networks provide the isolation and abstraction layers for our application containers. Services will store and share their data by <span class="No-Break">using </span><span class="No-Break"><strong class="bold">volumes</strong></span><span class="No-Break">.</span></p>
<p>Services may need additional configurations, and we will use <strong class="bold">config</strong> and <strong class="bold">secret</strong> resources to add specific information to manage the application’s behavior. These objects will be mounted inside our containers, and processes running inside them will use the provided configurations. Secrets will be used to inject sensitive data and the container runtime will treat <span class="No-Break">them differently.</span></p>
<p>As discussed <a id="_idIndexMarker593"/>earlier in this chapter, Compose v1 will be deprecated soon, and you should migrate to at least Compose v2. Your files may need some changes. You can verify this by reviewing the documentation at <a href="https://docs.docker.com/compose/compose-file/compose-versioning">https://docs.docker.com/compose/compose-file/compose-versioning</a>. The Compose application model specification merges the object definitions from v2 <span class="No-Break">and v3.</span></p>
<p>Now, let’s deep dive into the Docker Compose YAML file <span class="No-Break">definition keys.</span></p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor123"/>YAML file definition keys</h2>
<p>By default, the <strong class="source-inline">docker-compose</strong> command will look for <strong class="source-inline">docker-compose.yaml</strong> or <strong class="source-inline">compose.yaml</strong> files in the current directory (you can use either <strong class="source-inline">.yaml</strong> or <strong class="source-inline">.yml</strong> extensions). Multiple Compose files can be used at the same time, and the order in which they <a id="_idIndexMarker594"/>appear will define the final file specification to use. Values will be overridden by the latest ordered file. We can also use variables that can be expanded in runtime by setting our environment variables. This will help us use a general file with variables for <span class="No-Break">multiple environments.</span></p>
<p>The basic schema of a Compose YAML file will be presented <span class="No-Break">as follows:</span></p>
<pre class="source-code">
services:
      service_name1:
            &lt;SERVICE_SPECS&gt;
...
      service_nameN:
            &lt;SERVICE_SPECS&gt;
volumes:
      volume_name1:
            &lt;VOLUME_SPECS&gt;
…
      volume_nameN:
            &lt;VOLUME_SPECS&gt;
networks:
      network_name1:
            &lt;NETWORK_SPECS&gt;
…
      network_nameN:
            &lt;NETWORK_SPECS&gt;</pre> <p>Each service <a id="_idIndexMarker595"/>will need at least a container image definition or a directory where its Dockerfile <span class="No-Break">is located.</span></p>
<p>Let’s review the Compose syntax with an <span class="No-Break">example file:</span></p>
<pre class="source-code">
version: "3.7"
services:
  # load balancer
  lb:
    build: simplestlb
    image: myregistry/simplest-lab:simplestlb
    environment:
      - APPLICATION_ALIAS=simplestapp
      - APPLICATION_PORT=3000
    networks:
      simplestlab:
          aliases:
          - simplestlb
    ports:
      - "8080:80"
  db:
    build: simplestdb
    image: myregistry/simplest-lab:simplestdb
    environment:
        - "POSTGRES_PASSWORD=changeme"
    networks:
       simplestlab:
        aliases:
          - simplestdb
    volumes:
      - pgdata:/var/lib/postgresql/data
  app:
    build: simplestapp
    image: myregistry/simplest-lab:simplestapp
    environment:
      - dbhost=simplestdb
      - dbname=demo
      - dbuser=demo
      - dbpasswd=d3m0
    networks:
       simplestlab:
        aliases:
          - simplestapp
    depends_on:
      - lb
      - db
volumes:
  pgdata:
networks:
  simplestlab:
    ipam:
      driver: default
      config:
        - subnet: 172.16.0.0/16</pre> <p>The first <a id="_idIndexMarker596"/>line is used to identify the Compose syntax version used. Currently, the <strong class="source-inline">version</strong> key is only informative, added for backward compatibility. If some keys are not allowed in the current Compose release, we will be warned, and those keys will be ignored. At the time of writing this book, Compose YAML files do not require this <span class="No-Break"><strong class="source-inline">version</strong></span><span class="No-Break"> key.</span></p>
<p>This Compose YAML file contains three service definitions: <strong class="source-inline">lb</strong>, <strong class="source-inline">db</strong>, and <strong class="source-inline">app</strong>. All of them have an <strong class="source-inline">image</strong> key, which defines the image repository that will be used for creating each service. We also have a <strong class="source-inline">build</strong> key, which defines the directory that will be used for building the defined image. Having both keys will allow us to create the required image with the defined name before executing the service. As you may have noticed, we have defined dependencies for the <strong class="source-inline">app</strong> service. This service depends on the <strong class="source-inline">lb</strong> and <strong class="source-inline">db</strong> services; hence, their containers must be running and healthy before any <strong class="source-inline">app</strong> container starts. Health checks defined in each container image will be used to verify the healthiness of the <a id="_idIndexMarker597"/>container’s processes. That’s why you, as a developer, should define the appropriate health checks for your <span class="No-Break">application’s components.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">Although, in this example, we used the <strong class="source-inline">depends_on</strong> key, it is very important to include the management of different component dependencies in our application’s code. This is important because the <strong class="source-inline">depends_on</strong> key is only available in Compose YAML files. When you deploy your applications in Docker Swarm or Kubernetes, the dependencies can’t be managed in the same way. Compose manages dependencies for you, but this feature does not exist in orchestrated environments and your applications should be prepared for that. You may, for example, verify the connectivity with your database component before executing certain tasks, or you might manage the exceptions in your code related to the loss of this connection. Your application component may need several components, and you should decide what your application has to do if one of them is down. Key application components should stop your code in case full application <span class="No-Break">functionality breaks.</span></p>
<p>In this example, we also defined one volume, <strong class="source-inline">pgdata</strong>, and a network, <strong class="source-inline">simplestlab</strong>. The <strong class="source-inline">volumes</strong> and <strong class="source-inline">networks</strong> sections allow us to define objects to be used by the containers. Each defined service should include the volumes and networks that should be attached to the service’s containers. Containers associated with a service will be named after the service name, including the project as a prefix. Each container is considered an instance for the service and will be numbered; hence, the final container will be <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">&lt;PROJECT_NAME&gt;-&lt;SERVICE_NAME&gt;-&lt;INSTANCE_NUMBER&gt;</strong></span><span class="No-Break">.</span></p>
<p>We can have more than one instance per service. This means that multiple containers may run for a defined service. We will use <strong class="source-inline">--scale SERVICE_NAME=&lt;NUMBER_OF_REPLICAS&gt;</strong> to define the number of replicas that should be running for a <span class="No-Break">specific service.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">As mentioned before, dynamic names will be used for the service containers, but we can use the <strong class="source-inline">container_name</strong> key to define a specific name. This may be interesting for accessing a container name from other containers, but this service wouldn’t be able to scale because, as you already know, container names are unique for each container runtime; thus, we cannot manage replicas in <span class="No-Break">this situation.</span></p>
<p>Compose YAML files allow us to overwrite all the keys defined in the container images. We will <a id="_idIndexMarker598"/>include them inside each <strong class="source-inline">services</strong> definition block. In the presented example, we have included some environment variables for <span class="No-Break">all services:</span></p>
<pre class="source-code">
…
services:
  lb:
    environment:
      - APPLICATION_ALIAS=simplestapp
      - APPLICATION_PORT=3000
…
  db:
    environment:
        - "POSTGRES_PASSWORD=changeme"
…
  app:
    environment:
      - dbhost=simplestdb
      - dbname=demo
      - dbuser=demo
      - dbpasswd=d3m0
…</pre> <p>As you may notice, these environment variables define some configurations that will change the application components’ behavior. Some of these configurations contain sensitive data, and we can use additional Compose objects such as <strong class="source-inline">secrets</strong>. Non-sensitive data can be written using <span class="No-Break"><strong class="source-inline">config</strong></span><span class="No-Break"> objects.</span></p>
<p>For these <a id="_idIndexMarker599"/>objects, an additional key will be used at the <span class="No-Break">root level:</span></p>
<pre class="source-code">
...services:
  app:
...
    configs:
     - source: appconfig
        target: /app/config
        uid: '103'
        gid: '103'
        mode: 0440
volumes:
…
networks:
...
configs:
  appconfig:
    file: ./appconfig.txt</pre> <p>In this example, we changed all the <strong class="source-inline">app</strong> component environment variables for a <strong class="source-inline">config</strong> object, which will be mounted inside <span class="No-Break">the container.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">By default, <strong class="source-inline">config</strong> object files will be mounted in <strong class="source-inline">/&lt;source&gt;</strong> if no <strong class="source-inline">target</strong> key is used. Although there is a short version for mounting <strong class="source-inline">config</strong> object files inside service containers, it is recommended to use the presented long format, as it allows us to specify the complete paths for both <strong class="source-inline">source</strong> and <strong class="source-inline">target</strong>, as well as the file’s permissions <span class="No-Break">and ownership.</span></p>
<p>Secret objects are only available in <strong class="source-inline">swarm</strong> mode. This means that even if you are just using a single node, you must execute <strong class="source-inline">docker swarm init</strong> to initialize a single-node Swarm cluster. This will allow us to create secrets, which are stored as cluster objects by the <a id="_idIndexMarker600"/>Docker container engine. Compose can manage these objects and present them in our service’s containers. By default, secrets will be mounted inside containers in the <strong class="source-inline">/run/secrets/&lt;SECRET_NAME&gt;</strong> path, but this can be changed, as we will see in the <span class="No-Break">following example.</span></p>
<p>First, we create a secret with the database password, used in the <strong class="source-inline">db</strong> service, by using <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">secret create</strong></span><span class="No-Break">:</span></p>
<pre class="console">
$ printf "mysecretdbpassword" | docker secret create postgres_pass -
dzr8bbh5jqgwhfidpnrq7m5qs</pre> <p>Then, we can change our Compose YAML file to include this <span class="No-Break">new </span><span class="No-Break"><strong class="source-inline">secret</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
…
  db:
    build: simplestdb
    image: myregistry/simplest-lab:simplestdb
    environment:
        - POSTGRES_PASSWORD_FILE: /run/secrets/postgres_pass
    secrets:
    - postgres_pass
…
secrets:
  postgres_pass:
     external: true</pre> <p>In this example, we created the secret using the standard output and we used <strong class="source-inline">external: true</strong> to declare that the secret is already set and the container runtime must use its key store to find it. We could have used a file instead as the source. It is also common to integrate some files as <strong class="source-inline">secrets</strong> inside containers by adding them in the <span class="No-Break">following format:</span></p>
<pre class="source-code">
secrets:
  my_secret_name:
    file: &lt;FULL_PATH_TO_SECRET_FILE&gt;</pre> <p>The main difference here is that you may be using a plain text file as a secret that will be encrypted <a id="_idIndexMarker601"/>by the Docker container runtime and mounted inside your containers. Anyone with access to this plain text file will read your secrets. Using the standard output increases security because only the container runtime will have access to the <strong class="source-inline">secret</strong> object. In fact, the Docker Swarm store can also be encrypted, adding a new layer <span class="No-Break">of security.</span></p>
<p>Now that we understand the basic Compose YAML syntax, we can continue learning how to use these files to build and share our application’s <span class="No-Break">container images.</span></p>
<h1 id="_idParaDest-108"><a id="_idTextAnchor124"/>Building and sharing multi-container applications</h1>
<p>Docker Compose allows you to run multi-container applications on single nodes. These applications <a id="_idIndexMarker602"/>will not really have high availability, as you will have a single point of failure and you will probably prefer to use orchestrated <a id="_idIndexMarker603"/>clusters by using Kubernetes or Docker Swarm. But even in these situations, <strong class="source-inline">docker-compose</strong> will help you build and manage the container images for your project. In this section, we will learn how to use <span class="No-Break">these features.</span></p>
<p>Your Compose YAML file will have some service definitions, and each service’s container will need an image definition or a <strong class="source-inline">build</strong> directory. The <strong class="source-inline">image</strong> key will be used for either downloading this image from a registry (if it does not exist in your container runtime already) or setting the name of the service’s container image to be created if a <strong class="source-inline">build</strong> folder exists. As we already mentioned in the previous section, the project’s name will be used as a prefix for all your images by default, but having this <strong class="source-inline">image</strong> key overrides this. Project prefixes will help you identify all the images prepared for a project but may <a id="_idIndexMarker604"/>be confusing when a project must be <a id="_idIndexMarker605"/>executed twice (two different project instances). In such situations, it may be convenient to prepare and push your images for both projects instead of building them with default <span class="No-Break">folder names.</span></p>
<p>We will now focus on the <span class="No-Break"><strong class="source-inline">build</strong></span><span class="No-Break">-related keys:</span></p>
<pre class="source-code">
services:
  lb:
    build: simplestlb
    image: myregistry/simplest-lab:simplestlb
...
  db:
    build: simplestdb
    image: myregistry/simplest-lab:simplestdb
...
  app:
    build: simplestapp
    image: myregistry/simplest-lab:simplestapp</pre> <p>As we mentioned, the <strong class="source-inline">image</strong> key defines the images to be downloaded but in this situation, the <strong class="source-inline">build</strong> key is also present with a folder string, which means that this folder will be used for building <span class="No-Break">the image:</span></p>
<pre class="source-code">
<strong class="bold">$ docker-compose --project-name test build \</strong>
<strong class="bold">--progress quit --quiet</strong>
<strong class="bold">$ docker image ls</strong>
<strong class="bold">REPOSITORY                TAG           IMAGE ID       CREATED      SIZE</strong>
<strong class="bold">myregistry/simplest-lab   simplestapp   26a95450819f   3 days ago   73.7MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestdb    7d43a735f2aa   3 days ago   243MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestlb    3431155dcfd0   3 days ago   8.51MB</strong></pre> <p>As you <a id="_idIndexMarker606"/>may notice, a project name is included to <a id="_idIndexMarker607"/>avoid using the default directory name as a prefix, but the images created used the repository and tag <span class="No-Break">strings defined.</span></p>
<p>Let’s remove the <strong class="source-inline">image</strong> key lines and launch the <strong class="source-inline">build</strong> <span class="No-Break">process again:</span></p>
<pre class="source-code">
<strong class="bold">$ docker-compose --project-name test build \</strong>
<strong class="bold">--progress quit --quiet</strong>
<strong class="bold">$ docker image ls</strong>
<strong class="bold">REPOSITORY                TAG           IMAGE ID       CREATED      SIZE</strong>
<strong class="bold">test-app                  latest        b1179d0492be   3 days ago   73.7MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestapp   b1179d0492be   3 days ago   73.7MB</strong>
<strong class="bold">test-db                   latest        8afd263a1e89   3 days ago   243MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestdb    8afd263a1e89   3 days ago   243MB</strong>
<strong class="bold">test-lb                   latest        4ac39ad7cefd   3 days ago   8.51MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestlb    4ac39ad7cefd   3 days ago   8.51MB</strong></pre> <p>New images were built (cached layers were used) with new names. Notice the project’s name prefix and the folder name. No tags were added, so <strong class="source-inline">latest</strong> was used by default. This is what we expect in such situations, but we could have used any of the following keys to modify the <span class="No-Break"><strong class="source-inline">build</strong></span><span class="No-Break"> process:</span></p>
<ul>
<li><strong class="source-inline">context</strong>: This key must be included inside the <strong class="source-inline">build</strong> key to identify the context used for each image. All the files included in this <strong class="source-inline">context</strong> directory will be passed to the container runtime for analysis. Take care to remove any unnecessary files in <span class="No-Break">this path.</span></li>
<li><strong class="source-inline">dockerfile</strong>: By default, the container runtime will use any existing Dockerfile in your <strong class="source-inline">build</strong> folder, but we can use this key to change this filename and use <span class="No-Break">our own.</span></li>
<li><strong class="source-inline">dockerfile_inline</strong>: This key may be very interesting, as it allows us to use <strong class="source-inline">inline</strong> definitions, as we already<a id="_idTextAnchor125"/> learned in <a href="B19845_02.xhtml#_idTextAnchor036"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building Docker Images</em>. These quick definitions don’t permit any <strong class="source-inline">COPY</strong> or <span class="No-Break"><strong class="source-inline">ADD</strong></span><span class="No-Break"> keys.</span></li>
<li><strong class="source-inline">args</strong>: This key is equivalent to <strong class="source-inline">--build-arg</strong> and it allows us to add any required arguments to our <strong class="source-inline">build</strong> process. Remember that you should include appropriate <strong class="source-inline">ARG</strong> keys in <span class="No-Break">your Dockerfile.</span></li>
<li><strong class="source-inline">labels</strong>: We can include labels in our Dockerfile, and we can also add new ones or overwrite <a id="_idIndexMarker608"/>those already defined by using <a id="_idIndexMarker609"/>the <strong class="source-inline">labels</strong> key. We will include a list with these labels in <span class="No-Break">key-value format.</span></li>
<li><strong class="source-inline">targets</strong>: This key will identify which targets should be compiled in the <strong class="source-inline">build</strong> process. This may be of interest when you want to separate the base image and some additional debug ones from the production-ready final <span class="No-Break">container images.</span></li>
<li><strong class="source-inline">tags</strong>: We can add more than one tag at a time. This may be pretty interesting for defining a <strong class="source-inline">build</strong> process that creates a container image for different registries. By using this key, you will be able to push to all registries at the same time (you will need to be already logged in or you will be asked for your username <span class="No-Break">and password).</span></li>
<li><strong class="source-inline">platforms</strong>: Remember that we learned that <strong class="source-inline">buildx</strong> allowed us to prepare images for different container runtimes architectures (we learned how to create images for ARM64, AMD64, and so on in <a href="B19845_02.xhtml#_idTextAnchor036"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building Docker Images</em>). In our Compose file, we can write which architectures must always be included in the <strong class="source-inline">build</strong> process. This is very interesting for automating your software <span class="No-Break">supply chain.</span></li>
<li><strong class="source-inline">secrets</strong>: Sometimes, we need to include a token, an authentication file with a username and password, or a certificate for accessing some SSL-protected site during the <strong class="source-inline">build</strong> process. In such situations, we can use a secret to introduce this information only at such a stage. You should always avoid adding sensitive information <a id="_idIndexMarker610"/>to your container images. Secrets will only be accessible to the containers created for building the image; thus <a id="_idIndexMarker611"/>they will not be present in the final image. We will need to define a <strong class="source-inline">secrets</strong> object in our Compose file, but this time, it will be used in the <strong class="source-inline">build</strong> process instead of the container runtime. Here is an example of adding a certificate required to access <span class="No-Break">a server:</span><pre class="source-code">
services:
  frontend:
    build:
      secrets:
        - server-certificate
secrets:
  server-certificate:
    file: ./server.cert</pre><p class="list-inset">We can use the long syntax, which is always recommended because it allows us to set the destination path for the included file (by default, the secrets will be present in <strong class="source-inline">/run/secrets</strong>) and its permissions <span class="No-Break">and ownership:</span></p><pre class="source-code">services:
  frontend:
    build:
      secrets:
        - source: server-certificate
          target: server.cert
          uid: "103"
          gid: "103"
          mode: 0440
secrets:
  server-certificate:
    file: ./server.cert</pre></li> </ul>
<p>There are some keys that may be interesting to you if you plan on modifying the default caching behavior during the <strong class="source-inline">build</strong> processes. You can find additional information <span class="No-Break">at </span><a href="https://docs.docker.com/compose/compose-file/build/"><span class="No-Break">https://docs.docker.com/compose/compose-file/build/</span></a><span class="No-Break">.</span></p>
<p>You can push images to the registries to share them using <strong class="source-inline">docker-compose</strong> if you included a registry in the <strong class="source-inline">image</strong> key definition; otherwise, images will <span class="No-Break">be local.</span></p>
<p>By default, all images will be pushed when you execute <strong class="source-inline">docker-compose push</strong>, but as with any <a id="_idIndexMarker612"/>other Compose action, you may need to <a id="_idIndexMarker613"/>pass a service as an argument. In this case, it is useful to use the <strong class="source-inline">--include-deps</strong> argument to push all the images of the services defined in the <strong class="source-inline">depends_on</strong> key. This will ensure that your service will not miss any required images when it <span class="No-Break">is executed:</span></p>
<pre class="console">
$ docker-compose --project-name test push --include-deps app
[+] Running 0/26bc077c4d137 Layer already exists   3.6s
⠇ Pushing lb: 0bc077c4d137 Layer already exists    3.8s
…
⠧ Pushing db: a65fdf68ac5a Layer already exists    3.7s
…
⠧ Pushing app: 7dfc1aa4c504 Layer already exists   3.7s</pre> <p>Notice, in this example, that even though we have just pushed the <strong class="source-inline">app</strong> service image, <strong class="source-inline">lb</strong> and <strong class="source-inline">db</strong> are also pushed to our registry because they were declared <span class="No-Break">as dependencies.</span></p>
<p>In this section, we learned how to use <strong class="source-inline">docker-compose</strong> for building and sharing our application’s components. In the next section, we will run containers defined in our Compose YAML files and review their logs <span class="No-Break">and status.</span></p>
<h1 id="_idParaDest-109"><a id="_idTextAnchor126"/>Running and debugging multi-container applications</h1>
<p>Applications executed using Docker Compose will be orchestrated but without high availability. This doesn’t mean you can’t use it in production, but you may need additional applications <a id="_idIndexMarker614"/>or infrastructure to keep your components <span class="No-Break">always on.</span></p>
<p>Docker Compose <a id="_idIndexMarker615"/>provides an easy way of running applications using a <em class="italic">single point of management</em>. You may have more than one YAML file for defining your application’s components, but the <strong class="source-inline">docker-compose</strong> command will merge them into a single definition. We will simply use <strong class="source-inline">docker-compose up</strong> to launch our complete application, although we can manage each component separately by simply adding its service’s name. <strong class="source-inline">docker-compose</strong> will refresh the components’ status and will just recreate those that have stopped or are non-existent. By default, it will attach our terminal to all application containers, which may be very useful for debugging but it isn’t useful for publishing our services. We will use <strong class="source-inline">-d</strong> or <strong class="source-inline">--detach</strong> to launch all container processes in <span class="No-Break">the background.</span></p>
<p>The <strong class="source-inline">docker-compose up</strong> execution will first verify whether all the required images are present on your system. If they aren’t found, the container runtime will receive the order of creating them if a <strong class="source-inline">build</strong> key is found. If this key isn’t present, images will be downloaded from the registry defined in your <strong class="source-inline">image</strong> key. This process will be followed every time you execute <strong class="source-inline">docker-compose up</strong>. If you are changing some code within your application’s component folders, you will need to recreate them by changing your compose YAML <strong class="source-inline">image</strong> tags or the <span class="No-Break">image’s digest.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">You can use <strong class="source-inline">docker-compose up --d --build</strong> to specifically ask your container runtime to rebuild all the images (or part of them if you specified a service). As you may expect, the runtime will check each image layer (<strong class="source-inline">RUN</strong> and <strong class="source-inline">COPY</strong>/<strong class="source-inline">ADD</strong> keys) and rebuild only those that have changed. This will avoid the use of an intermediate <strong class="source-inline">docker-compose build</strong> process. Remember to maintain your container runtime disk space by pruning old <span class="No-Break">unnecessary images.</span></p>
<p>As we already mentioned in this section, containers will always be created if they don’t exist when we execute <strong class="source-inline">docker-compose up</strong>. But in some cases, you will need to execute a fresh start of all containers (maybe some non-resolved dependencies in your code may need to force some order or reconnection). In such situations, we can use the <strong class="source-inline">--force-recreate</strong> argument to enforce the recreation of your <span class="No-Break">services’ containers.</span></p>
<p>We will use the <strong class="source-inline">entrypoint</strong> and <strong class="source-inline">command</strong> keys to <em class="italic">overwrite</em> the ones defined in the images used <a id="_idIndexMarker616"/>for creating each service container and <a id="_idIndexMarker617"/>we will specifically define which services will be available for the users by publishing them. All other services will use the internally defined network for <span class="No-Break">their communications.</span></p>
<p>As you may expect, everything <a id="_idIndexMarker618"/>we learned about <strong class="bold">container networking</strong> in <a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Running Docker Containers</em>, will also apply here. Therefore, an internal DNS is available for all the communications provided in the internal network, and services will be published with their defined names. This is key to understanding how your application’s components will know each other. You shouldn’t use their instance name (<strong class="source-inline">&lt;PROJECT_NAME&gt;_&lt;SERVICE_NAME&gt;_&lt;INSTANCE&gt;</strong>); we will instead use the service’s name to locate a defined service. For example, we will use <strong class="source-inline">db</strong> in our <strong class="source-inline">app</strong> component connection string. Take care because your instance name will also be available but shouldn’t be used. This will really break the portability and dynamism of your applications if you move them to clustered environments where instances’ names may not be usable or if you use more than one replica for <span class="No-Break">some services.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">We can manage the number of container replicas for a service by using the <strong class="source-inline">replicas</strong> key. These replicas will run in isolation, and you will not need a load balancer service to redirect the service requests to each instance. Consider the <span class="No-Break">following example:</span></p>
<p class="callout"><span class="No-Break"><strong class="source-inline">services:</strong></span></p>
<p class="callout"><strong class="source-inline"> </strong><span class="No-Break"><strong class="source-inline">app:</strong></span></p>
<p class="callout"><strong class="source-inline">…</strong></p>
<p class="callout"><strong class="source-inline"> </strong><span class="No-Break"><strong class="source-inline">deploy:</strong></span></p>
<p class="callout"><strong class="source-inline"> </strong><span class="No-Break"><strong class="source-inline">replicas: 2</strong></span></p>
<p class="callout"><strong class="source-inline">…</strong></p>
<p class="callout">In such a situation, two containers of our <strong class="source-inline">app</strong> service will be launched. Docker Swarm and Kubernetes will provide TCP load balancer capabilities. If you need to apply your own balancer rules (such as specific weights), you need to add your own load balancer service. Your container runtime will just manage OSI layer 3 <span class="No-Break">communications (</span><a href="https://en.wikipedia.org/wiki/OSI_model"><span class="No-Break">https://en.wikipedia.org/wiki/OSI_model</span></a><span class="No-Break">).</span></p>
<p>Multi-container applications defined in a Compose file will run after we execute <strong class="source-inline">docker-compose up --detach</strong>, and to review their <em class="italic">state</em>, we will use <strong class="source-inline">docker-compose ps</strong>. Remember to add your project in all your commands if you need to overwrite the <a id="_idIndexMarker619"/>default project’s name (current folder). We can use common <strong class="source-inline">--filter</strong> and <strong class="source-inline">--format</strong> arguments to filter and modify the <a id="_idIndexMarker620"/>output of this command. If some of the service’s containers are missing, maybe they didn’t start correctly; by default, <strong class="source-inline">docker-compose ps</strong> will only show the running containers. To review all the containers associated with our project, we will use the <strong class="source-inline">--all</strong> argument, which will show the running and <span class="No-Break">stopped containers.</span></p>
<p>If any issues are found in our project’s containers, we will see them as exited in the <strong class="source-inline">docker-compose ps</strong> command’s output. We will use <strong class="source-inline">docker-compose logs</strong> to review all container logs at once, or we can choose to review only the specific service in error by adding the name of the service to <span class="No-Break">this command.</span></p>
<p>We can use the <strong class="source-inline">--file</strong> (or <strong class="source-inline">-f</strong>) argument to define the complete path to our Compose YAML file. For this to work, it is very useful to first list all the Compose applications running in our system by using <strong class="source-inline">docker-compose ls</strong>. The full path to each application’s Compose YAML file will be shown along with its project’s name, as in <span class="No-Break">this example:</span></p>
<pre class="console">
$ docker-compose ls
NAME                STATUS              CONFIG FILES
test                running(3)          /home/frjaraur/labs/simplest-lab/docker-compose.yaml</pre> <p>In this case, we can add the path to the Compose file to any <span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break"> action:</span></p>
<pre class="console">
$ docker-compose --project-name test \
--file /home/frjaraur/labs/simplest-lab/docker-compose.yaml ps
NAME                IMAGE                                         COMMAND                  SERVICE             CREATED             STATUS              PORTS
test-app-1          docker.io/frjaraur/simplest-lab:simplestapp   "node simplestapp.js…"   app                 25 hours ago        Up 28 minutes       3000/tcp
test-db-1           docker.io/frjaraur/simplest-lab:simplestdb    "docker-entrypoint.s…"   db                  25 hours ago        Up 24 minutes       5432/tcp
test-lb-1           docker.io/frjaraur/simplest-lab:simplestlb    "/entrypoint.sh /bin…"   lb                  25 hours ago        Up 24 minutes       0.0.0.0:8080-&gt;80/tcp</pre> <p>This will <a id="_idIndexMarker621"/>work even with <strong class="source-inline">build</strong> actions, as the Compose <a id="_idIndexMarker622"/>YAML file location will be used as a reference for all commands. The <strong class="source-inline">context</strong> key may be included to modify <span class="No-Break">its behavior.</span></p>
<p>We can review the port exposed for the application in the <strong class="source-inline">docker-compose ps</strong> output. To review our application’s logs, we can use <strong class="source-inline">docker-compose logs</strong>, and each service will be represented in a different random color. This is very useful for following the different entries in each service. We can specify a single service by passing its name as <span class="No-Break">an argument.</span></p>
<p>The following screenshot shows the output of <strong class="source-inline">docker-compose logs</strong> using <strong class="source-inline">--tail 5</strong> to only retrieve the latest <span class="No-Break">five lines:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<img alt="Figure 5.2 – Service container logs retrieved by using docker-compose logs" height="535" src="image/B19845_05_02.jpg" width="1461"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Service container logs retrieved by using docker-compose logs</p>
<p>Notice that in this simple test, we only have two services, and colors are applied to each one. We retrieved only the latest five lines of each container by adding <strong class="source-inline">--tail 5</strong>. This argument <a id="_idIndexMarker623"/>applies to all containers (we didn’t get the latest five lines of all logs merged). It is also important to mention that service names <a id="_idIndexMarker624"/>must be used as arguments when we need to use an action in a specific service. We will never use the container names; hence, we need to include the appropriate <span class="No-Break">project name.</span></p>
<p>We can use the same approach to access a container’s namespace by using the <strong class="source-inline">exec</strong> action. Remember that we learned in <a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Running Docker Containers</em>, that we can execute a new process inside our container (it will share all the container’s process kernel namespaces). By using <strong class="source-inline">docker-compose exec &lt;SERVICE_NAME&gt;</strong>, we can execute a new process inside any of our <span class="No-Break">service’s containers:</span></p>
<pre class="console">
$ docker-compose --project-name test exec db ps -ef
PID   USER     TIME  COMMAND
    1 postgres  0:00 postgres
   53 postgres  0:00 postgres: checkpointer
   54 postgres  0:00 postgres: background writer
   55 postgres  0:00 postgres: walwriter
   56 postgres  0:00 postgres: autovacuum launcher
   57 postgres  0:00 postgres: stats collector
   58 postgres  0:00 postgres: logical replication launcher
   90 root      0:00 ps -ef</pre> <p>In summary, we will be able to run the same actions for containers by <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break">.</span></p>
<p>For you as a developer, Docker Compose can really help you develop applications faster. You will be able to run all application containers at once. In the development stage, you can include your code in specific containers by mounting a volume, and you can verify how your <a id="_idIndexMarker625"/>changes affect other components. For example, you can mount the code of one application component and change it while other <a id="_idIndexMarker626"/>components are running. Of course, you can do this without the <strong class="source-inline">docker-compose</strong> command line, but you will need to automate your deployments with scripts and verify the containers’ state. Docker Compose orchestrates this for you, and you can focus on changing your code. If you work in a team and all other developers provide container images and you share some application information, you can run these images locally while you are still working on <span class="No-Break">your component.</span></p>
<p>Now that we know how to run and interact with multi-container applications, we will end this chapter by learning how to use environment variables to deploy your applications under <span class="No-Break">different circumstances.</span></p>
<h1 id="_idParaDest-110"><a id="_idTextAnchor127"/>Managing multiple environments with Docker Compose</h1>
<p>In this section, we will learn how to prepare our Compose YAML files as templates for running <a id="_idIndexMarker627"/>our applications in different environments and under different circumstances, such as developing <span class="No-Break">or debugging.</span></p>
<p>If you <a id="_idIndexMarker628"/>are familiar with the use of environment variables in different operating systems, this section will seem pretty easy. We already learned how to use variables to modify the default behavior of Dockerfiles (<a href="B19845_02.xhtml#_idTextAnchor036"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building Docker Images</em>) and containers at runtime (<a href="B19845_04.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Running Docker Containers</em>). We used variables to overwrite the default values defined and modify the <strong class="source-inline">build</strong> process or the execution of container image processes. We will use the same approach with Compose YAML files. We will now review some of the different options we have to use variables with the <strong class="source-inline">docker-compose</strong> <span class="No-Break">command line.</span></p>
<p>We can define a <strong class="source-inline">.env</strong> file with all the variables we are going to use in a Compose YAML file defined as a template. Docker Compose will search for this file in our project’s root folder by default, but we can use <strong class="source-inline">--env-file &lt;FULL_FILE_PATH&gt;</strong> or the <strong class="source-inline">env_file</strong> key in our Compose YAML file. In this case, the key must be set for each service using the <span class="No-Break">environment file:</span></p>
<pre class="source-code">
env_file:
  - ./debug.env</pre> <p>The environment file will overwrite the values defined in our images. Multiple environment files <a id="_idIndexMarker629"/>can be included; thus, the order is critical. The lower ones in your list will overwrite the previous values, but <a id="_idIndexMarker630"/>this also happens when we use more than one Compose YAML file. The order of the arguments passed will modify the final behavior of <span class="No-Break">the execution.</span></p>
<p>You, as a developer, must prepare your Compose YAML files with variables to modify the execution passed to your container runtime.  The following example shows how we can implement some variables to deploy applications in <span class="No-Break">different environments:</span></p>
<pre class="source-code">
services:
  lb:
    build:
      context: ./simplestlb
      args:
        alpineversion: "1.14"
      dockerfile: Dockerfile.${environment}
      labels:
        org.codegazers.description: "Test image"
    image: ${dockerhubid}/simplest-lab:simplestlb
    environment:
      - APPLICATION_ALIAS=simplestapp
      - APPLICATION_PORT=${backend_port}
    networks:
      simplestlab:
          aliases:
          - simplestlb
    ports:
      - "${loadbalancer_port}:80"</pre> <p>In this <a id="_idIndexMarker631"/>example, we can complete <a id="_idIndexMarker632"/>our variables with the following <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">env</strong></span><span class="No-Break"> file:</span></p>
<pre class="source-code">
environment=dev
dockerhubid=frjaraur
loadbalancer_port=8080
backend_port=3000</pre> <p>This environment file will help us define a base build and deployment. Different Dockerfiles will be included – <strong class="source-inline">Dockerfile.dev</strong> and <strong class="source-inline">Dockerfile.prod</strong>, <span class="No-Break">for example.</span></p>
<p>We can then verify the actual configuration applied <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
$ docker-compose --project-name test \
--file myapp-docker-compose.yaml config
name: test
services:
  lb:
...
      context: /home/frjaraur/tests/dcadeg/chapter5/simplest-lab/simplestlb
      dockerfile: Dockerfile.dev
      args:
        alpineversion: "1.14"
      labels:
        org.codegazers.description: Test image
    environment:
      APPLICATION_ALIAS: simplestapp
      APPLICATION_PORT: "3000"
    image: frjaraur/simplest-lab:simplestlb
    ...
    ports:
    - mode: ingress
      target: 80
      published: "8080"
      protocol: tcp
networks:
...</pre> <p>All the <a id="_idIndexMarker633"/>values have already been <a id="_idIndexMarker634"/>assigned using the <strong class="source-inline">.env</strong> file, but these can be <span class="No-Break">overridden manually:</span></p>
<pre class="console">
$ dockerhubid=myid \
 docker-compose --project-name test \
--file myapp-docker-compose.yaml config
…
    image: myid/simplest-lab:simplestlb
...</pre> <p>Remember that profiles and targets can also be used to prepare specific images and then run the services <span class="No-Break">completely customized.</span></p>
<p>We can now review some labs that will help us better understand some of the content of <span class="No-Break">this chapter.</span></p>
<h1 id="_idParaDest-111"><a id="_idTextAnchor128"/>Labs</h1>
<p>The following <a id="_idIndexMarker635"/>labs will help you deploy a simple demo application by using some of the commands learned in this chapter. The code for the labs is available in this book’s GitHub repository at <a href="https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git">https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git</a>. Ensur<a href="https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git">e that you have the latest revision available by simply executing <strong class="source-inline">git</strong></a><strong class="source-inline"> clone https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git</strong> to download all its content or <strong class="source-inline">git pull</strong> if you have already downloaded the repository before. All commands and content used in these labs will be located inside the <span class="No-Break"><strong class="source-inline">Docker-for-Developers-Handbook/Chapter5</strong></span><span class="No-Break"> directory.</span></p>
<p>In this chapter, we learned how to deploy a complete application using <strong class="source-inline">docker-compose</strong>. Let’s put this into practice by deploying a <span class="No-Break">sample application.</span></p>
<h2 id="_idParaDest-112"><a id="_idTextAnchor129"/>Deploying a simple demo application</h2>
<p>In this lab, we will learn how to deploy an application with three components: a load balancer, a frontend, and <span class="No-Break">a database.</span></p>
<p>There are <a id="_idIndexMarker636"/>hundreds of good Docker Compose examples and, in fact, there are many vendors who provide their applications packaged in the <a id="_idIndexMarker637"/>Compose YAML format, even for production. We chose this pretty simple application because we are focusing on the Docker command line and not on the <span class="No-Break">application itself.</span></p>
<p>If you list the content of the <strong class="source-inline">Chapter5</strong> folder, you will see a folder named <strong class="source-inline">simplestapp</strong>. There is a subfolder for each component and a Compose file that will allow us to deploy the <span class="No-Break">full application.</span></p>
<p>The Compose YAML file that defines our application contains the <span class="No-Break">following code:</span></p>
<pre class="source-code">
version: "3.7"
services:
  lb:
    build: simplestlb
    image: myregistry/simplest-lab:simplestlb
    environment:
      - APPLICATION_ALIAS=simplestapp
      - APPLICATION_PORT=3000
    networks:
      simplestlab:
          aliases:
          - simplestlb
    ports:
      - "8080:80"
  db:
    build: simplestdb
    image: myregistry/simplest-lab:simplestdb
    environment:
        - "POSTGRES_PASSWORD=changeme"
    networks:
       simplestlab:
        aliases:
          - simplestdb
    volumes:
      - pgdata:/var/lib/postgresql/data
  app:
    build: simplestapp
    image: myregistry/simplest-lab:simplestapp
    environment:
      - dbhost=simplestdb
      - dbname=demo
      - dbuser=demo
      - dbpasswd=d3m0
    networks:
       simplestlab:
        aliases:
          - simplestapp
    depends_on:
      - lb
      - db
volumes:
  pgdata:
networks:
  simplestlab:
    ipam:
      driver: default
      config:
        - subnet: 172.16.0.0/16</pre> <p>This application <a id="_idIndexMarker638"/>is a very simplified demo for <a id="_idIndexMarker639"/>showing how various components could be deployed. Never use environment variables for your sensitive data. We already learned how to use <strong class="source-inline">configs</strong> and <strong class="source-inline">secrets</strong> objects in this chapter. It is good to also notice that we didn’t use a non-root user for the database and load balancer components. You, as a developer, should always try to keep security at the maximum on your application components. It is also important to notice the lack of health checks at the Dockerfile and Compose levels. We will learn more about application health checks in Kubernetes later in this book because it may not always be a good idea to include some <strong class="bold">Transmission Control Protocol</strong> (<strong class="bold">TCP</strong>) check tools in your images. In <a href="B19845_08.xhtml#_idTextAnchor170"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Deploying Applications with the Kubernetes Orchestrator</em>, we will learn how this orchestration platform provides internal mechanisms for such tasks and how we can enforce better <span class="No-Break">security options.</span></p>
<p>In this lab, only one volume will be used for the database component, and the only service published <a id="_idIndexMarker640"/>is the load balancer. We included this <a id="_idIndexMarker641"/>service just to let you understand how we can integrate a multilayer application and only share one visible component. All images will be created locally (you may want to upload to your own registry or Docker Hub account). Follow the next steps to deploy the <strong class="source-inline">simplestapp</strong> application described in the <span class="No-Break"><strong class="source-inline">compose</strong></span><span class="No-Break"> file:</span></p>
<ol>
<li>To build all the images for this project, we will use <span class="No-Break"><strong class="source-inline">docker-compose build</strong></span><span class="No-Break">:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 build</strong>
<strong class="bold">[+] Building 0.0s (0/0)</strong>
<strong class="bold">…</strong>
<strong class="bold"> =&gt; =&gt; writing image sha256:2d88460e20ca557fcd25907b5f026926b0e61d93fde58a8e0b854cfa0864c3bd                       0.0s</strong>
<strong class="bold"> =&gt; =&gt; naming to docker.io/myregistry/simplest-lab:simplestapp                                                     0.0s</strong></pre><p class="list-inset">We could have directly used <strong class="source-inline">docker-compose run</strong> to build or pull the images and run all containers, but this way, we can review the process step <span class="No-Break">by step.</span></p></li> </ol>
<p class="callout-heading">Important note</p>
<p class="callout">If you reset your Docker Desktop before starting the labs, you may find some errors regarding an old Docker container runtime integration on your <span class="No-Break">WSL environment:</span></p>
<p class="callout"><strong class="source-inline">$ docker-compose --file simplestlab/docker-compose.yaml --project-name </strong><span class="No-Break"><strong class="source-inline">chapter5 build</strong></span></p>
<p class="callout"><strong class="source-inline">docker endpoint for "default" </strong><span class="No-Break"><strong class="source-inline">not found</strong></span></p>
<p class="callout">The solution is very easy: simply remove your old Docker integration by removing your <strong class="source-inline">.docker</strong> directory, located in your home directory: <strong class="source-inline">$ rm -</strong><span class="No-Break"><strong class="source-inline">rf ~/.docker</strong></span><span class="No-Break">.</span></p>
<ol>
<li value="2">We can <a id="_idIndexMarker642"/>take a <a id="_idIndexMarker643"/>look at the images <span class="No-Break">created locally:</span><pre class="source-code">
<strong class="bold">$ docker image ls</strong>
<strong class="bold">REPOSITORY                TAG           IMAGE ID       CREATED         SIZE</strong>
<strong class="bold">myregistry/simplest-lab   simplestapp   2d88460e20ca   8 minutes ago   73.5MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestdb    e872ee4e9593   8 minutes ago   243MB</strong>
<strong class="bold">myregistry/simplest-lab   simplestlb    bab86a191910   8 minutes ago   8.51MB</strong></pre><p class="list-inset">As you may notice, all the images created follow the names defined in the Compose YAML file. Because the <strong class="source-inline">build</strong> key exists, the build process is executed instead of pulling <span class="No-Break">images directly.</span></p></li> <li>Let’s now create the container for the <span class="No-Break">database service:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 create db</strong>
<strong class="bold">[+] Running 3/3</strong>
<strong class="bold"> :: Network chapter5_simplestlab  Created                                              0.8s</strong>
<strong class="bold"> :: Volume "chapter5_pgdata"      Created                                                     0.0s</strong>
<strong class="bold"> :: Container chapter5-db-1       Created                             0.2s</strong></pre><p class="list-inset">All the objects required for the database service are created. It is not running yet, but it is ready <span class="No-Break">for that.</span></p></li> <li>We run <a id="_idIndexMarker644"/>this service alone and review <span class="No-Break">its status:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 up -d db</strong>
<strong class="bold">[+] Running 1/1</strong>
<strong class="bold"> :: Container chapter5-db-1  Started</strong></pre><p class="list-inset">If you <a id="_idIndexMarker645"/>omit the Compose filename and the project’s name, we will get neither the services nor <span class="No-Break">the containers:</span></p><pre class="source-code"><strong class="bold">$ docker-compose ps</strong>
<strong class="bold">no configuration file provided: not found</strong>
<strong class="bold">$ docker-compose --file simplestlab/docker-compose.yaml ps</strong>
<strong class="bold">NAME                IMAGE               COMMAND             SERVICE             CREATED             STATUS              PORTS</strong></pre><p class="list-inset">Always ensure you use the appropriate name and Compose file for all the commands related to <span class="No-Break">a project:</span></p><pre class="source-code"><strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 ps</strong>
<strong class="bold">NAME                IMAGE                                COMMAND                  SERVICE             CREATED             STATUS              PORTS</strong>
<strong class="bold">chapter5-db-1       myregistry/simplest-lab:simplestdb   "docker-entrypoint.s…"   db                  4 minutes ago       Up 3 minutes        5432/tcp</strong></pre></li> <li>We will now run the <strong class="source-inline">lb</strong> and <strong class="source-inline">app</strong> services by using <strong class="source-inline">docker-compose </strong><span class="No-Break"><strong class="source-inline">up -d</strong></span><span class="No-Break">:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 up -d</strong>
<strong class="bold">[+] Running 3/3</strong>
<strong class="bold"> :: Container chapter5-lb-1   Started                                        2.0s</strong>
<strong class="bold"> :: Container chapter5-db-1   Running                                  0.0s</strong>
<strong class="bold"> :: Container chapter5-app-1  Started                                  2.9s</strong></pre><p class="list-inset">Your services <a id="_idIndexMarker646"/>will quickly change their status from <strong class="source-inline">Created</strong> <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">Started</strong></span><span class="No-Break">.</span></p></li> <li>We can <a id="_idIndexMarker647"/>now review the status of all our application components and the <span class="No-Break">ports exposed:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 ps</strong>
<strong class="bold">NAME                IMAGE                                 COMMAND                  SERVICE             CREATED             STATUS              PORTS</strong>
<strong class="bold">chapter5-app-1      myregistry/simplest-lab:simplestapp   "node simplestapp.js…"   app                 9 minutes ago       Up 9 minutes        3000/tcp</strong>
<strong class="bold">chapter5-db-1       myregistry/simplest-lab:simplestdb    "docker-entrypoint.s…"   db                  16 minutes ago      Up 15 minutes       5432/tcp</strong>
<strong class="bold">chapter5-lb-1       myregistry/simplest-lab:simplestlb    "/entrypoint.sh /bin…"   lb                  9 minutes ago       Up 9 minutes        0.0.0.0:8080-&gt;80/tcp</strong></pre><p class="list-inset">Once<a href="http://127.0.0.1:8080"> running, you can <span id="_idIndexMarker648"/>ac</a>cess the <strong class="source-inline">simplestlab</strong> application <a id="_idIndexMarker649"/>by connecting with your browser <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">http://127.0.0.1:8080</strong></span><span class="No-Break">:</span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 5.3 – The simplestlab application" height="899" src="image/B19845_05_03.jpg" width="1657"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – The simplestlab application</p>
<p class="list-inset">This allows us to graphically review how requests are distributed when multiple backends <span class="No-Break">are available.</span></p>
<ol>
<li value="7">We can <a id="_idIndexMarker650"/>scale our <strong class="source-inline">app</strong> component in this example. This option may be complicated or impossible in other deployments, as it really <a id="_idIndexMarker651"/>depends on your own application code and logic. For example, you should scale a database component without appropriate database internal scale logic (you should review the database server <span class="No-Break">vendor’s documentation):</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 up --scale app=2 -d</strong>
<strong class="bold">[+] Running 4/4</strong>
<strong class="bold"> :: Container chapter5-db-1   Running                          0.0s</strong>
<strong class="bold"> :: Container chapter5-lb-1   Running                           0.0s</strong>
<strong class="bold"> :: Container chapter5-app-2  Created                               0.2s</strong>
<strong class="bold"> :: Container chapter5-app-1  Recreated                        10.8s</strong></pre></li> <li>We can <a id="_idIndexMarker652"/>now review the <strong class="source-inline">app</strong> service’s logs. We will <a id="_idIndexMarker653"/>retrieve both <span class="No-Break">containers’ logs:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name chapter5 logs app</strong>
<strong class="bold">chapter5-app-1  | dbuser: demo dbpasswd: d3m0</strong>
<strong class="bold">…</strong>
<strong class="bold">chapter5-app-1  | dbuser: demo dbpasswd: d3m0</strong>
<strong class="bold">…</strong>
<strong class="bold">chapter5-app-2  | Can use environment variables to avoid '/APP/dbconfig.js' file configurations.</strong></pre></li> </ol>
<p>Finally, your application is up and running, and we can move on to the next lab, in which we will use the same Compose file to deploy a second project with the <span class="No-Break">same application.</span></p>
<h2 id="_idParaDest-113"><a id="_idTextAnchor130"/>Deploying another project using the same Compose YAML file</h2>
<p>In this <a id="_idIndexMarker654"/>simple example, we will review and <a id="_idIndexMarker655"/>discuss the problems we may encounter by running two projects using the same Compose YAML file. To do this, we will follow <span class="No-Break">these instructions:</span></p>
<ol>
<li>Let’s create a new project by using a new <span class="No-Break">project name:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name newdemo create</strong>
<strong class="bold">[+] Running 0/0</strong>
<strong class="bold"> :: Network newdemo_simplestlab  Error    0.0s</strong>
<strong class="bold">failed to create network newdemo_simplestlab: Error response from daemon: Pool overlaps with other one on this address space</strong></pre><p class="list-inset">As you <a id="_idIndexMarker656"/>may notice, we defined a specific network in the <strong class="bold">classless inter-domain routing</strong> (<strong class="bold">CIDR</strong>) format for our project network. The <a id="_idIndexMarker657"/>Docker container runtime assigns IP ranges by using its own <strong class="bold">IP address management</strong> (<strong class="bold">IPAM</strong>); thus, it manages any IP overlap automatically for us. By using a specific range, we broke <a id="_idIndexMarker658"/>the dynamism of <span class="No-Break">the platform.</span></p></li> <li>Let’s remove <a id="_idIndexMarker659"/>the IP address range from our <span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break"> definition:</span><pre class="source-code">
networks:
  simplestlab:
    ipam:
      driver: default</pre><p class="list-inset">And now we try to deploy the <span class="No-Break">application again:</span></p><pre class="source-code"><strong class="bold">$ docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name newdemo create</strong>
<strong class="bold">[+] Running 5/5</strong>
<strong class="bold"> :: Network newdemo_simplestlab  Created                           0.9s</strong>
<strong class="bold"> :: Volume "newdemo_pgdata"      Created                         0.0s</strong>
<strong class="bold"> :: Container newdemo-db-1       Created                         0.2s</strong>
<strong class="bold"> :: Container newdemo-lb-1       Created                    0.2s</strong>
<strong class="bold"> :: Container newdemo-app-1      Created                      0.2s</strong></pre><p class="list-inset">We didn’t have any problems this time. The <strong class="source-inline">volume</strong> and <strong class="source-inline">network</strong> objects were created with the project prefix. We will not be able to reuse the project name <a id="_idIndexMarker660"/>because object names must <span class="No-Break">be unique.</span></p></li> <li>Let’s run <a id="_idIndexMarker661"/>all the application <span class="No-Break">components now:</span><pre class="source-code">
<strong class="bold">$ docker-compose --file simplestlab/docker-compose.yaml --project-name newdemo start</strong>
<strong class="bold">[+] Running 1/2</strong>
<strong class="bold"> :: Container newdemo-db-1  Started                            1.4s</strong>
<strong class="bold"> :: Container newdemo-lb-1  Starting                                    1.4s</strong>
<strong class="bold">Error response from daemon: driver failed programming external connectivity on endpoint newdemo-lb-1 (bb03c1b0a14a90a3022aca3c3a9a9d506b3e312cc864f0dcda6a5360d58ef3d0): Bind for 0.0.0.0:8080 failed: port is already allocated</strong></pre><p class="list-inset">You may notice that we also defined a specific port for our <strong class="source-inline">lb</strong> service. This seems fine for production, but defining a specific port in development, where multiple copies of an application can be expected, also breaks the dynamism of container-based components. For this to work, we could just simply change this port number, allow the system to choose a random one for us, or define a variable that will allow us to define a port for <span class="No-Break">each project.</span></p></li> <li>We change our Compose YAML and add the <strong class="source-inline">LB_PORT</strong> variable as the port for exposing <span class="No-Break">our application:</span><pre class="source-code">
services:
  lb:
…
    ports:
      - "${LB_PORT}:80"</pre><p class="list-inset">Then, we <a id="_idIndexMarker662"/>test <span class="No-Break">it again:</span></p><pre class="source-code"><strong class="bold">$ LB_PORT=8081 docker-compose --file \</strong>
<strong class="bold">simplestlab/docker-compose.yaml \</strong>
<strong class="bold">--project-name newdemo up lb</strong>
<strong class="bold">[+] Running 1/1</strong>
<strong class="bold"> :: Container newdemo-lb-1  Recreated</strong></pre><p class="list-inset">Let’s <a id="_idIndexMarker663"/>review the <span class="No-Break">component status:</span></p><pre class="source-code"><strong class="bold">$ docker-compose --file simplestlab/docker-compose.yaml --project-name newdemo ps</strong>
<strong class="bold">WARN[0000] The "LB_PORT" variable is not set. Defaulting to a blank string.</strong>
<strong class="bold">NAME                IMAGE                                COMMAND                  SERVICE             CREATED             STATUS              PORTS</strong>
<strong class="bold">newdemo-db-1        myregistry/simplest-lab:simplestdb   "docker-entrypoint.s…"   db                  11 minutes ago      Up 8 minutes        5432/tcp</strong>
<strong class="bold">newdemo-lb-1        myregistry/simplest-lab:simplestlb   "/entrypoint.sh /bin…"   lb                  46 seconds ago      Up 34 seconds       0.0.0.0:8081-&gt;80/tcp</strong>
<strong class="bold">$ docker-compose --file simplestlab/docker-compose.yaml --project-name newdemo up app -d</strong>
<strong class="bold">[+] Running 3/3</strong>
<strong class="bold"> :: Container newdemo-db-1   Running                              0.0s</strong>
<strong class="bold"> :: Container newdemo-lb-1   Running                       0.0s</strong>
<strong class="bold"> :: Container newdemo-app-1  Started                            1.4s</strong></pre></li> <li>Once we <a id="_idIndexMarker664"/>changed the unique <a id="_idIndexMarker665"/>and fixed values in the <strong class="source-inline">docker-compose.yaml</strong> file, we were able to deploy a second project using a unique Compose YAML file. We can list the projects deployed in our host along with their number <span class="No-Break">of components:</span><pre class="source-code">
<strong class="bold">$ docker-compose ls</strong>
<strong class="bold">NAME                STATUS              CONFIG FILES</strong>
<strong class="bold">chapter5            running(4)          /home/frjaraur/labs/Chapter5/simplestlab/docker-compose.yaml</strong>
<strong class="bold">newdemo             running(3)          /home/frjaraur/labs/Chapter5/simplestlab/docker-compose.yaml</strong></pre></li> </ol>
<p>With this simple example of the usual problems you may find while preparing your applications, we will end this chapter’s labs by removing all the <span class="No-Break">objects created.</span></p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor131"/>Removing all projects</h2>
<p>To remove <a id="_idIndexMarker666"/>all the created projects, we will perform the <span class="No-Break">following steps:</span></p>
<ol>
<li>We will remove all the deployed projects by using <span class="No-Break"><strong class="source-inline">docker-compose down</strong></span><span class="No-Break">:</span><pre class="source-code">
<strong class="bold">$ docker-compose -f  /home/frjaraur/labs/Chapter5/simplestlab/docker-compose.yaml --project-name chapter5 down</strong>
<strong class="bold">WARN[0000] The "LB_PORT" variable is not set. Defaulting to a blank string.</strong>
<strong class="bold">[+] Running 5/5</strong>
<strong class="bold">:: Container chapter5-app-2      Removed                          0.1s</strong>
<strong class="bold">:: Container chapter5-app-1      Removed                          0.1s</strong>
<strong class="bold">:: Container chapter5-db-1       Removed                          0.1s</strong>
<strong class="bold">:: Container chapter5-lb-1       Removed                          0.1s</strong>
<strong class="bold">:: Network chapter5_simplestlab  Removed                          0.6s</strong></pre><p class="list-inset">You may notice <a id="_idIndexMarker667"/>that volumes are not listed as removed. We can review the current volumes on <span class="No-Break">your system:</span></p><pre class="source-code"><strong class="bold">$ docker volume ls</strong>
<strong class="bold">DRIVER    VOLUME NAME</strong>
<strong class="bold">local     chapter5_pgdata</strong>
<strong class="bold">local     newdemo_pgdata</strong></pre></li> <li>We will manually remove the volume present for the <strong class="source-inline">chapter5</strong> project, but we will use the <strong class="source-inline">--volumes</strong> argument to remove all the volumes associated with <span class="No-Break">a project:</span><pre class="source-code">
<strong class="bold">$ docker-compose -f  /home/frjaraur/labs/Chapter5/simplestlab/docker-compose.yaml --project-name newdemo down --volumes</strong>
<strong class="bold">WARN[0000] The "LB_PORT" variable is not set. Defaulting to a blank string.</strong>
<strong class="bold">[+] Running 5/5</strong>
<strong class="bold">:: Container newdemo-app-1      Removed                                  0.0s</strong>
<strong class="bold">:: Container newdemo-lb-1       Removed                              0.1s</strong>
<strong class="bold">:: Container newdemo-db-1       Removed                                0.1s</strong>
<strong class="bold">:: Volume newdemo_pgdata        Removed                                       0.1s</strong>
<strong class="bold">:: Network newdemo_simplestlab  Removed                                     0.6s</strong></pre><p class="list-inset">The volume <a id="_idIndexMarker668"/>from the <strong class="source-inline">newdemo</strong> project was removed, as we can verify now, but the volume from the <strong class="source-inline">Chapter5</strong> project is <span class="No-Break">still present:</span></p><pre class="source-code"><strong class="bold">$ docker volume ls</strong>
<strong class="bold">DRIVER    VOLUME NAME</strong>
<strong class="bold">local     chapter5_pgdata</strong></pre></li> <li>We remove the remaining <span class="No-Break">volume manually:</span><pre class="source-code">
<strong class="bold">$ docker volume rm  chapter5_pgdata</strong>
<strong class="bold">chapter5_pgdata</strong></pre></li> </ol>
<p>Additional labs are included in this book’s <span class="No-Break">GitHub repository.</span></p>
<h1 id="_idParaDest-115"><a id="_idTextAnchor132"/>Summary</h1>
<p>In this chapter, we covered the basic usage of Docker Compose and discussed how it will help you develop and run your multi-component applications locally. You will be able to run and review the status of all your application’s components using a single command line. We learned about the syntax of Compose YAML files and how to prepare template-like files for developing your applications using different customizations. You will probably run your applications in production using a clustered orchestrated environment such as Docker Swarm or Kubernetes, but <strong class="source-inline">docker-compose</strong> does also provide a basic orchestration for running your multi-container applications in production using a single server. Understanding the basic orchestration and networking features of Docker Compose will help us introduce more sophisticated orchestration methods, which we will learn about in the <span class="No-Break">next chapters.</span></p>
<p>In the next chapter, we will briefly review orchestration platforms that will help us run our <span class="No-Break">applications cluster-wide.</span></p>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer063">
<h1 id="_idParaDest-116" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor133"/>Part 2:Container Orchestration</h1>
<p>In this part of the book, we will cover the <strong class="bold">orchestration</strong> of containers in cluster-wide environments. We will learn how to deploy distributed component applications on different hosts in a cluster, allowing users to interact with components and <span class="No-Break">publish services.</span></p>
<p>This part has the <span class="No-Break">following chapters:</span></p>
<ul>
<li><em class="italic">Chapter 6</em>, <em class="italic">Fundamentals of Orchestration</em></li>
<li><a href="B19845_07.xhtml#_idTextAnchor147"><em class="italic">Chapter 7</em></a>, <em class="italic">Orchestrating with Swarm</em></li>
<li><a href="B19845_08.xhtml#_idTextAnchor170"><em class="italic">Chapter 8</em></a>, <em class="italic">Deploying Applications with the Kubernetes Orchestrator</em></li>
</ul>
</div>
<div>
<div id="_idContainer064">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer065">
</div>
</div>
</div></body></html>