- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kicking Off the OpenStack Setup – The Right Way (DevSecOps)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “In the middle of difficulty lies opportunity.”
  prefs: []
  type: TYPE_NORMAL
- en: – Albert Einstein
  prefs: []
  type: TYPE_NORMAL
- en: The OpenStack ecosystem, as discussed in the previous chapter, presents a vast
    array of design patterns, coupled with choices of hardware and tools to deploy
    a robust private cloud setup. With the Antelope release, there have been no significant
    changes to the core architecture system, but a few parts have been updated, with
    some additions and features. But that comes with the cost of increased complexity
    when it comes to the deployment and operation stages. The good news is that the
    OpenStack community, since its earliest releases, has created different approaches
    to avoid an arduous OpenStack operation experience. The key mechanism for this
    task is *automation* . There is, without a doubt, a high risk of getting into
    endless troubleshooting if the automation craft is overlooked. There are several
    tools maintained by vendors such as Puppet, Ansible, Chef, and a few others that
    are used in thousands of production deployments. To get an OpenStack setup up
    and running is not the goal of the journey but, rather, the deployment journey
    itself. That is where we will take advantage of automation and agile tools to
    bring the OpenStack operation to the next level, by adopting a DevOps path. Although
    that sounds like an amazing step toward a robust deployment process, it is still
    not complete without incubating security aspects from the early days of the deployment.
    Developing and operating the infrastructure process should be reimagined, from
    a DevOps picture to a DevSecOps one.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter presents the backbone of the future deployment and operational
    processes for an OpenStack private cloud setup by covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the DevOps philosophy behind the OpenStack deployment life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rethinking DevOps and introducing DevSecOps to see how it fits into our journey
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering a modern approach to deploying OpenStack in containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterating through automation tools and preparing for deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a first iteration of an OpenStack deployment via Continuous Integration/Continuous
    Delivery ( CI/CD) tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing for a large-scale deployment via code and Continuous Integration/Continuous
    Delivery ( CI/CD) pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating security checks in each deployment step in an automated fashion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing silos – DevOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **DevOps** has been popping up for almost a decade, pushing organizations
    to rethink how to structure their internal teams to achieve what DevOps promises.
    Dozens of definitions of the word *DevOps* can be found everywhere, but it can
    simply be summarized as a *silo remover* . DevOps comes with the philosophy of
    bringing the main software product’s direct contributors to the same table, including
    operations, testers, and developers. The aim of this movement is based on a few
    principles that motivate organizations to implement them practically – knowledge
    and responsibility sharing, respect, automating everything, monitoring continuously,
    embracing failure, and designing for reusability. However, DevOps has never been
    a tool or software but, rather, a set of principles that define processes and
    workflows to boost a company’s productivity. What makes this movement shine takes
    us back to the simple definition – *silo remover* . As operations and developers
    are not hindered by the wall sitting between them, more collaboration and knowledge
    are shared toward the same goal – decreasing the time to market with the highest
    possible quality and degree of efficiency. Without the existence of many tools,
    reflecting this idea in real life would be more difficult. **Continuous Integration**
    ( **CI** ) and **Continuous Delivery** or **Deployment** ( **CD** ) tools are
    examples that have contributed immensely to reflecting that idea. Another set
    of tools that gives more trust to machines than to humans is the concept of *automation*
    . CI/CD tools leave all the manual and routine build, testing, and deployment
    stages to a few pipelines running on a server. Meanwhile, teams focus on more
    interesting tasks with higher business values. The rise of the cloud era has brought
    another giant set of opportunities to accelerate the software development cycle
    with automation – **infrastructure automation** . This is one of the areas that
    OpenStack focuses on with some of its services, such as **Heat** . Treating **Infrastructure
    as Code** ( **IaC** ) inspires the gathered teams, Dev and Ops, to bring knowledge
    from the traditional software development life cycle and apply it at the infrastructure
    level.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is no longer a case of *that is not my business* but, rather, *it is my
    business too* . What really matters is focusing on the delivery of business products
    in a reasonably reduced amount of time, getting to market faster, and not missing
    out on a race with the competition. This can be summarized with a DevOps toolchain
    for different software deployments across the Dev and Ops stages, as shown in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – The DevOps toolchain](img/B21716_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – The DevOps toolchain
  prefs: []
  type: TYPE_NORMAL
- en: By adopting the same philosophy, we will deploy our OpenStack private cloud.
    But before reaching that stage, we need to acknowledge an important fact – there
    is no rule of thumb when it comes to applying what DevOps dictates. The structure
    of teams in organizations may differ, and IT disciplines can be in several dedicated
    pods per function or merged into one. The pursuit of *DevOps happiness* can be
    confusing if an organization does not assign and refactor its team’s structure,
    seek out subject matter experts, have cross-functional team members based on specialized
    knowledge, and so on. Some of these issues have revealed obstacles, due to the
    gaps left in terms of security and compliance. This is what we will uncover in
    the following section before bringing the pieces of OpenStack together.
  prefs: []
  type: TYPE_NORMAL
- en: Shifting to the left – DevSecOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *billion-dollar* idea of the DevOps philosophy is to bring people together
    – all disciplines, including Ops, Devs, and **Quality Assurance** ( **QA** ).
    Organizations should make it clear where silos are raised among all product contributors.
    That should include the security discipline in their agile ways of working. The
    *2021 State of DevSecOps* study ( [https://www.securitycompass.com/reports/2021-state-of-devsecops/](https://www.securitycompass.com/reports/2021-state-of-devsecops/)
    ) elaborated by *Security Compass* , a cybersecurity consultancy services provider,
    shows that 75% of responders (IT professionals and DevOps practitioners) agreed
    that security slows down the processes of product releases, leading to an increase
    in the time to market. That goes against what DevOps was created for. Focusing
    on speed to market might skip the security aspect. This *sacrifice* has triggered
    some scary numbers in some large enterprises, where there was an increase in the
    volume of data breaches or the number of cybersecurity attacks. Treating security
    as something to act upon reactively instead of proactively can cost in terms of
    budget and time for each security incident. There are a few chief reasons that
    capture the root cause of why cybersecurity and DevOps are left in two different
    silos – more manual security intervention during the development process and a
    lack of knowledge of tools. Investing in security is required to comply with standards
    and gain trust. Sacrificing that for speed to market will certainly lead to major
    losses later on. That leads us to the next bridge that needs to be built between
    DevOps and security, forming a DevSecOps alliance. In the same way that Dev and
    Ops merged, security should no longer be considered an afterthought. DevOps principles
    can be inherited to make a security fusion possible. That is how DevSecOps has
    become a new trend. Imagine the whole pressure of security eased across each discipline
    and pointing to the same product goal, armed with automation and faster feedback.
  prefs: []
  type: TYPE_NORMAL
- en: We can sum up the right approach for our future OpenStack deployments – DevOps
    with security at different stages of the process, as shown in the following toolchain.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Integrating security into the DevOps toolchain](img/B21716_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Integrating security into the DevOps toolchain
  prefs: []
  type: TYPE_NORMAL
- en: Embracing the deployment of a complex environment such as an OpenStack private
    cloud would require a DevSecOps approach, and a few best practices are covered
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Securing the cloud – moving with DevSecOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adopting DevOps practices is definitely a big deal to stay competitive in the
    market, increase productivity, and bring new possibilities for innovation. Conversely,
    with a lack of security, any product will be at risk of losing both trust and
    failure. Hence, the DevOps chain must be enforced with security and compliance
    insurance. One of the fundamental aspects of DevOps is automation and reusability.
    In an infrastructure context, we are not dealing with *pets* but with *cattle*
    . The *pets and cattle* analogy is a famous one, with on-prem servers referred
    to as *pets* . If there was any change, update, or failure of that pet server,
    a problem would arise. They are the long-lived and indispensable pieces of the
    infrastructure that should be taken more care of. On the other side of the analogy,
    *cattle* refer to servers in large on-demand environments such as the cloud. A
    cattle failure should not stop the business from running, and cattle can be replaced
    *immediately* . If we adopt the *cattle* analogy servers in the cloud should be
    instrumented to keep them immutable. That is where IaC comes into play. With one
    single source of truth and a shared pipeline, the *Sec* part becomes much easier
    to merge into the *DevOps* flow. With this capability, moving security from the
    right to the left becomes more feasible.
  prefs: []
  type: TYPE_NORMAL
- en: DevSecOps and OpenStack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The challenge of deploying a complex OpenStack ecosystem is made easier through
    DevOps, but what should not be overlooked as a cloud provider is protecting the
    first layer that runs a user’s workload(s). As we will explore in the next part
    of this section, there are several ways to deploy a complete OpenStack environment
    from code. Emphasizing security before starting to think about the code structure
    is vital to not miss a DevSecOps opportunity. As a rule of thumb, any code designed
    for an application infrastructure is subject to vulnerabilities. Although the
    different modules of OpenStack services are developed with security in mind, the
    gazillions of ways of configuring and parameterizing within a specific network
    architecture should be tested for security anomalies at every stage. Before welcoming
    any workload on top of the OpenStack infrastructure, the cloud itself must be
    ready with security controls and compliant with major standards.
  prefs: []
  type: TYPE_NORMAL
- en: Coding the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the biggest challenges of dealing with an OpenStack environment is the
    ways of handling its deployment and daily operations. If you consider a manual
    deployment for even a small environment, then in all likelihood, your OpenStack
    management processes, including updates, will face difficulties that cannot be
    avoided. That is where DevSecOps practices come in, with the fundamental mantra
    of IaC. A consistent approach is to treat the OpenStack ecosystem as code. The
    good news is that OpenStack code is provided with each stable release and is ready
    for deployment once configured and customized. But before we grasp a technical
    deployment, we should take into account a few common considerations to start building
    our toolchain:'
  prefs: []
  type: TYPE_NORMAL
- en: Map each OpenStack service as code per module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define target systems to run OpenStack services with one specific role or several
    roles. For example, a compute role is defined with the Nova service deployed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Draft the initial configuration for each service (role).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Think of roles as reusable code that can be deployed in different target environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure you integrate functional test stages between role setups.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider the integration of security rules and tools from the start. Map each
    nominated tool in each stage of the pipeline, from coding to the release phases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid *Big Bang* coding practices and implement smaller changes in an automated
    continuous deployment fashion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prepare to continuously monitor the following deployment metrics:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment frequency** : How often IaC is deployed (daily/weekly/monthly)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change lead time** : The window of time starting from the moment code has
    been committed to the time it is successfully deployed'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change failure rate** : The total percentage of committed IaC changes leading
    to system impairment or outage (including hotfixes and rollbacks)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean Time to Repair** ( **MTTR** ): The time needed to restore service outage
    from the moment it’s impaired'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a trunk-based development approach to facilitate code monitor changes and
    increase security visibility integration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Trunk-based software development is a coding practice that allows developers
    to regularly merge changes into a common trunk code base. The trunk-based practice
    dictates more frequent code releases with smaller changes.
  prefs: []
  type: TYPE_NORMAL
- en: The following section will cover the different tools that will be used to deploy
    an OpenStack environment in the DevSecOps style.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying in the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the first release of OpenStack, several deployment tools and wrappers
    have been developed to assist OpenStack operators with more enhanced, easier ways
    to set up a fully running OpenStack environment. With the rise of system management
    tools such as Chef, Puppet, SaltStack, and Ansible, the OpenStack community has
    dedicated different channels to each system management tool to develop different
    classes and modules through the OpenStack ecosystem evolution. Which one of these
    tools we choose is down to familiarity or the technical requirements of cloud
    operators. In this section, Ansible will be the system management tool we use.
  prefs: []
  type: TYPE_NORMAL
- en: Ansible in a nutshell
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like any other system management tool, Ansible uses its own glossary and terms
    to define infrastructure components, modules, relationships, and parameters. Conversely,
    unlike other tools, Ansible comes with a simple architecture setup that makes
    it a popular choice, and it can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It has the flexibility to handle interdependent complex service modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses an agentless transport mechanism to connect and update target systems
    without the need to install additional packages. It exposes only the *master*
    server where the Ansible software is running.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modules executed on target systems are auto-cleaned once installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is rich in core automation modules to extend more features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The infrastructure collection code written in YAML is organized in Ansible playbooks.
    YAML is easier to learn and master than other languages, such as Ruby for Chef.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the simplicity of the Ansible architecture, scalability is much simpler
    to implement compared to other tools that require running agents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a declarative method of programming, it focuses on describing the output
    of the desired state, rather than diving into how to do it and which steps must
    be taken to reach the resulting output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When dealing with the complexity of the OpenStack ecosystem, with all its sets
    of components, subcomponents, and parameter flavors, it is essential to briefly
    skim the surface of the Ansible terminology :'
  prefs: []
  type: TYPE_NORMAL
- en: '**Playbooks** : These consist of the main configuration file(s) that describes
    a series of actions to run on one or a group of hosts. The tasks are written in
    YAML and executed in order, from top to bottom, to accomplish full deployment
    or a configuration change.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Roles** : These present the organizational structure of playbooks by collecting
    different Ansible assets, such as tasks, variables, and modules, to deploy a service
    on one or a group of hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modules** : These are an abstract representation of a specific unit of code
    functionality. Modules can be written and customized to control system resources,
    files, and services. Ansible is shipped with some modules referred to as module
    libraries (core modules) that can be executed via customized playbooks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variables** : These are dynamic values used in roles and playbooks to reflect
    the desired configuration. Similar to programming language variables, Ansible
    variables enable the propagation of different states across different environments
    through the same role or playbook.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inventory** : This is a listing of managed hosts in the target environment.
    Ansible uses a configuration file in the **INI** format, which defines the name
    and IP of the managed target host. Hosts can be declared in inventory files using
    different patterns by nesting hosts by role, or by specifying a series of hosts
    via a combination and numeric patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The CI/CD system triggers Ansible to install and run playbooks across target
    OpenStack nodes defined in its inventory, as depicted in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – An OpenStack environment management through Ansible](img/B21716_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – An OpenStack environment management through Ansible
  prefs: []
  type: TYPE_NORMAL
- en: Integrating system management tools such as Ansible in OpenStack ecosystem life
    cycle management has introduced a significant change in the way such a complex
    ecosystem is managed and operated. Not surprisingly, the hunger to move quickly
    to adopt a private cloud setup and maximize the agility of its deployment has
    led to other challenges. That brings us to the root causes of OpenStack-tied dependencies
    between services. Thinking long term, the development of new OpenStack releases
    and feature integrations in an existing environment presents one of the ultimate
    challenges for a private cloud operation mission. Driving major upgrades has always
    been a blocker to seamlessly jumping to a new OpenStack release in a running production
    setup. That makes the upgrade case a very cautious operation and puts your **Service-Level
    Agreement** ( **SLA** ) at risk if one or several dependencies crash, due to a
    code compatibility version that has been overlooked. Although tests can help to
    identify such anomalies, a massive number of tests for each component should be
    in place in advance, and that could be costly in terms of resources and human
    interactions. The other facet of these challenges is the lack of rollback mechanisms.
    Rolling back a change that causes an issue will definitely bring one or several
    parts of a whole system down, as you wait for your management tools to redeploy,
    restart the affected services, and test and wait for a complete synchronization
    between other dependent services to run them again. The most common OpenStack
    deployment options involve bare-metal machines or virtual machines, making such
    operational tasks heavier to roll, requiring full management of machine images,
    and it becomes costly when testing in an isolated environment. For example, upgrading
    or updating an OpenStack component version would require all inter-dependent services
    to be deployed in a different testing environment before propagating the change
    in the production one. Within the latest OpenStack releases, several organizations
    have been experimenting with the rise of containers for a fully containerized
    OpenStack cloud. Let’s unleash the container dilemma in the next section and explore
    what opportunities are in store for OpenStack deployment and management.
  prefs: []
  type: TYPE_NORMAL
- en: Containerizing the cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Container technology has been around for more than a decade, and companies have
    started deploying their workloads in containers to take advantage of resource
    optimization, environment isolation, and portability. Running different pieces
    of your software in lightweight, self-contained, and independent containers brings
    more flexibility to managing a complex software system. Running in an isolated
    mode, operations such as upgrades and rolling back become much easier and can
    be performed with more confidence.
  prefs: []
  type: TYPE_NORMAL
- en: 'By referring to our infrastructure code, we can see the benefit of the OpenStack
    software architecture’s modular design, which offers a great deal by taking advantage
    of container technology, where each module can live in a separate, stateless environment.
    Looking at the current state of container trends, an extended list of container
    and orchestration engines can be found, such as LXC, Docker, and Kubernetes. The
    OpenStack community did not miss the chance to adopt containerization technology
    early on, when containers started to become the standard for modern software development.
    Within the Antelope and later releases, we can find several deployment methods
    based on containers, combined with configuration management tools, as summarized
    in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Deployment project** | **Container** | **Project** | **Source** |'
  prefs: []
  type: TYPE_TB
- en: '| OpenStack-Ansible | LXC | Ansible | [https://docs.openstack.org/openstack-ansible/latest/](https://docs.openstack.org/openstack-ansible/latest/)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Kolla-Ansible | Docker | Ansible | [https://docs.openstack.org/kolla-ansible/latest/](https://docs.openstack.org/kolla-ansible/latest/)
    |'
  prefs: []
  type: TYPE_TB
- en: '| OpenStack-Helm | Docker | Kubernetes and Helm | [https://docs.openstack.org/openstack-helm/latest/](https://docs.openstack.org/openstack-helm/latest/)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Triple-O (currently no longer supported) | Docker | Ansible | [https://docs.openstack.org/tripleo-ansible/latest/](https://docs.openstack.org/tripleo-ansible/latest/)
    |'
  prefs: []
  type: TYPE_TB
- en: Table 2.1 – A list of OpenStack deployment tools running containers
  prefs: []
  type: TYPE_NORMAL
- en: The **OpenStack-Ansible** ( **OSA** ) project is one of the most widespread
    deployments based on LXC containers. The deployment of LXC containers running
    OpenStack services is orchestrated by Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: In our next deployment, we will adopt another emerging OpenStack project, named
    **Kolla-Ansible** . Similarly to OSA, the Kolla project uses Docker as a containerization
    tool by building a Docker container for each OpenStack service. Besides the design
    differences between LXC and Docker, Kolla extends the parameterization layout,
    making its containers more configurable, with an array of choices between the
    base operating system and template engines. This is not to mention Docker’s design
    advantages as a container technology, with the layered nature of its images, versioning,
    and portability for sharing capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Kolla has been integrated officially within the OpenStack subproject since the
    Liberty release. As per the official OpenStack definition of the Kolla project,
    *“Kolla’s mission is to provide production-ready containers and deployment tools
    for operating* *OpenStack clouds.”*
  prefs: []
  type: TYPE_NORMAL
- en: Those extra advantages make Docker more suitable for our deployment pipeline,
    where we will deal with a container service as an artifact that can be easily
    deployed through different environments, before promoting it to a production environment.
    As depicted in the following high-level schema, for each merged change in the
    code repository, the CI/CD tool builds an artifact composed of a software package
    encapsulated in a Docker image. The generated image will be committed to a private
    Docker registry, where Ansible will download it and orchestrate its setup in the
    designated OpenStack node.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – High-level CI/CD pipeline OpenStack deployment](img/B21716_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – High-level CI/CD pipeline OpenStack deployment
  prefs: []
  type: TYPE_NORMAL
- en: The other component of the deployment tool stack is the **Jinja2** templating
    tool. This is mainly used by Docker for the dynamic assignment of variables, based
    on defined parameters generated by Ansible. Jinja2 is designed mainly for Dockerfiles
    to support full system call interface compatibility for both RPM and DEB container
    distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Jinja2 templating in the Kolla context provides an array of ways of building
    Docker images of different source distributions, including CentOS, Debian, Fedora,
    Ubuntu, and RHEL container operating systems that can be parameterized per OpenStack
    service code.
  prefs: []
  type: TYPE_NORMAL
- en: As our main motivation is to solve the complexity of dependencies and provide
    a simpler and more scalable development experience, Kolla is the way to go, and
    indeed since its official first stable release, several production deployments
    have been performed the Kolla way.
  prefs: []
  type: TYPE_NORMAL
- en: Building the picture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Treating OpenStack deployment as IaC will help us to inherit and use most of
    the software tools and processes to deliver code artifacts, ready for deployment,
    with more confidence. Having a robust integration and deployment pipeline is vital
    to ensure that our software-defined data center does not fail on production day.
    Modern software development techniques involve several tools that increase automation
    and agility and, hence, faster feedback between each deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following tools will be employed for our OpenStack infrastructure code
    development:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A version control system** : GitHub will be our code repository for the OpenStack
    infrastructure code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A CI/CD tool** : Jenkins will be installed on the deployer machine and grant
    extra plugins to build and run deployment pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A system management tool** : The Ansible packages will be installed on the
    deployer machine and provide the OpenStack playbooks to be deployed inside the
    containers, in tandem with Kolla.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An image builder** : Dedicated to OpenStack containers, Kolla builds container
    images running different OpenStack services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Kolla-Ansible project code repository will be our starting point for the
    first OpenStack deployment, with minimum customization to have a rolling deployment
    pipeline initially. The official latest master stable branch of the project code
    can be found here: [https://github.com/openstack/kolla-ansible](https://github.com/openstack/kolla-ansible)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: Kolla-Ansible supports both all-in-one as well as multi-node OpenStack setups.
    As we’re aiming for a production setup, as discussed in the initial design draft
    in [*Chapter 1*](B21716_01.xhtml#_idTextAnchor014) , *Revisiting OpenStack –Design
    Considerations* , we will make sure our initial draft is the first deployment
    iteration ready for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a development environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting up a development environment mimicking a production one is highly recommended
    to ensure faster feedback during the development stages, as well as to fix any
    anomalies in code before promoting it to a production setup. Although running
    services in a container increases the flexibility of rolling back if issues are
    detected after deployment into production, a best practice is to act proactively
    by running service containers in an isolated environment through different deployment
    and testing stages. Upon successful deployment in the test environment, services’
    containers will be promoted and tagged as production-ready for deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how many physical machines will be invested in your development
    environments, the DevSecOps team will require an isolated environment for each
    member to run tests, before committing their changes to a main development branch
    that targets deployment in the development environment.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the local environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Vagrant is a revolutionary tool created by HashiCorp that can create, modify,
    and manage visualized environments through simple Vagrant command lines. The other
    exciting part of Vagrant is managing a local development environment through it.
    Vagrant configuration is highly customizable and supports a variety of local hypervisors
    to run virtual machines, such as VirtualBox, HyperV, and VMware.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our next setup will consider a local VirtualBox environment, depending on your
    development operating system machine; most Linux, Mac, and Windows distributions
    are supported and can be found here: [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once VirtualBox is installed, download the base image where the OpenStack environment
    will run. A good practice for VirtualBox development in Vagrant is to use the
    same operating system distribution for both the development and production environments.
    The chosen operating system in the next setup is Ubuntu **22.04 LTS** . In the
    following wizard, we will go through the different steps to prepare the Vagrant
    file before starting to deploy a local OpenStack environment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a Vagrant file by firing the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Modify the **box** stanza configuration section by providing the operating
    system image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Vagrant boxes can be created locally by backing up an image of any operating
    system, using tools such as **Packer** . Vagrant boxes can be shared and tagged
    with the version in the Vagrant cloud repository, as detailed here: [https://developer.hashicorp.com/vagrant/vagrant-cloud/boxes/create](https://developer.hashicorp.com/vagrant/vagrant-cloud/boxes/create)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'The local development machine should have a minimum of hardware specs, such
    as RAM and CPU, to accommodate a minimal setup of an OpenStack environment, as
    depicted in the following Vagrant configuration section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the virtual disk space to a minimum of 50 GB in the new **box** stanza
    line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to have the **vagrant-disksize** plugin installed by running the following
    command line – **vagrant plugin** **install vagrant-disksize** .
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, add a synced folder to sync the OpenStack infrastructure code on
    the development machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure the synced folder in the local machine exists by creating the **openstack_deploy**
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Networking can be configured to forward port access to specific services from
    the development machine to the guest box. Accessing OpenStack Horizon, for example,
    would require port forwarding on port **80** from the guest machine, which can
    be adjusted as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the Vagrant box by firing the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once started without errors, the Vagrant box is ready for access. The default
    login uses a Vagrant user that can be elevated to root to proceed with the next
    setup:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the Vagrant box is up and running, you should be able to start installing
    the required packages to deploy an all-in-one OpenStack environment.
  prefs: []
  type: TYPE_NORMAL
- en: Running the local cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Kolla-Ansible project code includes different ways of installing OpenStack
    in all-in-one or multi-nodes. As part of the infrastructure code process, we will
    adjust a few settings to run an all-in-one mode on the development machine. But
    first, we need to install the Git package on our local development host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Clone the OpenStack-Kolla repository to the designated local folder setup created
    in the previous section. The Vagrant configuration file will make any changes
    to the local folder, **openstack_deploy/** , visible to the guest box. Ideally,
    cloning the repositories should be done from your local Git server of choice.
    In this example, a private Git repository is used ( **ci.os** ). The following
    command clones the local repository running on the CI/CD instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple guide to optionally set up a local Git server running NGINX
    on the latest version of Ubuntu: [https://www.howtoforge.com/tutorial/ubuntu-git-server-installation/](https://www.howtoforge.com/tutorial/ubuntu-git-server-installation/)
    . The local Git server uses the latest stable master branch, cloned locally from
    the Kolla-Ansible repository: [https://github.com/openstack/kolla-ansible.git](https://github.com/openstack/kolla-ansible.git)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, create your development branch from the master to track local changes
    before pushing them to the next development branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, pushed changes should be made in a dedicated development branch of
    your choice before propagating them to the master branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to your Vagrant box and proceed to install environment dependencies
    and create a virtual environment. Make sure to change the path of your environment
    on the guest host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Install Ansible. Make sure a minimum version of 2.16 is installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Install the **kolla-ansible** runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Since OpenStack Yoga, a few additional dependencies need to be installed, which
    can be solved by running the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The Kolla-Ansible repository comes with two essential files that we will edit
    to run our local deployment – **globals.yml** and **passwords.yml** . Copy the
    files to a directory of your choice, which can be created, and make sure that
    the running guest user owns the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The **globals.yml** file includes several settings and adjustable configurations
    for different OpenStack control plane services, as well as shared ones. As part
    of our minimal test environment, we will edit the following settings to the copied
    **globals.yml** file under the **/** **etc/** **kolla/** folder:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Ubuntu to run as the base Linux distribution for the containers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Ensure that HAProxy is out of the scope of our initial setup in the test environment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select the network interface name to be assigned for all types of OpenStack
    networks:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Dedicate a second interface for the Neutron external network:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign a Keepalived floating IP, which should be reserved as a virtual IP for
    HA:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The **passwords.yml** file centralizes all the OpenStack purposes and other
    services’ passwords. To generate random password sets in one command instead of
    running them manually for each, Kolla comes with a simple command tool that generates
    passwords, which will be used during the deployment, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Make sure that the generated passwords are saved in the **passwords.yml** file
    under your custom directory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The other crucial file is under the **inventory** folder, which describes and
    instructs Kolla-Ansible on which hosts will be the target to apply the configuration.
    Inventory files are defined with the Ansible host group format and can be customized,
    based on the available hosts and assigned roles. The default available files are
    designed to run inventories for all-in-one and multi-hosts. To run a clean host
    target setup, make a copy of the files under the **inventory** directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The all-in-one Ansible inventory file will not require any changes for our
    development setup purposes. The format of the file is straightforward, where each
    host role section describes the name of the host or IP address. For the local
    test environment, all host roles will be configured with **localhost** , as shown
    in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Fire the **kolla-ansible** command line to install the bootstrap servers. The
    command will run the Ansible playbook against each host-assigned role in the inventory
    file. So far, all roles are gathered in the same localhost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – The kolla-ansible bootstrap servers’ output](img/B21716_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – The kolla-ansible bootstrap servers’ output
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, run a few deployment checks to closely monitor the bootstrapping
    process and detect possible failures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – The kolla-ansible prechecks’ output](img/B21716_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – The kolla-ansible prechecks’ output
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the bootstrapping process is finished without any detected failures, perform
    the deployment of the OpenStack environment, which will take a long time to create
    all the containers’ services and chain them together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – The kolla-ansible deployment output](img/B21716_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – The kolla-ansible deployment output
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The Ansible deployment will apply the playbooks and OpenStack roles using container
    images from the default OpenStack Docker repository. For the next development
    stage, make sure to build and push further images to a local repository. The next
    sections and chapters will discuss how to build local container images for different
    services and manage them locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment of the minimal setup of the OpenStack containers should result
    in zero failures by the end of the **kolla-ansible deploy** command line. The
    following Docker command line lists all the running containers deployed in the
    previous step that should be noted as healthy. Some containers will still be in
    the process of communicating with other system services, which will take a few
    minutes, before starting to evaluate the OpenStack services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – A list of the running OpenStack service containers](img/B21716_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – A list of the running OpenStack service containers
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to see OpenStack running in containers by firing a client test command.
    To fire a quick test, install the OpenStack client package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'To interact with OpenStack API services, admin credentials are required, which
    can be generated by the **kolla-ansible post deploy** command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – The kolla-ansible OpenStack post-deployment output](img/B21716_02_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 – The kolla-ansible OpenStack post-deployment output
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous command will generate the **cloud.yaml** file, which contains
    different OpenStack admin credentials to interact with OpenStack services via
    the client command line. The content of the file variables can be populated by
    exporting the path of the generated **cloud.yaml** file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Validate the running OpenStack environment by listing, for example, the **nova**
    host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – The OpenStack host list output](img/B21716_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – The OpenStack host list output
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenStack services can be managed easily through the Docker container command-line
    interface. For example, Keystone container service logs can be viewed by running
    the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The other option to inspect an OpenStack service container and report back
    container information, such as IP address and networking settings, can be performed
    by using the generic **docker inspect** command line, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Despite the flexibility of the usage of containers and the simplicity of destroying
    and building new ones in almost no time, in some cases, you might need to investigate
    a defined OpenStack service issue or configuration via shell access, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: An all-in-one setup helps to develop and test code locally. Larger environments,
    including staging and production, would require an extended setup, which will
    be detailed in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Extending the deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Expanding on our initial physical design, discussed in [*Chapter 1*](B21716_01.xhtml#_idTextAnchor014)
    , *Revisiting OpenStack – Design Considerations* , will require the evaluation
    of different hardware specifications and options for the chosen design. As we
    have narrowed down the methods of deployment and the different sets of tools to
    build our first production iteration, we will start splitting the roles of OpenStack
    components across different physical systems. Unlike a testing environment, a
    production environment should follow a well-architected design pattern, based
    on the isolation of services, fault tolerance, scalability, and redundancy on
    each layer. We will deep-dive into the extension of those architectural aspects
    in [*Chapter 3*](B21716_03.xhtml#_idTextAnchor108) , *OpenStack Control Plane
    – Shared Services* , and [*Chapter 7*](B21716_07.xhtml#_idTextAnchor174) , *Running
    a Highly Available Cloud – Meeting* *the SLA* .
  prefs: []
  type: TYPE_NORMAL
- en: Our deployment pipeline will be the source of truth to deploy any environment
    if you consider going through a minimal all-in-one setup testing environment to
    a staging one, mimicking the production that will be promoted to production if
    all stages of the pipeline tests, including security ones, are executed with 0
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to not introduce any user production workloads before getting a minimum
    level of redundancy in each control and data plane across your OpenStack environment.
    More details on extending to a highly available setup will be discussed in [*Chapter
    7*](B21716_07.xhtml#_idTextAnchor174) , *Running a Highly Available Cloud – Meeting*
    *the SLA* .
  prefs: []
  type: TYPE_NORMAL
- en: The deployment expansion for the environment should take an incremental approach
    by splitting the roles whenever feasible, and you should take into consideration
    that some services can be optionally separated on their own physical servers.
    A good practice is to start splitting additional roles in the physical layout
    once the core services are rolling and after gaining more operational expertise
    for each iteration. As the deployment pipeline feeds back the state of each new
    deployment, more technical decisions will need to be made to introduce improvements
    to the physical infrastructure layout, and you can choose which services can be
    moved to their own server in the next iteration. To safely start the deployment
    journey, we will need to install and configure our deployer before proceeding
    with infrastructure deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the deployer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our deployer host will be installed with the following software and hardware
    settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jenkins version 2.414.1
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker version 1.12.6 or greater
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ansible 2.3.1 or greater
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Python 1.10.0 or greater
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolla-Ansible 16.1.0-16 – an OpenStack Antelope release or later
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Git version control
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operating system** : Ubuntu 22.04 LTS'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: pip and Python dependencies including **python-dev**
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hardware** :'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CPU** : At least 4 CPU cores and 64 bits x86'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory** : At least 4 GB of RAM'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disk space** : At least 50 GB of free disk space'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network** : At least two network interfaces'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Start by installing Jenkins, by updating your local system and Java runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the required GPG key for the Jenkins repository files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command will address the local system repository to download
    a recent version of Jenkins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Run an update of the **apt** package list and install Jenkins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure Jenkins is running by firing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If the Jenkins daemon is not running, issue the **start** command to launch
    its process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the Jenkins service is up and running, point to the CI/CD server address
    in a browser on the default **8080** port to access the user interface, and then
    proceed with the preliminary setup of the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Jenkins home page](img/B21716_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – Jenkins home page
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to add a few plugins before building the pipeline, starting
    with **Git SCM** plugins. To do this, click on **Manage Jenkins** on the upper-left
    corner tab. Type **git** in the search bar on the **Available Plugin** tab and
    click **Install** **without restart** :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Jenkins’ Git SCM plugin setup](img/B21716_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 – Jenkins’ Git SCM plugin setup
  prefs: []
  type: TYPE_NORMAL
- en: Once Jenkins and its required plugins are installed, we can move forward by
    setting up the CI/CD pipeline and different stages for future deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Actioning the deployer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our Jenkins file can be checked into the repository. The SCM pipeline will
    run the job definition with the configured path. The Jenkins pipeline definition
    can be summarized in high level in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a local test environment on the destination testing host.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check out the repository from a defined branch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the required testing packages, including **kolla-** **ansible** and
    Docker runtimes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the bootstrap server script.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run Kolla prechecks on the bootstrapped testing environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the OpenStack testing environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the target environments you plan to run through the CI/CD pipeline,
    make sure to adjust the configuration layout of the main **globals.yml** and **inventory.yml**
    files separately in each environment. Each environment should run with a dedicated
    Jenkins pipeline file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to create our first pipeline for the testing environment.
    Jenkins provides different options to create the job pipeline definition, either
    via the user interface wizard or by simply creating a Jenkins file that can live
    in the main directory of the OpenStack infrastructure as a code repository. For
    this purpose, our first job definition will follow the SCM method. The following
    snippets define the Jenkins deployment pipeline, starting with the first stage,
    where a virtual Python environment will be sourced to run each build in its own
    local environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The next stage will install all required dependencies, including **pip** ,
    the Ansible runtime, and the **kolla-ansible** package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Once all the required packages are installed locally, the next stage will define
    the file structure of the infrastructure code under the **/etc/kolla** directory
    and set a few parameters in the **globals.yml** file, such as the network interface
    and the type of distribution Kolla will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step will generate different secrets for all OpenStack services in
    their configurations. The secret file will inject each secret for each service
    during the OpenStack service installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the pipeline will instruct Jenkins to prepare the container scripts for
    booting, including the system configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The next stage will run a precheck task to make sure that the bootstrap step
    was performed without issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The final stage is to deploy the services, pull the images, and run the services
    in containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure to have a new testing branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Commit and push the created file to the source code repository with the new
    branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Using the Jenkins file the SCM way enables us to treat the pipeline definition
    as code. Make sure that all changes and updates for any job definition go through
    the pipeline code. The pipeline file is written in Groovy syntax. A recommendation
    is to use an IDE to highlight the Jenkins file code format in the same way as
    for YAML. If your IDE does not highlight the Groovy syntax, add **#!/usr/bin/env
    groovy** to the top of the pipeline Jenkins file.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the Jenkins user interface, select **New Item** from the top-left menu.
    Select **Pipeline** as the type of job, with the desired name to run the test
    pipeline. The next wizard creates a pipeline item, named **openstack-dev** :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Jenkins pipeline creation](img/B21716_02_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.13 – Jenkins pipeline creation
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the pipeline script from SCM in the **Configure** tab and Git by specifying
    the repository URL. Make sure to configure the script of the Jenkins file in the
    repository directory path:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – The Jenkins pipeline SCM job definition](img/B21716_02_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 – The Jenkins pipeline SCM job definition
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first deployment setup for the testing environment is ready to go. All
    that is left is to push the button. Click on **Build Now** on the left-hand side
    of the newly created job definition in Jenkins, where the different stages declared
    in the pipeline code will be visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – The Jenkins OpenStack test deployment pipeline](img/B21716_02_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.15 – The Jenkins OpenStack test deployment pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'Jenkins jobs that are running can be monitored by clicking on the **Console
    Output** tab, where each stage defined in the pipeline file is reported to support
    further debugging and troubleshooting when possible errors occur:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Jenkins OpenStack test deployment output](img/B21716_02_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.16 – Jenkins OpenStack test deployment output
  prefs: []
  type: TYPE_NORMAL
- en: The Jenkins console output is very handy for troubleshooting any possible issues
    that could occur during the Ansible run. Make sure the **failed** status is **0**
    . When the deployment status ends with the **SUCCESS** value, we can enforce the
    pipeline with additional security checks.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying with security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we emphasized at the start of this chapter, security should be considered
    in the early steps of building and deployment projects. That is what has been
    defined as a *shift to the left* . The craft of automating security checks should
    be learned in testing environments to report any potential vulnerabilities before
    promoting the infrastructure to a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first security enforcement will be conducted by installing an additional
    Jenkins plugin, which will be an interesting asset to our DevSecOps pipeline.
    As we are dealing with containers as the main artifacts, we will install a container
    inspection plugin to perform security scans on the built containers at a later
    stage. **Anchore** is one of the most widely used container vulnerability-scanning
    platforms, providing seamless integration with CI/CD tools, source code, and even
    container registries for both Docker and Kubernetes. The Anchore plugin exists
    for Jenkins and can be installed straightforwardly in the same way we installed
    the Git plugin. On the **Available plugins** tab, search for **anchore** :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Searching for the Jenkins Anchore plugin](img/B21716_02_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.17 – Searching for the Jenkins Anchore plugin
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the **Anchore Container Image Scanner** plugin and click on **Install**
    **without restart** :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18 – The Jenkins Anchore plugin setup](img/B21716_02_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.18 – The Jenkins Anchore plugin setup
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'More details about the Anchore platform can be found here: [https://anchore.com/container-vulnerability-scanning/](https://anchore.com/container-vulnerability-scanning/)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the plugin is installed, we need to adjust our settings to instruct our
    deployer to use a Docker repository at a specific address and port. For this example,
    the image registry will be deployed in the deployer host, named **master_registry**
    , by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure to update the **globals.yml** file to use the local Docker registry
    by editing the following configuration lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Commit and push your changes to the main infrastructure code repository so
    that our CI/CD will point to the local registry in later image build steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Before getting the image build pipeline running, we will install the Anchore
    engine to run the container inspection later. The Anchore open source version
    comes as a Docker image that can run standalone. Proceed by downloading the Anchore
    engine **docker-compose** file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Optionally, reset the admin password defined by the **ANCHORE_ADMIN_PASSWORD**
    configuration line in the **docker-compose.yaml** file. That will be needed for
    later steps.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For permanent access to the Anchore engine interface, export the Anchore endpoint,
    username, and password to the **ANCHORE_CLI_URL** , **ANCHORE_CLI_USER** , and
    **ANCHORE_CLI_PASS** environment variables, respectively. If the variables are
    not populated within the operating system, you will need to export them in each
    run of the CI/CD pipeline execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create and run the Anchore engine Docker container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The Anchore CLI is very handy to interact with the engine and can be installed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'On the Jenkins dashboard, configure the installed Anchore plugin by pointing
    to **Manage Jenkins** and clicking on **System** . Provide the engine username
    of **admin** , the password, and the engine URL defined in the **docker-compose.yaml**
    file for the Anchore engine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – The Jenkins Anchore engine configuration](img/B21716_02_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.19 – The Jenkins Anchore engine configuration
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Anchore engine open source project is not maintained anymore but is still
    available on GitHub and Docker Hub for evaluation, along with its Jenkins plugin.
    An enterprise edition has replaced the open source version. More info on the open
    source Anchore engine can be found here: [https://github.com/anchore/anchore-engine](https://github.com/anchore/anchore-engine)
    . Other similar container security inspection solutions can be found at [https://github.com/anchore/syft](https://github.com/anchore/syft)
    and [https://github.com/anchore/grype](https://github.com/anchore/grype) .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Building images and pushing them to the local registry can be automated by
    optionally using a dedicated pipeline, with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Build an OpenStack service Docker image using Kolla.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run an Anchore security check on the pushed image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the created OpenStack service Docker image using Kolla if no specific vulnerabilities
    have been detected by Anchore.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our image pipeline script is structured in three stages – build images, Anchore
    security scans, and push images – if the vulnerability scans are successful. This
    can be depicted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the pipeline script in Jenkins and run the pipeline from the new job definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Running the OpenStack inspection image pipeline](img/B21716_02_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.20 – Running the OpenStack inspection image pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Running the OpenStack security scan image pipeline will generate a useful vulnerability
    assessment and trigger a **stop** action so that the pipeline will fail. Anchore
    reports the cause of the failure from the previous run, which did not comply with
    the engine policy.
  prefs: []
  type: TYPE_NORMAL
- en: Automating the OpenStack deployment by starting with a development environment
    helps to deliver a higher code quality empowered by security guardrails. Cloud
    operators will learn about possible issues during the cloud infrastructure deployment
    and master how to solve them earlier. It goes hand in hand with security and anomaly
    detection practices, which should support the move to production with more confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has been a quite milestone in defining the right way and best practices
    to run a complete OpenStack deployment in a DevSecOps style. Inheriting modern,
    agile software development practices in infrastructure management is considered
    a great opportunity for cloud operators, and hence for DevSecOps, to focus on
    infrastructure improvement and extension, rather than being blocked by traditional,
    manual operations tasks. The OpenStack ecosystem, with the latest additional services
    and functions, can be cumbersome to manage if no proper agile methods are considered
    from the start of the journey. This chapter has highlighted security fusion from
    day one. Silos should no longer exist between infrastructure and security duties.
    Undoubtedly, that is a game changer toward a successful deployment experience,
    armed with security and automation. As we have built a solid draft together with
    the right tooling and processes, we will take our momentum to the next chapter
    to extend our production design and deployment, cover OpenStack clustering, define
    its various services’ roles, and deploy them in a DevSecOps way.
  prefs: []
  type: TYPE_NORMAL
