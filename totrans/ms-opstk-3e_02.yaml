- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kicking Off the OpenStack Setup – The Right Way (DevSecOps)
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “In the middle of difficulty lies opportunity.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: – Albert Einstein
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: The OpenStack ecosystem, as discussed in the previous chapter, presents a vast
    array of design patterns, coupled with choices of hardware and tools to deploy
    a robust private cloud setup. With the Antelope release, there have been no significant
    changes to the core architecture system, but a few parts have been updated, with
    some additions and features. But that comes with the cost of increased complexity
    when it comes to the deployment and operation stages. The good news is that the
    OpenStack community, since its earliest releases, has created different approaches
    to avoid an arduous OpenStack operation experience. The key mechanism for this
    task is *automation* . There is, without a doubt, a high risk of getting into
    endless troubleshooting if the automation craft is overlooked. There are several
    tools maintained by vendors such as Puppet, Ansible, Chef, and a few others that
    are used in thousands of production deployments. To get an OpenStack setup up
    and running is not the goal of the journey but, rather, the deployment journey
    itself. That is where we will take advantage of automation and agile tools to
    bring the OpenStack operation to the next level, by adopting a DevOps path. Although
    that sounds like an amazing step toward a robust deployment process, it is still
    not complete without incubating security aspects from the early days of the deployment.
    Developing and operating the infrastructure process should be reimagined, from
    a DevOps picture to a DevSecOps one.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter presents the backbone of the future deployment and operational
    processes for an OpenStack private cloud setup by covering the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the DevOps philosophy behind the OpenStack deployment life cycle
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rethinking DevOps and introducing DevSecOps to see how it fits into our journey
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering a modern approach to deploying OpenStack in containers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterating through automation tools and preparing for deployment
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a first iteration of an OpenStack deployment via Continuous Integration/Continuous
    Delivery ( CI/CD) tools
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing for a large-scale deployment via code and Continuous Integration/Continuous
    Delivery ( CI/CD) pipelines
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating security checks in each deployment step in an automated fashion
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing silos – DevOps
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **DevOps** has been popping up for almost a decade, pushing organizations
    to rethink how to structure their internal teams to achieve what DevOps promises.
    Dozens of definitions of the word *DevOps* can be found everywhere, but it can
    simply be summarized as a *silo remover* . DevOps comes with the philosophy of
    bringing the main software product’s direct contributors to the same table, including
    operations, testers, and developers. The aim of this movement is based on a few
    principles that motivate organizations to implement them practically – knowledge
    and responsibility sharing, respect, automating everything, monitoring continuously,
    embracing failure, and designing for reusability. However, DevOps has never been
    a tool or software but, rather, a set of principles that define processes and
    workflows to boost a company’s productivity. What makes this movement shine takes
    us back to the simple definition – *silo remover* . As operations and developers
    are not hindered by the wall sitting between them, more collaboration and knowledge
    are shared toward the same goal – decreasing the time to market with the highest
    possible quality and degree of efficiency. Without the existence of many tools,
    reflecting this idea in real life would be more difficult. **Continuous Integration**
    ( **CI** ) and **Continuous Delivery** or **Deployment** ( **CD** ) tools are
    examples that have contributed immensely to reflecting that idea. Another set
    of tools that gives more trust to machines than to humans is the concept of *automation*
    . CI/CD tools leave all the manual and routine build, testing, and deployment
    stages to a few pipelines running on a server. Meanwhile, teams focus on more
    interesting tasks with higher business values. The rise of the cloud era has brought
    another giant set of opportunities to accelerate the software development cycle
    with automation – **infrastructure automation** . This is one of the areas that
    OpenStack focuses on with some of its services, such as **Heat** . Treating **Infrastructure
    as Code** ( **IaC** ) inspires the gathered teams, Dev and Ops, to bring knowledge
    from the traditional software development life cycle and apply it at the infrastructure
    level.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'It is no longer a case of *that is not my business* but, rather, *it is my
    business too* . What really matters is focusing on the delivery of business products
    in a reasonably reduced amount of time, getting to market faster, and not missing
    out on a race with the competition. This can be summarized with a DevOps toolchain
    for different software deployments across the Dev and Ops stages, as shown in
    the following diagram:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – The DevOps toolchain](img/B21716_02_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – The DevOps toolchain
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: By adopting the same philosophy, we will deploy our OpenStack private cloud.
    But before reaching that stage, we need to acknowledge an important fact – there
    is no rule of thumb when it comes to applying what DevOps dictates. The structure
    of teams in organizations may differ, and IT disciplines can be in several dedicated
    pods per function or merged into one. The pursuit of *DevOps happiness* can be
    confusing if an organization does not assign and refactor its team’s structure,
    seek out subject matter experts, have cross-functional team members based on specialized
    knowledge, and so on. Some of these issues have revealed obstacles, due to the
    gaps left in terms of security and compliance. This is what we will uncover in
    the following section before bringing the pieces of OpenStack together.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Shifting to the left – DevSecOps
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *billion-dollar* idea of the DevOps philosophy is to bring people together
    – all disciplines, including Ops, Devs, and **Quality Assurance** ( **QA** ).
    Organizations should make it clear where silos are raised among all product contributors.
    That should include the security discipline in their agile ways of working. The
    *2021 State of DevSecOps* study ( [https://www.securitycompass.com/reports/2021-state-of-devsecops/](https://www.securitycompass.com/reports/2021-state-of-devsecops/)
    ) elaborated by *Security Compass* , a cybersecurity consultancy services provider,
    shows that 75% of responders (IT professionals and DevOps practitioners) agreed
    that security slows down the processes of product releases, leading to an increase
    in the time to market. That goes against what DevOps was created for. Focusing
    on speed to market might skip the security aspect. This *sacrifice* has triggered
    some scary numbers in some large enterprises, where there was an increase in the
    volume of data breaches or the number of cybersecurity attacks. Treating security
    as something to act upon reactively instead of proactively can cost in terms of
    budget and time for each security incident. There are a few chief reasons that
    capture the root cause of why cybersecurity and DevOps are left in two different
    silos – more manual security intervention during the development process and a
    lack of knowledge of tools. Investing in security is required to comply with standards
    and gain trust. Sacrificing that for speed to market will certainly lead to major
    losses later on. That leads us to the next bridge that needs to be built between
    DevOps and security, forming a DevSecOps alliance. In the same way that Dev and
    Ops merged, security should no longer be considered an afterthought. DevOps principles
    can be inherited to make a security fusion possible. That is how DevSecOps has
    become a new trend. Imagine the whole pressure of security eased across each discipline
    and pointing to the same product goal, armed with automation and faster feedback.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: We can sum up the right approach for our future OpenStack deployments – DevOps
    with security at different stages of the process, as shown in the following toolchain.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Integrating security into the DevOps toolchain](img/B21716_02_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Integrating security into the DevOps toolchain
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Embracing the deployment of a complex environment such as an OpenStack private
    cloud would require a DevSecOps approach, and a few best practices are covered
    in the next section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Securing the cloud – moving with DevSecOps
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adopting DevOps practices is definitely a big deal to stay competitive in the
    market, increase productivity, and bring new possibilities for innovation. Conversely,
    with a lack of security, any product will be at risk of losing both trust and
    failure. Hence, the DevOps chain must be enforced with security and compliance
    insurance. One of the fundamental aspects of DevOps is automation and reusability.
    In an infrastructure context, we are not dealing with *pets* but with *cattle*
    . The *pets and cattle* analogy is a famous one, with on-prem servers referred
    to as *pets* . If there was any change, update, or failure of that pet server,
    a problem would arise. They are the long-lived and indispensable pieces of the
    infrastructure that should be taken more care of. On the other side of the analogy,
    *cattle* refer to servers in large on-demand environments such as the cloud. A
    cattle failure should not stop the business from running, and cattle can be replaced
    *immediately* . If we adopt the *cattle* analogy servers in the cloud should be
    instrumented to keep them immutable. That is where IaC comes into play. With one
    single source of truth and a shared pipeline, the *Sec* part becomes much easier
    to merge into the *DevOps* flow. With this capability, moving security from the
    right to the left becomes more feasible.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: DevSecOps and OpenStack
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The challenge of deploying a complex OpenStack ecosystem is made easier through
    DevOps, but what should not be overlooked as a cloud provider is protecting the
    first layer that runs a user’s workload(s). As we will explore in the next part
    of this section, there are several ways to deploy a complete OpenStack environment
    from code. Emphasizing security before starting to think about the code structure
    is vital to not miss a DevSecOps opportunity. As a rule of thumb, any code designed
    for an application infrastructure is subject to vulnerabilities. Although the
    different modules of OpenStack services are developed with security in mind, the
    gazillions of ways of configuring and parameterizing within a specific network
    architecture should be tested for security anomalies at every stage. Before welcoming
    any workload on top of the OpenStack infrastructure, the cloud itself must be
    ready with security controls and compliant with major standards.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Coding the cloud
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the biggest challenges of dealing with an OpenStack environment is the
    ways of handling its deployment and daily operations. If you consider a manual
    deployment for even a small environment, then in all likelihood, your OpenStack
    management processes, including updates, will face difficulties that cannot be
    avoided. That is where DevSecOps practices come in, with the fundamental mantra
    of IaC. A consistent approach is to treat the OpenStack ecosystem as code. The
    good news is that OpenStack code is provided with each stable release and is ready
    for deployment once configured and customized. But before we grasp a technical
    deployment, we should take into account a few common considerations to start building
    our toolchain:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Map each OpenStack service as code per module.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define target systems to run OpenStack services with one specific role or several
    roles. For example, a compute role is defined with the Nova service deployed.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Draft the initial configuration for each service (role).
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Think of roles as reusable code that can be deployed in different target environments.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure you integrate functional test stages between role setups.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider the integration of security rules and tools from the start. Map each
    nominated tool in each stage of the pipeline, from coding to the release phases.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid *Big Bang* coding practices and implement smaller changes in an automated
    continuous deployment fashion.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prepare to continuously monitor the following deployment metrics:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment frequency** : How often IaC is deployed (daily/weekly/monthly)'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change lead time** : The window of time starting from the moment code has
    been committed to the time it is successfully deployed'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change failure rate** : The total percentage of committed IaC changes leading
    to system impairment or outage (including hotfixes and rollbacks)'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean Time to Repair** ( **MTTR** ): The time needed to restore service outage
    from the moment it’s impaired'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a trunk-based development approach to facilitate code monitor changes and
    increase security visibility integration.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Trunk-based software development is a coding practice that allows developers
    to regularly merge changes into a common trunk code base. The trunk-based practice
    dictates more frequent code releases with smaller changes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: The following section will cover the different tools that will be used to deploy
    an OpenStack environment in the DevSecOps style.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Deploying in the cloud
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the first release of OpenStack, several deployment tools and wrappers
    have been developed to assist OpenStack operators with more enhanced, easier ways
    to set up a fully running OpenStack environment. With the rise of system management
    tools such as Chef, Puppet, SaltStack, and Ansible, the OpenStack community has
    dedicated different channels to each system management tool to develop different
    classes and modules through the OpenStack ecosystem evolution. Which one of these
    tools we choose is down to familiarity or the technical requirements of cloud
    operators. In this section, Ansible will be the system management tool we use.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Ansible in a nutshell
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like any other system management tool, Ansible uses its own glossary and terms
    to define infrastructure components, modules, relationships, and parameters. Conversely,
    unlike other tools, Ansible comes with a simple architecture setup that makes
    it a popular choice, and it can be summarized as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: It has the flexibility to handle interdependent complex service modules.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses an agentless transport mechanism to connect and update target systems
    without the need to install additional packages. It exposes only the *master*
    server where the Ansible software is running.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modules executed on target systems are auto-cleaned once installed.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is rich in core automation modules to extend more features.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The infrastructure collection code written in YAML is organized in Ansible playbooks.
    YAML is easier to learn and master than other languages, such as Ruby for Chef.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the simplicity of the Ansible architecture, scalability is much simpler
    to implement compared to other tools that require running agents.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a declarative method of programming, it focuses on describing the output
    of the desired state, rather than diving into how to do it and which steps must
    be taken to reach the resulting output.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When dealing with the complexity of the OpenStack ecosystem, with all its sets
    of components, subcomponents, and parameter flavors, it is essential to briefly
    skim the surface of the Ansible terminology :'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '**Playbooks** : These consist of the main configuration file(s) that describes
    a series of actions to run on one or a group of hosts. The tasks are written in
    YAML and executed in order, from top to bottom, to accomplish full deployment
    or a configuration change.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Roles** : These present the organizational structure of playbooks by collecting
    different Ansible assets, such as tasks, variables, and modules, to deploy a service
    on one or a group of hosts.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modules** : These are an abstract representation of a specific unit of code
    functionality. Modules can be written and customized to control system resources,
    files, and services. Ansible is shipped with some modules referred to as module
    libraries (core modules) that can be executed via customized playbooks.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variables** : These are dynamic values used in roles and playbooks to reflect
    the desired configuration. Similar to programming language variables, Ansible
    variables enable the propagation of different states across different environments
    through the same role or playbook.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变量**：这些是用于角色和 playbook 中的动态值，用来反映所需的配置。类似于编程语言中的变量，Ansible 变量通过相同的角色或 playbook
    使不同的状态在不同环境中传播。'
- en: '**Inventory** : This is a listing of managed hosts in the target environment.
    Ansible uses a configuration file in the **INI** format, which defines the name
    and IP of the managed target host. Hosts can be declared in inventory files using
    different patterns by nesting hosts by role, or by specifying a series of hosts
    via a combination and numeric patterns.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库存**：这是目标环境中已管理主机的列表。Ansible 使用 **INI** 格式的配置文件，定义了已管理目标主机的名称和 IP。可以通过不同的模式在库存文件中声明主机，或通过角色嵌套主机，或通过组合和数字模式指定一系列主机。'
- en: 'The CI/CD system triggers Ansible to install and run playbooks across target
    OpenStack nodes defined in its inventory, as depicted in the following figure:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD 系统触发 Ansible 安装并在其库存中定义的目标 OpenStack 节点上运行 playbook，如下图所示：
- en: '![Figure 2.3 – An OpenStack environment management through Ansible](img/B21716_02_03.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3 – 通过 Ansible 管理 OpenStack 环境](img/B21716_02_03.jpg)'
- en: Figure 2.3 – An OpenStack environment management through Ansible
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 通过 Ansible 管理 OpenStack 环境
- en: Integrating system management tools such as Ansible in OpenStack ecosystem life
    cycle management has introduced a significant change in the way such a complex
    ecosystem is managed and operated. Not surprisingly, the hunger to move quickly
    to adopt a private cloud setup and maximize the agility of its deployment has
    led to other challenges. That brings us to the root causes of OpenStack-tied dependencies
    between services. Thinking long term, the development of new OpenStack releases
    and feature integrations in an existing environment presents one of the ultimate
    challenges for a private cloud operation mission. Driving major upgrades has always
    been a blocker to seamlessly jumping to a new OpenStack release in a running production
    setup. That makes the upgrade case a very cautious operation and puts your **Service-Level
    Agreement** ( **SLA** ) at risk if one or several dependencies crash, due to a
    code compatibility version that has been overlooked. Although tests can help to
    identify such anomalies, a massive number of tests for each component should be
    in place in advance, and that could be costly in terms of resources and human
    interactions. The other facet of these challenges is the lack of rollback mechanisms.
    Rolling back a change that causes an issue will definitely bring one or several
    parts of a whole system down, as you wait for your management tools to redeploy,
    restart the affected services, and test and wait for a complete synchronization
    between other dependent services to run them again. The most common OpenStack
    deployment options involve bare-metal machines or virtual machines, making such
    operational tasks heavier to roll, requiring full management of machine images,
    and it becomes costly when testing in an isolated environment. For example, upgrading
    or updating an OpenStack component version would require all inter-dependent services
    to be deployed in a different testing environment before propagating the change
    in the production one. Within the latest OpenStack releases, several organizations
    have been experimenting with the rise of containers for a fully containerized
    OpenStack cloud. Let’s unleash the container dilemma in the next section and explore
    what opportunities are in store for OpenStack deployment and management.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenStack 生态系统生命周期管理中集成 Ansible 等系统管理工具，带来了对如此复杂生态系统管理和操作方式的重大变革。毫不奇怪，快速迁移到采用私有云设置并最大化其部署灵活性的需求，带来了其他挑战。这引出了
    OpenStack 服务之间依赖关系的根本原因。从长远来看，开发新的 OpenStack 版本和将新功能集成到现有环境中，成为私有云操作任务的终极挑战之一。推动大规模升级一直是顺利迁移到新
    OpenStack 版本时的障碍，尤其是在生产环境中运行时。这使得升级操作变得非常谨慎，并且如果其中一个或多个依赖项因版本兼容性问题崩溃，可能会让你的**服务级别协议**（**SLA**）面临风险。尽管测试可以帮助识别此类异常，但每个组件需要提前进行大量的测试，这在资源和人工互动上会非常昂贵。另一个方面的挑战是缺乏回滚机制。回滚一个导致问题的更改必然会导致系统的某些部分或整个系统崩溃，因为你需要等待管理工具重新部署、重启受影响的服务、测试并等待其他依赖服务之间的完全同步，才能重新运行它们。最常见的
    OpenStack 部署选项包括裸金属机器或虚拟机，使得此类操作任务更加复杂，需要全面管理机器镜像，并且在隔离环境中进行测试时会增加成本。例如，升级或更新
    OpenStack 组件版本时，需要在不同的测试环境中部署所有相互依赖的服务，然后再在生产环境中传播更改。在最新的 OpenStack 版本中，一些组织已经开始尝试使用容器化的方式构建完全容器化的
    OpenStack 云。让我们在下一节解锁容器难题，探索 OpenStack 部署和管理的潜在机会。
- en: Containerizing the cloud
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器化云计算
- en: Container technology has been around for more than a decade, and companies have
    started deploying their workloads in containers to take advantage of resource
    optimization, environment isolation, and portability. Running different pieces
    of your software in lightweight, self-contained, and independent containers brings
    more flexibility to managing a complex software system. Running in an isolated
    mode, operations such as upgrades and rolling back become much easier and can
    be performed with more confidence.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术已经存在超过十年，企业开始将工作负载部署到容器中，以便利用资源优化、环境隔离和可移植性。将软件的不同部分运行在轻量级、自包含和独立的容器中，为管理复杂的软件系统带来了更大的灵活性。在隔离模式下运行时，像升级和回滚这样的操作变得更加容易，并且可以更有信心地执行。
- en: 'By referring to our infrastructure code, we can see the benefit of the OpenStack
    software architecture’s modular design, which offers a great deal by taking advantage
    of container technology, where each module can live in a separate, stateless environment.
    Looking at the current state of container trends, an extended list of container
    and orchestration engines can be found, such as LXC, Docker, and Kubernetes. The
    OpenStack community did not miss the chance to adopt containerization technology
    early on, when containers started to become the standard for modern software development.
    Within the Antelope and later releases, we can find several deployment methods
    based on containers, combined with configuration management tools, as summarized
    in the following table:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '| **Deployment project** | **Container** | **Project** | **Source** |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| OpenStack-Ansible | LXC | Ansible | [https://docs.openstack.org/openstack-ansible/latest/](https://docs.openstack.org/openstack-ansible/latest/)
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: '| Kolla-Ansible | Docker | Ansible | [https://docs.openstack.org/kolla-ansible/latest/](https://docs.openstack.org/kolla-ansible/latest/)
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
- en: '| OpenStack-Helm | Docker | Kubernetes and Helm | [https://docs.openstack.org/openstack-helm/latest/](https://docs.openstack.org/openstack-helm/latest/)
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
- en: '| Triple-O (currently no longer supported) | Docker | Ansible | [https://docs.openstack.org/tripleo-ansible/latest/](https://docs.openstack.org/tripleo-ansible/latest/)
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
- en: Table 2.1 – A list of OpenStack deployment tools running containers
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: The **OpenStack-Ansible** ( **OSA** ) project is one of the most widespread
    deployments based on LXC containers. The deployment of LXC containers running
    OpenStack services is orchestrated by Ansible.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: In our next deployment, we will adopt another emerging OpenStack project, named
    **Kolla-Ansible** . Similarly to OSA, the Kolla project uses Docker as a containerization
    tool by building a Docker container for each OpenStack service. Besides the design
    differences between LXC and Docker, Kolla extends the parameterization layout,
    making its containers more configurable, with an array of choices between the
    base operating system and template engines. This is not to mention Docker’s design
    advantages as a container technology, with the layered nature of its images, versioning,
    and portability for sharing capabilities.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Kolla has been integrated officially within the OpenStack subproject since the
    Liberty release. As per the official OpenStack definition of the Kolla project,
    *“Kolla’s mission is to provide production-ready containers and deployment tools
    for operating* *OpenStack clouds.”*
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Those extra advantages make Docker more suitable for our deployment pipeline,
    where we will deal with a container service as an artifact that can be easily
    deployed through different environments, before promoting it to a production environment.
    As depicted in the following high-level schema, for each merged change in the
    code repository, the CI/CD tool builds an artifact composed of a software package
    encapsulated in a Docker image. The generated image will be committed to a private
    Docker registry, where Ansible will download it and orchestrate its setup in the
    designated OpenStack node.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – High-level CI/CD pipeline OpenStack deployment](img/B21716_02_04.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – High-level CI/CD pipeline OpenStack deployment
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The other component of the deployment tool stack is the **Jinja2** templating
    tool. This is mainly used by Docker for the dynamic assignment of variables, based
    on defined parameters generated by Ansible. Jinja2 is designed mainly for Dockerfiles
    to support full system call interface compatibility for both RPM and DEB container
    distributions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Jinja2 templating in the Kolla context provides an array of ways of building
    Docker images of different source distributions, including CentOS, Debian, Fedora,
    Ubuntu, and RHEL container operating systems that can be parameterized per OpenStack
    service code.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: As our main motivation is to solve the complexity of dependencies and provide
    a simpler and more scalable development experience, Kolla is the way to go, and
    indeed since its official first stable release, several production deployments
    have been performed the Kolla way.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Building the picture
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Treating OpenStack deployment as IaC will help us to inherit and use most of
    the software tools and processes to deliver code artifacts, ready for deployment,
    with more confidence. Having a robust integration and deployment pipeline is vital
    to ensure that our software-defined data center does not fail on production day.
    Modern software development techniques involve several tools that increase automation
    and agility and, hence, faster feedback between each deployment.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'The following tools will be employed for our OpenStack infrastructure code
    development:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '**A version control system** : GitHub will be our code repository for the OpenStack
    infrastructure code.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A CI/CD tool** : Jenkins will be installed on the deployer machine and grant
    extra plugins to build and run deployment pipelines.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A system management tool** : The Ansible packages will be installed on the
    deployer machine and provide the OpenStack playbooks to be deployed inside the
    containers, in tandem with Kolla.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An image builder** : Dedicated to OpenStack containers, Kolla builds container
    images running different OpenStack services.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Kolla-Ansible project code repository will be our starting point for the
    first OpenStack deployment, with minimum customization to have a rolling deployment
    pipeline initially. The official latest master stable branch of the project code
    can be found here: [https://github.com/openstack/kolla-ansible](https://github.com/openstack/kolla-ansible)
    .'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Kolla-Ansible supports both all-in-one as well as multi-node OpenStack setups.
    As we’re aiming for a production setup, as discussed in the initial design draft
    in [*Chapter 1*](B21716_01.xhtml#_idTextAnchor014) , *Revisiting OpenStack –Design
    Considerations* , we will make sure our initial draft is the first deployment
    iteration ready for deployment.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a development environment
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting up a development environment mimicking a production one is highly recommended
    to ensure faster feedback during the development stages, as well as to fix any
    anomalies in code before promoting it to a production setup. Although running
    services in a container increases the flexibility of rolling back if issues are
    detected after deployment into production, a best practice is to act proactively
    by running service containers in an isolated environment through different deployment
    and testing stages. Upon successful deployment in the test environment, services’
    containers will be promoted and tagged as production-ready for deployment.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how many physical machines will be invested in your development
    environments, the DevSecOps team will require an isolated environment for each
    member to run tests, before committing their changes to a main development branch
    that targets deployment in the development environment.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the local environment
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Vagrant is a revolutionary tool created by HashiCorp that can create, modify,
    and manage visualized environments through simple Vagrant command lines. The other
    exciting part of Vagrant is managing a local development environment through it.
    Vagrant configuration is highly customizable and supports a variety of local hypervisors
    to run virtual machines, such as VirtualBox, HyperV, and VMware.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Our next setup will consider a local VirtualBox environment, depending on your
    development operating system machine; most Linux, Mac, and Windows distributions
    are supported and can be found here: [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)
    .'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'Once VirtualBox is installed, download the base image where the OpenStack environment
    will run. A good practice for VirtualBox development in Vagrant is to use the
    same operating system distribution for both the development and production environments.
    The chosen operating system in the next setup is Ubuntu **22.04 LTS** . In the
    following wizard, we will go through the different steps to prepare the Vagrant
    file before starting to deploy a local OpenStack environment:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a Vagrant file by firing the following command line:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Modify the **box** stanza configuration section by providing the operating
    system image:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Important note
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'Vagrant boxes can be created locally by backing up an image of any operating
    system, using tools such as **Packer** . Vagrant boxes can be shared and tagged
    with the version in the Vagrant cloud repository, as detailed here: [https://developer.hashicorp.com/vagrant/vagrant-cloud/boxes/create](https://developer.hashicorp.com/vagrant/vagrant-cloud/boxes/create)
    .'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'The local development machine should have a minimum of hardware specs, such
    as RAM and CPU, to accommodate a minimal setup of an OpenStack environment, as
    depicted in the following Vagrant configuration section:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Set the virtual disk space to a minimum of 50 GB in the new **box** stanza
    line:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Important note
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to have the **vagrant-disksize** plugin installed by running the following
    command line – **vagrant plugin** **install vagrant-disksize** .
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, add a synced folder to sync the OpenStack infrastructure code on
    the development machine:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Important note
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Make sure the synced folder in the local machine exists by creating the **openstack_deploy**
    folder.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Networking can be configured to forward port access to specific services from
    the development machine to the guest box. Accessing OpenStack Horizon, for example,
    would require port forwarding on port **80** from the guest machine, which can
    be adjusted as follows:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Start the Vagrant box by firing the following command line:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once started without errors, the Vagrant box is ready for access. The default
    login uses a Vagrant user that can be elevated to root to proceed with the next
    setup:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once the Vagrant box is up and running, you should be able to start installing
    the required packages to deploy an all-in-one OpenStack environment.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Running the local cloud
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Kolla-Ansible project code includes different ways of installing OpenStack
    in all-in-one or multi-nodes. As part of the infrastructure code process, we will
    adjust a few settings to run an all-in-one mode on the development machine. But
    first, we need to install the Git package on our local development host:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Clone the OpenStack-Kolla repository to the designated local folder setup created
    in the previous section. The Vagrant configuration file will make any changes
    to the local folder, **openstack_deploy/** , visible to the guest box. Ideally,
    cloning the repositories should be done from your local Git server of choice.
    In this example, a private Git repository is used ( **ci.os** ). The following
    command clones the local repository running on the CI/CD instance:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Important note
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple guide to optionally set up a local Git server running NGINX
    on the latest version of Ubuntu: [https://www.howtoforge.com/tutorial/ubuntu-git-server-installation/](https://www.howtoforge.com/tutorial/ubuntu-git-server-installation/)
    . The local Git server uses the latest stable master branch, cloned locally from
    the Kolla-Ansible repository: [https://github.com/openstack/kolla-ansible.git](https://github.com/openstack/kolla-ansible.git)
    .'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, create your development branch from the master to track local changes
    before pushing them to the next development branch:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Important note
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, pushed changes should be made in a dedicated development branch of
    your choice before propagating them to the master branch.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to your Vagrant box and proceed to install environment dependencies
    and create a virtual environment. Make sure to change the path of your environment
    on the guest host:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Install Ansible. Make sure a minimum version of 2.16 is installed:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Install the **kolla-ansible** runtime:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Since OpenStack Yoga, a few additional dependencies need to be installed, which
    can be solved by running the following command line:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The Kolla-Ansible repository comes with two essential files that we will edit
    to run our local deployment – **globals.yml** and **passwords.yml** . Copy the
    files to a directory of your choice, which can be created, and make sure that
    the running guest user owns the files:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The **globals.yml** file includes several settings and adjustable configurations
    for different OpenStack control plane services, as well as shared ones. As part
    of our minimal test environment, we will edit the following settings to the copied
    **globals.yml** file under the **/** **etc/** **kolla/** folder:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Ubuntu to run as the base Linux distribution for the containers:'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Ensure that HAProxy is out of the scope of our initial setup in the test environment:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Select the network interface name to be assigned for all types of OpenStack
    networks:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Dedicate a second interface for the Neutron external network:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Assign a Keepalived floating IP, which should be reserved as a virtual IP for
    HA:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The **passwords.yml** file centralizes all the OpenStack purposes and other
    services’ passwords. To generate random password sets in one command instead of
    running them manually for each, Kolla comes with a simple command tool that generates
    passwords, which will be used during the deployment, as follows:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Make sure that the generated passwords are saved in the **passwords.yml** file
    under your custom directory.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The other crucial file is under the **inventory** folder, which describes and
    instructs Kolla-Ansible on which hosts will be the target to apply the configuration.
    Inventory files are defined with the Ansible host group format and can be customized,
    based on the available hosts and assigned roles. The default available files are
    designed to run inventories for all-in-one and multi-hosts. To run a clean host
    target setup, make a copy of the files under the **inventory** directory:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The all-in-one Ansible inventory file will not require any changes for our
    development setup purposes. The format of the file is straightforward, where each
    host role section describes the name of the host or IP address. For the local
    test environment, all host roles will be configured with **localhost** , as shown
    in the following snippet:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Fire the **kolla-ansible** command line to install the bootstrap servers. The
    command will run the Ansible playbook against each host-assigned role in the inventory
    file. So far, all roles are gathered in the same localhost:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following is the output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – The kolla-ansible bootstrap servers’ output](img/B21716_02_05.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – The kolla-ansible bootstrap servers’ output
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, run a few deployment checks to closely monitor the bootstrapping
    process and detect possible failures:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here’s the output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – The kolla-ansible prechecks’ output](img/B21716_02_06.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – The kolla-ansible prechecks’ output
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the bootstrapping process is finished without any detected failures, perform
    the deployment of the OpenStack environment, which will take a long time to create
    all the containers’ services and chain them together:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here’s the output:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – The kolla-ansible deployment output](img/B21716_02_07.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – The kolla-ansible deployment output
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: The Ansible deployment will apply the playbooks and OpenStack roles using container
    images from the default OpenStack Docker repository. For the next development
    stage, make sure to build and push further images to a local repository. The next
    sections and chapters will discuss how to build local container images for different
    services and manage them locally.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment of the minimal setup of the OpenStack containers should result
    in zero failures by the end of the **kolla-ansible deploy** command line. The
    following Docker command line lists all the running containers deployed in the
    previous step that should be noted as healthy. Some containers will still be in
    the process of communicating with other system services, which will take a few
    minutes, before starting to evaluate the OpenStack services:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here’s the output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – A list of the running OpenStack service containers](img/B21716_02_08.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – A list of the running OpenStack service containers
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to see OpenStack running in containers by firing a client test command.
    To fire a quick test, install the OpenStack client package:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To interact with OpenStack API services, admin credentials are required, which
    can be generated by the **kolla-ansible post deploy** command, as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here’s the result:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – The kolla-ansible OpenStack post-deployment output](img/B21716_02_09.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 – The kolla-ansible OpenStack post-deployment output
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous command will generate the **cloud.yaml** file, which contains
    different OpenStack admin credentials to interact with OpenStack services via
    the client command line. The content of the file variables can be populated by
    exporting the path of the generated **cloud.yaml** file, as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Validate the running OpenStack environment by listing, for example, the **nova**
    host:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here’s the output:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – The OpenStack host list output](img/B21716_02_10.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 – The OpenStack host list output
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenStack services can be managed easily through the Docker container command-line
    interface. For example, Keystone container service logs can be viewed by running
    the following command line:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The other option to inspect an OpenStack service container and report back
    container information, such as IP address and networking settings, can be performed
    by using the generic **docker inspect** command line, as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Despite the flexibility of the usage of containers and the simplicity of destroying
    and building new ones in almost no time, in some cases, you might need to investigate
    a defined OpenStack service issue or configuration via shell access, as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: An all-in-one setup helps to develop and test code locally. Larger environments,
    including staging and production, would require an extended setup, which will
    be detailed in the next section.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Extending the deployment
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Expanding on our initial physical design, discussed in [*Chapter 1*](B21716_01.xhtml#_idTextAnchor014)
    , *Revisiting OpenStack – Design Considerations* , will require the evaluation
    of different hardware specifications and options for the chosen design. As we
    have narrowed down the methods of deployment and the different sets of tools to
    build our first production iteration, we will start splitting the roles of OpenStack
    components across different physical systems. Unlike a testing environment, a
    production environment should follow a well-architected design pattern, based
    on the isolation of services, fault tolerance, scalability, and redundancy on
    each layer. We will deep-dive into the extension of those architectural aspects
    in [*Chapter 3*](B21716_03.xhtml#_idTextAnchor108) , *OpenStack Control Plane
    – Shared Services* , and [*Chapter 7*](B21716_07.xhtml#_idTextAnchor174) , *Running
    a Highly Available Cloud – Meeting* *the SLA* .
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Our deployment pipeline will be the source of truth to deploy any environment
    if you consider going through a minimal all-in-one setup testing environment to
    a staging one, mimicking the production that will be promoted to production if
    all stages of the pipeline tests, including security ones, are executed with 0
    errors.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to not introduce any user production workloads before getting a minimum
    level of redundancy in each control and data plane across your OpenStack environment.
    More details on extending to a highly available setup will be discussed in [*Chapter
    7*](B21716_07.xhtml#_idTextAnchor174) , *Running a Highly Available Cloud – Meeting*
    *the SLA* .
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: The deployment expansion for the environment should take an incremental approach
    by splitting the roles whenever feasible, and you should take into consideration
    that some services can be optionally separated on their own physical servers.
    A good practice is to start splitting additional roles in the physical layout
    once the core services are rolling and after gaining more operational expertise
    for each iteration. As the deployment pipeline feeds back the state of each new
    deployment, more technical decisions will need to be made to introduce improvements
    to the physical infrastructure layout, and you can choose which services can be
    moved to their own server in the next iteration. To safely start the deployment
    journey, we will need to install and configure our deployer before proceeding
    with infrastructure deployment.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Installing the deployer
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our deployer host will be installed with the following software and hardware
    settings:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '**Software** :'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jenkins version 2.414.1
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker version 1.12.6 or greater
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ansible 2.3.1 or greater
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Python 1.10.0 or greater
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolla-Ansible 16.1.0-16 – an OpenStack Antelope release or later
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Git version control
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operating system** : Ubuntu 22.04 LTS'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: pip and Python dependencies including **python-dev**
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hardware** :'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CPU** : At least 4 CPU cores and 64 bits x86'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory** : At least 4 GB of RAM'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disk space** : At least 50 GB of free disk space'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network** : At least two network interfaces'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Start by installing Jenkins, by updating your local system and Java runtime:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Add the required GPG key for the Jenkins repository files:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The following command will address the local system repository to download
    a recent version of Jenkins:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Run an update of the **apt** package list and install Jenkins:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Make sure Jenkins is running by firing the following command:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'If the Jenkins daemon is not running, issue the **start** command to launch
    its process:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Once the Jenkins service is up and running, point to the CI/CD server address
    in a browser on the default **8080** port to access the user interface, and then
    proceed with the preliminary setup of the server:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Jenkins home page](img/B21716_02_11.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 – Jenkins home page
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to add a few plugins before building the pipeline, starting
    with **Git SCM** plugins. To do this, click on **Manage Jenkins** on the upper-left
    corner tab. Type **git** in the search bar on the **Available Plugin** tab and
    click **Install** **without restart** :'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Jenkins’ Git SCM plugin setup](img/B21716_02_12.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 – Jenkins’ Git SCM plugin setup
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Once Jenkins and its required plugins are installed, we can move forward by
    setting up the CI/CD pipeline and different stages for future deployment.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Actioning the deployer
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our Jenkins file can be checked into the repository. The SCM pipeline will
    run the job definition with the configured path. The Jenkins pipeline definition
    can be summarized in high level in the following steps:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Create a local test environment on the destination testing host.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check out the repository from a defined branch.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the required testing packages, including **kolla-** **ansible** and
    Docker runtimes.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the bootstrap server script.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run Kolla prechecks on the bootstrapped testing environment.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the OpenStack testing environment.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the target environments you plan to run through the CI/CD pipeline,
    make sure to adjust the configuration layout of the main **globals.yml** and **inventory.yml**
    files separately in each environment. Each environment should run with a dedicated
    Jenkins pipeline file.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to create our first pipeline for the testing environment.
    Jenkins provides different options to create the job pipeline definition, either
    via the user interface wizard or by simply creating a Jenkins file that can live
    in the main directory of the OpenStack infrastructure as a code repository. For
    this purpose, our first job definition will follow the SCM method. The following
    snippets define the Jenkins deployment pipeline, starting with the first stage,
    where a virtual Python environment will be sourced to run each build in its own
    local environment:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The next stage will install all required dependencies, including **pip** ,
    the Ansible runtime, and the **kolla-ansible** package:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Once all the required packages are installed locally, the next stage will define
    the file structure of the infrastructure code under the **/etc/kolla** directory
    and set a few parameters in the **globals.yml** file, such as the network interface
    and the type of distribution Kolla will use:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The next step will generate different secrets for all OpenStack services in
    their configurations. The secret file will inject each secret for each service
    during the OpenStack service installation:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next, the pipeline will instruct Jenkins to prepare the container scripts for
    booting, including the system configuration:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The next stage will run a precheck task to make sure that the bootstrap step
    was performed without issues:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The final stage is to deploy the services, pull the images, and run the services
    in containers:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Make sure to have a new testing branch:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Commit and push the created file to the source code repository with the new
    branch:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Important note
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Using the Jenkins file the SCM way enables us to treat the pipeline definition
    as code. Make sure that all changes and updates for any job definition go through
    the pipeline code. The pipeline file is written in Groovy syntax. A recommendation
    is to use an IDE to highlight the Jenkins file code format in the same way as
    for YAML. If your IDE does not highlight the Groovy syntax, add **#!/usr/bin/env
    groovy** to the top of the pipeline Jenkins file.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: 'From the Jenkins user interface, select **New Item** from the top-left menu.
    Select **Pipeline** as the type of job, with the desired name to run the test
    pipeline. The next wizard creates a pipeline item, named **openstack-dev** :'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Jenkins pipeline creation](img/B21716_02_13.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: Figure 2.13 – Jenkins pipeline creation
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the pipeline script from SCM in the **Configure** tab and Git by specifying
    the repository URL. Make sure to configure the script of the Jenkins file in the
    repository directory path:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – The Jenkins pipeline SCM job definition](img/B21716_02_14.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 – The Jenkins pipeline SCM job definition
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first deployment setup for the testing environment is ready to go. All
    that is left is to push the button. Click on **Build Now** on the left-hand side
    of the newly created job definition in Jenkins, where the different stages declared
    in the pipeline code will be visible:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – The Jenkins OpenStack test deployment pipeline](img/B21716_02_15.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
- en: Figure 2.15 – The Jenkins OpenStack test deployment pipeline
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 'Jenkins jobs that are running can be monitored by clicking on the **Console
    Output** tab, where each stage defined in the pipeline file is reported to support
    further debugging and troubleshooting when possible errors occur:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Jenkins OpenStack test deployment output](img/B21716_02_16.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
- en: Figure 2.16 – Jenkins OpenStack test deployment output
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: The Jenkins console output is very handy for troubleshooting any possible issues
    that could occur during the Ansible run. Make sure the **failed** status is **0**
    . When the deployment status ends with the **SUCCESS** value, we can enforce the
    pipeline with additional security checks.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Deploying with security
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we emphasized at the start of this chapter, security should be considered
    in the early steps of building and deployment projects. That is what has been
    defined as a *shift to the left* . The craft of automating security checks should
    be learned in testing environments to report any potential vulnerabilities before
    promoting the infrastructure to a production environment.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first security enforcement will be conducted by installing an additional
    Jenkins plugin, which will be an interesting asset to our DevSecOps pipeline.
    As we are dealing with containers as the main artifacts, we will install a container
    inspection plugin to perform security scans on the built containers at a later
    stage. **Anchore** is one of the most widely used container vulnerability-scanning
    platforms, providing seamless integration with CI/CD tools, source code, and even
    container registries for both Docker and Kubernetes. The Anchore plugin exists
    for Jenkins and can be installed straightforwardly in the same way we installed
    the Git plugin. On the **Available plugins** tab, search for **anchore** :'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Searching for the Jenkins Anchore plugin](img/B21716_02_17.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
- en: Figure 2.17 – Searching for the Jenkins Anchore plugin
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the **Anchore Container Image Scanner** plugin and click on **Install**
    **without restart** :'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18 – The Jenkins Anchore plugin setup](img/B21716_02_18.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
- en: Figure 2.18 – The Jenkins Anchore plugin setup
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'More details about the Anchore platform can be found here: [https://anchore.com/container-vulnerability-scanning/](https://anchore.com/container-vulnerability-scanning/)
    .'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the plugin is installed, we need to adjust our settings to instruct our
    deployer to use a Docker repository at a specific address and port. For this example,
    the image registry will be deployed in the deployer host, named **master_registry**
    , by running the following command:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Make sure to update the **globals.yml** file to use the local Docker registry
    by editing the following configuration lines:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Commit and push your changes to the main infrastructure code repository so
    that our CI/CD will point to the local registry in later image build steps:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Before getting the image build pipeline running, we will install the Anchore
    engine to run the container inspection later. The Anchore open source version
    comes as a Docker image that can run standalone. Proceed by downloading the Anchore
    engine **docker-compose** file, as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Optionally, reset the admin password defined by the **ANCHORE_ADMIN_PASSWORD**
    configuration line in the **docker-compose.yaml** file. That will be needed for
    later steps.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: For permanent access to the Anchore engine interface, export the Anchore endpoint,
    username, and password to the **ANCHORE_CLI_URL** , **ANCHORE_CLI_USER** , and
    **ANCHORE_CLI_PASS** environment variables, respectively. If the variables are
    not populated within the operating system, you will need to export them in each
    run of the CI/CD pipeline execution.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create and run the Anchore engine Docker container:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The Anchore CLI is very handy to interact with the engine and can be installed
    as follows:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'On the Jenkins dashboard, configure the installed Anchore plugin by pointing
    to **Manage Jenkins** and clicking on **System** . Provide the engine username
    of **admin** , the password, and the engine URL defined in the **docker-compose.yaml**
    file for the Anchore engine:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – The Jenkins Anchore engine configuration](img/B21716_02_19.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
- en: Figure 2.19 – The Jenkins Anchore engine configuration
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: 'The Anchore engine open source project is not maintained anymore but is still
    available on GitHub and Docker Hub for evaluation, along with its Jenkins plugin.
    An enterprise edition has replaced the open source version. More info on the open
    source Anchore engine can be found here: [https://github.com/anchore/anchore-engine](https://github.com/anchore/anchore-engine)
    . Other similar container security inspection solutions can be found at [https://github.com/anchore/syft](https://github.com/anchore/syft)
    and [https://github.com/anchore/grype](https://github.com/anchore/grype) .'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'Building images and pushing them to the local registry can be automated by
    optionally using a dedicated pipeline, with the following steps:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Build an OpenStack service Docker image using Kolla.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run an Anchore security check on the pushed image.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the created OpenStack service Docker image using Kolla if no specific vulnerabilities
    have been detected by Anchore.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our image pipeline script is structured in three stages – build images, Anchore
    security scans, and push images – if the vulnerability scans are successful. This
    can be depicted as follows:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Save the pipeline script in Jenkins and run the pipeline from the new job definition:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Running the OpenStack inspection image pipeline](img/B21716_02_20.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
- en: Figure 2.20 – Running the OpenStack inspection image pipeline
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Running the OpenStack security scan image pipeline will generate a useful vulnerability
    assessment and trigger a **stop** action so that the pipeline will fail. Anchore
    reports the cause of the failure from the previous run, which did not comply with
    the engine policy.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Automating the OpenStack deployment by starting with a development environment
    helps to deliver a higher code quality empowered by security guardrails. Cloud
    operators will learn about possible issues during the cloud infrastructure deployment
    and master how to solve them earlier. It goes hand in hand with security and anomaly
    detection practices, which should support the move to production with more confidence.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has been a quite milestone in defining the right way and best practices
    to run a complete OpenStack deployment in a DevSecOps style. Inheriting modern,
    agile software development practices in infrastructure management is considered
    a great opportunity for cloud operators, and hence for DevSecOps, to focus on
    infrastructure improvement and extension, rather than being blocked by traditional,
    manual operations tasks. The OpenStack ecosystem, with the latest additional services
    and functions, can be cumbersome to manage if no proper agile methods are considered
    from the start of the journey. This chapter has highlighted security fusion from
    day one. Silos should no longer exist between infrastructure and security duties.
    Undoubtedly, that is a game changer toward a successful deployment experience,
    armed with security and automation. As we have built a solid draft together with
    the right tooling and processes, we will take our momentum to the next chapter
    to extend our production design and deployment, cover OpenStack clustering, define
    its various services’ roles, and deploy them in a DevSecOps way.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
