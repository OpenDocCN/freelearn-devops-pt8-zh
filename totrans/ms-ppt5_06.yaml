- en: Workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll discuss the workflow in Puppet. We''ll cover what makes
    a good technical workflow, how to apply that to Puppet, and how to use the **Puppet
    Development Kit** (**PDK**) to improve our workflow. We''ll investigate the following
    qualities of a good workflow: ease of use, rapid feedback, ease of onboarding,
    and quality control. We''ll use Puppet Git repositories to provide a basic Puppet
    workflow that can be tuned to any system of management. We''ll also explore the
    new PDK released by Puppet, which can improve our workflow.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Puppet workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing a Puppet workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the PDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A workflow is a series of processes that work flows through, from initiation
    to completion. As the Puppet environments become more complex in an organization,
    a trusted and shared workflow will make sharing work easier. A Puppet workflow
    should allow us to access code, edit code, test our code, and, eventually, deploy
    our code back to the Puppet Master. Although it is not required, it is highly
    recommended that an organization or group of workers adopt a shared workflow.
    A shared workflow possesses a few main benefits, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A measurable ease of use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rapid feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ease of onboarding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quality control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ease of use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary reason to design and begin a workflow is to provide for ease of
    use. A team should design a workflow around their code base, allowing them to
    understand how to retrieve specific code, how to edit that code, and the impacts
    of the new edits. A workflow also provides a standardized way of packaging the
    code, to be delivered and used by the existing code base. Each step in the workflow
    should be clear, concise, communicated, and repeatable. It is important that everyone
    on the team understands not only how the workflow works, but why each step of
    the workflow exists, so that they can troubleshoot and contribute to the workflow,
    should something change in the organization.
  prefs: []
  type: TYPE_NORMAL
- en: One of the primary benefits of a shared workflow, as opposed to individualized
    workflows, is the ability to measure the impact of the workflow on the organization.
    To measure our workflow, we first separate standard and nonstandard units of work.
    The edits that we make to our code often vary in size and complexity, and are
    not easy to measure in standard units. On the other hand, code is generally checked
    out, tested, and deployed in the same way every time, leaving us with a good estimate
    of how long it will take to go through our workflow, minus the code edits.
  prefs: []
  type: TYPE_NORMAL
- en: If our workflow takes about 30 seconds to clone the code repository, an unknown
    amount of time to edit code, 5 minutes to run a test, and another 30 seconds to
    deploy the code in our environment, our workflow, with a single test, will take
    about 6 minutes. If we have eight members of our team, who each run through this
    workflow 10 times a day on average, our workflow actually constitutes about 8
    hours a week of our combined work (*8 x 10 x 6* = *480* minutes, or 8 hours).
    Cutting this testing time in half reduces our total time as a team spent on the
    workflow by about 3 1/3 hours per week. Because of this measurable amount of time
    that can be saved in a workflow, a team should consider optimizing their workflow
    whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, you won't need more than a rough estimate of the time it takes to
    perform the standard functions of the workflow, but you will need to know which
    pieces might be performed more than once. With Puppet, a user will likely write,
    push, and test code more than they will pull it down. You can inspect each piece
    of the workflow separately and seek to improve a part of the process, but you
    should consider the ramifications of a change to the rest of the workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Rapid feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good workflow should provide constant feedback to its users. Each step should
    be clearly defined, with strict pass or fail criteria. For example, Git will warn
    a user whenever it detects a problem, such as being unable to pull code or push
    code back to the origin repository. We can extend this with Git commit hooks,
    both server-side and client-side, which perform checks to ensure that the code
    is in a proper state before being accepted into an organizational Git server from
    the local repository. Running Puppet itself within our test criteria, we expect
    clean and idempotent runs. The Puppet catalog should not produce failing resources,
    nor should it manage the same resource with every Puppet run.
  prefs: []
  type: TYPE_NORMAL
- en: The time it takes to solve problems with Puppet shrinks as more feedback is
    provided by a workflow to the engineer. If you work in a workflow that requires
    pushing code to an environment on the Puppet Master, and you are testing on a
    true agent, a simple run of `puppet parser validate` can save a lot of time. The
    parser validation will quickly tell you if Puppet code can be compiled, rather
    than what it will do. This simple command can reduce the number of times that
    we `git commit` on the code, push it to the Git repository, deploy it to an environment,
    log in to the test machine, and wait for the Puppet agent to trigger a catalog
    error. We can even ensure that this command is run before every commit with a
    precommit Git hook. Automated testing tools, such as RSpec and Beaker, can extend
    this methodology, and, combined with a CI/CD pipeline (discussed in the next chapter),
    can provide even more rapid feedback to code developers.
  prefs: []
  type: TYPE_NORMAL
- en: Ease of onboarding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A well-built workflow naturally facilitates the ease of adding new members to
    a project, whether open source or a part of an organization. A simple tool suite
    and guide can be invaluable to those new members, and can help them to get over
    the hurdle of the first commit. Even a simple getting started `README` can go
    a long way, if properly maintained. Onboarding new members to a project is costly,
    and quality workflow can minimize the time spent by the new member. Bringing on
    new project members also requires some information and time from existing project
    members. If your project is an ongoing development effort, it's highly likely
    that you'll have some turnover, and saving time for existing members while shortening
    the time for new members to reach effectiveness should be a priority in your workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Quality control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good workflow should always seek to reduce mistakes and increase code quality.
    Every built-in safety mechanism in a workflow allows a team to iterate over more
    complex features more quickly. Simple things, such as preventing pushes directly
    to production branches and basing production environments on semantically versioned
    code, allow for rapid development, without any worries about toppling critical
    infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following lists a few examples of workflow improvements designed around
    security and stability:'
  prefs: []
  type: TYPE_NORMAL
- en: Preventing direct code pushes to production on the control repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preventing direct code pushes to masters on individual modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Puppet parser validation on all manifests prior to a push back to the 
    repository of origin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running code reviews prior to merging into a master or `production-like` branches
    of the control repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing a Puppet workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Puppet has undergone a lot of changes in code management since its beginnings.
    Even the general workflow has changed drastically. This section will help you
    to understand some of the history of code management in Puppet, some of the challenges,
    and, most importantly, some of the solutions for designing and working with a
    strong Puppet workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Originally, we wrote Puppet manifests directly to the disk. We logged on to
    the Puppet Master via SSH and edited our manifests directly, treating most of
    our code like configuration files for remote machines. This model required custom
    backups and recovery for code applied to agents, and did not provide easy rollbacks. If
    something went wrong in a deployment, you were forced to take snippets of code
    from a backup manually and deploy it to a system. Some members of the community
    took to storing their Puppet code in Git. As the number of individual repositories
    grew in organizations, manually bringing in Git repositories individually became
    more troublesome, and some community open source projects formed that were focused
    on staging Git code.
  prefs: []
  type: TYPE_NORMAL
- en: Components of the Puppet workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although r10k is not the only Puppet Code Manager, it has become the standard
    Code Manager deployed to enterprise organizations. We''ll break the work down
    into tasks and repositories, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Repositories:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Control repository
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Module repositories
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tasks:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clone
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create new branch
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Edit relevant code
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Add and commit
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Push
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet login and deploy
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Classify
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Test (automatic or manual)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Repositories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Code management requires that all code be stored in Git. Splitting your code
    up into multiple repositories and placing the code on the master allows for references
    to different versions of code. Each of your modules should reside in a separate
    repository, allowing for versioning and governance on a per-module basis. The
    `Puppetfile` will call these repositories by using the Puppet Forge, or pointers
    at your own local Git instance.
  prefs: []
  type: TYPE_NORMAL
- en: Control repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our control repository, as described in the previous chapter, is nothing more
    than a Git code repository. The only unique quality that you need to keep in mind
    when working with it, is that branch names correspond to Puppet environments.
    If you create a Git branch named `feature` and deploy the code, the Puppet Master
    will deploy that code to `/etc/puppetlabs/code/environments/feature`. Generally,
    the Master branch is replaced with another protected branch named `production`
    in the control repository, so that agents can check in to a production branch
    by default.
  prefs: []
  type: TYPE_NORMAL
- en: Module repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Module repositories are standard Git repositories. Generally, we want to protect
    the master branch and keep it from receiving direct commits. Contributors to component
    modules should instead submit pull requests to the repository and allow for a
    code review before accepting the code into the master branch. The master branch
    should be a functional version of the module at all times, although it need not
    be a version ready to be deployed into production. Treating the master as stable
    code allows non-production environments to point reliably at the master branch
    of all repositories, to get the latest accepted code during development. When
    it comes to deploying to production, we'll actually use a Git tag to create a
    version, such as 1.2.0\. We can then deploy our latest code into non-production
    and formally accept code into production.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary driver of the workflow in a Code Manager or r10k-based system is
    a Git workflow. There are multiple models of Git workflows, such as GitHub flow
    and Git flow, but the primary focus of this book isn't on Git, so we'll start
    with a minimal set of commands and procedures. The most effective way to get started
    is to work on the temporary environments provided by our control repository. In
    this workflow, we assume that a Git solution is already implemented on-site, or
    is provided by a managed service provider, and the Puppet Master is using Code
    Manager to deploy environments.
  prefs: []
  type: TYPE_NORMAL
- en: The first step of the workflow is to identify the components that need to change.
    In this workflow example, we'll assume that we're performing a change on a component
    module and a profile embedded in the control repository. We'll include remediation
    steps during the manual test phase, to include new code deployments and new pushes
    to the Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: Clone and edit the component repositories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we''ll clone the component module, change to a new feature branch, and
    perform edits on the files in the repository. We''ll ensure that we use a Git
    branch during development, so that we can send our code to the upstream Git repository
    without impacting the original code. We''ll end this step with a new snapshot
    of code on a separate branch of an existing module, so that we can test this code
    in isolation. This set of steps is the general workflow for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Making a copy of the upstream repository for an individual module (`git clone`/`pull`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a branch of the module, separate from the Master (`git checkout`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Making any and all edits to the code (IDE of choice)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a snapshot of the current state of the code (`git add` and `commit`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sending the snapshot back to the upstream repository (`git push`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In action, the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Our edits are now in the upstream repository, in a `new_feature` branch. The
    master branch will continue to serve as a reference point for further development
    for others, and for testing in a staging environment. So that we can begin to
    test this code, we'll create a new Puppet environment, designed specifically for
    testing and iteration over this code set.
  prefs: []
  type: TYPE_NORMAL
- en: Cloning the control repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first step starts like the last one: cloning the Git repository. One thing
    to remember about Puppet environments is that a branch of this repository corresponds
    to a Puppet environment. Most users of Puppet don''t have a master environment,
    but rather, the production environment that Puppet places nodes into by default.
    If your organization has any environments prior to production, as many do, you''ll
    want to make sure that you begin on the existing branch before creating a new
    branch. The `git checkout -b` command creates a new branch, starting from the
    branch that you are currently on. The following are the steps for creating a new
    environment, modeled after an existing environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Make a copy of the control repository from the upstream repository (`git clone`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check out the environment that you want to write new code against (`git checkout`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check out a new branch, based on the current branch (`git checkout -b`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Like the steps we took for our component module repository, this set of commands
    ensures that we have a local copy of the repository with the latest commits to
    the integration branch, and that we started a new branch based on the existing
    code. We're in a state to edit files found directly in our control repository,
    such as the `Puppetfile`, `hieradata`, and embedded `roles` and `profiles` (if
    you keep them in the control repository, rather than as separate, individual repositories).
    Once we have the code, we will want to edit the relevant files, create a new commit,
    push the code back to the origin repository, and deploy the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Editing the control repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we''re inside of the local copy of the intended environment, it will be
    the right time to make changes to the code. We generally spawn these additional
    short-lived environments so that simple commands can be used to deploy new code.
    We have a few files to target, because we think of the control repository as a
    configuration file for the rest of the environment. The `Puppetfile` is used to
    manage dependencies, including any component modules (from the Forge or your own
    environment). `roles` and `profiles` are often kept in the control repository,
    as well, and code can be edited directly in these environments. The workflow for
    making changes in the control repository is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Edit the files (in the IDE of your choice).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a snapshot of the current state of the code (`git add` and `commit`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Send the environment back to the remote repository (`git push`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we've edited a module and files in the control repository and
    pushed them back to the origin. We'll now deploy the branch we made in the preceding
    code, and we will tweak our profile to use the module changes. Unless you have
    set up Git hooks or a CI/CD solution, you'll also have to trigger an environment
    deployment on the Puppet Master.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the new environment on the Puppet Master
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Puppet provides the PE Client Tools, as described in [Chapter 5](6c818865-77fb-4527-a3a5-922db1301217.xhtml),
    *Managing Code*, specifically for deploying code. If these tools are not available
    on your workstation, you can also log in to the Puppet Master, where they are
    already available for use. Assuming that you are using Code Manager, the following
    steps remain the same whether you are on a local workstation or a remote server:'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve the login token from Puppet Enterprise (`puppet-access login`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy an environment from the upstream repository branch (`puppet-code deploy`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now our code has been deployed as a fresh environment on the Puppet Master.
    We're still missing a step to classify our test system and ensure that it is placed
    in the proper environment. For a Puppet Enterprise user, you can both classify
    and declare an environment by using a node classifier group in the PE console.
    To create a new node group, select an environment, check the environment group
    box, name it, and click Create. Enter your new environment group, pin your test
    node to the group, and add any relevant classes to the classification page.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also classify via `manifests/site.pp` in the control repository, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The code for classification via Hiera is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: There are multiple ways to classify that are commonly used by Puppet users,
    but without automated testing, we'll have to do some classification and run the
    agent to check the results of our tests.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After your test node is properly attached to the environment group, you can
    log in to the node and trigger an agent run with puppet `agent -t`. Alternatively,
    you can run the Puppet agent through the PE console and read the log there. If
    you don''t see any changes, there are a few possible reasons, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The agent has already run, between when you classified the node in the console
    and ran the Puppet agent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A step was missed and the code was not properly deployed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your code does not trigger any new changes on the system, and you should modify
    the system to see if Puppet corrects the change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ensure that you check the resources targeted by your change to see whether
    the agent has already deployed the new changes. You might also want to verify
    that the code deployment was done properly, and that you pushed your code back
    to the Git repository. If your code does not trigger any changes on the system,
    or if it triggers undesired changes, you can perform the following shorter workflow
    until the code is resolved properly:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the code in the target repository: the control repository or the module
    repository (with the IDE of choice)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a snapshot of the code (`git add` and `commit`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the code back to the remote repository (`git push`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Redeploy the environment (`puppet-access login` and `puppet-code deploy`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Trigger an agent run on the test machine (`puppet agent` or PE console)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check for changes on the target system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Repeat until the desired state is achieved:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Once our code is in the desired state, we will be ready to begin placing it
    back into a long-lived environment on the Puppet Master. Modules should have their
    code merged back to the master, and changes to the control repository will need
    to be merged with a longer lived branch.
  prefs: []
  type: TYPE_NORMAL
- en: Merging branches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our earlier steps, we isolated our working code into a feature-branch and
    a short-lived, non-production environment. While teams and organizations should
    select some merging safeguards and strategies, such as peer code reviews and automated
    testing, this section will focus on the steps required to merge branches into
    master or long-lived branches in Puppet. Enterprise and open source web-based
    Git solutions usually contain some extra controls to indicate who can merge into
    a repository, and to which branches. The general best practice is to allow for
    a peer review of code, and the reviewer can accept the code into the long-lived
    branch or master branch. Merging our code via the command line is a simple process,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Switch to the branch that you want to merge to (`git checkout`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge another branch into this one (`git merge`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Push the merged branch into upstream repository (`git push`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Merging in the control repository can sometimes be troublesome, due to the `Puppetfile`
    being (intentionally) different between versions. Our `production-like` branches
    should use Git tags to declare the intended version of the code to be deployed
    and promoted up the series of environments. Our `non-production-like` environments
    are generally pointed to the master branch of each module, providing the latest
    accepted stable code to the environment for testing and development. Merging is
    performed in the same way as with a component module; just ensure that you don't
    overwrite the `Puppetfile` on a `production-like` branch with the less controlled
    `Puppetfile` in a `non-production-like` branch. Production branches should refer
    to Git tags for deploying code.
  prefs: []
  type: TYPE_NORMAL
- en: Git tags and versioning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Git tags are used to create a permanent state of code and separate it from
    the existing branches. Tags are not intended to be iterated upon, but rather,
    should be used as a marker in time for the state of the code. This makes tags
    a perfect fit for the release versioning of Puppet code. We can create tags from
    any branch, but the master is the most common branch to cut release tags from.
    We can simply use the `git tag` command on our module repository to create a snapshot
    with a semantic version number and push it to the origin repository, to be called
    on by r10k or Code Manager. The workflow for a Git tag is also short, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Check out the target branch (usually the master) for the tag (`git checkout`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Version the code (`git tag`)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Push the tag to the remote repository (`git push`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'After our module has been properly versioned, we can edit the `production-like`
    Puppetfile to utilize our tag, rather than point to a particular development or
    master branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This is a simple version of the Puppet workflow, but it still leaves room for
    improvement. Puppet recently released a tool called the PDK, to help facilitate
    quality Puppet tooling into your workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Using the PDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good workflow should provide ease of use, rapid feedback, ease of onboarding,
    and quality control. The PDK aims to increase productivity across this space.
    Many tools in the PDK have existed for quite some time, but they were often difficult
    to use and configure for workstation development.
  prefs: []
  type: TYPE_NORMAL
- en: PDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Puppet makes the PDK freely available on their website, and it has a release
    for each major operating system. It uses a fully isolated environment to provide
    Puppet binaries and RubyGems that make development much simpler. Tools included
    in the PDK, as of version 1.5.0, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create new Puppet artifacts:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modules
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Classes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Defined types
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Tasks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet Ruby providers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PDK validate—simple health checks:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet parser validate (Puppet syntax)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet lint (Puppet style)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet metadata syntax
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Puppet metadata style
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RuboCop (Ruby style)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: PDK test unit (Puppet RSpec—unit testing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating new Puppet artifacts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The PDK allows users to create new artifacts, using best practices. Each `pdk
    new` command builds an artifact already structured for Puppet. These artifacts
    are intended to conform to Puppet's best practices. If you're testing the PDK
    in an isolated environment for the first time, starting with a new module is the
    easiest method.
  prefs: []
  type: TYPE_NORMAL
- en: The pdk new command
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The command `pdk new module` brings the user to a prompt, requesting that the
    user specify the Puppet Forge username, the author''s full name, the module license,
    and the supported operating systems. If you do not have a Forge username or a
    module license, you can enter in any value. After the prompt, you''ll find a new
    directory that contains code. If you want to send this code to an upstream repository,
    follow these steps on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If you're working with a previously created module, you can use the `pdk convert`
    command to place any items missing from the template into the existing module.
    By default, the PDK deploys the templates found at [https://github.com/puppetlabs/pdk-templates](https://github.com/puppetlabs/pdk-templates).
    If you need to change any of the files found here, you can clone a copy of `pdk-templates`
    from the official repository and send it to a central Git repository. You'll need
    to use the `pdk convert --template-url <https> ` to select the new template and
    deploy it to the existing module. The `--template-url flag ` command will also
    set the new URL as the default URL on the workstation.
  prefs: []
  type: TYPE_NORMAL
- en: You should feel free to make your own copy of this template, as the one provided
    by Puppet is fairly extensive and rather opinionated. It even includes some ways
    to get started with CI/CD systems, such as `gitlab-ci`. Trim the files for systems
    that you don't use, and make sure that everything provided by the template makes
    sense for your organization.
  prefs: []
  type: TYPE_NORMAL
- en: 'The template repository provides three directories and configuration files
    to the PDK, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`moduleroot`: The Ruby templates in this directory will be placed on top of
    existing files. This is useful when you want to enforce a particular file, like
    a CI/CD pipeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`moduleroot_init`: The Ruby templates in this directory will not override existing
    files. This is great for starter files, like module templates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`object_templates`: The Ruby templates that determine the output of the file
    on commands like `pdk new class`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config_defaults.yaml`: This provides defaults and variables to be used for
    all Ruby templates in the PDK template.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once you have your new module template, you can begin to create manifests inside
    of the module for Puppet code with the PDK. From inside of the new module, we
    can use `pdk new class` to begin making manifests. The command creates manifests
    according to an autoload layout, so running `pdk new class server::main` would
    create a file at `manifests/server/main.pp`. The class created with the default
    template will start as an empty, non-parameterized class, with Puppet string-style
    documentation at the top of the file. The `pdk new defined_type ` command will
    make a similar file, but will use the defined declaration instead of the class
    declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The `pdk new task` command will create files in the `tasks` directory, based
    on the template for use with Puppet tasks. Puppet tasks are a way to automate
    ad hoc scripts and commands across your infrastructure, using Puppet. `pdk new
    provider` is an experimental feature for designing new custom Ruby providers to
    Puppet.
  prefs: []
  type: TYPE_NORMAL
- en: Once the new objects are created and developed against, the PDK will also provide
    a tool suite for syntax and style, with `pdk validate`.
  prefs: []
  type: TYPE_NORMAL
- en: The pdk validate command
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The PDK provides `pdk validate` to check both syntax and style. Syntax checks
    make sure that your code can compile, and that you''re not missing things such
    as commas or closing braces in manifests or JSON metadata. Syntax checks can also
    be performed manually on manifests with `puppet parser validate`. Style checking
    looks at the code to make sure that it adheres to a standard style guide. Puppet-lint
    is used to provide style checks to Puppet, and all of the rules can be found at [http://puppet-lint.com/](http://puppet-lint.com/).
    When a module is healthy, the PDK will return check marks against all tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'An invalid `metadata.json` will prevent the uploading of modules to the Forge
    and the running of RSpec tests. This file details the author of the module, and
    other information, such as dependencies and supported operating systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`pdk validate` also runs Puppet parser validation across every manifest in
    the module. In the following example, a curly brace was forgotten at the end of
    `init.pp`, and the PDK is informing us that the code will not compile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If the Puppet parser validation passes, `puppet-lint` will run on all manifests.
    It will print out errors and warnings in the code, based on the Puppet Style Guide.
    In the following example, we run pdk validate against a manifest has a line that
    continues beyond 140 characters on line 10 and trailing whitespace after line
    9:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'In some cases, rather than print out a warning or error, we want to disable
    it. A list of checks can be found at [http://puppet-lint.com/checks/](http://puppet-lint.com/checks/),
    and can be used to disable individual checks. In the following example, notice
    the comment after the message statement, telling lint to ignore the 140-character
    limit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have multiple places in a single manifest that we''d like to ignore,
    we can use the lint block `ignore` by placing the comment on a line alone and
    ending it with `# lint:endignore`. In the following example, we have two large
    strings that won''t be alerted on `puppet-lint`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have a check that you''d like to disable, you can also create a `puppet-lint.rc`
    file. This file can be placed in `/etc` for a global config, as `.puppet-lint.rc`
    in the home directory for a user config, or at the base of a module, as `.puppet-lint.rc`.
    If your team uses local development workstations, consider adding a `.puppet-lint.rc`
    to your PDK template, to enforce a standard on each repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, any Ruby code will be validated by RuboCop. RuboCop will check the
    style of all Ruby files in a module. This provides style checking to custom facts,
    types, providers, and even tasks written in Ruby:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '`pdk validate` provides a quick check of the style and syntax of your code.
    It does not check the functionality of your code. The PDK also provides a boiler
    template for RSpec tests out of the box, so that when a new class is created with `pdk
    new class`, a simple corresponding RSpec test is created along with it.'
  prefs: []
  type: TYPE_NORMAL
- en: The pdk test unit command
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'New manifests built with `pdk new class` are also provided with a default RSpec
    test. Unit tests are written to ensure that a manifest performs what is expected
    as it is running. The default unit test provided by Puppet ensures that the code
    compiles successfully on every operating system listed in the `metadata.json`,
    with default facts for those operating systems. This can be expanded to create
    more robust unit tests. In the following example, a check has been added that
    states that the `init.pp` of the module should provide a file called `/etc/example`
    that is not provided by the manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The simple test provided by the default PDK only provides `it { is_expected.to
    compile }` as an RSpec test for each module. In the next chapter, we'll expand
    upon our initial RSpec module, as we cover unit tests and provide some basic code
    coverage testing to our Puppet modules.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started this chapter by detailing what makes for a good workflow. Much of
    the workflow becomes easier when combined with continuous integration and continuous
    delivery strategies, which will be covered in the next chapter. We'll expand upon
    the RSpec tests built by the Puppet PDK, and we'll discuss acceptance test strategies.
    We'll also cover some new workflows and tools to provide more immediate feedback
    during the development of Puppet code and manifests.
  prefs: []
  type: TYPE_NORMAL
