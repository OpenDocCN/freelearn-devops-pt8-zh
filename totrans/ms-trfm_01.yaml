- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding Terraform Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At its core, **Terraform** is a simple command-line program that evaluates source
    code, which describes what a desired state should look like, compares it against
    what the actual state is, constructs a plan to transform the actual state into
    the desired state, and can execute the plan. But don’t let its perceived simplicity
    fool you. Terraform’s internal complexity manifests itself in its external simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform is a large, source-available project written in Go that maintains
    the command-line executable. It provides baseline functionality such as **HashiCorp
    Configuration Language** (**HCL**) parsing, state management, plan creation, and
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform is extremely powerful, yet ironically, it does very little by itself.
    But here’s the exciting part: Terraform’s superpower comes from its extensibility,
    a power that is not limited to its creators. The actual Terraform executable,
    by itself, can’t do much, but when bundled with one of its plugins—called **providers**—Terraform
    can do quite a lot! This extensibility is a testament to the collaborative nature
    of the Terraform community, where everyone can contribute to its growth and capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Terraform architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Terraform state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding how to build and consume modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding how to use the **command-line interface** (**CLI**) effectively
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Terraform has four superpowers that distinguish it from other tools: *planning*,
    *extensibility*, *configuration language*, and *modularity*. Some tools may share
    some of these, but they don’t have them all. With these powers combined, Terraform
    is a game changer in cloud automation.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Terraform architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The biggest differentiator of Terraform is that, well, Terraform plans ahead.
    Let’s look at how Terraform handles planning in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The plan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When working with Terraform, you will be following a process where Terraform
    is used to analyze the existing environment. In doing this analysis, Terraform
    is determining what (if any) changes in the code need to be applied to the actual
    environment to bring it up to date. Terraform itemizes these changes as actions
    within the plan. While Terraform does this analysis on our behalf, produces the
    plan, and is fully capable of executing that plan against the environment, we
    are still responsible for reviewing the plan and determining if the planned changes
    are what we intended:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Terraform resources are straightforward machines with inputs
    and outputs](img/B21183_01_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Terraform resources are straightforward machines with inputs and
    outputs
  prefs: []
  type: TYPE_NORMAL
- en: Terraform represents every component in your environment as a resource in this
    analysis. Resources are extremely simple machines. They take inputs and produce
    outputs. They also can be chained together, thus creating explicit relationships
    between the components within your environment. These relationships inform Terraform’s
    analysis of your environment and the sequence of actions enumerated in the plan.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have decided that this plan is what we intended, we ask Terraform to
    execute it. Terraform will then apply that plan to our actual environment. The
    outcome of this process is that Terraform will bring our environment up to date
    with the description in the code.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform’s design encourages developers to repeat this process. Therefore,
    as the developer updates their code, with each iteration of the code applied to
    the environment, we will continually assess the current state and determine the
    future state to match the environment our code describes. Each time we run Terraform
    to assess the environment, it will produce a plan. This plan was generated at
    a point in time when evaluating the differences between the actual environment
    and the code base.
  prefs: []
  type: TYPE_NORMAL
- en: On *Day 1*, since the environment does not exist, everything Terraform must
    create the developer described within the code. On *Day 2*, however, things are
    more complex. On *Day 1*, we started cleaning. However, on *Day 2*, we are still
    determining where we are starting because Terraform has already provisioned the
    environment once before. Many things could have changed since *Day 1*. We could
    have intentionally modified the code base to change the environment. Likewise,
    *gremlins* could have altered our environment during the night, thus introducing
    drift into our environment and requiring us to roll back their changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To analyze the existing environment, Terraform consults two sources of information:
    **Terraform state** and the environment itself—via the provider (which is also
    informed by Terraform state). If the Terraform state is empty, then Terraform
    assumes the environment does not exist and creates a plan that will create everything:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2 – Resource plan, Day 1: everything needs to be created](img/B21183_01_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2 – Resource plan, Day 1: everything needs to be created'
  prefs: []
  type: TYPE_NORMAL
- en: 'If Terraform state exists, things will get interesting, and Terraform will
    have to earn its paycheck. Terraform will use the Terraform state to analyze the
    environment by querying the provider (s) about the health and configuration of
    each resource declared within. Based on these results, Terraform will construct
    a set of instructions. Once Terraform executes these instructions, the current
    environment will match the desired environment—as described in the code. However,
    after the first time Terraform has executed your plan successfully, if you ask
    Terraform to create a plan again, it will consult the Terraform state and use
    the providers to consult the actual environment and see that no changes are needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Resource plan, Day 2: no changes in your environment](img/B21183_01_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3 – Resource plan, Day 2: no changes in your environment'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create such an instruction set, Terraform must generate a complete dependency
    graph of the resources within the environment to determine what order it must
    execute the instructions. The relationships between the resources infer these
    dependencies. If one resource takes in, as an input variable, the value of another
    resource’s output variable, Terraform will determine that there is a dependency
    between these resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Dependencies: one resource’s inputs is another resource’s outputs](img/B21183_01_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4 – Dependencies: one resource’s inputs is another resource’s outputs'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, Terraform will only know the results of instructions after executing
    them. Hence, the obligatory warning message `known after apply`. However, this
    dependency graph and the subsequent plan are the crux of the Terraform machine.
  prefs: []
  type: TYPE_NORMAL
- en: This process makes Terraform an idempotent tool, meaning it can be applied multiple
    times without changing the result beyond the initial application. Idempotence
    is not necessarily unique to Terraform across automation tools, as some tools
    operate similarly. **Ansible** is a great example, also ensuring that repeat operations
    do not alter the state unless changes are necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Execution phases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Terraform’s core workflow follows a three-stage process: *initialize*, *plan*,
    and *apply*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Terraform execution phases](img/B21183_01_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 – Terraform execution phases
  prefs: []
  type: TYPE_NORMAL
- en: Let’s examine each stage to see what parts of our code base are being utilized
    and what actions Terraform is taking.
  prefs: []
  type: TYPE_NORMAL
- en: Initialize
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, initialize the Terraform workspace using the `terraform init` command,
    which loads and configures all referenced providers and modules:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 1.6 – Terraform initialization loads provider and module dependencies\
    \ and verifies backend connect\uFEFFivity](img/B21183_01_6.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 1.6 – Terraform initialization loads provider and module dependencies
    and verifies backend connectivity
  prefs: []
  type: TYPE_NORMAL
- en: Plan
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Once a Terraform has initialized its workspace, it can generate a plan using
    the `terraform plan` command. Although the command seems simple, this is a very
    complex process.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, a dependency graph is built of all resources using the implicit (and
    sometimes explicit relationships between them). Then, Terraform checks the state
    file to determine if it has already provisioned the resource. Suppose the resource
    exists in the state file. In that case, Terraform will communicate with the resource
    via its respective provider and compare the desired state with the expected state
    as stored in the state file and the actual state reported by the provider. Terraform
    makes note of any differences and creates an action plan for each resource. The
    action can be *create*, *update*, or *destroy*:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 1.7 – terraform plan evaluates the current code base with a set of\
    \ input variables and compares it against the workspace’s Terraform \uFEFFstate](img/B21183_01_7.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 1.7 – terraform plan evaluates the current code base with a set of input
    variables and compares it against the workspace’s Terraform state
  prefs: []
  type: TYPE_NORMAL
- en: Apply
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Once a Terraform has generated a plan, it can optionally execute it against
    the actual environment using the `terraform apply` command. Using the dependency
    graph, Terraform will execute each resource action in sequence. If resource actions
    are not dependent on each other, then Terraform will execute them in parallel.
    During this phase, Terraform will constantly communicate with each provider, initiating
    commands and checking the status of the relevant provider. As Terraform completes
    resource actions, it will continually update the Terraform state:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 1.8 – terraform apply executes the plan through communication with\
    \ the providers, updates the Terraform state, and returns output var\uFEFFiables](img/B21183_01_8.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 1.8 – terraform apply executes the plan through communication with the
    providers, updates the Terraform state, and returns output variables
  prefs: []
  type: TYPE_NORMAL
- en: Resource actions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When Terraform generates a plan, it evaluates each resource to determine if
    change is required to achieve the desired state of the infrastructure. There are
    several different situations where Terraform will determine action is needed on
    a particular resource.
  prefs: []
  type: TYPE_NORMAL
- en: Create
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A create action can occur in three situations:'
  prefs: []
  type: TYPE_NORMAL
- en: The resource is completely new
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Something outside of Terraform deleted the resource
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The developer updated a resource’s code in such a way that the provider requires
    it to be destroyed and re-created
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s what adding a new resource looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.9 – Adding a new resource](img/B21183_01_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.9 – Adding a new resource
  prefs: []
  type: TYPE_NORMAL
- en: When a resource is entirely new, it doesn’t exist in the Terraform state file.
    For example, we want to create a `vm001`. If this is the case, Terraform doesn’t
    use the provider to check if the resource is there. As a result, you can run into
    situations where the plan will generate successfully, but when Terraform executes
    the plan, it will fail. This situation usually boils down to resource naming conflicts
    when another user has provisioned another unrelated resource with the same name
    as the one Terraform plans to create (that is, somebody has already provisioned
    a VM named `vm001`). This situation can occur if someone creates a resource manually
    or even when a resource is created through Terraform but in a different Terraform
    workspace and, consequently, a different Terraform state file.
  prefs: []
  type: TYPE_NORMAL
- en: 'A prime example of the concept of **drift** is when someone manually deletes
    a resource outside of Terraform:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.10 – Drift](img/B21183_01_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.10 – Drift
  prefs: []
  type: TYPE_NORMAL
- en: When a developer changes a resource, sometimes the provider requires it to be
    destroyed and then re-created. For example, we want to change our VM’s hardware
    profile from 4 CPU cores and 16 GB RAM to 8 CPU cores and 32 GB RAM. This logic
    exists in the provider’s code base at the resource level. It would help if you
    carefully check the documentation of the resources you are using to ensure you
    are aware of any potential disruptions or data loss that could occur when updates
    force a resource to be destroyed and re-created.
  prefs: []
  type: TYPE_NORMAL
- en: Change
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A change action can occur in two situations:'
  prefs: []
  type: TYPE_NORMAL
- en: The resource has changed in code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The resource has been modified outside of Terraform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s what changing an existing resource looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.11 – Updating an existing resource](img/B21183_01_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.11 – Updating an existing resource
  prefs: []
  type: TYPE_NORMAL
- en: This change won’t require the resource to be destroyed and re-created. This
    could be something simple such as changing the tags of a resource. These types
    of changes can also be introduced by drift. For example, someone adds a new tag
    manually using the cloud platform’s management portal without updating the Terraform
    code base.
  prefs: []
  type: TYPE_NORMAL
- en: Destroy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A destroy action can occur in two situations:'
  prefs: []
  type: TYPE_NORMAL
- en: The developer deleted the resource from the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The developer updated a resource’s code in such a way that the provider requires
    it to be destroyed and re-created
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s what removing an existing resource looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.12 – Removing an existing resource](img/B21183_01_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.12 – Removing an existing resource
  prefs: []
  type: TYPE_NORMAL
- en: This could be as simple as removing an unused—or, more likely, no longer used—resource.
    For example, removing an unnecessary `22` to the entire internet—is probably a
    good idea!
  prefs: []
  type: TYPE_NORMAL
- en: Resource action plans can have a cascading effect. Naturally, dependent resources
    are also new if a resource is entirely new. However, it would be best to be mindful
    when the resource needs to be destroyed and re-created. This action is called
    a **drop-create** action. When a resource plays a critical role within the environment,
    it is very common that when a drop-create action occurs, there will be a large
    swath of the resource graph that will also be destroyed and then re-created—usually,
    any resource dependent on the resource being drop-created.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration language
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When Terraform was first only a glimmer in the minds of Armon Dadgar and Mitchell
    Hashimoto, the industry had two paradigms of **Infrastructure-as-Code** (**IaC**):
    imperative, which dominated under the names of Chef and Puppet, using traditional
    programming languages such as Ruby and Python. However, there were declarative
    approaches, but most were an exercise of crafting large and complex JSON documents.'
  prefs: []
  type: TYPE_NORMAL
- en: The two major cloud platforms, **Amazon Web Services** (**AWS**) and **Microsoft
    Azure**, had already adopted resource typing in their respective IaC solutions.
    AWS CloudFormation and **Azure Resource Manager** (**ARM**) templates leveraged
    a consistent schema to describe resources of various types. Each resource type
    had a standard set of attributes that helped the platform target the appropriate
    resource provider to handle the request. Likewise, each resource type had its
    own custom attributes and schema to configure its unique nature. But the solutions
    were silos within the respective cloud platforms.
  prefs: []
  type: TYPE_NORMAL
- en: So, in many ways, the industry was primed and ready for a solution that would
    adopt a resource type-based approach and thus knock down the silos between cloud
    providers enabling, at the very least, a tool that could describe resources on
    multiple clouds within the same context. There were challenges with both imperative
    and declarative approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Imperative approaches resulted in overly complex code, nested structures, and
    elaborate state-checking logic made for difficult-to-maintain code bases that
    could quickly descend into spaghetti code. Also, programming language and platform
    heritage could stoke religious rivalries between developer camps.
  prefs: []
  type: TYPE_NORMAL
- en: The declarative solutions, on the other hand, relied on industry-standard document
    formats such as **JSON** and **YAML**. These formats encouraged a simple top-down
    approach and induced no tribalism due to their neutral nature. However, they made
    it difficult to represent complex expressions and implement simple iterations
    and loops, and even simple things such as annotating code with code comments were
    not possible or overly cumbersome.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform brought the best of both worlds by bringing elements of an imperative
    language, such as expressions and looping, and fusing it with the best of the
    declarative model that encouraged a simple top-down approach to defining resources
    within an environment.
  prefs: []
  type: TYPE_NORMAL
- en: '**HCL** uses simple block definitions that allow for a more concise representation
    of resources than other declarative solutions but a more code-like syntax, all
    linking between blocks that acknowledges the resource type-driven nature of cloud
    computing in its bones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'A block’s definition has three parts: the `resource`, the resource type is
    `random_string`, and the reference name is `foo`. To create dependencies between
    resources, we use the reference name and type to access output values from the
    resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we create an Azure resource group by referencing the
    `result` output value from the random string named `foo`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This simple pattern describes how we can combine dozens, sometimes hundreds,
    of resources to build sophisticated cloud architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.13 – Chaining of Terraform resources, where the outputs of one resource
    act as inputs to another](img/B21183_01_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.13 – Chaining of Terraform resources, where the outputs of one resource
    act as inputs to another
  prefs: []
  type: TYPE_NORMAL
- en: Using this preceding pattern in HCL allows Terraform to determine the relationships
    between our resources and construct a plan to provision them all. The funny part
    and the sheer brilliance of the whole thing is that it’s just a fancy game of
    connecting the dots.
  prefs: []
  type: TYPE_NORMAL
- en: Modularity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Everything lives in modules. When you make your first Terraform project, you
    inadvertently create your first Terraform module. That’s because every Terraform
    project is a root module. In your root module, you declare providers,
  prefs: []
  type: TYPE_NORMAL
- en: One ubiquitous pattern within Terraform is that when you code resources, modules,
    or data sources, you work with inputs and outputs. Each Terraform resource and
    data source works in this manner, as does your entire Terraform workspace, allowing
    Terraform to be embedded neatly into a toolchain within a pipeline to provision
    an environment.
  prefs: []
  type: TYPE_NORMAL
- en: The root module doesn’t have to be the only module that you write. You can create
    reusable modules that are designed to encapsulate reusable aspects of your solutions
    that can be shared across root modules. The difference between a root module and
    a reusable module is that the root module is designed to be the entry point for
    deploying one or more environments. Reusable modules are simply components that
    define useful patterns or best practices and allow you to save time having to
    re-create them whenever you want to create a new environment or a similar solution.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have taken a high-level look at Terraform’s architecture and understand
    the core technology, we know that it comprises the Terraform command-line application
    and the HCL functional language. We also know that Terraform’s superpower is that
    the design of the core technology is highly extensible by leveraging providers
    to adapt the technology to a multitude of extremely diverse platforms and technologies
    and the built-in modularity that enables practitioners to easily create simple
    or sophisticated IaC solutions that can be packaged and made to be reusable across
    teams and organizations.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll delve into a critical subsystem that enables Terraform to achieve
    consistent, idempotent IaC motion across various platforms and technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Terraform state
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Terraform uses the state to remember what was previously provisioned in a given
    workspace. Some critics of Terraform, when they compare it to AWS CloudFormation
    or ARM templates, point out that these technologies don’t rely on this concept
    of maintaining state in an externalized file. Of course, this is only true because
    these tools only support a single target platform and can tightly couple to the
    proprietary nature in which those platforms maintain state. However, Terraform—with
    its flexible plugin architecture—can’t assume anything about the platform and
    the resources that it provisions to each target platform. Therefore, Terraform
    needs to drop to the lowest common denominator and ensure that it knows what it
    has provisioned before in a uniform and consistent fashion.
  prefs: []
  type: TYPE_NORMAL
- en: This approach to maintaining the state provides a couple of benefits. First,
    it uniformly records what Terraform has provisioned across platforms that maintain
    their internal state and those that don’t. Second, it allows Terraform to define
    a boundary between managed and unmanaged resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'This problem is the classic **Jurassic Park problem**. In *Jurassic Park*,
    they had genetically engineered all these dinosaurs. They engineered them with
    population control in mind—so that they couldn’t mate—or so they thought. In the
    park, they had all these sophisticated systems to track where all the dinosaurs
    were and how many of them there were. However, the big flaw of their design was
    that they programmed their systems to only look for dinosaurs that they genetically
    engineered. So, their system worked flawlessly and showed them where all the dinosaurs
    they created were. Wouldn’t you know it? The number of dinosaurs always matched
    the number they expected to see. That’s bad for Jurassic Park because, due to
    this flaw, they were unaware of a defect in their genetic engineering that allowed
    the dinosaurs to mate. Jurassic Park had too many dinosaurs, and things got—well—a
    little out of hand:'
  prefs: []
  type: TYPE_NORMAL
- en: f
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.14 – The Jurassic Park problem](img/B21183_01_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.14 – The Jurassic Park problem
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform only looks for resources that it has provisioned. It can do that
    because it maintains a state file. The state file is just like the list of dinosaurs
    that Jurassic Park thinks it has. This approach was terrible for Jurassic Park.
    But for Terraform, it’s a good thing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.15 – Terraform ignores resources provisioned externally, even if
    those resources draw dependencies on resources provisioned by Terraform](img/B21183_01_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.15 – Terraform ignores resources provisioned externally, even if those
    resources draw dependencies on resources provisioned by Terraform
  prefs: []
  type: TYPE_NORMAL
- en: Why? Because not all resources are going to be—or need to be—created and managed
    by Terraform. By clearly scoping what Terraform is responsible for (and what it’s
    not), it allows Terraform to be flexible in allowing organizations to choose their
    level of involvement with Terraform. Some teams and organizations will start small
    and only deploy a few things with Terraform. At the same time, others might go
    nuts and provision everything with Terraform. Still, there will very likely be
    things that are happening that Terraform doesn’t know about. The Terraform state
    is constructing guard rails to keep Terraform in its box and let it know what
    it’s allowed to touch. Doing so enables Terraform to play well with others and
    gives freedom to teams and individuals to use whatever method or tools they want
    to control aspects of an environment.
  prefs: []
  type: TYPE_NORMAL
- en: State file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Terraform state is a JSON data file stored somewhere Terraform knows how to
    find it. This file maintains a list of resources. Each resource has a resource
    type identifier and all configurations for that resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'The state file mirrors what we describe in our code but is much more verbose
    than what we declare in our code. The following code generates a random string
    with a length of four characters, no uppercase characters, and no special-case
    characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'After running `terraform apply`, Terraform will produce a state file containing
    the same resource but with more context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `provider` and `type` instances help identify which resource type this resource
    is and which Terraform providers the developer uses.
  prefs: []
  type: TYPE_NORMAL
- en: The `schema_version` parameter of the resource attribute helps identify whether
    the current resource is compatible with the current version of the provider. If
    it is not, it can help give the provider an indicator of how to upgrade it to
    the latest version of the schema.
  prefs: []
  type: TYPE_NORMAL
- en: Partial resource management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to Terraform’s nature as a piece of **open source software** (**OSS**) and
    the built-in assumption that these cloud providers are their own piece of software
    that is evolving over time, at a different pace than the Terraform providers,
    there will be periods of time where the cloud providers will have features that
    Terraform is unaware of.
  prefs: []
  type: TYPE_NORMAL
- en: When this happens, we don’t want Terraform to fight with the cloud provider
    to turn them off just because Terraform isn’t aware of them. This scenario is
    extremely common as it presents itself naturally when an environment is being
    managed by Terraform and a specific version of the Terraform provider. As the
    Terraform provider has new features added to keep pace with the target cloud platform,
    the provider version is not always kept up to date in the Terraform code—nor should
    it have to be.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we provide an environment using Terraform and v1.0, our favorite cloud
    platform’s Terraform provider. The next day, our favorite cloud provider added
    this amazing feature, Feature X. We still have the same code and the same Terraform
    state file, but we are extremely eager to try out Feature X. However, we are using
    the latest version of the Terraform provider—v1.0—and it has no support for Feature
    X.
  prefs: []
  type: TYPE_NORMAL
- en: What can we do? Well, we can wait for our friendly internet strangers who contribute
    to the Terraform provider’s open source project to add support for Feature X.
    However, we don’t know when that will be.
  prefs: []
  type: TYPE_NORMAL
- en: Did we mention we were extremely eager to try out Feature X? If we just can’t
    wait, we could just enable Feature X directly on our favorite cloud platform.
    *Wouldn’t this create drift*, you say? In normal circumstances—yes—as we’re modifying
    our Terraform-managed resource using our favorite cloud platform web interface.
    Normally, the next time we run `terraform apply`, Terraform will detect that changes
    have been made to that resource outside the environment and revert our changes.
    However, since we are on v1.0 of the Terraform provider, Terraform is happily
    ignorant of Feature X. Thus, any changes we make to the configuration of Feature
    X will go unnoticed by Terraform. This also means that if you delete that `terraform
    destroy` resource and re-create it, you’d have to go out to the portal and manually
    reconfigure Feature X all over again.
  prefs: []
  type: TYPE_NORMAL
- en: That is, until we upgraded to v1.1 of the Terraform provider, which was released
    the day after we manually set up Feature X on our resource. Now that we are using
    v1.1 of the Terraform provider, the resource Terraform is using to provision that
    service to our favorite cloud platform is now aware of Feature X. If our code
    is still the same, it’s going to think that Feature X shouldn’t be enabled at
    all and should remove it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid this, we’ll need to carefully run `terraform plan` with v1.1 of the
    Terraform provider to see what changes Terraform is planning using this upgraded
    version of the provider. Then, we’ll need to update our code to configure Feature
    X just as it is configured. Once we do that, Terraform will see that no changes
    are required, and Terraform will bring Feature X under management:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.16 – Managing the perpetual change that occurs as a new cloud platform’s
    capabilities are created, exposed through the Terraform provider and adopted in
    your Terraform codebase](img/B21183_01_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.16 – Managing the perpetual change that occurs as a new cloud platform’s
    capabilities are created, exposed through the Terraform provider and adopted in
    your Terraform codebase
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have looked at how Terraform maintains the state and how this aspect
    of its architecture affects how Terraform creates and executes plans, let’s move
    on to the more practical topic of developing and consuming modules.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how to build and consume modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of Terraform’s most powerful capabilities is its ease of organizing and
    packaging reusable code, which increases the maintainability of your code base
    and improves the reusability of common patterns in your architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional developers have it easy—you must simply create a new method to encapsulate
    a reusable code block. In other IaC tools, doing the same thing is a challenge.
    In Terraform, all you need is a new folder.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform scopes every module within a folder. When you run `terraform init`,
    Terraform transforms the current working directory into the root module of the
    workspace. You can use modules stored in other folders within the same repository
    just by using a relative path to reference the module. It is a standard convention
    within the Terraform community for storing local modules in a `modules` directory
    near the root module’s directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this folder structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The path to the root module is `/terraform/root`. The path to the `rando` module
    is `/terraform/modules/rando`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the contents of the root module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The preceding list of files is a typical convention for the file structure of
    a module. In the `versions.tf` file, you should declare the `terraform` block,
    which contains both the Terraform version and each of the referenced Terraform
    providers and their corresponding versions.
  prefs: []
  type: TYPE_NORMAL
- en: In the `variables.tf` file, you should declare all the input variables this
    module expects. It’s essential to keep all input variables declared in one place
    to make it easier for the module consumer to understand the contract for this
    module.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, in the `outputs.tf` file, you should be used to declare all the output
    values that this module will produce.
  prefs: []
  type: TYPE_NORMAL
- en: Since it is possible to declare input variables and outputs in any `.tf` file
    within the folder, nothing prevents you from following this approach. However,
    you don’t want to make other developers scan every file in your module’s folder
    for a `variable` block to get a good understanding of the module’s interface.
  prefs: []
  type: TYPE_NORMAL
- en: In the `main.tf` file, you should declare the *meat* of your module. This file
    is where the magic happens. However, you are not limited to just one file. At
    your discretion, you can create additional `.tf` files to better organize more
    complex modules into relevant sections or groupings of related resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to understand the relative path to get to the `rando` module to reference
    the `rando` module from the root module. This relative path is calculated based
    on the root module’s working directory. Therefore, a declaration of the `rando`
    module would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `source` meta-argument is a required attribute for every `module` block.
    You’ll notice that declaring a module differs slightly from declaring a resource
    or a data source. For example, when declaring a module, the resource type is omitted.
    That’s because a `module` block is both a block type and a resource type. Therefore,
    besides the module block definition, we only need a reference name.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can reference our module’s output values simply by recognizing that `module`
    is the resource type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the preceding code, we are referencing the `result` attribute
    on a module called `foo` because modules are not as descriptive of a type; therefore,
    it’s even more important to give more detail in the reference name.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the basics for creating and referencing our custom modules,
    let’s look deeper into the module design question.
  prefs: []
  type: TYPE_NORMAL
- en: Module design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many ways, the decision to create a module in Terraform is the same as deciding
    to write a new method when writing in a traditional programming language such
    as Java or C#.
  prefs: []
  type: TYPE_NORMAL
- en: Just like in a traditional programming language, you could write all your code
    from start to finish in a single file using a single method, and if there were
    repeated parts, you would copy and paste them to repeat them.
  prefs: []
  type: TYPE_NORMAL
- en: Just like in a traditional programming language, there are reasons to write
    methods encapsulating repeating blocks of code. Otherwise, if you didn’t encapsulate
    that code into a method, you’d have to copy and paste it repeatedly.
  prefs: []
  type: TYPE_NORMAL
- en: The decision about when to create a module versus just putting it in the root
    module is an important one. You should have good reasons for creating a module.
    You should always focus on value. When someone uses your module—which could be
    just yourself or your team—does it make their life easier by using it?
  prefs: []
  type: TYPE_NORMAL
- en: Root modules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many different ways to set up your root module in Terraform. The debate
    continues, with some vehemently advocating one method over the other. It’s important
    to be aware of the different approaches so that you can recognize them when you
    see them and evaluate which approach works best for you.
  prefs: []
  type: TYPE_NORMAL
- en: Folder per environment
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One common technique for structuring a root module is setting up a different
    folder for each environment you want to provision and maintain. In this approach,
    there is a folder for each long-lived environment. This folder contains a root
    module that can stand alone from the other environments. Consider the following
    folder structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding folder structure has three environments: `dev`, `test`, and `prod`.
    Each environment has its own root module that is completely isolated from other
    modules. It has its own `required_providers` block and defines its own provider
    declarations. This approach has strong isolation between each environment—so much
    so that practically every aspect of the deployment could be altered from environment
    to environment. The version of Terraform, the version of the providers, and the
    version of the other modules used within the solution, the input parameters, and
    their values are all customized within the files within the corresponding folder
    for the environment.'
  prefs: []
  type: TYPE_NORMAL
- en: This approach is more common where the practitioners aren’t comfortable using
    GitFlow and maintaining other branches and following a `develop`) to more mature
    branches (for example, `main`—where production code exists).
  prefs: []
  type: TYPE_NORMAL
- en: Variable file per environment
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another technique is to maintain a single Terraform code base and multiple input
    variable files for each environment. This approach is focused on maintaining consistency
    and compatibility between environments. It is more difficult with this approach
    to make massive structural differences between the environments as it becomes
    difficult to merge changes from branch to branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following folder structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As with the previous approach, where we had explicit folders for each environment,
    this approach still allows the same variation between environments but requires
    you to maintain long-lived branches for each environment as you make changes to
    the core structure of the root module. This aligns more with a software development
    process called GitFlow (more on that in [*Chapter 6*](B21183_06.xhtml#_idTextAnchor330)).
  prefs: []
  type: TYPE_NORMAL
- en: The key characteristics of this approach are that environmental differences
    are captured in different input variable values stored in the corresponding`.tfvars`
    files. The goal is that any variation between the environments will eventually
    be stored within these files, and the code bases for each environment—stored within
    several long-lived source code branches—will eventually mirror each other. This
    allows us to have different sizes and counts in our production environment versus
    our development environment and maintain consistency between the architecture
    and configuration deployed across each environment.
  prefs: []
  type: TYPE_NORMAL
- en: Reusable modules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have our root module under control, it’s time to start thinking
    about when to create reusable modules that can be utilized in our root modules
    to produce sophisticated cloud architectures that will power our applications
    and solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Encapsulation of complexity
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The number of resources you plan to encapsulate within the module is an important
    metric, as it can indicate if you are reducing complexity by creating a module
    or adding more (spoiler alert: adding more is bad). Modules can range from one
    resource to dozens—even hundreds—of resources. When considering the number of
    resources you put into your module, you should consider the value you bring when
    someone uses the module.'
  prefs: []
  type: TYPE_NORMAL
- en: If your module only encapsulates one resource block, your code would likely
    be simpler by directly referencing the resource. In this situation, the module
    adds a layer of abstraction on top of the underlying resource you are provisioning.
    If that’s all it’s doing, then you need to reduce the complexity more to justify
    the creation of a module.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose your module encapsulates a few tightly related resources that are highly
    dependent on each other and have limited integration points with other resources.
    For example, when creating an NSG and a collection of rules. Creating a module
    encapsulating these tightly coupled resources might be a good idea because it
    will make it easier and more concise for the developer to create an NSG. In that
    case, this is the sweet spot for creating a module. You are likely trading one
    or two additional input variables for one or two additional corresponding resource
    blocks. That’s a good trade-off:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.17 – Module design: encapsulation of complexity](img/B21183_01_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.17 – Module design: encapsulation of complexity'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram shows that this module is provisioning three resource
    types. Our module defines a single interface that will provision this cluster
    of resources. Some simple inputs, `A` and `B`, are passed to the main resource
    and child resource 1\. A more complex input object, `C`, which happens to be an
    array, is passed in and used to construct a resource block for each item in the
    list.
  prefs: []
  type: TYPE_NORMAL
- en: Repeating patterns
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another common scenario is when you have many resources that you want to be
    repeated based on the size of a collection (either a list or a map). In this situation,
    you should tell each resource how many copies of it you want and pass in all the
    input variables to satisfy its requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.18 – Module design: repeating inside the module](img/B21183_01_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.18 – Module design: repeating inside the module'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if you encapsulate the repeating resources into a module, rather than
    repeating every resource, you repeat the module. This approach can significantly
    enhance the readability and maintainability of your code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.19 – Module design: repeating outside the module](img/B21183_01_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.19 – Module design: repeating outside the module'
  prefs: []
  type: TYPE_NORMAL
- en: 'The outside consumer of the module is responsible for introducing iteration
    on the module resource itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: By applying the iterator to the module itself, we achieve the same outcome as
    if we adorn every resource declared in the module with a count and pass in the
    number of resources as an input variable to the module. However, working with
    every resource inside the module becomes more difficult.
  prefs: []
  type: TYPE_NORMAL
- en: When you design your module to be repeated by a parent module, your module doesn’t
    have to think about the complexity of how many resources the parent module wants
    to create across all items in the collection. Each module instance only has to
    worry about one instance of each resource.
  prefs: []
  type: TYPE_NORMAL
- en: Does it flatten or simplify the resource in a way that can make the resource
    easier to use?
  prefs: []
  type: TYPE_NORMAL
- en: If you are starting from scratch, it’s best to let those patterns emerge over
    time. The code in the method is, by its very nature, a rather opinionated piece
    of code. Once you identify one, all it takes is a destroy, refractor, and re-apply,
    and you’re using your new module.
  prefs: []
  type: TYPE_NORMAL
- en: Destroying the entire environment and starting over isn’t always an option.
    This approach can only be used in a development or testing environment. In production
    environments, you will need to take a different approach.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, you can write a method you can use in many scenarios. This approach
    is most common when developing framework code that tackles a horizontal problem
    space. But sometimes methods are intended to do very particular things.
  prefs: []
  type: TYPE_NORMAL
- en: This same principle applies to Terraform module design. Some modules are highly
    flexible and designed in a framework, while others are more like *Hey, I want
    to do this specific thing, and I want to keep it simple.* With a scenario-driven
    module, the interface to the module will be very, very simple because it’s only
    about shepherding dependency inputs into the module’s scope that the module needs
    and doesn’t have on its own within its scope.
  prefs: []
  type: TYPE_NORMAL
- en: A framework module typically has a much more complex interface; as a result,
    it will have many more levers that the module consumer can pull. Sometimes, those
    inputs are no longer straightforward primitive types (`string`, `bool`, `number`);
    they are complex objects you construct and pass in. As the number of scenarios
    your module supports increases, so does the complexity of your module. You have
    to pass in a lot more parameters to configure it. It will become much more tedious
    and error-prone to pass those complex objects as you may have to implement more
    object construction logic using local variables.
  prefs: []
  type: TYPE_NORMAL
- en: Most Terraform providers have resources that do not require you to construct
    complex objects to use them. You will use primitive types, sometimes collection
    types, and nested blocks.
  prefs: []
  type: TYPE_NORMAL
- en: However, when building modules, you do have the ability to create complex objects
    as input variables. You should avoid overly complex data structures because of
    the complexity that it adds. Frequently, the dependencies between resources are
    relatively small. So, if you only need small pathways to connect two objects,
    why create massive **data transfer objects** (**DTOs**) to pass context from one
    object to another? It makes the code easier to understand and easier to maintain.
    Future authors and your module consumers will be cursing your name, just like
    in poorly written traditional software.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve seen software where there have been methods where instead of using the
    correct primitive types such as `bool` and `number`, everything is a string. Will
    that work? Sure. But does that make it easy to understand? Does that inject additional
    complexity, such as constantly type-casting the input values back and forth between
    strings into their proper type? You should use the correct type and simplify the
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: We have to strike a balance between using complex types and having too many
    input variables on a module because having too many input variables affects cyclomatic
    complexity, making it difficult to maintain. However, unlike other languages,
    working with HCL is challenging when using complex objects. Developers could be
    more efficient when constructing and transforming large, complex data types. HCL
    is excellent for developers when declaring and associating resources by piping
    output variables into input variables.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming modules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we understand the design considerations for when and how to design sound
    modules, let’s look at how we can consume and manage modules, from small scenario-driven
    modules to strongly versioned framework modules.
  prefs: []
  type: TYPE_NORMAL
- en: Local modules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Local modules can maximize code reuse within your Terraform solutions without
    incurring the overhead of setting up and maintaining a separate module repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using local modules for application-specific patterns, such as components or
    layers within your architecture, can be a great way to organize your Terraform
    code. One typical pattern when deploying to the cloud is active-active, multi-region
    deployments. In this situation, you should design the module to provision the
    application to a single region, and then this module should be deployed to a configurable
    set of regions using the `count` or `for_each` meta-argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.20 – Using Modules to encapsulate resources provisioned to a single
    region of a Cloud platform](img/B21183_01_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.20 – Using Modules to encapsulate resources provisioned to a single
    region of a Cloud platform
  prefs: []
  type: TYPE_NORMAL
- en: With this approach, you can create load-balancing resources in the root module
    to distribute traffic across the regional endpoints, coupled with multiple instances
    of the regional deployment module in the desired number of regions.
  prefs: []
  type: TYPE_NORMAL
- en: This consumption approach is ideal when only the module is used within the current
    project. This scenario can manifest in layered or multi-region architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Remote repositories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using external modules is the best way to capitalize on highly reusable patterns
    within your architecture. Terraform allows you to reference a module that is not
    stored in your project’s source code repository. The most common way of referencing
    a remote module is via a Git repository. This method works with any Git-compatible
    repository, from GitHub to Azure DevOps to GitLab.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing your modules publicly on the open internet makes it extremely easy
    to reference them from any source code repository, whether public or private.
    However, in some enterprise scenarios, public repositories are not allowed—corporate
    governance may only allow private repositories. In these situations, you must
    select an authentication mechanism to access those modules as an end user and
    from within your pipelines. You can authenticate with your private, remote Terraform
    module repositories using an SSH key or a public access token.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have secured your authentication to the Git repository that stores
    your modules, you must reference the module from your source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The preceding examples show how you reference a specific module hosted in a
    Git repository on Azure DevOps. Using this approach, you will access the default
    branch for the Git repository, which will most likely be `main`, and it will take
    the latest commit from that branch—never a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: 'The proper way is to specify a reference for a specific module version. When
    using the `ref` query string parameter for your Git repository URL, you can target
    a specific tag, branch, or commit within the Git repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Tags are the ideal method to guarantee a specific version because creating a
    tag within a Git repository doesn’t require changing your branching strategy.
    Once you are done testing the module, you can push a tag and rest assured that
    you will always receive that exact version of the module when you specify that
    tag as the `ref` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform registry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'HashiCorp provides a mechanism for third-party module publishers to distribute
    their modules. This repository is accessible via `registry.terraform.io` and houses
    a tremendous wealth of Terraform modules in a publicly accessible, stable, and
    versioned environment. When you publish modules here, you must meet specific requirements
    to allow you and others to reference the module using a simple name and version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The Terraform module registry ultimately uses GitHub under the hood, so you
    are referencing a module in a GitHub repository. However, it allows you to use
    a simplified module name and version without the additional complexity of the
    GitHub repository’s information.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how we can use modules to build more manageable IaC solutions
    and understand that modules can serve different purposes under different contexts,
    let’s move on to understand the CLI better so that we can build automation around
    Terraform to integrate it with our release pipeline and CI/CD process.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how to use the CLI effectively
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand Terraform’s core architecture, let’s examine its CLI
    and how to interact with it. There are many different commands, but we’ll focus
    on the important ones for implementing the core Terraform workflow. I’d encourage
    you to explore HashiCorp’s documentation for some of the more obscure ones, and
    later in [*Chapter 17*](B21183_17.xhtml#_idTextAnchor700), when we discuss managing
    existing environments using Terraform, we’ll be covering some more commands useful
    in that context.
  prefs: []
  type: TYPE_NORMAL
- en: init
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is an important command and probably the first one you will ever execute
    when working with Terraform. The reason is that Terraform works within a working
    directory instead of other tools that operate on a single file (such as ARM or
    CloudFormation) or an entry point file (such as Ansible). Terraform also relies
    on hidden directories to load important context about the workspace. This approach
    is very similar to how Git works when you clone a repository. Therefore, we must
    allow Terraform to set things up so that everything it needs is in the right place
    and makes itself at home. The `terraform init` command does just that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The Terraform initialize command accomplishes a few things:'
  prefs: []
  type: TYPE_NORMAL
- en: Provider installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Module installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend initialization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provider installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, it analyzes the directory and searches for provider declarations and
    downloads and installs those providers. It doesn’t connect to the providers, so
    a successful `init` process doesn’t indicate that your provider credentials are
    good. It suggests that the providers and specific versions of those providers
    you specified exist, and it installs them. As an extension of Terraform, each
    provider is just a Golang executable that Terraform interfaces with. Therefore,
    Terraform needs to download and stage that executable somewhere to know where
    to execute it when the time comes.
  prefs: []
  type: TYPE_NORMAL
- en: Each provider’s binary is downloaded and stored in the hidden directories created
    during the `init` process. These hidden directories and their contents enable
    other Terraform operations to function. Still, they are not files that need special
    protection, so you should not be too concerned if you delete them accidentally—or
    on purpose. To bring them back, one must rerun `init`, and Terraform will re-generate
    them as before.
  prefs: []
  type: TYPE_NORMAL
- en: Module installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Second, it analyzes the working directory and searches for module declarations
    within the code base. It then downloads and installs those modules from their
    respective source locations. It doesn’t matter if you reference modules using
    a relative path or a remote GitHub repository; a local copy of the module folder
    will be downloaded and stored in the hidden directories that Terraform uses for
    execution. As with the provider binaries, these module files must be there for
    future Terraform operations to succeed. Again, just like the provider binaries,
    these files do not require protection as Terraform will also bring them back with
    a single call to `terraform init`.
  prefs: []
  type: TYPE_NORMAL
- en: If you are developing reusable modules, you are most likely simultaneously using
    those modules in a root module that you use to test them. You run `terraform init`
    on the root module’s folder, and that root module references your reusable module.
    It’s important to note that if you change your module, simply rerunning `init`
    will not automatically bring in those updates. If the version of the module reference
    has stayed the same, Terraform will check the folder in which it loaded the modules
    and see that it has already downloaded that module version. To force it to download
    a new copy of your modules, you will need to either increment the version of the
    module (which can be tedious during module development) or manually clear the
    modules by deleting them from the `.``terraform` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Backend initialization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lastly, Terraform will look for a `backend` block within the `terraform` block
    of your working directory’s `.tf` files. Most backends require some configuration
    settings to work. Ultimately, a Terraform backend provides a location for the
    Terraform state file, so these configuration settings guide the Terraform backend
    on how to get to the Terraform state file.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to use the ARM backend, you must specify a way to triangulate
    to the correct Azure Blob Storage account container state file. Terraform will
    pass several landmarks along the way on the journey that Terraform takes to get
    to the location of the desired state file: first, the resource group where the
    storage account lives, then the storage account where the storage container lives,
    then the storage container where the state file lives, and finally, the name of
    the state file, which Terraform locates using the `key` value and the current
    Terraform workspace name.'
  prefs: []
  type: TYPE_NORMAL
- en: A fully populated Terraform backend configuration for Azure would use the `key`
    value and the current Terraform workspace name.
  prefs: []
  type: TYPE_NORMAL
- en: 'A fully populated Terraform backend configuration for Azure would look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The Azure backend will use `resource_group_name`, `storage_account_name`, and
    `container_name` to get to the place on Azure where files are stored. Then, `key`
    and the workspace name are used to formulate the name of the state file. If you
    are using the default workspace, then the name of the state file will be the value
    of `key`. However, if you use a named workspace, the Azure backend will generate
    a state file name that looks like `foo.tfstate:env:prod` for a workspace named
    `prod`.
  prefs: []
  type: TYPE_NORMAL
- en: Each Terraform backend plugin will have a different strategy for reading and
    writing state files and its logic for generating the state filename where the
    state is ultimately stored. Getting to know your provider, the available backend,
    and how to configure it is essential.
  prefs: []
  type: TYPE_NORMAL
- en: validate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`terraform validate` is a helpful method that is essentially the closest thing
    to a compiler. It analyzes all code files within the scope and verifies references
    and syntax. If there are any broken references to data sources or resources, running
    this command will help you find them without having to initialize your backend.
    As a result, the `validate` command is a helpful command to execute as an early
    warning to detect any problems with your code before you move on to other steps.'
  prefs: []
  type: TYPE_NORMAL
- en: workspace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`terraform workspace` is about creating forks of the same Terraform solution
    to have different instances or forks of the Terraform state. Just like in source
    code, when you create a fork, the idea is that you will modify the code, and those
    modifications will remain long-term. Therefore, you may never merge the newly
    forked code base into the `main` branch.'
  prefs: []
  type: TYPE_NORMAL
- en: Whether you realize it or not, you are using Terraform workspaces. You just
    aren’t using a custom-named workspace. You can find this out by running the `terraform
    workspace show` command, which will say `default`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new workspace for each long-lived environment is a good idea—even
    if you plan on segmenting your backend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running `terraform workspace new dev` will create a new workspace for your
    development environment. You can run the same command for your production environment,
    such as `terraform workspace new prod`. From then on, any Terraform operation
    that utilizes the state will use the state file for the selected workspace. You
    can change back and forth between these state files by changing the workspace
    like this: `terraform workspace select dev` or `terraform workspace` `select prod`.'
  prefs: []
  type: TYPE_NORMAL
- en: With workspaces, you might create a workspace to test something out with the
    intent of eventually making those same updates in the original workspace.
  prefs: []
  type: TYPE_NORMAL
- en: Workspaces represent utterly different environments because the dev environment
    will always differ slightly from the test, staging, or production environments.
    These environments will live in isolated workspaces and have the same isolation
    within their state file.
  prefs: []
  type: TYPE_NORMAL
- en: The common thread is that the workspaces work off the same code base. The idea
    is that you will have the same code base and deploy multiple environments with
    it—most likely long-lived environments, but not necessarily so.
  prefs: []
  type: TYPE_NORMAL
- en: plan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`terraform plan` is a read-only operation that requires access to your backend
    state and requires you to have executed `terraform init` prior. Also, if you use
    a non-default workspace, you should select your workspace before you run `plan`.
    `terraform workspace select` allows you to do that.'
  prefs: []
  type: TYPE_NORMAL
- en: '`terraform plan` will perform a read-only operation, checking the state file
    and checking in with every resource in the state file. This process can take a
    while, depending on how many resources are in your state file and how long it
    takes for the provider to get a response from whoever it’s talking to. So, to
    keep your Terraform projects lean and fast, consider how much scope you want to
    keep within a single Terraform workspace.'
  prefs: []
  type: TYPE_NORMAL
- en: You may consider splitting those chunks into sub-workspaces if it’s too big.
    I’ve seen projects where an entire solution is in one Terraform state file, and
    it takes 45 minutes to run a plan. Having too broad workspace isolation can be
    extremely painful, and I would highly advise you to consider the boundaries of
    the components of your system and organize your Terraform workspaces so that you
    have smaller, semi-dependent workspaces. It’s okay to have dependencies between
    workspaces. Still, you need to call out those dependencies using data sources
    so that you don’t get into a situation where you can make a circular reference
    between two Terraform workspaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Terraform needs you to set all your input variables before you can run the
    `plan` operation. You can do this in three ways: through an individual command-line
    argument, a variable file, and environment variables.'
  prefs: []
  type: TYPE_NORMAL
- en: An **individual command-line argument** is helpful for small projects with interactive
    command-line sessions. Still, it quickly becomes unmanageable when the environment
    grows more complex or you want to use a pipeline tool—a scenario on which we will
    spend the bulk of this book.
  prefs: []
  type: TYPE_NORMAL
- en: The **environment variable** approach is instrumental in the pipeline tool approach
    because it allows you to execute Terraform commands without modifying the arguments
    to the command you run.
  prefs: []
  type: TYPE_NORMAL
- en: apply
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`terraform apply` is the most crucial operation in the arsenal. Before execution,
    this command requires `terraform init` to have been executed successfully. Selecting
    the correct workspace corresponding to the input parameters you specify will also
    be essential.'
  prefs: []
  type: TYPE_NORMAL
- en: '`terraform apply` is also unique compared to other operations: you can execute
    it by pointing at a single file rather than a working directory. The `terraform
    plan` command outputs the plan file. If a plan file is not specified, `terraform
    apply` will execute a plan before the `apply` stage.'
  prefs: []
  type: TYPE_NORMAL
- en: It is best practice to execute `apply` by always passing in a plan file. Doing
    so will ensure that you don’t have any surprises when you execute. However, there
    is still a chance that something changed in the environment between when you last
    ran `plan` and when you finally executed `apply`.
  prefs: []
  type: TYPE_NORMAL
- en: This is particularly important when working on a team of multiple people that
    might be introducing change to the environment, either using Terraform locally
    or through a CI/CD pipeline. Changes could also be introduced outside of Terraform
    through manual changes within the cloud platform’s management portal. Using a
    Terraform plan file when you run `terraform apply` will help keep the plan you
    execute exactly how you intended with the best information available at the time
    of provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: As with `plan`, input variables can set their values in many ways.
  prefs: []
  type: TYPE_NORMAL
- en: destroy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`terraform destroy` is how you can completely eradicate your entire environment.
    The ability to do so is advantageous when your solution spans multiple logical
    groups within the target platform or when using multiple providers.'
  prefs: []
  type: TYPE_NORMAL
- en: Logical container deletion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some platforms make it easy to manage the life cycle of related resources. For
    example, Microsoft Azure resources every resource to be provisioned within a resource
    group, and on **Google Cloud Platform** (**GCP**), every resource is provisioned
    within the context of a project. The Azure resource group and Google Cloud project
    are logical containers you can use to clean up after yourself quickly with a cascading
    delete operation. Platforms that lack this feature can make it extremely tedious
    to clean up after yourself, such as in AWS, where you must navigate to many different
    portal pages to ensure you delete everything. Savvy command-line power users can
    string together their clean-up scripts using a well-planned tagging scheme. Still,
    tools such as Terraform add a lot of value in just being able to delete every
    resource you provisioned with a single command.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-platform deletion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Even on cloud platforms with logical containers, to collectively manage the
    life cycle of related resources, you still need help with associated resources
    that you provision in tangential systems or platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we took an in-depth look at Terraform’s architecture. We primarily
    focused on two critical architectural components: state and modularity. Having
    a sound understanding of Terraform’s architecture is vital for you to be able
    to use Terraform to its fullest effectively. Finally, we ended by looking at Terraform’s
    CLI, which will enable you to, when you’re ready, integrate Terraform with your
    own CI/CD pipelines. In the next chapter, we will explore HCL so that we can lay
    the foundation on which we can start building IaC using Terraform.'
  prefs: []
  type: TYPE_NORMAL
