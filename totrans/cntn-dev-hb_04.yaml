- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running Docker Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software containers are the new standard application artifacts for modern platforms.
    In the previous chapters, we learned to create software container images and share
    them with other developers or services. In this chapter, we will learn how to
    effectively work with containers. We will understand the main Docker containers’
    objects and how to manage them using the appropriate command-line actions and
    options. Understanding the container network model and how to manage persistent
    data is key for working with containers. We will also cover the concepts for managing
    both. At the end of this chapter, we will review some very important maintenance
    tasks you should know about so that you can manage your environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Docker software container objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about using the command line to work with containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limiting container access to host resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing container behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container runtime maintenance tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book teaches you how to use software containers to improve your application’s
    development. The labs for this chapter can be found at [https://github.com/PacktPublishing/Docker-for-Developers-Handbook/tree/main/Chapter4](https://github.com/PacktPublishing/Docker-for-Developers-Handbook/tree/main/Chapter4).
    Here, you will find some extended explanations that have been omitted in this
    chapter’s content to make it easier to follow. The *Code In Action* video for
    this chapter can be found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin this chapter by introducing the most important Docker container
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Docker software container objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Container runtimes usually work by following a client-server model. We interact
    with the runtime by using a client command line such as `docker`, `nerdctl`, or
    `crictl`, depending on the backend. The runtime itself is responsible for managing
    different objects or resources, which can easily be manipulated by interacting
    with it. Before we learn how to interact with and manage software containers,
    we will learn about the different objects that are managed by the container runtime
    in this section. All commands or actions will be related to them, to either create,
    remove, or modify their properties. We learned about container images in [*Chapter
    1*](B19845_01.xhtml#_idTextAnchor015), *Modern Infrastructure and Applications
    with Docker*, and [*Chapter 2*](B19845_02.xhtml#_idTextAnchor036), *Building Docker
    Images*, where we also learned how to build them. Let’s start by reviewing these
    well-known objects, which are common within all container runtimes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Container images**: These objects are also referred to as **container artifacts**.
    They are the base for creating a container because they contain all the files,
    integrated into different layers, that will be included inside a container’s filesystem.
    The images also contain the meta-information required for running a container,
    such as the processes that will run internally, the ports that will be exposed
    externally, the volumes that will be used to override the container’s filesystem,
    and so on. You, as a developer, will create and use a lot of images for your applications.
    Please take the best practices for security that were reviewed in [*Chapter 2*](B19845_02.xhtml#_idTextAnchor036),
    *Building Docker Images*, into account.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Containers**: When we use a container image and run a container using it,
    we are telling the container runtime to execute the processes defined in the image’s
    meta-information and use the image layers to provide a base filesystem for these
    processes. Kernel features such as cgroups and namespaces are also provided to
    isolate containers. This makes it possible to run different containers in the
    same hosts in a secure way. None of them will see each other unless specifically
    declared. The container’s filesystem layer will be added on top of the image layers
    in read and write mode. All layers below the container layer will be used in read-only
    mode, and the files that have been modified or created will be managed using the
    features of CoW filesystems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker0` bridge interface at the host level, although other network options
    and drivers can be used. The container runtime manages IP addresses with an internal
    IPAM, and a NAT is used to allow container access to the real host’s attached
    network. Network objects allow us to create different bridge interfaces and attach
    containers to them, isolating containers running within different networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volumes**: CoW filesystems may impact the application’s behavior. If your
    processes change a lot of files or any file must persist throughout a container’s
    life cycle, a volume must be used to override CoW filesystem management. We use
    volumes to store files outside of the container’s layers. These can be folders
    in our host system, remote filesystems, or even external block devices. Different
    drivers can be used and, by default, volumes will be locally available in each
    underlying host as folders.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these objects will be identified by unique IDs and we will use either their
    names or IDs to refer to them. Common actions for creating and removing them will
    be available in our client command line. We can also list them and inspect their
    properties, and we can use Go template formatting, as we learned in [*Chapter
    2*](B19845_02.xhtml#_idTextAnchor036), *Building* *Docker Images*.
  prefs: []
  type: TYPE_NORMAL
- en: Container orchestrators will have their own set of objects or resources (in
    Kubernetes). We will review them in [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147),
    *Orchestrating with Swarm*, and [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170),
    *Deploying Applications with* *the* *Kubernetes* *Orchestrator*, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Before we review these new objects, let’s remember that containers are processes
    that run on top of hosts thanks to container runtimes. These processes run isolated
    from each other by using the special kernel features of the hosts. Container images
    will provide the base filesystems for these processes and we will use a client
    command line to interact with them.
  prefs: []
  type: TYPE_NORMAL
- en: Containers are considered stateless and ephemeral, although they exist on the
    underlying host. Applications running within containers should be prepared to
    run anywhere, and their state and data should be managed out of the container’s
    life cycle. What if we need to store an application’s data or its status? We can
    use the volume objects to persist data and processes’ states when containers are
    removed or a new container is created using the same data. If we are working in
    a distributed or orchestrated environment, sharing these volumes is critical,
    and we need to use external volumes to attach the data to the containers wherever
    it’s needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the container runtime we use, the location of the files related
    to containers may change, but in the case of a Docker container runtime, we expect
    to have all images and container layers and their files under `/var/lib/docker`
    or `c:\ProgramData\docker`. This may seem completely different on new desktop
    environments, such as Docker Desktop and Rancher Desktop. In these environments,
    we will use WSL or the Windows command line to execute the client and interact
    with a container runtime. The runtime runs in a different WSL environment; hence,
    you will not be able to reach its data path. To review the current data path from
    your client, you can use `docker info` if you are using Docker as the container
    runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you use `containerd` directly, the data root path will be located under the
    `/var/lib/containerd` directory, but in both cases, you will not be able to access
    these folders in desktop environments because client access uses a pipe connection
    to access the container runtime remotely. All the objects’ meta-information will
    be stored under this `DockerRootDir` path and we will be able to retrieve the
    objects’ properties by using the container runtime client with appropriate commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using WSL2 with Docker Desktop, two WSL instances will have been
    created: `docker-desktop` and `docker-desktop-data`. The second one is used for
    mounting all data inside your own WSL instance (`ubuntu-22.04` in my case, but
    it may differ for you). This is possible thanks to the integration with Docker
    Desktop. We can find all the Docker container content inside the `\\wsl.localhost\docker-desktop-data\data\docker`
    directory. The following PowerShell screenshot shows my environment’s data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Docker container runtime objects data inside the docker-desktop-data
    WSL instance](img/B19845_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Docker container runtime objects data inside the docker-desktop-data
    WSL instance
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know about the main objects that are managed by the container runtime,
    we can review the command-line options we have for managing and interacting with
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about using the command line to work with containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn how to manage containers. We will use the Docker
    command line, provided by the Docker client (the `docker-client` package or WSL
    integrated into Docker Desktop environments). All the command-line actions we
    are going to discuss in this chapter will be similar for other clients, such as
    `nerdctl` or `podman`, although in the latter case, it does not use a `containerd`
    daemon.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker client sends actions to the Docker daemon via an API every time we
    retrieve information about Docker objects. Clients can use **SSH**, **HTTP/HTTPS**,
    or direct **sockets** (or **pipes** in Microsoft operating systems).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will start with the actions that are common and available to all
    container runtime objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`create`: All the container runtime objects can be created and destroyed. This
    doesn’t apply to container images because we will use `docker image build` to
    start a building process to create them. All objects will automatically receive
    an ID, and in some cases, such as with containers, an automated random name will
    also be added. If we want to assign a defined name, we can use the `--``name`
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`list`: This action will show all the objects in the defined category; for
    example, `docker image list` will retrieve all the images available locally in
    our container runtime. As we learned in [*Chapter 2*](B19845_02.xhtml#_idTextAnchor036),
    *Building Docker Images*, we have options for filtering and formatting the output
    using `--all` argument. If we only need the object identifiers, we can use the
    `--quiet` option. This can be very useful for piping the output to another command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You may notice that we can also use `docker container ps` or the shorter version,
    `docker ps`, to list containers. Containers are processes that run in our host
    with kernel features providing isolation; hence, it seems appropriate to use this
    argument as if we were listing processes. By default, only running processes (or
    containers) will be listed, and we will have to use the `--all` argument to show
    stopped ones as well.
  prefs: []
  type: TYPE_NORMAL
- en: '`inspect`: Inspecting objects will allow us to retrieve all the information
    related to the defined object. By default, all objects’ data will be presented
    in JSON format, but we can also use the `--format` argument to format the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`remove`: All objects can also be removed. We will use their IDs or names to
    delete them. In some cases, internal dependencies may appear. For example, we
    can’t remove a container image if any existing container is using it. To avoid
    these dependencies, we can use the `--``force` argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These actions are common to all container runtime-managed objects, but when
    we deep dive into containers, more are available. Next, we will review the current
    actions for containers, but first, we have to understand that when we create an
    object, we prepare all the required configurations. This means that creating a
    container will prepare the container to run, but the container will be stopped.
    Let’s see this feature in action with a quick example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Our Docker container runtime has just created a container, but it is not running,
    although it is still in our host system.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can remove this container and check it again. We will not be able to retrieve
    any value from this object because it will now not exist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can continue reviewing the actions for containers, starting with the
    action for actually starting a container after its creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '`start`: This action requires a previously created container object to exist.
    The container runtime will execute the defined container object’s processes with
    its host’s isolation and defined attached resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`run`: This action will `--detach` argument; in this case, the container will
    run in the background and our terminal will be detached from the container. We
    can use `--interactive` and `--tty` to execute the current container in interactive
    mode and use a pseudo-terminal; this way, we can actively interact with the container’s
    main process. Containers will run using all the parameters defined in their configuration,
    such as usernames, defined kernel namespaces, volumes, networks, and so on. Some
    of these definitions may be modified by adding different arguments to our command
    line.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stop`: Containers can be stopped. This action will ask the container runtime
    to send a stop signal (`SIGTERM`) to the container’s main process and it will
    wait 10 seconds (by default) before sending a kill signal (`SIGKILL`) if the process
    is still alive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kill`: Killing a container will directly ask the container runtime to send
    a `SIGKILL` signal. You, as a developer, should prepare your applications to die
    correctly in case `SIGTERM` or `SIGKILL` is received. Ensure your files are closed
    correctly and no unmanaged process continues running after the main process has
    died.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`restart`: This action will be used to stop and start the container. We can
    ask the container runtime to always restart our container whenever our main process
    dies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pause`/`unpause`: Containers can be paused. This will make the container runtime
    inform the kernel to remove any CPU time from the container’s processes. This
    is important because paused containers can be used to share container resources,
    such as volumes and namespaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You may get stuck and be unable to exit the container’s main process standard
    and error output if you run certain processes in the foreground without the `--interactive`
    argument. To avoid this situation, you can use the *CTRL* + *P* + *Q* keyboard
    sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that have learned about the most important actions for managing containers,
    let’s review some of the arguments we can use to modify the container’s behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--name`: Each container will be identified by a unique ID, but a name will
    always be assigned. This name will be random and composed of two strings. An internal
    database will be used to generate them and the final concatenated string will
    be unique. We can avoid this behavior by using `--name` and passing a string of
    our choice, but remember, container names must be unique and you will not be able
    to reuse this name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--restart`: As mentioned before, we can ask the container runtime to manage
    the container’s life cycle for us. By default, containers will not restart if
    the main process dies, but we can use strings such as `on-failure`, `always`,
    or `unless-stopped` to define whether the container should start in case of failure
    (any exit code other than `0`), always, or just in case we didn’t effectively
    stop the container, respectively. We can also ensure that the Docker runtime does
    not manage the life cycle of the container by not using any specific string or
    command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--entrypoint`: This option will allow us to override the container image’s
    defined entry point (main process). It is very important to understand that anyone
    can change your image’s entry point, executing whatever binary or script is available
    in your image’s layers; therefore, it is critical to strictly include the files
    required by your application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--env`: We can add new environment variables by using this argument or `--env-file`.
    In this case, a file with a key-value format will be included to add a set of
    variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--expose`: By default, only the ports defined in the container’s image will
    be exposed, but it is possible to add new ones if some modifications of the container’s
    behavior require new ports or protocols.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--user`: This argument allows us to modify the user who effectively executes
    the container’s main process. You must ensure that your application can run if
    you change the container’s user; this may be critical if you run your applications
    inside Kubernetes. In [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170), *Deploying
    Applications with* *the* *Kubernetes Orchestrator*, we will learn whether we can
    improve our application’s security by using **security contexts**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--publish` and `--publish-all`: These arguments allow us to publish one port
    (we can use the arguments multiple times to add multiple ports) or all the image’s
    defined exposed ports. This will make the application accessible from outside
    of the container’s network using NAT. Random host ports will be used to publish
    your applications unless you define specific ports during container execution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--memory` and `--cpus`: These options, among others, will allow us to manage
    the amount of memory and CPU resources that will be attached to the container.
    We can also include the host’s GPUs by using `-–gpus`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we have had an overview of the most important arguments that are used
    with containers, we will take a look at some critical options for securing our
    workloads:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--cap-add`: This option allows us to specifically add some kernel capabilities
    to our processes inside the container’s execution. Kernel capabilities are a set
    of privileges associated with a superuser, which the system provides in a fine-grained
    way. By default, a container runtime does not allow *privileged* containers to
    run with all available capabilities. Container runtimes allow only a subset of
    all available capabilities by default (the currently available capabilities can
    be reviewed at [https://man7.org/linux/man-pages/man7/capabilities.7.xhtml](https://man7.org/linux/man-pages/man7/capabilities.7.xhtml)).
    The Docker runtime, for example, allows 14 capabilities ([https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities)),
    which will probably be enough for your applications to run, but if your applications
    need some specific capability, such as the permission to manage network interfaces
    using `NET_ADMIN`, you should add that using the `--cap-add NET_ADMIN` argument.
    Adding capabilities may be useful for modifying your current kernel behavior if
    your application needs some special features. You, as a developer, should inform
    the relevant parties about the special privileges needed by your applications
    because capabilities may be dropped in secure container orchestrator environments.
    Inform your DevOps or cluster administrator teams about your special requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--cap-drop`: This option, in contrast, is used to remove certain capabilities.
    This may be very useful, for example, if we need to remove the possibility of
    changing file ownership inside a container’s life cycle, which we can do using
    `--cap-drop CHWON`, or remove the ability to send raw network packets, for example,
    ICMP, which is done using `--cap-drop NET_RAW`. You may find secure environments
    where all capabilities are dropped.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Both `--cap-drop` and `--cap-add` can be used with the `ALL` argument, which
    means that all capabilities will be dropped or added, respectively. It is very
    important for you, as a developer, to test the possible issues that may appear
    if you drop all available capabilities. This will help you prepare your applications
    for secure environments.
  prefs: []
  type: TYPE_NORMAL
- en: '`--privileged`: This argument will provide all capabilities and avoid any resource
    limitations. You should avoid using this option for your application containers.
    Take time to review which capabilities and resources are required for your application
    and apply them. Overriding all the process limits in production is a bad idea
    and should be applied only to specific application containers, for example, to
    monitor your infrastructure. In these specific cases, you may need extra resources
    or be able to access all the host’s capabilities, processes, and so on to manage
    applications from the containers themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--disable-content-trust`: This option will disable any Docker Content Trust
    verification; hence, any signature or image source check will be omitted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--read-only`: Executing containers in `/tmp` directory, you need to set up
    a volume attached to this path to allow this interaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--security-opt`: Some extended security measures may need extra options, for
    example, for setting up a different `seccomp` profile or specifying SELinux options.
    In general, this option allows us to modify Linux security modules’ behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we know how to run containers and the most important options, let’s
    review how to limit and include the underlying host’s resources.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting container access to host resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn how to limit hosts’ resources inside containers,
    but first, we will take a look at the container network model and how to use volumes
    to override container storage.
  prefs: []
  type: TYPE_NORMAL
- en: Network isolation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`docker0` by default. This interface is created during Docker daemon installation
    and all IP containers’ interfaces will be associated with `docker0`. Different
    drivers can be used to extend this default behavior, for example, to attach network
    VLANs to containers directly.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the following network plugins are available: `bridge`, `host`,
    `ipvlan`, `macvlan`, `null`, and `overlay`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, a fresh Docker container runtime installation creates three different
    interfaces. We can review them by listing the default network objects after installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'All containers will run using the `bridge` interface by default. Every time
    we create a container, a virtual interface is created in the host, attached to
    `docker0`. All egress and ingress traffic will go through this interface. In this
    scenario, it is very important to understand that all containers attached to this
    common bridge will see each other. Let’s see how this happens in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This container does not receive an IP address until it runs. We can now execute
    it and review the IP address again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The container runtime manages the IP assignment and we can verify the network
    segment that was used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s verify what happens when another container runs attached to the network
    bridge interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The second container executed three pings to the first one’s IP address and
    it was reachable. Both containers run in the same network segment, associated
    with the same bridge interface. This default behavior can be managed by setting
    certain network object’s keys during their creation, such as `com.docker.network.bridge.enable_icc`,
    which manages the isolation between containers in the same network (additional
    information can be found at [https://docs.docker.com/engine/reference/commandline/network_create](https://docs.docker.com/engine/reference/commandline/network_create)).
  prefs: []
  type: TYPE_NORMAL
- en: We will use `--network` to define the networks to which containers should attach.
  prefs: []
  type: TYPE_NORMAL
- en: The `none` network can be used to initialize and run containers without any
    networking capabilities. This can be interesting when we run certain tasks that
    don’t require any network traffic – for example, managing data stored in a volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can share the host’s network namespace by using the `host` network. When
    we attach a container to this network, it will use the host’s IP interfaces. We
    can verify this behavior by executing `docker container run --rm --network=host
    alpine ip address show`. The following screenshot shows the output of this command,
    showing the interfaces inside a container using the `host` network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – The network interfaces of our host, included inside a running
    container](img/B19845_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – The network interfaces of our host, included inside a running container
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that `docker0` and the previous container’s interface are inside
    the new container. The `host` network is used for monitoring and security applications
    – when we need access to all the host interfaces to manage or retrieve their traffic
    statistics, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We used the `--rm` argument to remove the container right after its execution.
    This option is very useful for testing and executing quick commands inside containers.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding custom networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can also create custom networks, as with any other container runtime objects.
    We can use `docker network create <NETWORK_NAME>` for such tasks; a new bridge
    network interface will be created by default. These new network interfaces will
    be similar to the `docker0` interface, but some important features are added:'
  prefs: []
  type: TYPE_NORMAL
- en: Each custom network is isolated from the others, using a completely different
    network segment. A new bridge interface will be created for each custom network
    and the network the segment will be associated with. All containers running attached
    to this network will see each other, but they won’t reach the ones attached to
    any other network, including the default bridge. This also works the opposite
    way; hence, containers attached to a network will only see those working on the
    same network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom networks can be dynamically attached. This means that containers can
    be attached and detached by using `docker network connect <CONTAINER>` and `docker
    network disconnect <CONTAINER>`. This behavior can’t be reproduced in the default
    bridge network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An internal DNS is provided for each custom network. This means that all containers
    that are attached can be accessed by using their names. Hence, network discovery
    is provided, and each time a new container runs attached to this network, a new
    entry is added to the internal DNS. However, remember that DNS names will only
    be accessible internally in the defined network. Default bridge networks can also
    access containers via their names if we use the `--link` argument. This way, we
    can link containers together to make them work as if they were using a DNS, but
    this will only work for the containers included in this argument; no other containers
    will be seen by their names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s see a quick example by creating a new network using `docker network create`.
    We will also define a name, its scope, and the associated subnet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s try to access the container attached to the created custom network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'It is accessible by its name, but let’s try this again with the container attached
    to the default network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'It is not accessible by the DNS name. Let’s verify whether the network is available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'All packets are lost. The bridge network is not accessible from the custom
    one we created, although both use the host’s interfaces. Each network is attached
    to its own bridge network, but we can attach a container to both networks using
    `docker connect <``NETWORK> <CONTAINER>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have a container attached to the custom and default bridge networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, we can now reach the containers in the custom network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Some options can modify the default networking behavior inside containers.
    Let’s see some of them for running containers or creating networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--add-host`: This option allows us to include some external hosts in `host:ip`
    format to make them available as if they were included in the DNS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--dns`, `--dns-search`, and `--dns-option`: These options allow us to modify
    the DNS resolution for the container. By default, the container runtime will include
    its current DNS, but we can change this behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--domainname`: We can set the container’s domain name to something other than
    the default one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--ip`: Although it is quite important to use default dynamic IP address mappings,
    we may prefer to assign a specific IP address to the container. Use this option
    with care as you can’t reuse IP addresses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--hostname`: By default, each container will use the container’s ID as its
    name, but we can change this behavior by using this option.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--link`: This option will allow us to attach two or more containers by using
    this option multiple times. It is quite similar to the `--add-host` option, but
    in this case, we will use it to attach a container to a DNS name in `CONTAINER_NAME:DNS_ALIAS`
    format to make it accessible via its DNS name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--network-alias`: Sometimes, we need a container to be known in the network
    with multiple names. This option allows us to add a DNS alias to the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--subnet` and `--ip-range`: This option is available for networks and allows
    us to modify the internal IP’s assignation. We can also modify the default gateway
    for each network by using the `--gateway` argument (by default, the lowest IP
    address will be used).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we’ll learn how volumes work.
  prefs: []
  type: TYPE_NORMAL
- en: Managing persistent data with containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applications running in containers must be prepared to run in any host. We can
    even go further and say that we should be able to run them in the cloud or on-premises
    environments. However, containers’ life cycles should not include process states
    and data. **Volumes** will help us manage data outside of containers’ life cycles
    and hosts (if we’re using remote storage solutions such as NAS). In this section,
    we will learn how container runtimes manage local volumes. Volumes will allow
    containers to access hosts’ filesystems or remote filesystems.
  prefs: []
  type: TYPE_NORMAL
- en: Local volumes will be expected to be located by default under the `DockerRootDir`
    path in the container runtime’s host. This will work for `VOLUME` key is declared
    in any image’s meta-information, and **named volumes**, which are created or declared
    by users during a container’s execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use any local filesystem (`tmpfs` volume (this is very interesting
    when we need the fastest possible storage backend). In the case of bind mounts,
    any directory or file from the host’s filesystem can be included inside a container.
    But a problem arises here: whenever we move an application to another host, any
    expected location related to the host may be different. To avoid such a situation,
    it is recommended to use external storage, presented on other hosts at the same
    time or whenever a container needs to run. This is especially relevant for clusters,
    where a pool of nodes can run your containers. At this point, we will just discuss
    having data outside of a container’s life cycle; in [*Chapter 10*](B19845_10.xhtml#_idTextAnchor231),
    *Leveraging Application Data Management* *in Kubernetes*, we will discuss how
    to manage data in these more complicated scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s deep dive a bit and describe the local volume types:'
  prefs: []
  type: TYPE_NORMAL
- en: '`VOLUME` definition. These volumes are used to override the container’s filesystem,
    but we, as users, are not responsible for its content. In other terms, whenever
    a new container runs, a new volume will be created dynamically and new data will
    be used. If we need data to persist between executions, we have to define a volume
    by ourselves. The container runtime manages the unnamed volumes completely. We
    can remove them using the `docker volume rm` command but we will need to stop
    and remove the associated containers first. Let’s run a quick example with the
    `postgres:alpine` image, which uses a dynamic unnamed volume to override the container’s
    filesystem for the `/``var/lib/postgresql/data` directory:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker run -d -P \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: -v DATA:/var/lib/postgresql/data postgres:alpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ad7dde43bfa926fb7afaa2525c7b54a089875332baced7f86cd3709f04629709
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $ docker container inspect ad7dde43bf \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --format="{{ .Mounts }}"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[{volume DATA /var/lib/docker/volumes/DATA/_data /var/lib/postgresql/data local
    z true }]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $ docker volume ls
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: DRIVER    VOLUME NAME
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: local     343e58f19c66d664e92a512ca2e8bb201d8787bc62bb9835d5b2d5ba46584fe2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: DATA is the name of the volume, and we will be able to reuse this volume whenever
    we remove the postgresql container and create a new one.Data will be persisted
    in the volumes in both examples but the named volume will allow us to manage the
    data most conveniently.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is very important to understand that named and unnamed (dynamic) volumes
    use our host’s storage. You must take care of volumes forgotten in your filesystem;
    we will review some techniques for this in the *Container runtime maintenance
    tasks* section later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bind mounts**: In this case, we will include a host’s directory or file inside
    our container. We will practice using this type of volume in the *Labs* section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**In-memory or tmpfs volumes**: These volumes can be used to override the container’s
    storage, providing fast storage, such as the host’s memory. This can be very useful
    for storing a small amount of data that changes quite often, such as statistics.
    It also can be very dangerous if you don’t limit the amount of memory for use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Volumes can be used in read-only mode to preserve any existing data. This is
    very useful for presenting data from the host that you want to ensure remains
    unchanged, such as operating system files. We can also manipulate the ownership
    and permissions seen inside the container’s filesystem for any mounted volume.
    It is also common to use `--volumes-from` to share volumes between containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you have probably noticed, we used the `-v` or `--volumes` argument to add
    volumes to our container at runtime. We can use this argument multiple times and
    use the `--volume SOURCE_VOLUME:FULL_DESTINE_PATH[:ro][:Z]` format, where `SOURCE_VOLUME`
    can be any of the previously described types (you have to use the full path for
    the shared directory when using bind mounts). A volume can be mounted in read-only
    mode, which is very interesting when you provide configurations to your container,
    and we can force SELinux usage if needed with the `Z` option. However, we can
    also use volumes with the `--mount` argument, which provides an extended version
    of the volume-mounting options in key-value format:'
  prefs: []
  type: TYPE_NORMAL
- en: '`type`: We specify the type of the mount (`bind`, `volume`, or `tmpfs`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`source` (or `src`): This key is used to define the source of the mount. The
    value can either be a name (for named volumes), a full path (for bind mounts),
    or empty (for unnamed volumes).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target` (or `dst`): This key defines the destination path where the volume
    will be presented.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also include the `volume-opt`.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned how to include the host’s network and filesystems inside
    containers, let’s continue by accessing the CPU and memory, among other resources.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting access to host hardware resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sharing host resources within containers is the key to the container model,
    but this requires being able to limit how they access these resources. In [*Chapter
    1*](B19845_01.xhtml#_idTextAnchor015), *Modern Infrastructure and Applications
    with Docker*, we learned that resource isolation is provided by cgroups.
  prefs: []
  type: TYPE_NORMAL
- en: If our host runs out of memory or CPU, all containers running on top will be
    affected. That’s why is so important to limit access to the host’s resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, containers run without any limits; hence, they can consume all
    the host’s resources. You, as a developer, should know the resources that are
    required by all your application components and limit the resources provided to
    them. We will now review the arguments we can pass to the container runtime to
    effectively limit the container’s access to resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--cpus`: This argument allows us to define the number of CPUs provided to
    the container’s main process. This value depends on the number of CPUs available
    to the host. We can use decimals to indicate a subset of the total number of CPUs.
    This value guarantees the number of CPUs that can be used to run the container’s
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--memory`: We can set the maximum memory available to the container’s processes.
    When this limit is reached, the host’s kernel will kill the container’s main process
    by executing a runtime called `--oom-kill-disable`; however, it is not recommended
    as you may leave your host without any protection if too much memory is consumed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Container runtimes provide more options for managing CPU and memory resources
    available for any container. It is possible to even limit the access to block
    devices’ **input/output** (**I/O**) operations or modify the default kernel’s
    scheduling behavior. We have just reviewed the most important ones to help you
    understand how we can limit access to the host’s resources. You can review the
    full options at [https://docs.docker.com/config/containers/resource_constraints/](https://docs.docker.com/config/containers/resource_constraints/).
  prefs: []
  type: TYPE_NORMAL
- en: Extending access to host resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Containers run on top of our hosts thanks to container runtimes. By default,
    the host’s CPU and memory are provided thanks to cgroups. Volumes are provided
    inside containers using different types (dynamic unnamed volumes, named volumes,
    host binds, or tmpfs volumes) and the network is provided using kernel namespaces.
    We can use other Docker client arguments to integrate or modify kernel namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--ipc`: This argument allows us to modify the IPC behavior (shared memory
    segments, semaphores, and message queues) inside containers. It is quite common
    to include the host’s IPC by using `--ipc host` for monitoring purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--pid`: This option is intended to set the PID kernel namespace. By default,
    containers run with their own process trees, but we can include other containers’
    PIDs by using `--pid container:CONTAINER_NAME`. We can also include the underlying
    host’s PIDs tree by using `--pid host`. This can be very interesting if your application
    needs to monitor the host’s processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--userns`: We can create a different kernel user’s namespace and include it
    inside containers. This allows us to map different user IDs to the processes running
    inside the containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other interesting options allow us to include different host devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--device`: This option allows us to include the host’s devices inside containers.
    Processes running inside the containers will see these devices as if they were
    directly connected to the container. We can use this option to mount block devices
    (`--device=/dev/sda:/dev/xvdc`), sound devices (`--device=/dev/snd:/dev/snd`),
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--gpus`: We can include `--``gpus all`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we learned how to limit access to different hosts’ resources.
    In the next section, we will learn how to manage containers running in our host
    and their behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Managing container behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The container runtime will help us understand containers’ behavior by providing
    a set of options for reviewing process logs, copying files to and from containers,
    executing processes inside them, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following actions allow us to interact with container processes and filesystems:'
  prefs: []
  type: TYPE_NORMAL
- en: '`exec`: We can attach new processes to the containers’ namespaces by using
    `docker container exec`. This option will allow us to run any script or binary
    included in the container’s filesystems or mounted columns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`attach`: When a container is running in the background, detached from the
    container runtime client’s command line, we can attach its output by using this
    action. We will attach the Docker client to the container’s main process; hence,
    all the output and errors will be shown in our terminal. Take care with this option
    because you should detach from the container’s main process output to free your
    terminal. Do not use the *Ctrl* + *C* keyboard combination because this will send
    a `SIGNINT` signal to the container’s main process and it will probably be stopped.
    You can detach from the container’s process by using *Ctrl* + *P* + *Q*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cp`: Sometimes, we need to retrieve some files from the container for debugging,
    for example, certain errors. We can use the `cp` action to copy files to/from
    a container. Remember that you can use volumes to provide files or directories
    to containers; the `cp` action should be used with small files because it uses
    the container runtime and your client to retrieve the files from the containers
    or send them from the local client.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logs`: Retrieving the logs from containers is key to understanding how your
    applications work. A container has a main process and this process’s `STDOUT`
    and `STDERR` streams are the output we receive by using the `logs` action. We
    can use `--follow` to attach to the container’s process output continuously and
    `--tail` to retrieve only a set of lines. It is possible to filter logs by dates
    by using `--since` and `--until`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you need to execute an interactive session within a container, it is important
    to include `--interactive` and `--tty`. These options ask the container runtime
    to prepare a pseudo-terminal and interactive session attached to the binary defined
    in the `exec` action; for example, we will use `docker container exec --ti CONTAINER
    /bin/bash` to execute a *bash* shell inside a defined container.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use a running container to create a container image. We learned
    about this feature in [*Chapter 2*](B19845_02.xhtml#_idTextAnchor036), *Building
    Docker Images*. Creating images from containers does not provide a reproducible
    recipe and it is not a good method for creating images, but in certain situations,
    you may need the container’s content to review the files included.
  prefs: []
  type: TYPE_NORMAL
- en: We can use `docker container commit` to create an image from the container’s
    layer and export all the layers by using `docker container export`. This action
    will only store the files included in the container. It does not include any meta-information
    because we are only working with the content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another action that’s quite interesting for quickly debugging the file changes
    made by the container’s processes is `diff`. This action allows us to retrieve
    the changes that are created in the container’s layer by comparing all its files
    with the image’s layers. Let’s review this action with a quick example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the command’s output, the `/tmp` directory was changed (indicated
    by `C`) and a file was added, `/tmp/TESTFILE` (indicated by `A`).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have had a good overview of how to interact with containers and
    obtain information for debugging our applications, let’s learn some housekeeping
    tasks that will help us maintain our container’s environment healthily.
  prefs: []
  type: TYPE_NORMAL
- en: Container runtime maintenance tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to take a quick look at some housekeeping actions
    that are available for maintaining our container runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining the right amount of storage available in your host is a very important
    task. Depending on your container runtime, you may have to prune certain objects
    instead of using a general tool. This happens, for example, with the `containerd`
    client called `nerdctl`. If you are using Rancher Desktop, you will need to specifically
    remove unnecessary objects per category. Let’s review how this can be done with
    the Docker client using `docker system prune`. But before you prune your system
    and clean old objects, you should first understand where the disk space has been
    used.
  prefs: []
  type: TYPE_NORMAL
- en: 'To review the actual amount of disk that’s been allocated to different objects,
    we can use the `docker system` `df` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This command shows the space used by images, containers, and local volumes
    on your system. We can obtain quite descriptive information by adding the `–-verbose`
    argument, which will show us exactly the amount of space that’s used by every
    object in our host. Specific sections for each object category will show the space
    we will free up after removing those objects (only object headers and one object
    line are shown as an example; you can access the full output at [https://github.com/PacktPublishing/Docker-for-Developers-Handbook/blob/main/Chapter4/Readme.md](https://github.com/PacktPublishing/Docker-for-Developers-Handbook/blob/main/Chapter4/Readme.md)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This output gives us a good idea of how are we running our environment. You,
    as a developer, will probably have a lot of cached layers if you are building
    your images locally. These layers will help speed up your build processes but
    all the layers that have not been used for a long time can be removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at how images are distributed in our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: All the images based on `alpine` share `7.05MB`; hence, using common base images
    will help you save a lot of storage and is a good practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `CONTAINERS` section will help us find possible problems because we don’t
    expect to have much space in containers. Remember that containers are intended
    to be ephemeral, and persistent data should be maintained outside of their storage.
    Application logs should be redirected to either volumes or `STDOUT`/`STDERR` (this
    is the recommended option). Therefore, the space used by containers should be
    minimal, only consisting of runtime modifications that shouldn’t persist. In our
    example, we can see a couple of containers with several megabytes of usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In both cases, the `trivy` database is probably included in the container’s
    layer (we used `trivy` and updated its database during the build process for these
    images).
  prefs: []
  type: TYPE_NORMAL
- en: We also have a few volumes (dynamic and named) present, but no data was stored
    because we didn’t add any data to the database example.
  prefs: []
  type: TYPE_NORMAL
- en: And finally, we can see the cache section in the output of the `docker system
    df –verbose` command, where we will find the shared layers used in the `buildx`
    processes.
  prefs: []
  type: TYPE_NORMAL
- en: The objects’ disk usage shown by `docker system df` is a representation of the
    physical space distributed in `/var/lib/docker` (the default being `rootDir`).
  prefs: []
  type: TYPE_NORMAL
- en: Pruning container objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once we know how our host’s storage is distributed, we can proceed with cleaning
    unused objects. We will use `docker system prune` to clean all unused objects
    in one go. It will try to free disk space by removing objects from different categories.
    We can include the volumes by using the `--volumes` argument. The `system prune`
    command will remove the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**All dangling images (by default)**: Image layers not referenced by any container
    image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All unused images (using the --all argument)**: Images not referenced by
    any container (running or stopped in our system).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All stopped containers (by default)**: By default, all stopped containers
    will be removed (those with an *exited* status). This will remove the containers’
    layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All unused volumes (using --volumes)**: Volumes are not used by any container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All unused networks (by default)**: Networks with no containers attached.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All dangling cache layers (by default)**: All layers that are not referenced
    in any build process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You will always be asked to confirm this action as it can’t be undone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: A summary of the reclaimed space is shown after the cleaning process.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each category of objects, we can execute these pruning processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker` `container prune`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker` `image prune`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker` `buildx prune`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker` `network prune`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These actions will only clean specific objects, which may be very useful if
    you don’t want to change other objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'All pruning options can be filtered using the appropriate `--filter` argument.
    These are some of the most common filters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`until`: We use a timestamp argument to only remove containers that were created
    before a date.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`label`: This will help us filter which objects from a category will only be
    removed. Multiple labels can be used, separated by commas. Labels can be filtered
    by their existence or absence and we can use keys and values for fine-grained
    selections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you are planning to schedule prune processes, you may need to use `--force`
    to execute them in a non-interactive way.
  prefs: []
  type: TYPE_NORMAL
- en: Before you move on to the next section, it is important to know that your containers’
    logs will also be present in your host system.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring container runtime logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Container logging options for your system depend on your container runtime.
    In this section, we will quickly review some of the options available for a Docker
    container runtime as this is the one that has the most advanced options. You will
    probably find options for logging using JSON format, but Docker also provides
    other logging drivers.
  prefs: []
  type: TYPE_NORMAL
- en: By default, the Docker daemon will use the `json-file` logging driver, but we
    can change this behavior in Docker’s `daemon.json` file. This driver uses more
    disk space than others and that’s why it is recommended to use the local logging
    driver for local development. We can use our host’s system logs in Linux environments
    by configuring `syslog` or `journald` drivers, but if we need to send our containers
    logs to an external application, we will probably use `gelf` (a commonly used
    standard) or `splunk` drivers, although there are also some drivers specific for
    cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can configure some housekeeping options by adding specific keys to the `daemon.json`
    file. Here is an example that will keep the logs’ size under 20 MB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We will apply this configuration and restart our Docker container runtime.
    We can make these changes in Docker Desktop:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – The available Docker daemon settings in Docker Desktop (the
    embedded daemon.json file configured in our environment)](img/B19845_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – The available Docker daemon settings in Docker Desktop (the embedded
    daemon.json file configured in our environment)
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to define a specific logging driver for each container, although
    it is preferred to define a common one for your entire environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we complete this section, we should talk about the different logging
    strategies we can use in our environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local logging**: You will probably use local logging when developing your
    applications. These logs will be removed whenever you remove a container and will
    always be managed by the container runtime. These are only present locally on
    your computer desktop, laptop, or server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volumes**: Using a container’s external storage will allow us to ensure that
    logs persist between executions; although these logs may be attached to the host’s
    storage, which will keep them locally only. If you want to keep these logs available
    in other servers just in case you move your containers (or execute new ones with
    the same attached volume), you will need to use external storage solutions such
    as NAS or SAN for your volumes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External logging ingestion**: This should be your choice for production.
    Your application may send your logs directly from your code to an external logs
    ingestion solution or you may configure your container runtimes to send them directly
    for you. This will help you keep a homogeneous environment if your applications
    run in containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will review some of the content we learned about in
    this chapter by executing some labs.
  prefs: []
  type: TYPE_NORMAL
- en: Labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following labs will provide examples to put the concepts and procedures
    that you learned about in this chapter into practice. We will use Docker Desktop
    as the container runtime and WSL2 (or your Linux/macOS Terminal) to execute the
    commands described.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure you have downloaded the content of this book’s GitHub repository from
    [https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git](https://github.com/PacktPublishing/Docker-for-Developers-Handbook.git).
    For this chapter’s labs, we will use the content of the `Chapter4` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing container networking concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will review some of the most important networking topics
    we learned about in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will run a container in the background, which will be used as a reference
    in other steps. We will run a simple `sleep` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container run -ti --rm \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --name two alpine ping -c1 one
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: one can’t be resolved, but let’s verify whether communications exist. We used
    the --rm argument to delete the container right after its execution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s verify the container’s IP address by using the `inspect` action:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container run -ti --rm --name two \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --add-host one:172.17.0.2 alpine ping -c1 one
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'PING one (172.17.0.2): 56 data bytes'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.116 ms'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '--- one ping statistics ---'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 1 packets transmitted, 1 packets received, 0% packet loss
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: round-trip min/avg/max = 0.116/0.116/0.116 ms
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container rm --force one
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'testnet network and review its IPAM configuration:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And now we start our reference container attached to this network:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This can also be done by using `docker network connect NETWORK CONTAINER` if
    the container is already running (for example, if we reused the container from
    previous steps and attached it to the bridge network, we would have been able
    to also connect the new custom network).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s review the IP addresses that were assigned to the containers in
    this custom network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: $ docker container run -ti --rm --name two \
  prefs: []
  type: TYPE_NORMAL
- en: --net testnet alpine ping -c1 one
  prefs: []
  type: TYPE_NORMAL
- en: 'PING one (172.18.0.2): 56 data bytes'
  prefs: []
  type: TYPE_NORMAL
- en: '64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.117 ms'
  prefs: []
  type: TYPE_NORMAL
- en: '--- one ping statistics ---'
  prefs: []
  type: TYPE_NORMAL
- en: 1 packets transmitted, 1 packets received, 0% packet loss
  prefs: []
  type: TYPE_NORMAL
- en: docker0 bridge interface by default).
  prefs: []
  type: TYPE_NORMAL
- en: Access to container services
  prefs: []
  type: TYPE_NORMAL
- en: 'In this lab, we will use the created custom network and run a simple NGINX
    web server:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run a new container using the `nginx:alpine` image, attached to the custom
    network. Notice that we didn’t use `--it` (interactive and pseudo-terminal attached)
    arguments because we will not interact with the NGINX process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker ps
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: CONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS     NAMES
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 1eb773889e80   nginx:alpine   "/docker-entrypoint.…"   4 minutes ago    Up 4
    minutes    80/tcp    webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'curl package and test the connection to the web server running in the custom
    network:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we are executing a shell within the reference container, we can verify
    that the reference container’s hostname is the container’s ID by default before
    exiting:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'data directory in the current path, and we will just create the index.xhtml
    file by using a simple echo command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container run -d --net testnet -v $(pwd)/data:/usr/share/nginx/html
    \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --name webserver nginx:alpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'webserver service again:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container run -d --net testnet -v $(pwd)/data:/usr/share/nginx/html
    \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --name webserver2 nginx:alpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $ docker container exec -ti one curl webserver2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'index.xhtml file and verify the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that we can change the static content with the container in a running
    state. If your application manages static content, you will be able to verify
    the changes online while developing, but this may not work for your application
    if your processes read the information while they start. In these cases, you will
    need to restart/recreate your containers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '2.  Finally, let’s remove the second web server:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container run -d --net testnet \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –name webserver \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --mount type=bind,source=$(pwd)/data,target=/usr/share/nginx/html \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: nginx:alpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b2446c4e77be587f911d141238a5a4a8c1c518b6aa2a0418e574e89dc135d23b
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $ docker container exec -ti one curl webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: My webserver 2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '3.  Now, let’s test the behavior of a named volume:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s test this once more to verify the changes:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As we have seen, we can manage persistent data inside containers using volumes
    and we can copy some content inside them using `docker cp` (you can use the same
    command to retrieve the container’s content). We also tested all the internal
    communications; we didn’t expose any service outside of the container runtime
    environment. Let’s remove both `webserver` containers if they still exist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s move on to the next lab.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing applications
  prefs: []
  type: TYPE_NORMAL
- en: 'In this lab, we will expose the application’s containers outside of the container
    runtime’s internal networks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `--publish-all` or `-P` argument to publish all the image’s
    defined exposed ports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '2.  Now, let’s check the service from our host. We can use `localhost`, `127.0.0.1`,
    or `0.0.0.0` as the IP address because we didn’t specify any of the host’s IP
    addresses:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container commit one myalpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: sha256:6732b418977ae171a31a86460315a83d13961387daacf5393e965921499b446e
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you are using the `host` network in Linux directly, you will be able to connect
    directly to your container’s ports, even if they aren’t exposed. This doesn’t
    work in WSL environments directly, but you can use this behavior in cluster environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can use this new container by connecting it to the host’s network to
    verify how the network changed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container exec \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: -ti two ip add show|grep "inet "
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: inet 127.0.0.1/8 scope host lo
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: inet 192.168.65.4 peer 192.168.65.5/32 scope global eth0
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: inet 172.18.0.1/16 brd 172.18.255.255 scope global br-582fe354cf84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '2.  However, you should notice that DNS container resolution doesn’t work in
    the host network:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '3.  Let’s retrieve the web server’s IP address to access it via the host network
    container:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we will review how to limit access to the host’s hardware resources and
    how exceeding the memory limit will trigger the execution of the OOM-Killer kernel
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting containers’ resource usage
  prefs: []
  type: TYPE_NORMAL
- en: 'In this lab, we will review how to limit the host’s memory inside a container:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create a custom image, including the `stress-ng` application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker run -d --name stress stress stress-ng  \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --vm-bytes 1024M  --fork 1 -m 1
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'docker stats to retrieve the current container’s resource usage:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker stats --no-stream
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: CONTAINER ID   NAME      CPU %     MEM USAGE / LIMIT     MEM %     NET I/O     BLOCK
    I/O   PIDS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'stress container and run it again, limiting its access to the host’s memory:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker stats --no-stream
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: CONTAINER ID   NAME              CPU %     MEM USAGE / LIMIT   MEM %     NET
    I/O       BLOCK I/O   PIDS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ff3f4797af43   stress-limited   166.65%   125.1MiB / 128MiB   97.74%    1.12kB
    / 0B   0B / 0B     4
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker stats --no-stream
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: CONTAINER ID   NAME              CPU %     MEM USAGE / LIMIT   MEM %     NET
    I/O       BLOCK I/O   PIDS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ff3f4797af43   stress-limited   142.81%   127MiB / 128MiB     99.19%    1.12kB
    / 0B   0B / 0B     5
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ dmesg|grep -i oom
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[22893.337110] oom_reaper: reaped process 19232 (stress-ng), now anon-rss:0kB,
    file-rss:0kB, shmem-rss:32kB'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[22893.915193] stress-ng invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0,
    oom_score_adj=1000'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[22893.915221]  oom_kill_process.cold+0xb/0x10'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[22893.915307] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents
    oom_score_adj name'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: stress-ng worker processes, but it launches more (this is the normal stress-ng
    behavior, but your applications may die if OOM-Killer is asked to destroy your
    processes).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '2.  We will finish this lab by simply removing the used containers:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can now move on to the next lab, in which we will learn how to limit the
    use of privileged users in our processes if they are not needed.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding the use of root users inside containers
  prefs: []
  type: TYPE_NORMAL
- en: 'This quick lab will show you how to run an NGINX web server without `root`.
    But first, we will review what happens when you change the default NGINX environment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s review the user that a default `nginx:alpine` image will use by
    simply executing a new web server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ curl 0.0.0.0:8080 -I
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: HTTP/1.1 200 OK
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '2.  Now, let’s retrieve its logs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker logs webserver --details \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --timestamps --tail 2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2023-03-31T19:29:35.362006700Z  172.17.0.1 - - [31/Mar/2023:19:29:35 +0000]
    "GET / HTTP/1.1" 200 615 "-" "curl/7.81.0" "-"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '--timestamp to show the container runtime’s included timestamp. This can be
    very useful when the running application does not provide any timestamp.By default,
    NGINX writes to `/var/log/nginx/access.log` and `/var/log/nginx/error.log`. It
    is very interesting to learn how this container’s image developers set the processes
    up to write to `/dev/stdout` and `/dev/stderr`. You can learn more at [github.com/nginxinc/docker-nginx/blob/73a5acae6945b75b433cafd0c9318e4378e72cbb/mainline/alpine-slim/Dockerfile](http://github.com/nginxinc/docker-nginx/blob/73a5acae6945b75b433cafd0c9318e4378e72cbb/mainline/alpine-slim/Dockerfile).
    An extract of the currently important lines is shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '3.  Now, let’s check the user running this instance:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker container rm webserver --force -v
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '0 user (root) to a common 1000 ID:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker logs webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'nginx: [warn] the "user" directive makes sense only if the master process runs
    with super-user privileges, ignored in /etc/nginx/nginx.conf:2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2023/04/01 11:36:03 [emerg] 1#1: mkdir() "/var/cache/nginx/client_temp" failed
    (13: Permission denied)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '80 because it is system-restricted; if this port must be used in your environment,
    special capabilities such as NET_BIND_SERVICE should be added. Instead of changing
    the current image behavior, we will use a new image from NGINX, Inc.:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can find this image and its information at [https://hub.docker.com/r/nginxinc/nginx-unprivileged#!](https://hub.docker.com/r/nginxinc/nginx-unprivileged#!).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '4.  Let’s pull the image from Docker Hub and review the ports and the user
    used:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker image inspect \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: nginxinc/nginx-unprivileged:alpine-slim \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --format="{{ .Config.ExposedPorts }} {{ .Config.User }}"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '8080 on our host’s port 8080. Notice that we used the --publish option, which
    allows us to even use a specific IP address from our host in IP:host_port:container_port
    format:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '5.  Let’s test our web server again and review the logs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '6.  Now, let’s review the web server’s user:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we expected, this `webserver` application runs using a non-privileged user
    and it’s safer than the one running as `root`. You, as the developer, must prioritize
    the usage of non-privileged users in your applications to improve the components’
    security.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning the container runtime
  prefs: []
  type: TYPE_NORMAL
- en: 'To finish this chapter’s labs, we will quickly clean up all the objects that
    were created during the labs by using a combination of commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kill all the running containers (we can also remove them using a single line,
    but we will kill them before using the `prune` action):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '2.  Now, we can use `docker system prune` to remove all the objects that were
    created. We will use `--all` to remove all the unused images and the volumes by
    adding `–-volumes` (you will be asked for confirmation):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker system df
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Images          0         0         0B        0B
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Containers      0         0         0B        0B
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Local Volumes   0         0         0B        0B
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Build Cache     0         0         0B        0B
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In these labs, we covered almost all the content that we reviewed in this chapter.
    You may find additional information in the GitHub repository that’s been prepared
    for this chapter: [https://github.com/PacktPublishing/Docker-for-Developers-Handbook/tree/main/Chapter4](https://github.com/PacktPublishing/Docker-for-Developers-Handbook/tree/main/Chapter4).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we learned how to run containers and manage their behavior.
    We also reviewed how we can limit access to the host’s resources by applying different
    kernel features. Different techniques allow us to interact with containers while
    they are running, and we can use them to retrieve important information about
    the applications running inside. By the end of this chapter, we also learned about
    some simple commands that will help us keep our environments free of old unused
    containers’ objects.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to create container images, store them, and run containers
    using them, we can move on to the next chapter, where we will learn how to run
    applications by using multiple containers that interact with each other.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
