- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gaining Application Insights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have seen how to implement our applications using software
    containers and how Kubernetes helps us run them in production with security and
    high availability. We can run and manage our own Kubernetes environments to prepare
    our applications for any Kubernetes environment; few changes will be necessary
    to customize our deployments for specific platforms. In this chapter, we will
    learn how to gain access to our application’s Kubernetes resources and the different
    tools that can be used to identify problems in our applications. We will review
    **Prometheus** as a popular tool in the Kubernetes world for monitoring an application’s
    component health, interactions, and resources. We will also explore **Loki**,
    which is an open source logging platform that’s highly extensible, configurable,
    and easy to integrate with Kubernetes. By the end of this chapter, we will have
    taken a look at some **instrumentation** options for our applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a summary of the content in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding your application’s behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obtaining access to your Kubernetes resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring your application’s metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging your application’s important information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load testing your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding instrumentation to your application’s code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the labs for this chapter at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter12](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter12),
    where you will find some extended explanations that have been omitted from this
    chapter’s content to make it easier to follow. The *Code In Action* video for
    this chapter can be found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding your application’s behavior
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding how your application works can be very hard if you don’t know
    how your application works. This may sound obvious, but the better you know your
    application, the better you can implement different mechanisms to verify its status
    at every moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'You, as a developer, have to ask yourself which is the best place in your code
    to add monitoring endpoints or flags. But your application should also be monitored
    using external third-party tools, which leads us to the following list of monitoring
    mechanisms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Internal application metrics**: Implementing monitoring points in our code
    may be difficult at the end of the project, but if you introduce them from the
    beginning and measure the time between transactions, you will have a great overall
    performance view of your application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internal health checks**: Health checks are crucial for identifying when
    your application fails, but we can go further. We can have some simple error/OK
    quick tests that can be executed very often and help Kubernetes keep the application
    up and running.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External application metrics**: Some components such as databases may allow
    you to query certain metrics that can be exported and used by an external component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External health checks**: These health checks are used to provide a good
    overview of the application’s behavior. They can be complex and include multiple
    components, and they may trigger some alarms or create events that will help us
    manage the application’s status.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We haven’t talked about how any of these mechanisms can be implemented yet.
    While including some metrics in our application may require us to make some changes
    in the code, add some entries with metric values, or create the sources to be
    retrieved for such metrics, other points can be achieved by using external tools,
    outside of the application’s code.
  prefs: []
  type: TYPE_NORMAL
- en: Running your applications in containers can help you implement any of the models
    described here. But *never* include a parallel check process inside your application
    container. This is not how containers should be used. Remember that we introduced
    the concept of a container as the main process that runs isolated in a host, sharing
    its kernel among all other containers, in [*Chapter 1*](B19845_01.xhtml#_idTextAnchor015),
    *Modern Infrastructure and Applications with Docker*. Running more than one process
    is not a good practice because you will need to ensure that all processes receive
    SIGTERM or SIGKILL signals whenever the container needs to stop, and this may
    be tricky if you fork the processes and they run separately in the container’s
    namespace (the same as a PID namespace but without dependencies).
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to implement different models for monitoring,
    logging, and even tracing our application’s processes. But let’s get started by
    reviewing how to retrieve and manage our application’s Kubernetes resources from
    our own application’s workloads, which is key for some of the different tools
    we are going to use later.
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining access to your Kubernetes resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes, your applications need to manage certain Kubernetes resources. Let’s
    think about the following situations:'
  prefs: []
  type: TYPE_NORMAL
- en: The default Kubernetes autoscaling doesn’t cover our requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to create some resources triggered by an event – for example, when our
    application starts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In these scenarios, our application’s processes will need to retrieve information
    from the Kubernetes API and create some resources. If we think of this workflow,
    at least our Pods will require network access to the Kubernetes API server’s IP
    address and appropriate permissions for the required actions and resources. In
    this section, we will learn how to create and manage Kubernetes objects from our
    application’s processes.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to remember a few concepts from [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170),
    *Deploying Applications with* *the* *Kubernetes Orchestrator*. In that chapter,
    we talked about how Kubernetes improves our application’s security by using different
    authentication and authorization strategies. You may need to ask your Kubernetes
    administrators about some Kubernetes platform insights, but you will probably
    be using **role-based access control** (**RBAC**) in your environment because,
    currently, all Kubernetes platforms work with such a mechanism. This means that
    all Kubernetes API requests must be authorized by a **role authorization system**.
    Kubernetes will use either client certificates, bearer tokens, or an authenticating
    proxy to authenticate API requests through authentication plugins, and when client
    requests are authenticated, the authorization system will allow or deny them.
  prefs: []
  type: TYPE_NORMAL
- en: By default, all Pods running in a namespace will inherit a service account and
    its token to authenticate the application processes within the Kubernetes cluster.
    This behavior is not secure and that’s why it can be avoided by your Kubernetes
    administrators. But in any case, we will use a service account included in the
    Pod definition and its associated token to identify the processes and validate
    access to the specified resources and actions.
  prefs: []
  type: TYPE_NORMAL
- en: Within the Kubernetes cluster, the RBAC API declares roles and their bindings
    for pairing Kubernetes resources with the actions allowed for them. This role
    system will include namespaced authorizations (Role and RoleBinding resources)
    and cluster-wide authorizations (ClusterRole and ClusterRoleBinding resources),
    which help us provide fine-grained access.
  prefs: []
  type: TYPE_NORMAL
- en: Role and ClusterRole resources define rules that represent additive permissions;
    so, if no rule exists for a permission, it is denied. We will match resources
    and the verbs allowed for them in their manifest definitions. We will use ClusterRole
    resources to define cluster-wide permissions or define namespace-scoped permissions
    from a higher level, which allows us to reuse them in several namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example of a Role and how we associate it with a ServiceAccount
    resource using a RoleBinding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Role and RoleBinding resources allowing us to list and read
    Pods in a namespace](img/B19845_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Role and RoleBinding resources allowing us to list and read Pods
    in a namespace
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that in both resources, we defined `namespace` because we are using
    namespace-scoped resources (they can be omitted if we deploy them on the current
    namespace). In the Role resource, we defined the list of `verbs` or actions allowed
    and `resources` in which the actions will be applied (you can use `kubectl api-resources
    -o wide` to retrieve the verbs available for each Kubernetes resource). The `apiGroups`
    key is used when we have different resources with the same name but belonging
    to different APIs. Let’s see this configuration in action with a quick example.
    We will create both Role and RoleBinding resources in the `default` namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Creating resources so that Pods can be listed and read in a
    namespace](img/B19845_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Creating resources so that Pods can be listed and read in a namespace
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We can use either `kubectl create role pod-reader --verb=get,list,watch --resource=Pods`
    to create the `pod-reader` Role resource from the preceding code snippet.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have applied the RoleBinding resource to a specific service account, but
    it doesn’t exist yet. Let’s create it before moving on:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Creating the myserviceaccount ServiceAccount resource](img/B19845_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Creating the myserviceaccount ServiceAccount resource
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a Role that allows us to list, watch, and get Pods within any namespace
    (but applied to the current `default` namespace), and a RoleBinding associating
    this Role resource with a defined service account, `myserviceaccount`, in the
    `default`namespace. We will now run a Pod with this service account and get the
    list of current Pods. We will run a Pod with the `kubectl` command line included
    in the container image. We included the `myserviceaccount` service account resource
    and used `get pod` as arguments for the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4 – Creating a Pod that lists all the Pods in the current namespace](img/B19845_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Creating a Pod that lists all the Pods in the current namespace
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding code snippet, we created a Pod whose container will use the
    `myserviceaccount` service account to interact with the Kubernetes API. Notice
    that we just retrieved the logs from the Pod and we get the output from the `kubectl
    get pods` command line that’s executed. All the Pods running at the time of execution
    were listed. Let’s try the same with a new Pod that doesn’t use this service account:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can retrieve the logs from this new Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this time, the new Pod does not have access to the Kubernetes
    API (the `default` service account was used by default, which doesn’t have permission
    to list the Pods in the namespace).
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the Kubernetes API may become complex when you create custom resources
    and need fine-grained access, but be sure that the principles for managing RBAC
    access are the same.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You can implement your own `Kubeconfig` file to use with your application. Kubernetes
    offers out-of-the-box integration with a service account’s tokens, but you can
    use a Secret resource to include your authentication file and use it in your application.
    This is especially useful when you’re managing different Kubernetes clusters from
    a unified control plane cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In these examples, we are not using a NetworkPolicy resource, but you will need
    to ensure your Pods have access to Kubernetes API server Pods. These Pods will
    use control plane hosts’ IP addresses and port `6443`, although this may vary
    between Kubernetes platforms (confirm these requirements with your Kubernetes
    administrators). If your platform administrators configured GlobalNetworkPolicy
    resources, you may need to add some **egress** rules for your deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we used the kubectl Kubernetes client, but you will find client
    libraries and modules for different code languages, which makes integration more
    secure. Attackers will not be able to exploit erroneous RBAC configurations if
    your code only manages required resources. On the other hand, adding new functionalities
    may require you to recompile your code, but it is worth it. Here is a link to
    the current documentation, where you will find more information about the client
    libraries: [https://kubernetes.io/docs/reference/using-api/client-libraries/](https://kubernetes.io/docs/reference/using-api/client-libraries/).
    At the time of writing this book, C, .NET, Go, Perl, Python, Java, JavaScript,
    and Ruby, among other languages, are officially supported. If you require a different
    language, such as Rust, there are community projects developing libraries for
    accessing Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s introduce the concept of Kubernetes operators, which will help us
    deploy and operate applications in Kubernetes. We will use some of them in this
    chapter and it is interesting to learn the basics before we do so.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **Kubernetes operator** is a piece of software that runs and integrates with
    Kubernetes to manage applications and their components. They use the concepts
    we’ve learned about so far in this chapter to monitor and create resources as
    needed by your applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes operators are designed to automate most of the repetitive tasks
    a human operator must do to manage an application. There are many well-documented
    examples of Kubernetes operators that will help you perform tasks such as deploying
    databases with high availability, managing complex applications with multiple
    components with just one YAML manifest, and so on. These are some of the tasks
    you may expect from a Kubernetes operator designed for a certain application:'
  prefs: []
  type: TYPE_NORMAL
- en: Automated deployment of the application and all its components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management and creation of Kubernetes **CustomResourceDefinitions** (**CRDs**)
    required for the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backup and restore features that will help recover the application with easy
    steps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fully managed application upgrades, with all the internal application components
    such as database schema migrations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a leader when your application requires a distributed control plane
    or must manage the master-worker (or master-slave) relations between application
    components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, operators are key for managing complex application deployments,
    and their integration into Kubernetes makes things more simple. There are good
    examples of managing databases, created by the most important software database
    vendors, and for many other software categories. You may find what you need at
    [https://operatorhub.io](https://operatorhub.io). In the following section, we
    will use the **Prometheus Operator** to deploy and manage the Prometheus monitoring
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: In case you don’t find a Kubernetes operator that meets your application requirements,
    you can code your own operator using any of the **software development kits**
    (**SDKs**) available for different languages ([https://kubernetes.io/docs/concepts/extend-kubernetes/operator/#writing-operator](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/#writing-operator)).
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have learned how Kubernetes can be queried for some resources’ statuses
    and how to manage them within our applications. In the following section, we will
    learn how **third-party applications** can be used to monitor our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring your application’s metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing your application’s metrics is key to understanding how you are serving
    your users or other applications. In this section, we will learn how to monitor
    our applications using **Prometheus**, a monitoring solution that fits very well
    in the Kubernetes ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus is an open source monitoring solution that’s been hosted by the **Cloud
    Native Computing Foundation** (**CNCF**) since 2016\. It is used to collect, store,
    and represent metrics and alert users using thresholds. It can be integrated into
    any infrastructure, although it is known to work great with Kubernetes. It comes
    included within some Kubernetes platform deployments and that’s why it is considered
    standard within the Kubernetes community.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus includes a data model that is easy to query, using its own **Prometheus
    query language** (**PromQL**), which stores metrics recorded over time from different
    sources identified by key-value pairs. By default, Prometheus will pull different
    endpoints via HTTP requests, although pushing data is also available, but less
    common. These endpoints, usually identified as **targets**, can be auto-discovered
    or manually configured, which makes Prometheus fit perfectly in Kubernetes clusters
    where dynamism is a must.
  prefs: []
  type: TYPE_NORMAL
- en: Although Prometheus provides a graphing tool, it is very common to integrate
    it as a data source in more advanced dashboard tools such as **Grafana** or to
    directly consume its data via an API (using PromQL queries).
  prefs: []
  type: TYPE_NORMAL
- en: We are not going to cover this tool in depth in this book as it would be out
    of its scope, but we will review some of its components, quick installation, and
    how to implement some monitoring endpoints for your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Prometheus architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prometheus is based on at least five different components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prometheus server**: This is the core component. It retrieves metrics data
    from Prometheus exporters and adds data from the **Pushgateway**. All this data
    is stored in its own **time series database** (**TSDB**) and is available via
    the HTTP API, also managed by the Prometheus server component. It also checks
    the different configured thresholds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pushgateway**: There are some devices or components that can’t be scraped.
    The Pushgateway component allows you to directly push the data into Prometheus,
    instead of waiting for it to be pulled. Different libraries exist for common languages
    such as Java, Go, Python, and Ruby, among others supported by the community.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alertmanager**: Alertmanager handles all the alerts generated from the Prometheus
    server. Different notification backends can be used, such as email or webhooks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus web UI**: The provided web UI allows us to query stored metrics,
    quickly graph data, and review the status of the different targets configured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus exporters**: These components are the key to the extensibility
    of the platform. Many client libraries are officially supported for different
    code languages (and others are unofficially supported) that allow us to create
    metrics for our applications. When Prometheus scrapes your endpoints, the client
    library presents the data, and it will be stored in the server for later access
    or threshold validation. You can find officially supported Prometheus exporters
    inside GitHub’s Prometheus organization ([https://github.com/orgs/prometheus/repositories?q=exporter&type=all](https://github.com/orgs/prometheus/repositories?q=exporter&type=all)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prometheus can monitor your applications running in Kubernetes by either running
    inside your Kubernetes cluster (in its own namespace or even within your application’s
    namespace, which is not recommended) or externally, in a different infrastructure,
    such as virtual machines. It is recommended to run Prometheus inside your Kubernetes
    cluster because you will be able to use internal communications, instead of having
    to publish your exporters externally to be pulled from outside of the cluster.
    This will improve security, even if you expose your exporters internally using
    HTTP instead of HTTPS protocol. Running in Kubernetes will allow us to deploy
    Prometheus as a Kubernetes operator, which will help us implement the auto-discovery
    of targets as well as an easy-to-manage complete monitoring platform. All the
    components will be installed for us, and we will just have to configure how they
    should be deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Prometheus
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To install the Prometheus monitoring platform, we will use **Helm**, which
    is a tool that allows us to easily customize and deploy a set of manifests. We
    will deep dive into using Helm to package applications in [*Chapter 13*](B19845_13.xhtml#_idTextAnchor287),
    *Managing the* *Application Life Cycle*. In this case, these manifests include
    the **kube-prometheus** platform components ([https://github.com/prometheus-operator/kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)).
    The kube-prometheus community project installs a cluster-ready monitoring platform
    with the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Prometheus Operator**, which will create its own CRDs and manage the Service
    discovery integration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus** and **Alertmanager** with high availability, both deployed as
    StatefulSets. A set of default alerts is included, which will help you start monitoring
    your Kubernetes environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus node-exporter**, deployed as a DaemonSet to all the Kubernetes
    cluster nodes. This exporter will have host-related metrics such as CPU, memory,
    and disk space available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus Adapter for Kubernetes Metrics APIs**, which integrates all the
    Kubernetes Metrics Server metrics into Prometheus automatically.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kube-state-metrics**, which connects with the Kubernetes API server and retrieves
    the status of different resources such as Pods, Deployments, and so on, and delivers
    them as metrics for Prometheus. By default, important metrics are created and
    configured for you.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grafana**, deployed as part of the platform to enhance Prometheus graphs
    in Grafana dashboards. A set of default dashboards is included to show you how
    your platform works.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The default alerts and dashboards included in the kube-prometheus project are
    taken from the **kubernetes-mixin** project ([https://github.com/kubernetes-monitoring/kubernetes-mixin](https://github.com/kubernetes-monitoring/kubernetes-mixin)),
    which provides a set of well-documented rules and simple dashboards for monitoring
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: You, as a developer, will probably not use many of the dashboards and metrics
    provided by this platform, but it will help you understand how to implement your
    metrics and rules and create dashboards with your data.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the `kube-prometheus-stack` is easy. A Helm Chart (Helm-specific
    package) is ready for us. We will just add the Prometheus community Helm Charts
    repository, update the repositories cache, and install a Helm Chart release in
    our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Rancher Desktop, Helm comes preinstalled with your command-line
    tools, but on other platforms, it may be necessary to install it before using
    it. Helm is available for Windows, macOS, and Linux and there are different methods
    for installing it. We recommend that you use the binary directly. That way, you
    can update it whenever you need it and use a different release if required. If
    you are using Windows, you can use `Get-Content` to download it and then add it
    to your `PATH`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Installing the Helm binary using gc to download the required
    package](img/B19845_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Installing the Helm binary using gc to download the required package
  prefs: []
  type: TYPE_NORMAL
- en: 'Once Helm has been installed, we will just use `helm install` with `--create-namespace`
    to tell Helm to create a new namespace for us. In this example, we are using Minikube
    as the Kubernetes environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Installing the Prometheus stack using Helm](img/B19845_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Installing the Prometheus stack using Helm
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few seconds, the Prometheus stack will be up and running. At this point,
    we can check the platform’s Pod and Service resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Prometheus stack Pod and Service resources](img/B19845_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Prometheus stack Pod and Service resources
  prefs: []
  type: TYPE_NORMAL
- en: This small installation is intended only for local usage – so that you can develop
    your own monitors for your application on your desktop computer. Notice that we
    didn’t even include a PersistentVolume, so data will be lost every time you restart
    your environment. A lot of customizations can be done at the installation level
    to cover all your specific needs, but you should read the documentation before
    configuring your own Helm values YAML file ([https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml)).
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the Prometheus environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will learn about the GUI and features of Prometheus. We
    can get into Prometheus by using the `prometheus-stack-grafana` Service:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a quick review, we will use `port-foward` to access the Grafana web UI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 12.8 – Prometheus GUI showing the Status section](img/B19845_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Prometheus GUI showing the Status section
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can go to the **Targets** section and review which targets are currently
    monitored by the Prometheus platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Prometheus GUI showing the Targets section](img/B19845_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Prometheus GUI showing the Targets section
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the filter on the right-hand side to uncheck the **Healthy** targets
    and view which targets are currently down:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Prometheus GUI showing the Unhealthy targets in the Targets
    section](img/B19845_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Prometheus GUI showing the Unhealthy targets in the Targets section
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry – this is normal. Minikube does not expose all the Kubernetes metrics;
    therefore, some monitoring endpoints will not be available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review some of the metrics that are currently retrieved by clicking on
    `container_cpu_usage_seconds_total` metric):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Prometheus GUI showing the Graph section with a metric as
    a query](img/B19845_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Prometheus GUI showing the Graph section with a metric as a query
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we only have metrics from objects running on the **kube-system**
    and **monitoring** (created for the stack itself) namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a quick web server deployment on the default namespace and verify
    that it appears in the monitoring platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In a few seconds, the new Pod for the web server deployment will appear in
    the Prometheus **Graph** section:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Filtered list of Kubernetes containers using CPU](img/B19845_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Filtered list of Kubernetes containers using CPU
  prefs: []
  type: TYPE_NORMAL
- en: Notice that in this case, we used a new PromQL query, `container_cpu_usage_seconds_total{namespace!~"monitoring",namespace!~"kube-system"}`,
    in which we removed any metrics from the `monitoring` and `kube-system` namespaces.
    The metrics were automatically included thanks to the Prometheus Adapter for the
    Kubernetes Metrics APIs component.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge of Kubernetes metrics or Pod metrics is outside the scope of this
    chapter. We are using Prometheus to show you how you can deliver your application
    metrics. Each exporter or integration mentioned in this section has its documentation,
    where you will find information about the metrics available. The use of PromQL
    and Prometheus itself is also outside the scope of this book. You can find very
    useful documentation at [https://prometheus.io/docs](https://prometheus.io/docs).
    To monitor our applications and retrieve their active hardware resource consumption,
    we don’t need to deploy the Alertmanager component, which will reduce the requirements
    of your desktop environment.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus uses labels to filter resources. Choosing good metrics and label
    conventions will help you design your application monitoring. Take a close look
    at [https://prometheus.io/docs/practices/naming](https://prometheus.io/docs/practices/naming),
    where the documentation explains a good naming and labeling strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know about the basics of the Prometheus interface, we can move on
    and review how the Prometheus server gets infrastructure and application data.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how Prometheus manages metrics data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s review how targets are configured by the Prometheus Operator:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will retrieve the new CRDs created by the Prometheus stack deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.13 – Filtered list of available Kubernetes API resources](img/B19845_12_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 – Filtered list of available Kubernetes API resources
  prefs: []
  type: TYPE_NORMAL
- en: The Prometheus Operator will use **PodMonitor** and **ServiceMonitor** resources
    to query the associated endpoints in time intervals. Therefore, to monitor our
    application, we will need to create a custom metric exporter, to provide the application
    metrics, and a PodMonitor or ServiceMonitor to expose them for Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a quick look at some of the metrics that have been exposed. We will
    review the Node Exporter component here. The Service resource associated with
    this monitoring component can be easily retrieved using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s expose that Pod and review the presented data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.14 – Exposing Prometheus Node Exporter via the port forwarding
    feature](img/B19845_12_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.14 – Exposing Prometheus Node Exporter via the port forwarding feature
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now open a new PowerShell terminal and use `Invoke-WebRequest` to retrieve
    the data or any web browser (you will obtain an intermediate web page indicating
    that the metrics will be found in the `/``metrics` path):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.15 – Metrics available from Node Exporter, exposed via port forwarding
    in local port 9100](img/B19845_12_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.15 – Metrics available from Node Exporter, exposed via port forwarding
    in local port 9100
  prefs: []
  type: TYPE_NORMAL
- en: 'The metrics for the Node Exporter component are published internally by an
    associated Service resource. This is how we should create our monitoring endpoint.
    We can use two different architectures here:'
  prefs: []
  type: TYPE_NORMAL
- en: Integrate our monitoring component inside our application Pod using a new container
    and sidecar pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run a separate Pod with the monitor component and retrieve the data internally
    using the Kubernetes overlay network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You must remember that the containers running inside a Pod share a common IP
    address and will always be scheduled together. This may be the main difference
    and why you will probably choose the first option from the preceding list. Running
    a different Pod will also require some dependency tracking between both Pods and
    node affinity patterns (if we want them to run together on the same host). In
    either of these situations, we will need a PodMonitor or ServiceMonitor resource.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll take a quick look at how Prometheus will automatically scrape metrics
    from a new exporter when we create exporters for our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Scraping metrics with Prometheus
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prometheus installation creates a new resource, `Prometheus`, which represents
    a Prometheus instance. We can list Prometheus instances in our cluster (we used
    `-A` to include all the namespaces in the search):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If we take a look at this resource, we will realize that two interesting keys
    will decide which resources to monitor. Let’s get the `Prometheus` resource YAML
    manifest and review some interesting keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This `Prometheus` resource includes important keys to modify the behavior of
    Prometheus itself (such as `scrapeInterval`, data `retention`, and `evaluationInterval`).
    From the preceding code snippet, we can see that all the ServiceMonitor resources
    from all namespaces will be monitored if they include the `release=prometheus-stack`
    label. The same is required for PodMonitors, so we will just create a ServiceMonitor
    resource for our new application monitor. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.16 – ServiceMonitor example manifest](img/B19845_12_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.16 – ServiceMonitor example manifest
  prefs: []
  type: TYPE_NORMAL
- en: In the *Labs* section, we will add some open source monitoring endpoints for
    our application (the **Postgres exporter** from [https://grafana.com/oss/prometheus/exporters/](https://grafana.com/oss/prometheus/exporters/)).
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s review some quick concepts for configuring a good logging strategy
    for our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Logging your application’s important information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will get a general overview of different logging strategies
    and how to implement an open source Kubernetes-ready solution such as **Grafana
    Loki**.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096), *Running Docker Containers*,
    we talked about which strategies were available for our applications. As a rule
    of thumb, processes running in containers should always log standard and error
    outputs. This makes it easier or at least prepares a good solution for all the
    processes at the same time. However, your application may need a different **logging
    strategy** for different use cases. For example, you shouldn’t log any sensitive
    information to the standard output. While local logging can be helpful when you
    are developing your application, it may be very tricky (or even only available
    for Kubernetes administrators) in a development or production environment. Therefore,
    we should use either volumes or an external logging ingestion platform. Using
    volumes may require additional access so that you can recover your logs from a
    storage backend, so an external platform would be a better approach for covering
    your logging needs. The fact is that using an external platform can make your
    life easier if your application runs in Kubernetes. There are plenty of Kubernetes-ready
    logging platforms that will allow you to push all your container logs to a backend
    in which you will be able to manage and add appropriate views for different users.
    This will solve the problem of logging sensitive data because it may be necessary
    for debugging purposes but only visible to certain trusty users. You may need
    to ask your Kubernetes administrators because you will probably have a logging
    solution already working on your Kubernetes platform.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll discuss how you can use Grafana Loki in your Kubernetes
    environment to read and forward your application’s containers and send them to
    a unified backend, in which we will be able to use additional tools such as Grafana
    to review the application’s data.
  prefs: []
  type: TYPE_NORMAL
- en: Grafana Loki can be deployed using different modes, depending on the size of
    your platform and the number of logs expected. To develop and prepare the logs
    of your applications, we will use a minimal installation, as we already did with
    Prometheus. We will use the **monolithic** mode ([https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/](https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/)),
    in which all of Loki’s microservices will run together in a single container image.
    Loki is capable of managing a large number of logs and it uses object storage
    backends. For our needs as developers, it won’t be necessary, and we will just
    use local storage (filesystem mode) provided by our own Kubernetes platform.
  prefs: []
  type: TYPE_NORMAL
- en: While Grafana Loki provides the server-side part, **Grafana Promtail** will
    work as an agent, reading, preparing, and sending logs to Loki’s backend.
  prefs: []
  type: TYPE_NORMAL
- en: We are not interested in how Grafana Loki or Prometheus work or can be customized.
    The purpose of this chapter is to learn how we can use them to monitor and log
    our application’s processes, so we will install Loki and configure Promtail to
    retrieve the logs from Kubernetes deployed applications.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Loki and Promtail
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s move forward by installing Grafana Loki in our Kubernetes cluster so
    that we can manage all the platform logs. After that, we will be ready to install
    Promtail to retrieve and push the logs to the Loki server:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use `helm` again to install Grafana Loki in a different namespace.
    The simplest installation is the single binary chart method with filesystem storage
    ([https://grafana.com/docs/loki/latest/installation/helm/install-monolithic](https://grafana.com/docs/loki/latest/installation/helm/install-monolithic)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.17 – Grafana Loki installation using Helm](img/B19845_12_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.17 – Grafana Loki installation using Helm
  prefs: []
  type: TYPE_NORMAL
- en: 'We used the following settings to apply the monolithic mode and remove API
    authentication:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: All these flags will help you reduce the hardware resources required for a testing
    environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'It is now up and running. Let’s take a quick look at the Service resources
    before installing the Promtail component:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.18 – Grafana Loki Service resources](img/B19845_12_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.18 – Grafana Loki Service resources
  prefs: []
  type: TYPE_NORMAL
- en: We’ve reviewed the Loki Services because we are going to configure Promtail
    to send all the logging information retrieved to the `loki-gateway` Service, available
    in the `logging` namespace on port `80`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Helm can show us the default values that will be used to install a Helm Chart
    if we execute `helm show values <CHART>`. So, we can retrieve the default values
    for the `grafana/promtail` chart by issuing `helm show values grafana/promtail`.
    The output is huge, with all the default values shown, but we only need to review
    the client configuration. This configuration applies to Promtail and defines where
    to send the logs that are read from the different sources:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'By default, Promtail will send all the data to `http://loki-gateway`, which
    we have seen exists inside the Kubernetes cluster if we run this tool in the logging
    namespace, alongside Grafana Loki. We’ll proceed to install Promtail using the
    logging namespace, using the default values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.19 – Promtail installation using a Helm Chart](img/B19845_12_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.19 – Promtail installation using a Helm Chart
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, we can review the logs of all Kubernetes clusters in Grafana.
    But first, we will need to configure Prometheus (monitoring) and Loki (logging)
    data sources in Grafana. We will use port forwarding to expose the Grafana Service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 12.20 – Grafana – Data sources configuration](img/B19845_12_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.20 – Grafana – Data sources configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that the deployment of Grafana using the `kube-prometheus-stack` Chart
    already configured the Prometheus and Alertmanager data sources for us. We will
    configure a new data source for Loki:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.21 – Grafana Loki data source configuration](img/B19845_12_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.21 – Grafana Loki data source configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Save & Test** – and that’s it! You may receive an error stating
    “**Data source connected, but no labels were received. Verify that Loki and Promtail
    are correctly configured**”. This indicates that we don’t have labels available
    yet for indexing data; it occurs when you have just installed the Promtail component.
    If you wait a few minutes, labels will be available, and everything will work
    correctly. Anyway, we can verify the Loki data by clicking the **Explore** button,
    at the beginning of the **Data sources** | **Settings** page. The **Explore**
    section allows us to retrieve data directly from any Loki-type source. In our
    example, we used Loki as the name of the source, and we can select the available
    labels generated by Promtail with the information from our containers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.22 – Exploring Loki data sources](img/B19845_12_22_new.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.22 – Exploring Loki data sources
  prefs: []
  type: TYPE_NORMAL
- en: 'We can retrieve all the logs from the `kube-system` namespace by simply selecting
    the namespace label and the appropriate value from the list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.23 – Exploring the logs from all the Pod resources from the kube-system
    namespace](img/B19845_12_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.23 – Exploring the logs from all the Pod resources from the kube-system
    namespace
  prefs: []
  type: TYPE_NORMAL
- en: You will be able to filter by any of the current labels and add very useful
    operations such as grouping, counting the number of appearances of certain strings,
    searching for specific regex patterns, and so on. Lots of options are available
    and they will be very useful for you as a developer. You can have all the logs
    from different applications’ components in one unified dashboard, or even prepare
    your own application dashboard with metrics and logs, mixing different sources.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus, Loki, and Grafana are very powerful tools and we can only cover
    the basics here. It is up to you to create dashboards using the Grafana documentation
    ([https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/](https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/)).
    The Grafana community provides many dashboard examples ([https://grafana.com/grafana/dashboards/](https://grafana.com/grafana/dashboards/)).
    We will create a fully functional dashboard for the `simplestlab` application
    in the *Labs* section.
  prefs: []
  type: TYPE_NORMAL
- en: The next section will introduce some load-testing mechanisms and review how
    to use the **Grafana k6** open source tool.
  prefs: []
  type: TYPE_NORMAL
- en: Load testing your applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Load testing** is the task in which we review how our application works by
    measuring its behavior under different stressful circumstances. You, as a developer,
    always have to think about how your application will manage these stressful situations
    and try to answer some of the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Will my application work under high user loads?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will my application’s components be impacted in such a case?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will scaling up some components maintain the overall performance or might this
    cause problems with other components?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the application before it goes to production will help us predict how
    the application is going to work. **Automation** is key to simulating thousands
    of requests at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'With load testing or **performance testing**, we try to put pressure on our
    applications and increase their workloads. We can test our applications for different
    reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: To understand how our application behaves with an expected load
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To ascertain the maximum load under which our application will work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To try to find possible memory or performance issues that could appear over
    time (memory leaks, fulfillment of certain storage resources, cache, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To test how our application auto-scales in certain circumstances and how the
    different components will be affected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To confirm some configuration changes in development before they are done in
    production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To test the application performance from different locations that have different
    network speeds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these test points can be delivered with some scripting techniques and automation.
    Depending on the application we are testing, we can use some well-known, simple
    but effective tools such as **Apache JMeter** ([https://jmeter.apache.org](https://jmeter.apache.org))
    or – even simpler – **Apache Bench** ([https://httpd.apache.org/docs/2.4/programs/ab.xhtml](https://httpd.apache.org/docs/2.4/programs/ab.xhtml)).
    These tools can emulate application requests but they never behave like a real
    web browser, but **Selenium** ([https://www.selenium.dev](https://www.selenium.dev))
    does. This tool includes a **WebDriver** component that emulates a **World Wide
    Web Consortium** (**W3C**) browsing experience, but it may be complex to integrate
    into automated processes (different releases and integration with different languages
    can be time-consuming). Grafana provides k6, which is an open source tool that
    was created by Load Impact some years ago and is now part of the Grafana tools
    ecosystem. It is a very small tool, written in Go, and can be configured via JavaScript,
    which makes it very customized.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Grafana k6 functionality can be extended by using extensions, although you will
    need to recompile your k6 binary to include them ([https://k6.io/docs/extensions](https://k6.io/docs/extensions)).
  prefs: []
  type: TYPE_NORMAL
- en: Grafana k6 tests can be integrated into the **Grafana SaaS platform** (**Grafana
    Cloud**) or your own Grafana environment, although some features are only available
    in the cloud platform at the time of writing this book.
  prefs: []
  type: TYPE_NORMAL
- en: Installing this tool is very simple; it can be run on Linux, macOS, and Windows
    and is suitable for running within containers, which makes it perfect to run in
    Kubernetes as a Job resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install this tool on Windows, open a PowerShell console with administrator
    privileges and execute `winget` `install k6`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.24 – Grafana k6 installation on Windows](img/B19845_12_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.24 – Grafana k6 installation on Windows
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see a quick example of its usage by writing a simple JavaScript `check`
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now test this example script for 10 seconds, simulating five virtual
    users with the k6 command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.25 – Executing a k6 test script](img/B19845_12_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.25 – Executing a k6 test script
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we are verifying a `200` code that was returned from
    the page. We can now use 5,000 virtual users for the same amount of time, which
    may create performance problems in the backend. The results can be integrated
    into different analysis tools such as Prometheus, Datadog, and so on. If you are
    already familiar with Prometheus and Grafana, you will probably like k6.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a bunch of good usage examples ([https://k6.io/docs/examples](https://k6.io/docs/examples))
    in which Grafana documents different use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Single and complex API requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTTP and OAuth authentication with authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The correlation of tokens, dynamic data, and cookie management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: POST data parameterization and HTML forms and the parsing of results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data uploads or scraping websites
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load testing of HTTP2, WebSockets, and SOAP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can create a more complex example by adding some content parsing and increasing
    and decreasing the number of virtual users during the execution of the test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, we are looking for all the `link` strings and
    retrieving their `href` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.26 – Executing a k6 test script parsing the “links” string](img/B19845_12_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.26 – Executing a k6 test script parsing the “links” string
  prefs: []
  type: TYPE_NORMAL
- en: Grafana k6 is very configurable. We can define stages in which we can change
    the behavior of the probe during the check as well as many complex features that
    are completely outside the scope of this book. We suggest that you read the tool’s
    documentation for a better understanding of its functionality and to customize
    it to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: We will now jump into the instrumentation part. In the next section, we will
    learn how to integrate some tracing technologies into our application observability
    strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Adding instrumentation to your application’s code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you code your applications, it should be easy to prepare appropriate monitoring
    endpoints and adequate monitoring tools to retrieve your application’s metrics.
    Observability helps us understand applications without really having good knowledge
    of their internal code. In this section, we will explore some tools that provide
    traces, metrics, and logs for our applications, without actively knowing our applications’
    functionality. **Monitoring** and **logging** are part of the observation tasks
    but in a different context. We actively know where to retrieve the monitoring
    and logging information from, but sometimes, we need to go further – for example,
    when we run a third-party application or we don’t have enough time to add monitoring
    endpoints to our application. It is important to prepare for monitoring your applications
    from the very beginning, even when you start to plan your application. The same
    applies to the logging part – you have to prepare your application to provide
    good logging information and not merely through the output of your processes as
    they are.
  prefs: []
  type: TYPE_NORMAL
- en: Distributing the same type of tracing, logging, and monitoring among your application’s
    components will help you understand what is going on in your application and follow
    every request through the different steps taken in your application’s processes.
    The traces, metrics, and logging data obtained are considered your application’s
    telemetry.
  prefs: []
  type: TYPE_NORMAL
- en: '**OpenTelemetry** has become a standard observability framework. It is open
    source and provides different tools and SDKs that help implement a telemetry solution
    to easily retrieve traces, logs, and metrics from your applications. This data
    can be integrated into Prometheus and other observability tools, such as Jaeger.'
  prefs: []
  type: TYPE_NORMAL
- en: The main goal of the OpenTelemetry platform is to add observability to your
    applications without any code modification. Currently, the Java, Python, Go, and
    Ruby programming languages are supported. The simplest way of working with OpenTelemetry
    in Kubernetes is using the **OpenTelemetry Operator**. This Kubernetes operator
    will deploy the required OpenTelemetry components for us and create the associated
    CRDs that will allow us to configure the environment. This implementation will
    deploy the Collector’s components, which will receive, process, filter, and export
    telemetry data to designed backends, and create the **OpenTelemetryCollector**
    and instrumentation resource definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four different ways or modes of deploying an OpenTelemetry Collector:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deployment Mode** allows us to control the Collector as if it were a simple
    application running in Kubernetes, and it is suitable for monitoring a simple
    application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DaemonSet Mode** will run a collector replica as an agent, on each cluster
    node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**StatefulSet Mode**, as expected, will be suitable when you don’t want to
    lose any tracing data. Multiple replicas can be executed and each one will have
    a dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sidecar Mode** will attach a collector container to the application’s workloads,
    which is better if you create and remove applications often (perfect for a development
    environment). It also offers a more fine-grained configuration if you use different
    languages and want to choose specific collectors for each application component.
    We can manage which collector to use for a specific Pod with special annotations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s run a quick demo environment from the OpenTelemetry community ([https://github.com/open-telemetry/opentelemetry-demo/](https://github.com/open-telemetry/opentelemetry-demo/)).
    This demo deploys a web store example application, Grafana, Jaeger, and the required
    OpenTelemetry components to obtain an application’s metrics and traces.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '**Jaeger** is a distributed tracing platform that maps and groups application
    flows and requests to help us understand workflow and performance issues, analyze
    our Services and their dependencies, and track down root causes when something
    goes wrong in our applications. You can find its documentation at the project’s
    URL: [https://www.jaegertracing.io/](https://www.jaegertracing.io/).'
  prefs: []
  type: TYPE_NORMAL
- en: The full demo is installed via a Helm Chart (`open-telemetry/opentelemetry-demo`).
    We can deploy it on any namespace, but all the components will run together. The
    presented demo provides a very good overview of what we can include in our desktop
    environment in either Docker Desktop, Rancher Desktop, or Minikube (it may work
    on any other Kubernetes environment), although it doesn’t follow some of the modern
    OpenTelemetry best practices for adding traces and managing collectors. This demo
    doesn’t deploy the Kubernetes OpenTelemetry Operator, and the OpenTelemetry Collector
    is deployed as a simple deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll install the demo and review the application and tools
    that have been deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the OpenTelemetry demo
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will install and review some of the most important features
    of a ready-to-use demo prepared by the OpenTelemetry project. This demo will deploy
    a simple web store application and the tools required for managing and retrieving
    the tracing data from different components (you can find additional useful information
    at [https://opentelemetry.io/docs/demo](https://opentelemetry.io/docs/demo)):'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will install the demo by following the simple steps described at
    [https://opentelemetry.io/docs/demo/kubernetes-deployment/](https://opentelemetry.io/docs/demo/kubernetes-deployment/).
    We will add the OpenTelemetry project’s Helm Chart repository and then issue `helm
    install` with the default values included in the demo package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.27 – OpenTelemetry demo application deployment](img/B19845_12_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.27 – OpenTelemetry demo application deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, different web UIs were deployed. We can quickly review the
    different Pods that were created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.28 – OpenTelemetry demo application running Pods](img/B19845_12_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.28 – OpenTelemetry demo application running Pods
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use port forwarding so that we can get quick and easy access to all
    the available demo web UIs. All will be reachable at once at localhost using different
    paths, thanks to a reverse proxy deployed with the demo Helm Chart. The web store
    application will be available at `http://localhost:8080`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.29 – Web store demo application accessible using the port-forward
    kubectl feature](img/B19845_12_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.29 – Web store demo application accessible using the port-forward
    kubectl feature
  prefs: []
  type: TYPE_NORMAL
- en: The demo web store shows a catalog of telescopes, and it will simulate a shopping
    experience.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now access Jaeger at `http://localhost:8080/jaeguer/ui`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.30 – The Jaeger UI using the port-forward kubectl feature](img/B19845_12_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.30 – The Jaeger UI using the port-forward kubectl feature
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Jaeger UI, we can select which Service to review, and the different
    traces will appear in the right panel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.31 – The Jaeger UI showing traces for different application Services](img/B19845_12_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.31 – The Jaeger UI showing traces for different application Services
  prefs: []
  type: TYPE_NORMAL
- en: 'An architecture overview is also available in the **System Architecture** tab
    so that you can verify the relations between the different application components:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.32 – The Jaeger UI showing the application components](img/B19845_12_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.32 – The Jaeger UI showing the application components
  prefs: []
  type: TYPE_NORMAL
- en: Notice that there’s a load generator workload, which is creating synthetic requests
    for us to be able to retrieve some statistics and traces from the demo environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The demo deployment also installs Grafana and Prometheus. The Grafana UI is
    available at `http://localhost:8080/grafana` and Prometheus and Jaeger data sources
    are configured for us:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.33 – The Grafana UI showing the configured data sources](img/B19845_12_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.33 – The Grafana UI showing the configured data sources
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we can use Grafana to graph the data from both data sources and
    create an application dashboard. The people from OpenTelemetry have prepared some
    dashboards for us, showing the application’s metrics and traces:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.34 – Grafana’s Dashboards page and the Spammetrics Demo Dashboard
    showing current requests per Service](img/B19845_12_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.34 – Grafana’s Dashboards page and the Spammetrics Demo Dashboard
    showing current requests per Service
  prefs: []
  type: TYPE_NORMAL
- en: We could have included Grafana Loki in this scenario, added some of the logging
    entries, and, finally, created a custom dashboard with all the relevant metrics,
    traces, and log entries. The Grafana platform can even include certain databases
    as data sources, which will improve the overall overview of our application’s
    health.
  prefs: []
  type: TYPE_NORMAL
- en: Labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will show you how to implement some of the techniques that were
    covered in this chapter using the `simplestlab` three-tier application in Kubernetes.
    We will deploy a complete observability platform, including Grafana, Prometheus,
    and Loki, and prepare some exporters for our application’s components.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for these labs is available in this book’s GitHub repository at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git](https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git).
    Ensure you have the latest revision available by simply executing `git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git`
    to download all its content or `git pull` if you’ve already downloaded the repository
    before. All the manifests and steps required for running the labs are included
    in the `Containers-for-Developers-Handbook/Chapter12` directory. All the manifests
    required for the labs are included in the code repository. Detailed instructions
    for running the labs are included in the `Chapter12` directory, after you download
    the associated GitHub. Let’s take a brief look at the steps that are to be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create a Minikube Kubernetes environment on our desktop computer.
    We will deploy a simple cluster with one node and ingress and metrics-server plugins:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Chapter12$ kubectl create ns simplestlab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Chapter12$ kubectl create -f .\simplestlab\ /
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: simplestlab application in the cluster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we will deploy a functional monitoring and logging environment on top
    of our Kubernetes desktop platform. To do this, we will first deploy the Kubernetes
    Prometheus stack. We prepared a custom `kube-prometheus-stack.values.yaml` values
    file with appropriate content for deploying a small environment with Grafana and
    Prometheus. We’ve provided the required Helm Charts inside the `Chapter12/charts`
    directory. In this case, we will use the `kube-prometheus-stack` subdirectory.
    To deploy the solution, we will use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: helm install loki --namespace logging /
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Chapter12/charts/promtail directory. We will leave the default values as they
    are because the communication with Loki will only be internal:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By the end of these labs, we will have modified our `simplestlab` application,
    adding some Prometheus exporters for monitoring different application components
    that will help us customize these components for the best performance. We will
    integrate a Postgres database exporter and the NGINX exporter for the `loadbalancer`
    component of `simplestlab`. Manifests for both integrations have been prepared
    for you in the `Chapter12/exporters` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Prometheus must be configured to poll these new targets – the Postgres database
    and NGINX exporters. We will prepare a ServiceMonitor resource for each one to
    inform Prometheus to retrieve metrics from these new sources. The ServiceMonitor
    resources manifests are included in the `Chapter12/exporters` directory. Here
    is the one that’s been prepared for you for the NGINX component:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Detailed information about creating simple queries in Grafana to graph data
    using these new metrics is available in the `Readme.md` file for this chapter,
    in this book’s GitHub repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The labs we’ve prepared for you in this chapter will give you an overview of
    how to implement a simple monitoring and logging solution for your applications
    and prepare some metrics to review the performance of some of your application’s
    components.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to implement some tools and techniques for monitoring,
    logging, and tracing our application workloads in Kubernetes. We also took a quick
    look at the load testing task, with an overview of what you should expect from
    your probes. We talked about Grafana, Prometheus, and Loki, among other tools,
    but the principles we discussed in this chapter can be applied to any monitoring,
    logging, or tracing tool you use.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring how much of the hardware resources your application consumes and
    reading the logs of your application’s components in a unified environment can
    help you understand your application’s limits and requirements. If you test how
    it behaves under heavy load, it can help to improve your application’s logic and
    predict the performance under unexpected circumstances. Adding traces to your
    code manually or using some of the automation mechanisms seen in this chapter
    will help you go further with your application’s development by understanding
    their insights and integrations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will make all the concepts seen so far fit in the application’s
    life cycle management.
  prefs: []
  type: TYPE_NORMAL
- en: Part 4:Improving Applications’ Development Workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we will review some well-known application life cycle management
    phases and best practices. We will cover how working with containers improves
    them, reviewing some continuous integration and continuous deployment logical
    patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B19845_13.xhtml#_idTextAnchor287), *Managing the Application
    Life Cycle*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
