- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Gaining Application Insights
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取应用程序洞察
- en: So far in this book, we have seen how to implement our applications using software
    containers and how Kubernetes helps us run them in production with security and
    high availability. We can run and manage our own Kubernetes environments to prepare
    our applications for any Kubernetes environment; few changes will be necessary
    to customize our deployments for specific platforms. In this chapter, we will
    learn how to gain access to our application’s Kubernetes resources and the different
    tools that can be used to identify problems in our applications. We will review
    **Prometheus** as a popular tool in the Kubernetes world for monitoring an application’s
    component health, interactions, and resources. We will also explore **Loki**,
    which is an open source logging platform that’s highly extensible, configurable,
    and easy to integrate with Kubernetes. By the end of this chapter, we will have
    taken a look at some **instrumentation** options for our applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书中我们已经看到如何使用软件容器实现应用程序，以及Kubernetes如何帮助我们在生产环境中运行它们，并确保安全性和高可用性。我们可以运行并管理自己的Kubernetes环境，为任何Kubernetes环境准备我们的应用程序；为了定制部署到特定平台，我们只需要做少量的修改。在本章中，我们将学习如何获取访问我们应用程序的Kubernetes资源权限，以及可以用于识别应用程序问题的不同工具。我们将回顾**Prometheus**，这是Kubernetes世界中用于监控应用程序组件健康状况、交互和资源的流行工具。我们还将探索**Loki**，这是一个开源日志平台，具有高度的可扩展性、可配置性，并且容易与Kubernetes集成。在本章结束时，我们将了解一些可用于应用程序的**仪器化**选项。
- en: 'Here is a summary of the content in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本章内容的总结：
- en: Understanding your application’s behavior
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解你的应用程序的行为
- en: Obtaining access to your Kubernetes resources
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取访问你的Kubernetes资源的权限
- en: Monitoring your application’s metrics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控你的应用程序的指标
- en: Logging your application’s important information
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录应用程序的重要信息
- en: Load testing your application
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对你的应用程序进行负载测试
- en: Adding instrumentation to your application’s code
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向应用程序代码中添加仪器化
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the labs for this chapter at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter12](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter12),
    where you will find some extended explanations that have been omitted from this
    chapter’s content to make it easier to follow. The *Code In Action* video for
    this chapter can be found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter12](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter12)找到本章的实验室，在那里你会找到一些本章内容中省略的扩展解释，以便让内容更容易跟随。本章的*Code
    In Action*视频可以在[https://packt.link/JdOIY](https://packt.link/JdOIY)找到。
- en: Understanding your application’s behavior
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解你的应用程序的行为
- en: Understanding how your application works can be very hard if you don’t know
    how your application works. This may sound obvious, but the better you know your
    application, the better you can implement different mechanisms to verify its status
    at every moment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道应用程序是如何工作的，理解其行为可能会非常困难。这听起来似乎很显而易见，但你对应用程序了解得越深入，就能更好地实施不同的机制，以随时验证它的状态。
- en: 'You, as a developer, have to ask yourself which is the best place in your code
    to add monitoring endpoints or flags. But your application should also be monitored
    using external third-party tools, which leads us to the following list of monitoring
    mechanisms:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发人员，你需要问自己，在哪里添加监控端点或标志是最合适的。但你的应用程序也应当通过外部第三方工具进行监控，这引出了以下几种监控机制：
- en: '**Internal application metrics**: Implementing monitoring points in our code
    may be difficult at the end of the project, but if you introduce them from the
    beginning and measure the time between transactions, you will have a great overall
    performance view of your application.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部应用程序指标**：在项目结束时实现监控点可能会很困难，但如果你从一开始就引入它们，并且测量事务之间的时间，你将能够获得应用程序的整体性能视图。'
- en: '**Internal health checks**: Health checks are crucial for identifying when
    your application fails, but we can go further. We can have some simple error/OK
    quick tests that can be executed very often and help Kubernetes keep the application
    up and running.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部健康检查**：健康检查对于识别应用程序何时失败至关重要，但我们可以进一步提升。我们可以有一些简单的错误/OK快速测试，这些测试可以频繁执行，帮助Kubernetes保持应用程序的正常运行。'
- en: '**External application metrics**: Some components such as databases may allow
    you to query certain metrics that can be exported and used by an external component.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部应用程序指标**：某些组件，如数据库，可能允许你查询可以导出并供外部组件使用的某些指标。'
- en: '**External health checks**: These health checks are used to provide a good
    overview of the application’s behavior. They can be complex and include multiple
    components, and they may trigger some alarms or create events that will help us
    manage the application’s status.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部健康检查**：这些健康检查用于提供应用程序行为的全面概述。它们可能很复杂，涉及多个组件，并且可能会触发一些警报或创建事件，帮助我们管理应用程序的状态。'
- en: We haven’t talked about how any of these mechanisms can be implemented yet.
    While including some metrics in our application may require us to make some changes
    in the code, add some entries with metric values, or create the sources to be
    retrieved for such metrics, other points can be achieved by using external tools,
    outside of the application’s code.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有讨论这些机制如何实现。虽然在应用程序中包含一些指标可能需要我们对代码进行一些修改，添加一些带有度量值的条目，或者创建需要提取的度量源，其他方面则可以通过使用外部工具，在应用程序代码之外来实现。
- en: Running your applications in containers can help you implement any of the models
    described here. But *never* include a parallel check process inside your application
    container. This is not how containers should be used. Remember that we introduced
    the concept of a container as the main process that runs isolated in a host, sharing
    its kernel among all other containers, in [*Chapter 1*](B19845_01.xhtml#_idTextAnchor015),
    *Modern Infrastructure and Applications with Docker*. Running more than one process
    is not a good practice because you will need to ensure that all processes receive
    SIGTERM or SIGKILL signals whenever the container needs to stop, and this may
    be tricky if you fork the processes and they run separately in the container’s
    namespace (the same as a PID namespace but without dependencies).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行应用程序可以帮助你实现这里描述的任何模型。但*绝对不要*在应用程序容器中包含并行检查进程。这不是容器的正确使用方式。记住，我们在[*第1章*](B19845_01.xhtml#_idTextAnchor015)《使用
    Docker 的现代基础设施与应用程序》中引入了容器的概念：容器是主进程，在主机中独立运行，共享内核给所有其他容器。运行多个进程并不是一个好的实践，因为你需要确保每个进程在容器停止时收到
    SIGTERM 或 SIGKILL 信号，如果你创建了多个进程并让它们在容器的命名空间中独立运行（类似于 PID 命名空间，但没有依赖关系），这可能会变得很棘手。
- en: In this chapter, we will learn how to implement different models for monitoring,
    logging, and even tracing our application’s processes. But let’s get started by
    reviewing how to retrieve and manage our application’s Kubernetes resources from
    our own application’s workloads, which is key for some of the different tools
    we are going to use later.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何实现不同的模型来监控、记录，甚至跟踪我们应用程序的进程。但让我们先从回顾如何从我们自己应用程序的工作负载中检索和管理 Kubernetes
    资源开始，这是我们后面将使用的某些工具的关键。
- en: Obtaining access to your Kubernetes resources
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取对 Kubernetes 资源的访问权限。
- en: 'Sometimes, your applications need to manage certain Kubernetes resources. Let’s
    think about the following situations:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你的应用程序需要管理某些 Kubernetes 资源。让我们考虑以下几种情况：
- en: The default Kubernetes autoscaling doesn’t cover our requirements
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认的 Kubernetes 自动扩展不符合我们的需求。
- en: We need to create some resources triggered by an event – for example, when our
    application starts
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要创建一些由事件触发的资源——例如，当我们的应用程序启动时。
- en: In these scenarios, our application’s processes will need to retrieve information
    from the Kubernetes API and create some resources. If we think of this workflow,
    at least our Pods will require network access to the Kubernetes API server’s IP
    address and appropriate permissions for the required actions and resources. In
    this section, we will learn how to create and manage Kubernetes objects from our
    application’s processes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些场景中，我们的应用程序进程需要从 Kubernetes API 获取信息并创建一些资源。如果我们考虑这个工作流，至少我们的 Pods 需要能够访问
    Kubernetes API 服务器的 IP 地址，并且具有执行所需操作和资源的适当权限。在本节中，我们将学习如何从应用程序进程中创建和管理 Kubernetes
    对象。
- en: First, we need to remember a few concepts from [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170),
    *Deploying Applications with* *the* *Kubernetes Orchestrator*. In that chapter,
    we talked about how Kubernetes improves our application’s security by using different
    authentication and authorization strategies. You may need to ask your Kubernetes
    administrators about some Kubernetes platform insights, but you will probably
    be using **role-based access control** (**RBAC**) in your environment because,
    currently, all Kubernetes platforms work with such a mechanism. This means that
    all Kubernetes API requests must be authorized by a **role authorization system**.
    Kubernetes will use either client certificates, bearer tokens, or an authenticating
    proxy to authenticate API requests through authentication plugins, and when client
    requests are authenticated, the authorization system will allow or deny them.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要记住一些来自[*第 8 章*](B19845_08.xhtml#_idTextAnchor170)的概念，*使用 Kubernetes 调度器部署应用程序*。在那一章中，我们讨论了
    Kubernetes 如何通过使用不同的身份验证和授权策略来提高应用程序的安全性。你可能需要向你的 Kubernetes 管理员询问一些 Kubernetes
    平台的见解，但你很可能会在你的环境中使用**基于角色的访问控制**（**RBAC**），因为目前所有 Kubernetes 平台都使用这种机制。这意味着所有
    Kubernetes API 请求都必须通过**角色授权系统**进行授权。Kubernetes 将使用客户端证书、持有者令牌或身份验证代理通过身份验证插件来验证
    API 请求，当客户端请求经过身份验证时，授权系统将允许或拒绝这些请求。
- en: By default, all Pods running in a namespace will inherit a service account and
    its token to authenticate the application processes within the Kubernetes cluster.
    This behavior is not secure and that’s why it can be avoided by your Kubernetes
    administrators. But in any case, we will use a service account included in the
    Pod definition and its associated token to identify the processes and validate
    access to the specified resources and actions.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，在命名空间中运行的所有 Pods 都将继承一个服务账户及其令牌，用于在 Kubernetes 集群内验证应用程序进程的身份。由于这种行为不安全，因此
    Kubernetes 管理员通常会避免这种情况。但是无论如何，我们将使用 Pod 定义中包含的服务账户及其关联令牌来标识进程并验证对指定资源和操作的访问权限。
- en: Within the Kubernetes cluster, the RBAC API declares roles and their bindings
    for pairing Kubernetes resources with the actions allowed for them. This role
    system will include namespaced authorizations (Role and RoleBinding resources)
    and cluster-wide authorizations (ClusterRole and ClusterRoleBinding resources),
    which help us provide fine-grained access.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群中，RBAC API 声明了角色及其绑定，用于将 Kubernetes 资源与允许的操作配对。该角色系统将包括命名空间授权（Role
    和 RoleBinding 资源）和集群级别授权（ClusterRole 和 ClusterRoleBinding 资源），它们帮助我们提供精细化访问控制。
- en: Role and ClusterRole resources define rules that represent additive permissions;
    so, if no rule exists for a permission, it is denied. We will match resources
    and the verbs allowed for them in their manifest definitions. We will use ClusterRole
    resources to define cluster-wide permissions or define namespace-scoped permissions
    from a higher level, which allows us to reuse them in several namespaces.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Role 和 ClusterRole 资源定义了表示附加权限的规则；因此，如果某个权限没有规则定义，则会被拒绝。我们将在它们的清单定义中匹配资源和允许的动词。我们将使用
    ClusterRole 资源来定义集群范围的权限，或从更高层次定义命名空间范围的权限，这使得我们可以在多个命名空间中重用它们。
- en: 'Let’s see an example of a Role and how we associate it with a ServiceAccount
    resource using a RoleBinding:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个角色的示例，以及如何通过 RoleBinding 将其与 ServiceAccount 资源关联：
- en: '![Figure 12.1 – Role and RoleBinding resources allowing us to list and read
    Pods in a namespace](img/B19845_12_01.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.1 – 角色和 RoleBinding 资源，允许我们在命名空间中列出和读取 Pods](img/B19845_12_01.jpg)'
- en: Figure 12.1 – Role and RoleBinding resources allowing us to list and read Pods
    in a namespace
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1 – 角色和 RoleBinding 资源，允许我们在命名空间中列出和读取 Pods
- en: 'Notice that in both resources, we defined `namespace` because we are using
    namespace-scoped resources (they can be omitted if we deploy them on the current
    namespace). In the Role resource, we defined the list of `verbs` or actions allowed
    and `resources` in which the actions will be applied (you can use `kubectl api-resources
    -o wide` to retrieve the verbs available for each Kubernetes resource). The `apiGroups`
    key is used when we have different resources with the same name but belonging
    to different APIs. Let’s see this configuration in action with a quick example.
    We will create both Role and RoleBinding resources in the `default` namespace:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这两个资源中，我们都定义了 `namespace`，因为我们使用了命名空间范围的资源（如果我们将其部署到当前命名空间，则可以省略）。在角色资源中，我们定义了允许的
    `verbs` 或动作列表，以及 `resources`，即这些动作将应用的资源（你可以使用 `kubectl api-resources -o wide`
    来检索每个 Kubernetes 资源可用的动作）。当我们有不同的资源，它们的名称相同，但属于不同的 API 时，`apiGroups` 键就会被使用。让我们通过一个快速示例来演示这个配置。我们将在
    `default` 命名空间中创建角色和角色绑定资源：
- en: '![Figure 12.2 – Creating resources so that Pods can be listed and read in a
    namespace](img/B19845_12_02.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.2 – 创建资源以便可以在命名空间中列出和读取 Pods](img/B19845_12_02.jpg)'
- en: Figure 12.2 – Creating resources so that Pods can be listed and read in a namespace
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.2 – 创建资源以便可以在命名空间中列出和读取 Pods
- en: Important note
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: We can use either `kubectl create role pod-reader --verb=get,list,watch --resource=Pods`
    to create the `pod-reader` Role resource from the preceding code snippet.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `kubectl create role pod-reader --verb=get,list,watch --resource=Pods`
    来创建前面代码片段中的 `pod-reader` 角色资源。
- en: 'We have applied the RoleBinding resource to a specific service account, but
    it doesn’t exist yet. Let’s create it before moving on:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将角色绑定资源应用于特定的服务账户，但它尚不存在。让我们在继续之前创建它：
- en: '![Figure 12.3 – Creating the myserviceaccount ServiceAccount resource](img/B19845_12_03.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.3 – 创建 `myserviceaccount` ServiceAccount 资源](img/B19845_12_03.jpg)'
- en: Figure 12.3 – Creating the myserviceaccount ServiceAccount resource
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.3 – 创建 `myserviceaccount` ServiceAccount 资源
- en: 'We have a Role that allows us to list, watch, and get Pods within any namespace
    (but applied to the current `default` namespace), and a RoleBinding associating
    this Role resource with a defined service account, `myserviceaccount`, in the
    `default`namespace. We will now run a Pod with this service account and get the
    list of current Pods. We will run a Pod with the `kubectl` command line included
    in the container image. We included the `myserviceaccount` service account resource
    and used `get pod` as arguments for the image:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个角色，它允许我们列出、查看和获取任何命名空间中的 Pods（但仅应用于当前的 `default` 命名空间），并且有一个角色绑定将该角色资源与
    `default` 命名空间中定义的服务账户 `myserviceaccount` 关联。我们现在将运行一个使用此服务账户的 Pod，并获取当前 Pods
    的列表。我们将运行一个包含 `kubectl` 命令行的容器镜像。我们包含了 `myserviceaccount` 服务账户资源，并将 `get pod`
    作为镜像的参数：
- en: '![Figure 12.4 – Creating a Pod that lists all the Pods in the current namespace](img/B19845_12_04.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.4 – 创建一个列出当前命名空间中所有 Pods 的 Pod](img/B19845_12_04.jpg)'
- en: Figure 12.4 – Creating a Pod that lists all the Pods in the current namespace
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4 – 创建一个列出当前命名空间中所有 Pods 的 Pod
- en: 'In the preceding code snippet, we created a Pod whose container will use the
    `myserviceaccount` service account to interact with the Kubernetes API. Notice
    that we just retrieved the logs from the Pod and we get the output from the `kubectl
    get pods` command line that’s executed. All the Pods running at the time of execution
    were listed. Let’s try the same with a new Pod that doesn’t use this service account:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们创建了一个 Pod，其容器将使用 `myserviceaccount` 服务账户与 Kubernetes API 进行交互。请注意，我们刚刚从
    Pod 中检索了日志，并且从执行的 `kubectl get pods` 命令行中得到了输出。执行时所有正在运行的 Pods 都被列出。让我们尝试使用一个不使用此服务账户的新
    Pod：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, we can retrieve the logs from this new Pod:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从这个新 Pod 中检索日志：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see, this time, the new Pod does not have access to the Kubernetes
    API (the `default` service account was used by default, which doesn’t have permission
    to list the Pods in the namespace).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这次新 Pod 无法访问 Kubernetes API（默认使用了 `default` 服务账户，而该账户没有权限列出命名空间中的 Pods）。
- en: Accessing the Kubernetes API may become complex when you create custom resources
    and need fine-grained access, but be sure that the principles for managing RBAC
    access are the same.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建自定义资源并需要细粒度访问时，访问 Kubernetes API 可能变得复杂，但请确保管理 RBAC 访问的原则是相同的。
- en: Important note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: You can implement your own `Kubeconfig` file to use with your application. Kubernetes
    offers out-of-the-box integration with a service account’s tokens, but you can
    use a Secret resource to include your authentication file and use it in your application.
    This is especially useful when you’re managing different Kubernetes clusters from
    a unified control plane cluster.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以实现自己的 `Kubeconfig` 文件来与应用程序一起使用。Kubernetes 提供了与服务账户令牌的开箱即用集成，但你可以使用 Secret
    资源来包含认证文件并在应用程序中使用它。当你从统一的控制平面集群管理不同的 Kubernetes 集群时，这尤其有用。
- en: In these examples, we are not using a NetworkPolicy resource, but you will need
    to ensure your Pods have access to Kubernetes API server Pods. These Pods will
    use control plane hosts’ IP addresses and port `6443`, although this may vary
    between Kubernetes platforms (confirm these requirements with your Kubernetes
    administrators). If your platform administrators configured GlobalNetworkPolicy
    resources, you may need to add some **egress** rules for your deployments.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些示例中，我们没有使用 NetworkPolicy 资源，但你需要确保你的 Pod 可以访问 Kubernetes API 服务器 Pod。这些 Pod
    将使用控制平面主机的 IP 地址和端口 `6443`，尽管这可能在不同的 Kubernetes 平台之间有所不同（请向你的 Kubernetes 管理员确认这些要求）。如果你的平台管理员配置了
    GlobalNetworkPolicy 资源，你可能需要为你的部署添加一些 **egress** 规则。
- en: 'In this example, we used the kubectl Kubernetes client, but you will find client
    libraries and modules for different code languages, which makes integration more
    secure. Attackers will not be able to exploit erroneous RBAC configurations if
    your code only manages required resources. On the other hand, adding new functionalities
    may require you to recompile your code, but it is worth it. Here is a link to
    the current documentation, where you will find more information about the client
    libraries: [https://kubernetes.io/docs/reference/using-api/client-libraries/](https://kubernetes.io/docs/reference/using-api/client-libraries/).
    At the time of writing this book, C, .NET, Go, Perl, Python, Java, JavaScript,
    and Ruby, among other languages, are officially supported. If you require a different
    language, such as Rust, there are community projects developing libraries for
    accessing Kubernetes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了 kubectl Kubernetes 客户端，但你会发现有适用于不同编程语言的客户端库和模块，这使得集成更加安全。如果你的代码仅管理必需的资源，攻击者将无法利用错误的
    RBAC 配置。另一方面，添加新功能可能需要重新编译代码，但这是值得的。这里有一个指向当前文档的链接，你可以在其中找到有关客户端库的更多信息：[https://kubernetes.io/docs/reference/using-api/client-libraries/](https://kubernetes.io/docs/reference/using-api/client-libraries/)。在本书撰写时，C、.NET、Go、Perl、Python、Java、JavaScript
    和 Ruby 等语言得到官方支持。如果你需要使用 Rust 等其他语言，可以找到一些社区项目正在开发用于访问 Kubernetes 的库。
- en: Now, let’s introduce the concept of Kubernetes operators, which will help us
    deploy and operate applications in Kubernetes. We will use some of them in this
    chapter and it is interesting to learn the basics before we do so.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们介绍 Kubernetes 操作符的概念，它将帮助我们在 Kubernetes 中部署和操作应用程序。在本章中我们将使用其中的一些操作符，在此之前了解其基础知识是非常有趣的。
- en: Understanding Kubernetes operators
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 操作符
- en: A **Kubernetes operator** is a piece of software that runs and integrates with
    Kubernetes to manage applications and their components. They use the concepts
    we’ve learned about so far in this chapter to monitor and create resources as
    needed by your applications.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes 操作符**是一个与 Kubernetes 集成运行的软件，用于管理应用程序及其组件。它们使用我们在本章中所学的概念，按需监控并创建资源，以支持你的应用程序。'
- en: 'Kubernetes operators are designed to automate most of the repetitive tasks
    a human operator must do to manage an application. There are many well-documented
    examples of Kubernetes operators that will help you perform tasks such as deploying
    databases with high availability, managing complex applications with multiple
    components with just one YAML manifest, and so on. These are some of the tasks
    you may expect from a Kubernetes operator designed for a certain application:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 操作符旨在自动化人类操作员管理应用程序时必须执行的大多数重复任务。市面上有许多经过充分文档化的 Kubernetes 操作符示例，它们将帮助你执行诸如部署高可用性数据库、使用单个
    YAML 清单管理具有多个组件的复杂应用程序等任务。这些都是你可能会期望 Kubernetes 操作符为某个特定应用程序所执行的一些任务：
- en: Automated deployment of the application and all its components
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动部署应用程序及其所有组件
- en: Management and creation of Kubernetes **CustomResourceDefinitions** (**CRDs**)
    required for the application
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理和创建应用程序所需的 Kubernetes **CustomResourceDefinitions**（**CRDs**）
- en: Backup and restore features that will help recover the application with easy
    steps
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份和恢复功能，帮助你通过简单的步骤恢复应用程序
- en: Fully managed application upgrades, with all the internal application components
    such as database schema migrations
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全托管的应用程序升级，涵盖所有内部应用程序组件，如数据库架构迁移
- en: Choosing a leader when your application requires a distributed control plane
    or must manage the master-worker (or master-slave) relations between application
    components
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您的应用程序需要分布式控制平面，或者必须管理应用程序组件之间的主从关系（或主从结构）时，选择一个领导者
- en: As you can see, operators are key for managing complex application deployments,
    and their integration into Kubernetes makes things more simple. There are good
    examples of managing databases, created by the most important software database
    vendors, and for many other software categories. You may find what you need at
    [https://operatorhub.io](https://operatorhub.io). In the following section, we
    will use the **Prometheus Operator** to deploy and manage the Prometheus monitoring
    tool.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，运维人员是管理复杂应用程序部署的关键，而将它们集成到 Kubernetes 中使得管理变得更加简便。数据库管理有很多好的例子，主要由最重要的软件数据库供应商创建，其他软件类别也有类似的例子。您可以在[https://operatorhub.io](https://operatorhub.io)找到所需内容。在接下来的部分，我们将使用**Prometheus
    Operator**来部署和管理 Prometheus 监控工具。
- en: In case you don’t find a Kubernetes operator that meets your application requirements,
    you can code your own operator using any of the **software development kits**
    (**SDKs**) available for different languages ([https://kubernetes.io/docs/concepts/extend-kubernetes/operator/#writing-operator](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/#writing-operator)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有找到符合您应用程序要求的 Kubernetes 运维操作符，您可以使用任何可用于不同语言的**软件开发工具包**（**SDKs**）来编写您自己的运维操作符（[https://kubernetes.io/docs/concepts/extend-kubernetes/operator/#writing-operator](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/#writing-operator)）。
- en: So far, we have learned how Kubernetes can be queried for some resources’ statuses
    and how to manage them within our applications. In the following section, we will
    learn how **third-party applications** can be used to monitor our applications.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何查询 Kubernetes 中某些资源的状态以及如何在应用程序中管理它们。在接下来的部分，我们将学习如何使用**第三方应用程序**来监控我们的应用程序。
- en: Monitoring your application’s metrics
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控您的应用程序指标
- en: Analyzing your application’s metrics is key to understanding how you are serving
    your users or other applications. In this section, we will learn how to monitor
    our applications using **Prometheus**, a monitoring solution that fits very well
    in the Kubernetes ecosystem.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 分析应用程序的指标是了解如何为用户或其他应用程序提供服务的关键。在这一部分，我们将学习如何使用**Prometheus**监控应用程序，这是一个非常适合
    Kubernetes 生态系统的监控解决方案。
- en: Prometheus is an open source monitoring solution that’s been hosted by the **Cloud
    Native Computing Foundation** (**CNCF**) since 2016\. It is used to collect, store,
    and represent metrics and alert users using thresholds. It can be integrated into
    any infrastructure, although it is known to work great with Kubernetes. It comes
    included within some Kubernetes platform deployments and that’s why it is considered
    standard within the Kubernetes community.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 是一个开源的监控解决方案，自 2016 年以来由**云原生计算基金会**（**CNCF**）托管。它用于收集、存储和呈现指标，并通过阈值向用户发出警报。它可以集成到任何基础设施中，尽管它与
    Kubernetes 配合使用时表现非常好。它已经包含在一些 Kubernetes 平台的部署中，因此它被认为是 Kubernetes 社区的标准。
- en: Prometheus includes a data model that is easy to query, using its own **Prometheus
    query language** (**PromQL**), which stores metrics recorded over time from different
    sources identified by key-value pairs. By default, Prometheus will pull different
    endpoints via HTTP requests, although pushing data is also available, but less
    common. These endpoints, usually identified as **targets**, can be auto-discovered
    or manually configured, which makes Prometheus fit perfectly in Kubernetes clusters
    where dynamism is a must.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 包括一个易于查询的数据模型，使用其专有的**Prometheus 查询语言**（**PromQL**），该语言通过键值对标识的不同来源存储随着时间记录的指标。默认情况下，Prometheus
    将通过 HTTP 请求拉取不同的端点，虽然推送数据也是可用的，但较少使用。这些端点通常被称为**targets**，可以自动发现或手动配置，这使得 Prometheus
    在需要动态性支持的 Kubernetes 集群中非常适用。
- en: Although Prometheus provides a graphing tool, it is very common to integrate
    it as a data source in more advanced dashboard tools such as **Grafana** or to
    directly consume its data via an API (using PromQL queries).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Prometheus 提供了一个图形工具，但通常将其作为数据源集成到更先进的仪表盘工具中，例如**Grafana**，或通过 API（使用 PromQL
    查询）直接消费其数据。
- en: We are not going to cover this tool in depth in this book as it would be out
    of its scope, but we will review some of its components, quick installation, and
    how to implement some monitoring endpoints for your applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不会深入讲解这个工具，因为它超出了本书的范围，但我们将回顾一些其组件、快速安装以及如何为你的应用程序实现一些监控端点。
- en: Exploring Prometheus architecture
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Prometheus 架构
- en: 'Prometheus is based on at least five different components:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 基于至少五个不同的组件：
- en: '**Prometheus server**: This is the core component. It retrieves metrics data
    from Prometheus exporters and adds data from the **Pushgateway**. All this data
    is stored in its own **time series database** (**TSDB**) and is available via
    the HTTP API, also managed by the Prometheus server component. It also checks
    the different configured thresholds.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 服务器**：这是核心组件。它从 Prometheus 导出器获取指标数据，并将来自 **Pushgateway** 的数据添加进去。所有这些数据都存储在其自己的
    **时间序列数据库**（**TSDB**）中，并可以通过 HTTP API 访问，这个 API 也是由 Prometheus 服务器组件管理的。它还会检查不同配置的阈值。'
- en: '**Pushgateway**: There are some devices or components that can’t be scraped.
    The Pushgateway component allows you to directly push the data into Prometheus,
    instead of waiting for it to be pulled. Different libraries exist for common languages
    such as Java, Go, Python, and Ruby, among others supported by the community.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pushgateway**：有些设备或组件无法被抓取。Pushgateway 组件允许你直接将数据推送到 Prometheus，而不是等待 Prometheus
    拉取。不同的库适用于常见的编程语言，如 Java、Go、Python 和 Ruby 等，也有其他社区支持的库。'
- en: '**Alertmanager**: Alertmanager handles all the alerts generated from the Prometheus
    server. Different notification backends can be used, such as email or webhooks.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Alertmanager**：Alertmanager 处理来自 Prometheus 服务器生成的所有警报。可以使用不同的通知后端，如电子邮件或
    Webhook。'
- en: '**Prometheus web UI**: The provided web UI allows us to query stored metrics,
    quickly graph data, and review the status of the different targets configured.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Web UI**：提供的 Web UI 使我们能够查询存储的指标、快速绘制数据图表，并查看不同配置目标的状态。'
- en: '**Prometheus exporters**: These components are the key to the extensibility
    of the platform. Many client libraries are officially supported for different
    code languages (and others are unofficially supported) that allow us to create
    metrics for our applications. When Prometheus scrapes your endpoints, the client
    library presents the data, and it will be stored in the server for later access
    or threshold validation. You can find officially supported Prometheus exporters
    inside GitHub’s Prometheus organization ([https://github.com/orgs/prometheus/repositories?q=exporter&type=all](https://github.com/orgs/prometheus/repositories?q=exporter&type=all)).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 导出器**：这些组件是平台可扩展性的关键。许多客户端库在不同的编程语言中得到了官方支持（还有一些是非官方支持的），允许我们为应用程序创建指标。当
    Prometheus 抓取你的端点时，客户端库会呈现数据，并将其存储在服务器中以供稍后访问或阈值验证。你可以在 GitHub 的 Prometheus 组织内找到官方支持的
    Prometheus 导出器（[https://github.com/orgs/prometheus/repositories?q=exporter&type=all](https://github.com/orgs/prometheus/repositories?q=exporter&type=all)）。'
- en: Prometheus can monitor your applications running in Kubernetes by either running
    inside your Kubernetes cluster (in its own namespace or even within your application’s
    namespace, which is not recommended) or externally, in a different infrastructure,
    such as virtual machines. It is recommended to run Prometheus inside your Kubernetes
    cluster because you will be able to use internal communications, instead of having
    to publish your exporters externally to be pulled from outside of the cluster.
    This will improve security, even if you expose your exporters internally using
    HTTP instead of HTTPS protocol. Running in Kubernetes will allow us to deploy
    Prometheus as a Kubernetes operator, which will help us implement the auto-discovery
    of targets as well as an easy-to-manage complete monitoring platform. All the
    components will be installed for us, and we will just have to configure how they
    should be deployed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 可以通过在 Kubernetes 集群内部运行（在自己的命名空间内，或者甚至在应用程序的命名空间内，不推荐这样做）或在外部不同的基础设施中运行（例如虚拟机），来监控运行在
    Kubernetes 中的应用程序。建议在 Kubernetes 集群内部运行 Prometheus，因为这样你可以使用内部通信，而不必将导出器暴露出去，以便从集群外部拉取数据。这将提高安全性，即使你通过
    HTTP 协议而非 HTTPS 协议在内部暴露导出器。将 Prometheus 部署在 Kubernetes 中将允许我们作为 Kubernetes 操作员来部署
    Prometheus，这将帮助我们实现目标的自动发现，并且轻松管理完整的监控平台。所有组件都会为我们安装，我们只需配置它们的部署方式。
- en: Installing Prometheus
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Prometheus
- en: 'To install the Prometheus monitoring platform, we will use **Helm**, which
    is a tool that allows us to easily customize and deploy a set of manifests. We
    will deep dive into using Helm to package applications in [*Chapter 13*](B19845_13.xhtml#_idTextAnchor287),
    *Managing the* *Application Life Cycle*. In this case, these manifests include
    the **kube-prometheus** platform components ([https://github.com/prometheus-operator/kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)).
    The kube-prometheus community project installs a cluster-ready monitoring platform
    with the following components:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装 Prometheus 监控平台，我们将使用 **Helm**，它是一个可以让我们轻松自定义和部署一组清单的工具。我们将在 [*第13章*](B19845_13.xhtml#_idTextAnchor287)《管理应用生命周期》中深入学习如何使用
    Helm 打包应用。在这种情况下，这些清单包括 **kube-prometheus** 平台组件（[https://github.com/prometheus-operator/kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)）。kube-prometheus
    社区项目安装了一个适合集群使用的监控平台，包含以下组件：
- en: The **Prometheus Operator**, which will create its own CRDs and manage the Service
    discovery integration.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Operator**，它将创建自己的 CRDs 并管理服务发现集成。'
- en: '**Prometheus** and **Alertmanager** with high availability, both deployed as
    StatefulSets. A set of default alerts is included, which will help you start monitoring
    your Kubernetes environment.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus** 和 **Alertmanager**，具有高可用性，均作为 StatefulSets 部署。包括一组默认的警报，帮助您开始监控
    Kubernetes 环境。'
- en: '**Prometheus node-exporter**, deployed as a DaemonSet to all the Kubernetes
    cluster nodes. This exporter will have host-related metrics such as CPU, memory,
    and disk space available.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus node-exporter**，作为 DaemonSet 部署到所有 Kubernetes 集群节点。此导出器将包含与主机相关的指标，如
    CPU、内存和磁盘空间。'
- en: '**Prometheus Adapter for Kubernetes Metrics APIs**, which integrates all the
    Kubernetes Metrics Server metrics into Prometheus automatically.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Adapter for Kubernetes Metrics APIs**，它会自动将所有 Kubernetes Metrics
    Server 的指标集成到 Prometheus 中。'
- en: '**kube-state-metrics**, which connects with the Kubernetes API server and retrieves
    the status of different resources such as Pods, Deployments, and so on, and delivers
    them as metrics for Prometheus. By default, important metrics are created and
    configured for you.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-state-metrics**，它连接到 Kubernetes API 服务器并获取不同资源（如 Pods、Deployments 等）的状态，并将这些状态以指标的形式提供给
    Prometheus。默认情况下，会为您创建并配置重要的指标。'
- en: '**Grafana**, deployed as part of the platform to enhance Prometheus graphs
    in Grafana dashboards. A set of default dashboards is included to show you how
    your platform works.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana**，作为平台的一部分部署，用于增强 Grafana 仪表盘中的 Prometheus 图表。包括一组默认仪表盘，以向您展示平台的工作原理。'
- en: Important note
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The default alerts and dashboards included in the kube-prometheus project are
    taken from the **kubernetes-mixin** project ([https://github.com/kubernetes-monitoring/kubernetes-mixin](https://github.com/kubernetes-monitoring/kubernetes-mixin)),
    which provides a set of well-documented rules and simple dashboards for monitoring
    Kubernetes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: kube-prometheus 项目中包含的默认警报和仪表盘来自 **kubernetes-mixin** 项目（[https://github.com/kubernetes-monitoring/kubernetes-mixin](https://github.com/kubernetes-monitoring/kubernetes-mixin)），该项目提供了一套良好文档化的规则和简单的
    Kubernetes 监控仪表盘。
- en: You, as a developer, will probably not use many of the dashboards and metrics
    provided by this platform, but it will help you understand how to implement your
    metrics and rules and create dashboards with your data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发人员，您可能不会使用该平台提供的许多仪表盘和指标，但它将帮助您了解如何实现自己的指标和规则，并使用您的数据创建仪表盘。
- en: Installing the `kube-prometheus-stack` is easy. A Helm Chart (Helm-specific
    package) is ready for us. We will just add the Prometheus community Helm Charts
    repository, update the repositories cache, and install a Helm Chart release in
    our cluster.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 `kube-prometheus-stack` 非常简单。我们有一个现成的 Helm Chart（Helm 特定的包）。我们只需添加 Prometheus
    社区 Helm Charts 仓库，更新仓库缓存，并在集群中安装 Helm Chart 发布版本。
- en: Important note
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'If you are using Rancher Desktop, Helm comes preinstalled with your command-line
    tools, but on other platforms, it may be necessary to install it before using
    it. Helm is available for Windows, macOS, and Linux and there are different methods
    for installing it. We recommend that you use the binary directly. That way, you
    can update it whenever you need it and use a different release if required. If
    you are using Windows, you can use `Get-Content` to download it and then add it
    to your `PATH`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是 Rancher Desktop，Helm 会预装在你的命令行工具中；但在其他平台上，可能需要先安装才能使用它。Helm 支持 Windows、macOS
    和 Linux，不同平台有不同的安装方法。我们建议直接使用二进制文件，这样你可以随时更新它并在需要时使用不同的版本。如果你使用的是 Windows，可以使用
    `Get-Content` 下载它，并将其添加到 `PATH` 中：
- en: '![Figure 12.5 – Installing the Helm binary using gc to download the required
    package](img/B19845_12_05.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.5 – 使用 gc 下载所需包来安装 Helm 二进制文件](img/B19845_12_05.jpg)'
- en: Figure 12.5 – Installing the Helm binary using gc to download the required package
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.5 – 使用 gc 下载所需包来安装 Helm 二进制文件
- en: 'Once Helm has been installed, we will just use `helm install` with `--create-namespace`
    to tell Helm to create a new namespace for us. In this example, we are using Minikube
    as the Kubernetes environment:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完 Helm 后，我们只需使用 `helm install` 并加上 `--create-namespace` 参数，告诉 Helm 为我们创建一个新的命名空间。在这个示例中，我们使用
    Minikube 作为 Kubernetes 环境：
- en: '![Figure 12.6 – Installing the Prometheus stack using Helm](img/B19845_12_06.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.6 – 使用 Helm 安装 Prometheus 堆栈](img/B19845_12_06.jpg)'
- en: Figure 12.6 – Installing the Prometheus stack using Helm
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.6 – 使用 Helm 安装 Prometheus 堆栈
- en: 'After a few seconds, the Prometheus stack will be up and running. At this point,
    we can check the platform’s Pod and Service resources:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，Prometheus 堆栈将启动并运行。此时，我们可以检查平台的 Pod 和 Service 资源：
- en: '![Figure 12.7 – Prometheus stack Pod and Service resources](img/B19845_12_07.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.7 – Prometheus 堆栈的 Pod 和 Service 资源](img/B19845_12_07.jpg)'
- en: Figure 12.7 – Prometheus stack Pod and Service resources
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.7 – Prometheus 堆栈的 Pod 和 Service 资源
- en: This small installation is intended only for local usage – so that you can develop
    your own monitors for your application on your desktop computer. Notice that we
    didn’t even include a PersistentVolume, so data will be lost every time you restart
    your environment. A lot of customizations can be done at the installation level
    to cover all your specific needs, but you should read the documentation before
    configuring your own Helm values YAML file ([https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小型安装仅用于本地使用——这样你可以在桌面计算机上为自己的应用程序开发监控。请注意，我们甚至没有包括 PersistentVolume，因此每次重启环境时数据都会丢失。在安装级别可以进行很多定制以满足你的特定需求，但在配置自己的
    Helm 值 YAML 文件之前，你应该先阅读文档 ([https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml))。
- en: Reviewing the Prometheus environment
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查 Prometheus 环境
- en: 'In this section, we will learn about the GUI and features of Prometheus. We
    can get into Prometheus by using the `prometheus-stack-grafana` Service:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解 Prometheus 的 GUI 和功能。我们可以通过使用 `prometheus-stack-grafana` Service
    来进入 Prometheus：
- en: 'For a quick review, we will use `port-foward` to access the Grafana web UI:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了快速查看，我们将使用 `port-forward` 访问 Grafana web UI：
- en: '[PRE2]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Figure 12.8 – Prometheus GUI showing the Status section](img/B19845_12_08.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.8 – Prometheus GUI 显示状态部分](img/B19845_12_08.jpg)'
- en: Figure 12.8 – Prometheus GUI showing the Status section
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.8 – Prometheus GUI 显示状态部分
- en: 'Now, we can go to the **Targets** section and review which targets are currently
    monitored by the Prometheus platform:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以进入 **Targets** 部分，查看当前 Prometheus 平台监控的目标：
- en: '![Figure 12.9 – Prometheus GUI showing the Targets section](img/B19845_12_09.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.9 – Prometheus GUI 显示 Targets 部分](img/B19845_12_09.jpg)'
- en: Figure 12.9 – Prometheus GUI showing the Targets section
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.9 – Prometheus GUI 显示 Targets 部分
- en: 'We can use the filter on the right-hand side to uncheck the **Healthy** targets
    and view which targets are currently down:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用右侧的过滤器，取消选中 **Healthy** 目标，以查看当前哪些目标处于不可用状态：
- en: '![Figure 12.10 – Prometheus GUI showing the Unhealthy targets in the Targets
    section](img/B19845_12_10.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.10 – Prometheus GUI 显示 Targets 部分中的不健康目标](img/B19845_12_10.jpg)'
- en: Figure 12.10 – Prometheus GUI showing the Unhealthy targets in the Targets section
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 – Prometheus GUI 显示 Targets 部分中的不健康目标
- en: Don’t worry – this is normal. Minikube does not expose all the Kubernetes metrics;
    therefore, some monitoring endpoints will not be available.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心——这是正常的。Minikube 并未公开所有 Kubernetes 指标，因此某些监控端点将不可用。
- en: 'Let’s review some of the metrics that are currently retrieved by clicking on
    `container_cpu_usage_seconds_total` metric):'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看当前通过点击`container_cpu_usage_seconds_total`指标获取的一些指标：
- en: '![Figure 12.11 – Prometheus GUI showing the Graph section with a metric as
    a query](img/B19845_12_11.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.11 – Prometheus GUI 显示带有查询的图形部分指标](img/B19845_12_11.jpg)'
- en: Figure 12.11 – Prometheus GUI showing the Graph section with a metric as a query
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.11 – Prometheus GUI 显示带有查询的图形部分指标
- en: Notice that we only have metrics from objects running on the **kube-system**
    and **monitoring** (created for the stack itself) namespaces.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们只获取来自**kube-system**和**monitoring**（为栈本身创建的）命名空间的指标。
- en: 'Let’s create a quick web server deployment on the default namespace and verify
    that it appears in the monitoring platform:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在默认命名空间上快速创建一个 Web 服务器部署，并验证它是否出现在监控平台中：
- en: '[PRE3]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In a few seconds, the new Pod for the web server deployment will appear in
    the Prometheus **Graph** section:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 几秒钟后，新的 Web 服务器 Pod 将出现在 Prometheus **Graph** 部分：
- en: '![Figure 12.12 – Filtered list of Kubernetes containers using CPU](img/B19845_12_12.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.12 – 使用 CPU 过滤的 Kubernetes 容器列表](img/B19845_12_12.jpg)'
- en: Figure 12.12 – Filtered list of Kubernetes containers using CPU
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.12 – 使用 CPU 过滤的 Kubernetes 容器列表
- en: Notice that in this case, we used a new PromQL query, `container_cpu_usage_seconds_total{namespace!~"monitoring",namespace!~"kube-system"}`,
    in which we removed any metrics from the `monitoring` and `kube-system` namespaces.
    The metrics were automatically included thanks to the Prometheus Adapter for the
    Kubernetes Metrics APIs component.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种情况下，我们使用了一个新的 PromQL 查询，`container_cpu_usage_seconds_total{namespace!~"monitoring",namespace!~"kube-system"}`，在其中我们移除了来自`monitoring`和`kube-system`命名空间的任何指标。这些指标通过
    Prometheus Adapter for Kubernetes Metrics APIs 组件自动包含。
- en: Important note
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Knowledge of Kubernetes metrics or Pod metrics is outside the scope of this
    chapter. We are using Prometheus to show you how you can deliver your application
    metrics. Each exporter or integration mentioned in this section has its documentation,
    where you will find information about the metrics available. The use of PromQL
    and Prometheus itself is also outside the scope of this book. You can find very
    useful documentation at [https://prometheus.io/docs](https://prometheus.io/docs).
    To monitor our applications and retrieve their active hardware resource consumption,
    we don’t need to deploy the Alertmanager component, which will reduce the requirements
    of your desktop environment.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Kubernetes 指标或 Pod 指标的知识超出了本章的范围。我们使用 Prometheus 来展示如何传递您的应用程序指标。本节中提到的每个导出器或集成都有其文档，您可以在其中找到可用指标的信息。PromQL
    和 Prometheus 本身的使用也超出了本书的范围。您可以在[https://prometheus.io/docs](https://prometheus.io/docs)上找到非常有用的文档。为了监控我们的应用程序并获取其活动硬件资源消耗，我们不需要部署
    Alertmanager 组件，这将减少您桌面环境的要求。
- en: Prometheus uses labels to filter resources. Choosing good metrics and label
    conventions will help you design your application monitoring. Take a close look
    at [https://prometheus.io/docs/practices/naming](https://prometheus.io/docs/practices/naming),
    where the documentation explains a good naming and labeling strategy.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 使用标签来过滤资源。选择良好的指标和标签约定将帮助您设计应用程序监控。仔细查看[https://prometheus.io/docs/practices/naming](https://prometheus.io/docs/practices/naming)，文档中解释了良好的命名和标签策略。
- en: Now that we know about the basics of the Prometheus interface, we can move on
    and review how the Prometheus server gets infrastructure and application data.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 Prometheus 界面的基础知识，接下来可以回顾 Prometheus 服务器如何获取基础设施和应用程序数据。
- en: Understanding how Prometheus manages metrics data
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解 Prometheus 如何管理指标数据
- en: 'Let’s review how targets are configured by the Prometheus Operator:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下 Prometheus Operator 如何配置目标：
- en: 'We will retrieve the new CRDs created by the Prometheus stack deployment:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将获取 Prometheus 栈部署创建的新 CRD：
- en: '![Figure 12.13 – Filtered list of available Kubernetes API resources](img/B19845_12_13.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.13 – 可用 Kubernetes API 资源的过滤列表](img/B19845_12_13.jpg)'
- en: Figure 12.13 – Filtered list of available Kubernetes API resources
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.13 – 可用 Kubernetes API 资源的过滤列表
- en: The Prometheus Operator will use **PodMonitor** and **ServiceMonitor** resources
    to query the associated endpoints in time intervals. Therefore, to monitor our
    application, we will need to create a custom metric exporter, to provide the application
    metrics, and a PodMonitor or ServiceMonitor to expose them for Prometheus.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus Operator 将使用 **PodMonitor** 和 **ServiceMonitor** 资源按时间间隔查询相关的端点。因此，要监控我们的应用程序，我们需要创建一个自定义的度量导出器，用于提供应用程序的度量数据，并创建一个
    PodMonitor 或 ServiceMonitor 来将其暴露给 Prometheus。
- en: 'Let’s take a quick look at some of the metrics that have been exposed. We will
    review the Node Exporter component here. The Service resource associated with
    this monitoring component can be easily retrieved using the following command:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们快速了解一下已经暴露的一些度量标准。我们将在这里回顾一下 Node Exporter 组件。与该监控组件关联的 Service 资源可以通过以下命令轻松获取：
- en: '[PRE4]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s expose that Pod and review the presented data:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们暴露这个 Pod 并查看展示的数据：
- en: '![Figure 12.14 – Exposing Prometheus Node Exporter via the port forwarding
    feature](img/B19845_12_14.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.14 – 通过端口转发功能暴露 Prometheus Node Exporter](img/B19845_12_14.jpg)'
- en: Figure 12.14 – Exposing Prometheus Node Exporter via the port forwarding feature
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.14 – 通过端口转发功能暴露 Prometheus Node Exporter
- en: 'We can now open a new PowerShell terminal and use `Invoke-WebRequest` to retrieve
    the data or any web browser (you will obtain an intermediate web page indicating
    that the metrics will be found in the `/``metrics` path):'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以打开一个新的 PowerShell 终端，并使用 `Invoke-WebRequest` 来检索数据，或者使用任何网页浏览器（你将获得一个中间网页，表明度量数据可以在
    `/metrics` 路径下找到）：
- en: '![Figure 12.15 – Metrics available from Node Exporter, exposed via port forwarding
    in local port 9100](img/B19845_12_15.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.15 – Node Exporter 提供的度量数据，通过本地端口 9100 的端口转发暴露](img/B19845_12_15.jpg)'
- en: Figure 12.15 – Metrics available from Node Exporter, exposed via port forwarding
    in local port 9100
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.15 – Node Exporter 提供的度量数据，通过本地端口 9100 的端口转发暴露
- en: 'The metrics for the Node Exporter component are published internally by an
    associated Service resource. This is how we should create our monitoring endpoint.
    We can use two different architectures here:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Node Exporter 组件的度量数据是通过一个关联的 Service 资源在内部发布的。这就是我们应该如何创建监控端点。我们可以在这里使用两种不同的架构：
- en: Integrate our monitoring component inside our application Pod using a new container
    and sidecar pattern
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将我们的监控组件集成到应用程序的 Pod 内部，使用新的容器和 sidecar 模式
- en: Run a separate Pod with the monitor component and retrieve the data internally
    using the Kubernetes overlay network
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一个独立的 Pod 来部署监控组件，并通过 Kubernetes 覆盖网络在内部检索数据
- en: You must remember that the containers running inside a Pod share a common IP
    address and will always be scheduled together. This may be the main difference
    and why you will probably choose the first option from the preceding list. Running
    a different Pod will also require some dependency tracking between both Pods and
    node affinity patterns (if we want them to run together on the same host). In
    either of these situations, we will need a PodMonitor or ServiceMonitor resource.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须记住，运行在 Pod 内的容器共享一个公共的 IP 地址，并且总是会一起调度。这可能是主要的区别，也可能是你选择前面列表中第一个选项的原因。运行一个不同的
    Pod 还需要在两个 Pod 之间进行一些依赖追踪和节点亲和模式（如果我们希望它们一起运行在同一个主机上）。在这两种情况下，我们都需要一个 PodMonitor
    或 ServiceMonitor 资源。
- en: Next, we’ll take a quick look at how Prometheus will automatically scrape metrics
    from a new exporter when we create exporters for our applications.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将快速了解 Prometheus 如何在我们为应用程序创建新的导出器时，自动抓取这些导出的度量数据。
- en: Scraping metrics with Prometheus
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Prometheus 抓取度量数据
- en: 'Prometheus installation creates a new resource, `Prometheus`, which represents
    a Prometheus instance. We can list Prometheus instances in our cluster (we used
    `-A` to include all the namespaces in the search):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 的安装会创建一个新的资源 `Prometheus`，它代表一个 Prometheus 实例。我们可以列出集群中的 Prometheus
    实例（我们使用了 `-A` 来包括所有命名空间进行搜索）：
- en: '[PRE5]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we take a look at this resource, we will realize that two interesting keys
    will decide which resources to monitor. Let’s get the `Prometheus` resource YAML
    manifest and review some interesting keys:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看这个资源，我们会发现有两个有趣的键决定了要监控哪些资源。让我们获取 `Prometheus` 资源的 YAML 清单并回顾一些有趣的键：
- en: '[PRE6]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This `Prometheus` resource includes important keys to modify the behavior of
    Prometheus itself (such as `scrapeInterval`, data `retention`, and `evaluationInterval`).
    From the preceding code snippet, we can see that all the ServiceMonitor resources
    from all namespaces will be monitored if they include the `release=prometheus-stack`
    label. The same is required for PodMonitors, so we will just create a ServiceMonitor
    resource for our new application monitor. Here is an example:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`Prometheus`资源包括了修改 Prometheus 本身行为的重要键值（例如 `scrapeInterval`、数据 `retention`
    和 `evaluationInterval`）。从前面的代码片段中，我们可以看到，如果所有命名空间中的 ServiceMonitor 资源包含 `release=prometheus-stack`
    标签，它们都会被监控。PodMonitors 也需要这样做，因此我们只需为我们的新应用监控创建一个 ServiceMonitor 资源。以下是一个示例：
- en: '![Figure 12.16 – ServiceMonitor example manifest](img/B19845_12_16.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.16 – ServiceMonitor 示例清单](img/B19845_12_16.jpg)'
- en: Figure 12.16 – ServiceMonitor example manifest
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.16 – ServiceMonitor 示例清单
- en: In the *Labs* section, we will add some open source monitoring endpoints for
    our application (the **Postgres exporter** from [https://grafana.com/oss/prometheus/exporters/](https://grafana.com/oss/prometheus/exporters/)).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在*实验室*部分，我们将为我们的应用程序添加一些开源监控端点（来自[https://grafana.com/oss/prometheus/exporters/](https://grafana.com/oss/prometheus/exporters/)的**Postgres
    exporter**）。
- en: Now, let’s review some quick concepts for configuring a good logging strategy
    for our applications.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一些配置良好日志记录策略的快速概念，适用于我们的应用程序。
- en: Logging your application’s important information
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录应用程序的重要信息
- en: In this section, we will get a general overview of different logging strategies
    and how to implement an open source Kubernetes-ready solution such as **Grafana
    Loki**.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将概述不同的日志记录策略，并讨论如何实现一个开源的、支持 Kubernetes 的解决方案，例如**Grafana Loki**。
- en: In [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096), *Running Docker Containers*,
    we talked about which strategies were available for our applications. As a rule
    of thumb, processes running in containers should always log standard and error
    outputs. This makes it easier or at least prepares a good solution for all the
    processes at the same time. However, your application may need a different **logging
    strategy** for different use cases. For example, you shouldn’t log any sensitive
    information to the standard output. While local logging can be helpful when you
    are developing your application, it may be very tricky (or even only available
    for Kubernetes administrators) in a development or production environment. Therefore,
    we should use either volumes or an external logging ingestion platform. Using
    volumes may require additional access so that you can recover your logs from a
    storage backend, so an external platform would be a better approach for covering
    your logging needs. The fact is that using an external platform can make your
    life easier if your application runs in Kubernetes. There are plenty of Kubernetes-ready
    logging platforms that will allow you to push all your container logs to a backend
    in which you will be able to manage and add appropriate views for different users.
    This will solve the problem of logging sensitive data because it may be necessary
    for debugging purposes but only visible to certain trusty users. You may need
    to ask your Kubernetes administrators because you will probably have a logging
    solution already working on your Kubernetes platform.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B19845_04.xhtml#_idTextAnchor096)中，*运行 Docker 容器*，我们讨论了可用于应用程序的策略。作为经验法则，运行在容器中的进程应该始终记录标准输出和错误输出。这使得所有进程更容易（或至少为所有进程同时准备了一个好的解决方案）。然而，您的应用程序可能需要针对不同用例采用不同的**日志记录策略**。例如，您不应将任何敏感信息记录到标准输出中。虽然本地日志记录在开发应用程序时可能很有帮助，但在开发或生产环境中，这可能会非常棘手（甚至仅限于
    Kubernetes 管理员可用）。因此，我们应使用卷或外部日志采集平台。使用卷可能需要额外的访问权限，以便您可以从存储后端恢复日志，因此外部平台将是一个更好的方法来满足您的日志记录需求。事实上，如果您的应用程序运行在
    Kubernetes 中，使用外部平台可以让您的生活更轻松。有很多 Kubernetes 就绪的日志记录平台，允许您将所有容器日志推送到后端，您可以在其中管理并为不同用户添加适当的视图。这将解决日志记录敏感数据的问题，因为它可能在调试过程中需要使用，但只能对某些信任的用户可见。您可能需要询问
    Kubernetes 管理员，因为您的 Kubernetes 平台可能已经有一个正在运行的日志记录解决方案。
- en: In this chapter, we’ll discuss how you can use Grafana Loki in your Kubernetes
    environment to read and forward your application’s containers and send them to
    a unified backend, in which we will be able to use additional tools such as Grafana
    to review the application’s data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何在 Kubernetes 环境中使用 Grafana Loki 来读取并转发应用程序的容器日志，并将其发送到统一的后端，在那里我们可以使用
    Grafana 等额外工具来查看应用程序的数据。
- en: Grafana Loki can be deployed using different modes, depending on the size of
    your platform and the number of logs expected. To develop and prepare the logs
    of your applications, we will use a minimal installation, as we already did with
    Prometheus. We will use the **monolithic** mode ([https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/](https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/)),
    in which all of Loki’s microservices will run together in a single container image.
    Loki is capable of managing a large number of logs and it uses object storage
    backends. For our needs as developers, it won’t be necessary, and we will just
    use local storage (filesystem mode) provided by our own Kubernetes platform.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Loki 可以使用不同的模式进行部署，具体取决于你的平台规模和预期的日志数量。为了开发和准备你的应用程序日志，我们将使用最小化安装，就像我们之前使用
    Prometheus 一样。我们将使用**单体**模式（[https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/](https://grafana.com/docs/loki/latest/fundamentals/architecture/deployment-modes/)），在这种模式下，Loki
    的所有微服务将一起运行在单个容器镜像中。Loki 能够管理大量日志，并且使用对象存储后端。对于我们作为开发者的需求来说，这不需要，我们将仅使用由我们自己的
    Kubernetes 平台提供的本地存储（文件系统模式）。
- en: While Grafana Loki provides the server-side part, **Grafana Promtail** will
    work as an agent, reading, preparing, and sending logs to Loki’s backend.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Grafana Loki 提供了服务器端的功能，**Grafana Promtail** 将作为代理工作，读取、准备并将日志发送到 Loki 后端。
- en: We are not interested in how Grafana Loki or Prometheus work or can be customized.
    The purpose of this chapter is to learn how we can use them to monitor and log
    our application’s processes, so we will install Loki and configure Promtail to
    retrieve the logs from Kubernetes deployed applications.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不关心 Grafana Loki 或 Prometheus 如何工作或如何定制化。本章的目的是学习如何使用它们来监控和记录我们的应用程序进程，所以我们将安装
    Loki 并配置 Promtail 从 Kubernetes 部署的应用程序中获取日志。
- en: Installing and configuring Loki and Promtail
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装和配置 Loki 与 Promtail
- en: 'Let’s move forward by installing Grafana Loki in our Kubernetes cluster so
    that we can manage all the platform logs. After that, we will be ready to install
    Promtail to retrieve and push the logs to the Loki server:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续在 Kubernetes 集群中安装 Grafana Loki，这样我们就能管理所有平台日志。之后，我们将准备好安装 Promtail 来检索并推送日志到
    Loki 服务器：
- en: 'We will use `helm` again to install Grafana Loki in a different namespace.
    The simplest installation is the single binary chart method with filesystem storage
    ([https://grafana.com/docs/loki/latest/installation/helm/install-monolithic](https://grafana.com/docs/loki/latest/installation/helm/install-monolithic)):'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将再次使用`helm`在不同的命名空间中安装 Grafana Loki。最简单的安装方法是使用单一二进制文件图表方法和文件系统存储（[https://grafana.com/docs/loki/latest/installation/helm/install-monolithic](https://grafana.com/docs/loki/latest/installation/helm/install-monolithic)）：
- en: '![Figure 12.17 – Grafana Loki installation using Helm](img/B19845_12_17.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.17 – 使用 Helm 安装 Grafana Loki](img/B19845_12_17.jpg)'
- en: Figure 12.17 – Grafana Loki installation using Helm
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.17 – 使用 Helm 安装 Grafana Loki
- en: 'We used the following settings to apply the monolithic mode and remove API
    authentication:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用了以下设置来应用单体模式并移除 API 身份验证：
- en: '[PRE7]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: All these flags will help you reduce the hardware resources required for a testing
    environment.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有这些标志将帮助你减少测试环境所需的硬件资源。
- en: 'It is now up and running. Let’s take a quick look at the Service resources
    before installing the Promtail component:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它现在已启动并运行。让我们在安装 Promtail 组件之前快速查看服务资源：
- en: '![Figure 12.18 – Grafana Loki Service resources](img/B19845_12_18.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.18 – Grafana Loki 服务资源](img/B19845_12_18.jpg)'
- en: Figure 12.18 – Grafana Loki Service resources
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.18 – Grafana Loki 服务资源
- en: We’ve reviewed the Loki Services because we are going to configure Promtail
    to send all the logging information retrieved to the `loki-gateway` Service, available
    in the `logging` namespace on port `80`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经查看了 Loki 服务，因为我们将配置 Promtail 将所有检索到的日志信息发送到`loki-gateway` 服务，该服务在 `logging`
    命名空间中的端口 `80` 上可用。
- en: 'Helm can show us the default values that will be used to install a Helm Chart
    if we execute `helm show values <CHART>`. So, we can retrieve the default values
    for the `grafana/promtail` chart by issuing `helm show values grafana/promtail`.
    The output is huge, with all the default values shown, but we only need to review
    the client configuration. This configuration applies to Promtail and defines where
    to send the logs that are read from the different sources:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Helm 可以通过执行 `helm show values <CHART>` 显示用于安装 Helm Chart 的默认值。因此，我们可以通过执行 `helm
    show values grafana/promtail` 来获取 `grafana/promtail` Chart 的默认值。输出内容非常庞大，显示了所有的默认值，但我们只需要查看客户端配置。该配置适用于
    Promtail，并定义了将从不同来源读取的日志发送到哪里：
- en: '[PRE8]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'By default, Promtail will send all the data to `http://loki-gateway`, which
    we have seen exists inside the Kubernetes cluster if we run this tool in the logging
    namespace, alongside Grafana Loki. We’ll proceed to install Promtail using the
    logging namespace, using the default values:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，Promtail 会将所有数据发送到 `http://loki-gateway`，如果我们在日志命名空间中运行该工具，并且与 Grafana
    Loki 一起使用，就会看到它存在于 Kubernetes 集群中。接下来，我们将使用日志命名空间并使用默认值安装 Promtail：
- en: '![Figure 12.19 – Promtail installation using a Helm Chart](img/B19845_12_19.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.19 – 使用 Helm Chart 安装 Promtail](img/B19845_12_19.jpg)'
- en: Figure 12.19 – Promtail installation using a Helm Chart
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.19 – 使用 Helm Chart 安装 Promtail
- en: 'Once installed, we can review the logs of all Kubernetes clusters in Grafana.
    But first, we will need to configure Prometheus (monitoring) and Loki (logging)
    data sources in Grafana. We will use port forwarding to expose the Grafana Service:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，我们可以在 Grafana 中查看所有 Kubernetes 集群的日志。但首先，我们需要在 Grafana 中配置 Prometheus（监控）和
    Loki（日志）数据源。我们将使用端口转发来公开 Grafana 服务：
- en: '[PRE9]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Figure 12.20 – Grafana – Data sources configuration](img/B19845_12_20.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.20 – Grafana – 数据源配置](img/B19845_12_20.jpg)'
- en: Figure 12.20 – Grafana – Data sources configuration
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.20 – Grafana – 数据源配置
- en: 'Notice that the deployment of Grafana using the `kube-prometheus-stack` Chart
    already configured the Prometheus and Alertmanager data sources for us. We will
    configure a new data source for Loki:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，使用 `kube-prometheus-stack` Chart 部署 Grafana 时，Prometheus 和 Alertmanager
    数据源已经为我们配置好了。我们将为 Loki 配置一个新的数据源：
- en: '![Figure 12.21 – Grafana Loki data source configuration](img/B19845_12_21.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.21 – Grafana Loki 数据源配置](img/B19845_12_21.jpg)'
- en: Figure 12.21 – Grafana Loki data source configuration
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.21 – Grafana Loki 数据源配置
- en: 'Click on **Save & Test** – and that’s it! You may receive an error stating
    “**Data source connected, but no labels were received. Verify that Loki and Promtail
    are correctly configured**”. This indicates that we don’t have labels available
    yet for indexing data; it occurs when you have just installed the Promtail component.
    If you wait a few minutes, labels will be available, and everything will work
    correctly. Anyway, we can verify the Loki data by clicking the **Explore** button,
    at the beginning of the **Data sources** | **Settings** page. The **Explore**
    section allows us to retrieve data directly from any Loki-type source. In our
    example, we used Loki as the name of the source, and we can select the available
    labels generated by Promtail with the information from our containers:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **保存并测试** – 就这样！你可能会收到一个错误信息，提示“**数据源已连接，但未收到标签。请确认 Loki 和 Promtail 已正确配置**”。这表示我们还没有可用于数据索引的标签；这通常发生在你刚刚安装完
    Promtail 组件时。如果等几分钟，标签就会变得可用，一切都会正常工作。无论如何，我们可以通过点击 **探索** 按钮，在 **数据源** | **设置**
    页面开头来验证 Loki 数据。**探索** 部分允许我们直接从任何 Loki 类型的数据源中检索数据。在我们的示例中，我们将 Loki 作为数据源的名称，并可以选择
    Promtail 生成的标签，使用来自我们容器的信息：
- en: '![Figure 12.22 – Exploring Loki data sources](img/B19845_12_22_new.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.22 – 探索 Loki 数据源](img/B19845_12_22_new.jpg)'
- en: Figure 12.22 – Exploring Loki data sources
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.22 – 探索 Loki 数据源
- en: 'We can retrieve all the logs from the `kube-system` namespace by simply selecting
    the namespace label and the appropriate value from the list:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只需选择命名空间标签和列表中的相应值，即可检索来自 `kube-system` 命名空间的所有日志：
- en: '![Figure 12.23 – Exploring the logs from all the Pod resources from the kube-system
    namespace](img/B19845_12_23.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.23 – 探索来自 kube-system 命名空间的所有 Pod 资源的日志](img/B19845_12_23.jpg)'
- en: Figure 12.23 – Exploring the logs from all the Pod resources from the kube-system
    namespace
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.23 – 探索来自 kube-system 命名空间的所有 Pod 资源的日志
- en: You will be able to filter by any of the current labels and add very useful
    operations such as grouping, counting the number of appearances of certain strings,
    searching for specific regex patterns, and so on. Lots of options are available
    and they will be very useful for you as a developer. You can have all the logs
    from different applications’ components in one unified dashboard, or even prepare
    your own application dashboard with metrics and logs, mixing different sources.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 你将能够根据当前标签进行筛选，并增加非常有用的操作，如分组、计数某些字符串出现的次数、搜索特定的正则表达式等。提供了许多选项，它们对你作为开发者会非常有用。你可以将不同应用组件的所有日志集中在一个统一的仪表板中，甚至准备你自己的应用仪表板，混合不同的数据源来展示指标和日志。
- en: Prometheus, Loki, and Grafana are very powerful tools and we can only cover
    the basics here. It is up to you to create dashboards using the Grafana documentation
    ([https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/](https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/)).
    The Grafana community provides many dashboard examples ([https://grafana.com/grafana/dashboards/](https://grafana.com/grafana/dashboards/)).
    We will create a fully functional dashboard for the `simplestlab` application
    in the *Labs* section.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus、Loki 和 Grafana 是非常强大的工具，我们在这里只能涵盖基础内容。你可以通过查看 Grafana 文档 ([https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/](https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/))
    来创建仪表板。Grafana 社区提供了许多仪表板示例 ([https://grafana.com/grafana/dashboards/](https://grafana.com/grafana/dashboards/))。我们将在*实验室*部分为
    `simplestlab` 应用创建一个功能齐全的仪表板。
- en: The next section will introduce some load-testing mechanisms and review how
    to use the **Grafana k6** open source tool.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分将介绍一些负载测试机制，并回顾如何使用开源工具**Grafana k6**。
- en: Load testing your applications
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对你的应用进行负载测试
- en: '**Load testing** is the task in which we review how our application works by
    measuring its behavior under different stressful circumstances. You, as a developer,
    always have to think about how your application will manage these stressful situations
    and try to answer some of the following questions:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**负载测试**是我们通过测量应用在不同压力情况下的表现来审视应用如何工作的任务。作为开发者，你总是需要考虑你的应用在这些压力情境下如何应对，并尝试回答以下一些问题：'
- en: Will my application work under high user loads?
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我的应用能否在高用户负载下正常运行？
- en: How will my application’s components be impacted in such a case?
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，我的应用组件将如何受到影响？
- en: Will scaling up some components maintain the overall performance or might this
    cause problems with other components?
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展某些组件是否能维持整体性能，还是会导致其他组件出现问题？
- en: Testing the application before it goes to production will help us predict how
    the application is going to work. **Automation** is key to simulating thousands
    of requests at a time.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用上线之前进行测试，帮助我们预测应用的表现。**自动化**是模拟大量请求的关键。
- en: 'With load testing or **performance testing**, we try to put pressure on our
    applications and increase their workloads. We can test our applications for different
    reasons:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在负载测试或**性能测试**中，我们试图给应用施加压力并增加它的工作负载。我们可以出于不同的原因对应用进行测试：
- en: To understand how our application behaves with an expected load
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解我们的应用在预期负载下的行为
- en: To ascertain the maximum load under which our application will work
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定应用能够承受的最大负载
- en: To try to find possible memory or performance issues that could appear over
    time (memory leaks, fulfillment of certain storage resources, cache, and so on)
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试发现可能随着时间推移出现的内存或性能问题（内存泄漏、存储资源的耗尽、缓存等）
- en: To test how our application auto-scales in certain circumstances and how the
    different components will be affected
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试我们的应用在某些情况下如何自动扩展，以及不同组件将如何受到影响
- en: To confirm some configuration changes in development before they are done in
    production
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开发环境中确认一些配置更改，确保它们在生产环境中进行之前不会出现问题
- en: To test the application performance from different locations that have different
    network speeds
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试应用在不同位置的表现，特别是那些网络速度不同的地方
- en: All these test points can be delivered with some scripting techniques and automation.
    Depending on the application we are testing, we can use some well-known, simple
    but effective tools such as **Apache JMeter** ([https://jmeter.apache.org](https://jmeter.apache.org))
    or – even simpler – **Apache Bench** ([https://httpd.apache.org/docs/2.4/programs/ab.xhtml](https://httpd.apache.org/docs/2.4/programs/ab.xhtml)).
    These tools can emulate application requests but they never behave like a real
    web browser, but **Selenium** ([https://www.selenium.dev](https://www.selenium.dev))
    does. This tool includes a **WebDriver** component that emulates a **World Wide
    Web Consortium** (**W3C**) browsing experience, but it may be complex to integrate
    into automated processes (different releases and integration with different languages
    can be time-consuming). Grafana provides k6, which is an open source tool that
    was created by Load Impact some years ago and is now part of the Grafana tools
    ecosystem. It is a very small tool, written in Go, and can be configured via JavaScript,
    which makes it very customized.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些测试点都可以通过一些脚本技术和自动化来交付。根据我们正在测试的应用程序，我们可以使用一些著名的、简单但有效的工具，如 **Apache JMeter**（[https://jmeter.apache.org](https://jmeter.apache.org)）或更简单的
    **Apache Bench**（[https://httpd.apache.org/docs/2.4/programs/ab.xhtml](https://httpd.apache.org/docs/2.4/programs/ab.xhtml)）。这些工具可以模拟应用程序请求，但它们永远不会像真实的网页浏览器一样行为，而
    **Selenium**（[https://www.selenium.dev](https://www.selenium.dev)）则会。该工具包括一个 **WebDriver**
    组件，模拟 **万维网联盟**（**W3C**）的浏览体验，但它可能在集成到自动化过程中时比较复杂（不同版本和与不同语言的集成可能非常耗时）。Grafana
    提供了 k6，它是一个开源工具，几年前由 Load Impact 创建，现在是 Grafana 工具生态系统的一部分。它是一个非常小巧的工具，使用 Go 编写，并可以通过
    JavaScript 进行配置，这使得它非常定制化。
- en: Important note
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Grafana k6 functionality can be extended by using extensions, although you will
    need to recompile your k6 binary to include them ([https://k6.io/docs/extensions](https://k6.io/docs/extensions)).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana k6 的功能可以通过使用扩展来扩展，尽管你需要重新编译 k6 二进制文件以包含它们（[https://k6.io/docs/extensions](https://k6.io/docs/extensions)）。
- en: Grafana k6 tests can be integrated into the **Grafana SaaS platform** (**Grafana
    Cloud**) or your own Grafana environment, although some features are only available
    in the cloud platform at the time of writing this book.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana k6 测试可以集成到 **Grafana SaaS 平台**（**Grafana Cloud**）或你自己的 Grafana 环境中，尽管在编写本书时，某些功能仅在云平台中提供。
- en: Installing this tool is very simple; it can be run on Linux, macOS, and Windows
    and is suitable for running within containers, which makes it perfect to run in
    Kubernetes as a Job resource.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这个工具非常简单；它可以在 Linux、macOS 和 Windows 上运行，并适用于在容器中运行，这使得它非常适合在 Kubernetes 中作为
    Job 资源运行。
- en: 'To install this tool on Windows, open a PowerShell console with administrator
    privileges and execute `winget` `install k6`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Windows 上安装此工具，请以管理员权限打开 PowerShell 控制台并执行 `winget` `install k6`：
- en: '![Figure 12.24 – Grafana k6 installation on Windows](img/B19845_12_24.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.24 – 在 Windows 上安装 Grafana k6](img/B19845_12_24.jpg)'
- en: Figure 12.24 – Grafana k6 installation on Windows
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.24 – 在 Windows 上安装 Grafana k6
- en: 'Let’s see a quick example of its usage by writing a simple JavaScript `check`
    script:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过编写一个简单的 JavaScript `check` 脚本来快速看看它的使用方法：
- en: '[PRE10]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can now test this example script for 10 seconds, simulating five virtual
    users with the k6 command line:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以测试这个示例脚本，模拟五个虚拟用户运行 10 秒钟，使用 k6 命令行：
- en: '![Figure 12.25 – Executing a k6 test script](img/B19845_12_25.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.25 – 执行 k6 测试脚本](img/B19845_12_25.jpg)'
- en: Figure 12.25 – Executing a k6 test script
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.25 – 执行 k6 测试脚本
- en: In the preceding example, we are verifying a `200` code that was returned from
    the page. We can now use 5,000 virtual users for the same amount of time, which
    may create performance problems in the backend. The results can be integrated
    into different analysis tools such as Prometheus, Datadog, and so on. If you are
    already familiar with Prometheus and Grafana, you will probably like k6.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们正在验证从页面返回的 `200` 代码。现在我们可以使用 5,000 个虚拟用户在相同的时间内进行测试，这可能会在后台引发性能问题。结果可以与不同的分析工具集成，如
    Prometheus、Datadog 等。如果你已经熟悉 Prometheus 和 Grafana，你可能会喜欢 k6。
- en: 'There is a bunch of good usage examples ([https://k6.io/docs/examples](https://k6.io/docs/examples))
    in which Grafana documents different use cases:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [https://k6.io/docs/examples](https://k6.io/docs/examples) 中有一些很好的使用示例，Grafana
    文档中列出了不同的用例：
- en: Single and complex API requests
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个和复杂的 API 请求
- en: HTTP and OAuth authentication with authorization
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP 和 OAuth 身份验证与授权
- en: The correlation of tokens, dynamic data, and cookie management
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令牌的关联、动态数据和 Cookie 管理
- en: POST data parameterization and HTML forms and the parsing of results
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: POST 数据参数化和 HTML 表单以及结果解析
- en: Data uploads or scraping websites
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据上传或抓取网站
- en: Load testing of HTTP2, WebSockets, and SOAP
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP2、WebSockets 和 SOAP 的负载测试
- en: 'We can create a more complex example by adding some content parsing and increasing
    and decreasing the number of virtual users during the execution of the test:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过添加一些内容解析，并在测试执行过程中增加或减少虚拟用户的数量，来创建一个更复杂的示例：
- en: '[PRE11]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the preceding code snippet, we are looking for all the `link` strings and
    retrieving their `href` values:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们正在查找所有的 `link` 字符串，并检索它们的 `href` 值：
- en: '![Figure 12.26 – Executing a k6 test script parsing the “links” string](img/B19845_12_26.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.26 – 执行一个 k6 测试脚本，解析“链接”字符串](img/B19845_12_26.jpg)'
- en: Figure 12.26 – Executing a k6 test script parsing the “links” string
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.26 – 执行一个 k6 测试脚本，解析“链接”字符串
- en: Grafana k6 is very configurable. We can define stages in which we can change
    the behavior of the probe during the check as well as many complex features that
    are completely outside the scope of this book. We suggest that you read the tool’s
    documentation for a better understanding of its functionality and to customize
    it to your needs.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana k6 非常可配置。我们可以定义阶段，在这些阶段中可以改变探针在检查过程中的行为，并且有许多复杂的功能完全超出了本书的范围。我们建议您阅读该工具的文档，以更好地理解其功能并根据需求进行定制。
- en: We will now jump into the instrumentation part. In the next section, we will
    learn how to integrate some tracing technologies into our application observability
    strategy.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将进入仪表化部分。在下一节中，我们将学习如何将一些追踪技术集成到我们的应用可观察性策略中。
- en: Adding instrumentation to your application’s code
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向应用程序的代码中添加仪表化
- en: When you code your applications, it should be easy to prepare appropriate monitoring
    endpoints and adequate monitoring tools to retrieve your application’s metrics.
    Observability helps us understand applications without really having good knowledge
    of their internal code. In this section, we will explore some tools that provide
    traces, metrics, and logs for our applications, without actively knowing our applications’
    functionality. **Monitoring** and **logging** are part of the observation tasks
    but in a different context. We actively know where to retrieve the monitoring
    and logging information from, but sometimes, we need to go further – for example,
    when we run a third-party application or we don’t have enough time to add monitoring
    endpoints to our application. It is important to prepare for monitoring your applications
    from the very beginning, even when you start to plan your application. The same
    applies to the logging part – you have to prepare your application to provide
    good logging information and not merely through the output of your processes as
    they are.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当您编写应用程序时，应该容易准备适当的监控端点和足够的监控工具，以便检索应用程序的指标。可观察性帮助我们理解应用程序，而不需要真正了解其内部代码。在这一节中，我们将探索一些提供追踪、指标和日志的工具，这些工具帮助我们了解应用程序，而无需积极地知道应用程序的功能。**监控**和**日志记录**是观察任务的一部分，但在不同的背景下。我们积极知道从哪里检索监控和日志信息，但有时，我们需要进一步探讨——例如，当我们运行第三方应用程序或没有足够的时间将监控端点添加到应用程序时。即使在开始规划应用程序时，也很重要为监控做好准备。同样，日志记录部分也是如此——您必须为应用程序提供良好的日志记录信息，而不仅仅是通过进程的输出。
- en: Distributing the same type of tracing, logging, and monitoring among your application’s
    components will help you understand what is going on in your application and follow
    every request through the different steps taken in your application’s processes.
    The traces, metrics, and logging data obtained are considered your application’s
    telemetry.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序的各个组件中分配相同类型的追踪、日志记录和监控将帮助您理解应用程序中发生的事情，并跟踪每个请求在应用程序流程中所采取的不同步骤。获取的追踪、指标和日志数据被视为您应用程序的遥测数据。
- en: '**OpenTelemetry** has become a standard observability framework. It is open
    source and provides different tools and SDKs that help implement a telemetry solution
    to easily retrieve traces, logs, and metrics from your applications. This data
    can be integrated into Prometheus and other observability tools, such as Jaeger.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenTelemetry** 已成为标准的可观察性框架。它是开源的，并提供不同的工具和 SDK，帮助实现遥测解决方案，轻松地从应用中检索追踪、日志和指标。这些数据可以集成到
    Prometheus 和其他可观察性工具中，如 Jaeger。'
- en: The main goal of the OpenTelemetry platform is to add observability to your
    applications without any code modification. Currently, the Java, Python, Go, and
    Ruby programming languages are supported. The simplest way of working with OpenTelemetry
    in Kubernetes is using the **OpenTelemetry Operator**. This Kubernetes operator
    will deploy the required OpenTelemetry components for us and create the associated
    CRDs that will allow us to configure the environment. This implementation will
    deploy the Collector’s components, which will receive, process, filter, and export
    telemetry data to designed backends, and create the **OpenTelemetryCollector**
    and instrumentation resource definitions.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 平台的主要目标是为你的应用程序添加可观察性，而无需任何代码修改。目前支持 Java、Python、Go 和 Ruby 编程语言。与
    Kubernetes 中使用 OpenTelemetry 的最简单方式是使用 **OpenTelemetry Operator**。这个 Kubernetes
    Operator 将为我们部署所需的 OpenTelemetry 组件，并创建关联的 CRD，允许我们配置环境。这个实现将会部署收集器的组件，这些组件将接收、处理、过滤并将遥测数据导出到指定的后端，并创建
    **OpenTelemetryCollector** 和仪表资源定义。
- en: 'There are four different ways or modes of deploying an OpenTelemetry Collector:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 OpenTelemetry Collector 有四种不同的方式或模式：
- en: '**Deployment Mode** allows us to control the Collector as if it were a simple
    application running in Kubernetes, and it is suitable for monitoring a simple
    application.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Deployment 模式** 允许我们像控制一个简单应用程序在 Kubernetes 中运行一样控制收集器，它适用于监控简单的应用程序。'
- en: '**DaemonSet Mode** will run a collector replica as an agent, on each cluster
    node.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DaemonSet 模式** 将会作为代理在每个集群节点上运行一个收集器副本。'
- en: '**StatefulSet Mode**, as expected, will be suitable when you don’t want to
    lose any tracing data. Multiple replicas can be executed and each one will have
    a dataset.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StatefulSet 模式**，如预期的那样，当你不想丢失任何追踪数据时，这种模式将非常适合。可以执行多个副本，每个副本将拥有一份数据集。'
- en: '**Sidecar Mode** will attach a collector container to the application’s workloads,
    which is better if you create and remove applications often (perfect for a development
    environment). It also offers a more fine-grained configuration if you use different
    languages and want to choose specific collectors for each application component.
    We can manage which collector to use for a specific Pod with special annotations.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sidecar 模式** 将会把一个收集器容器附加到应用程序的工作负载上，如果你经常创建和删除应用程序（非常适合开发环境），这种模式更为合适。如果你使用不同的语言并且希望为每个应用组件选择特定的收集器，它还提供了更精细的配置。我们可以通过特殊的注解来管理为特定
    Pod 使用哪个收集器。'
- en: Let’s run a quick demo environment from the OpenTelemetry community ([https://github.com/open-telemetry/opentelemetry-demo/](https://github.com/open-telemetry/opentelemetry-demo/)).
    This demo deploys a web store example application, Grafana, Jaeger, and the required
    OpenTelemetry components to obtain an application’s metrics and traces.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 OpenTelemetry 社区快速运行一个演示环境（[https://github.com/open-telemetry/opentelemetry-demo/](https://github.com/open-telemetry/opentelemetry-demo/)）。这个演示部署了一个网上商店示例应用程序、Grafana、Jaeger
    以及获取应用程序度量和追踪所需的 OpenTelemetry 组件。
- en: Important note
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: '**Jaeger** is a distributed tracing platform that maps and groups application
    flows and requests to help us understand workflow and performance issues, analyze
    our Services and their dependencies, and track down root causes when something
    goes wrong in our applications. You can find its documentation at the project’s
    URL: [https://www.jaegertracing.io/](https://www.jaegertracing.io/).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jaeger** 是一个分布式追踪平台，它将应用程序的流程和请求映射并分组，帮助我们理解工作流和性能问题，分析我们的服务及其依赖关系，并在应用程序出现故障时追踪根本原因。你可以在项目的
    URL 找到它的文档：[https://www.jaegertracing.io/](https://www.jaegertracing.io/)。'
- en: The full demo is installed via a Helm Chart (`open-telemetry/opentelemetry-demo`).
    We can deploy it on any namespace, but all the components will run together. The
    presented demo provides a very good overview of what we can include in our desktop
    environment in either Docker Desktop, Rancher Desktop, or Minikube (it may work
    on any other Kubernetes environment), although it doesn’t follow some of the modern
    OpenTelemetry best practices for adding traces and managing collectors. This demo
    doesn’t deploy the Kubernetes OpenTelemetry Operator, and the OpenTelemetry Collector
    is deployed as a simple deployment.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的演示通过 Helm Chart (`open-telemetry/opentelemetry-demo`) 安装。我们可以在任何命名空间上部署它，但所有组件将一起运行。所展示的演示提供了一个非常好的概览，说明我们可以在
    Docker Desktop、Rancher Desktop 或 Minikube 中将哪些内容包含到桌面环境中（也许在其他 Kubernetes 环境中也能工作），尽管它没有遵循一些现代的
    OpenTelemetry 最佳实践来添加追踪和管理收集器。这个演示没有部署 Kubernetes OpenTelemetry Operator，而是将 OpenTelemetry
    Collector 作为一个简单的部署进行部署。
- en: In the next section, we’ll install the demo and review the application and tools
    that have been deployed.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将安装演示并审查已部署的应用和工具。
- en: Reviewing the OpenTelemetry demo
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查 OpenTelemetry 演示
- en: 'In this section, we will install and review some of the most important features
    of a ready-to-use demo prepared by the OpenTelemetry project. This demo will deploy
    a simple web store application and the tools required for managing and retrieving
    the tracing data from different components (you can find additional useful information
    at [https://opentelemetry.io/docs/demo](https://opentelemetry.io/docs/demo)):'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将安装并审查 OpenTelemetry 项目准备的即用型演示的一些重要功能。该演示将部署一个简单的 web 商店应用及管理和检索来自不同组件的追踪数据所需的工具（更多有用的信息可以在
    [https://opentelemetry.io/docs/demo](https://opentelemetry.io/docs/demo) 找到）：
- en: 'First, we will install the demo by following the simple steps described at
    [https://opentelemetry.io/docs/demo/kubernetes-deployment/](https://opentelemetry.io/docs/demo/kubernetes-deployment/).
    We will add the OpenTelemetry project’s Helm Chart repository and then issue `helm
    install` with the default values included in the demo package:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将按照 [https://opentelemetry.io/docs/demo/kubernetes-deployment/](https://opentelemetry.io/docs/demo/kubernetes-deployment/)
    上描述的简单步骤安装演示。我们将添加 OpenTelemetry 项目的 Helm Chart 仓库，然后使用演示包中包含的默认值执行 `helm install`：
- en: '![Figure 12.27 – OpenTelemetry demo application deployment](img/B19845_12_27.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.27 – OpenTelemetry 演示应用部署](img/B19845_12_27.jpg)'
- en: Figure 12.27 – OpenTelemetry demo application deployment
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.27 – OpenTelemetry 演示应用部署
- en: 'As you can see, different web UIs were deployed. We can quickly review the
    different Pods that were created:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，部署了不同的 web UI。我们可以快速查看创建的不同 Pods：
- en: '![Figure 12.28 – OpenTelemetry demo application running Pods](img/B19845_12_28.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.28 – OpenTelemetry 演示应用运行的 Pods](img/B19845_12_28.jpg)'
- en: Figure 12.28 – OpenTelemetry demo application running Pods
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.28 – OpenTelemetry 演示应用运行的 Pods
- en: '[PRE12]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We will use port forwarding so that we can get quick and easy access to all
    the available demo web UIs. All will be reachable at once at localhost using different
    paths, thanks to a reverse proxy deployed with the demo Helm Chart. The web store
    application will be available at `http://localhost:8080`:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用端口转发，以便快速轻松地访问所有可用的演示 web UI。通过演示 Helm Chart 部署的反向代理，所有的 web UI 都可以通过 localhost
    在不同路径下同时访问。web 商店应用将可以在 `http://localhost:8080` 访问：
- en: '![Figure 12.29 – Web store demo application accessible using the port-forward
    kubectl feature](img/B19845_12_29.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.29 – 使用端口转发 kubectl 功能访问的 web 商店演示应用](img/B19845_12_29.jpg)'
- en: Figure 12.29 – Web store demo application accessible using the port-forward
    kubectl feature
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.29 – 使用端口转发 kubectl 功能访问的 web 商店演示应用
- en: The demo web store shows a catalog of telescopes, and it will simulate a shopping
    experience.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 演示 web 商店展示了望远镜的目录，并将模拟购物体验。
- en: 'We can now access Jaeger at `http://localhost:8080/jaeguer/ui`:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以在 `http://localhost:8080/jaeguer/ui` 访问 Jaeger：
- en: '![Figure 12.30 – The Jaeger UI using the port-forward kubectl feature](img/B19845_12_30.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.30 – Jaeger UI 使用端口转发 kubectl 功能](img/B19845_12_30.jpg)'
- en: Figure 12.30 – The Jaeger UI using the port-forward kubectl feature
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.30 – Jaeger UI 使用端口转发 kubectl 功能
- en: 'In the Jaeger UI, we can select which Service to review, and the different
    traces will appear in the right panel:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jaeger UI 中，我们可以选择要查看的服务，不同的追踪数据会出现在右侧面板：
- en: '![Figure 12.31 – The Jaeger UI showing traces for different application Services](img/B19845_12_31.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.31 – Jaeger UI 显示不同应用服务的追踪信息](img/B19845_12_31.jpg)'
- en: Figure 12.31 – The Jaeger UI showing traces for different application Services
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.31 – Jaeger UI 显示不同应用服务的追踪信息
- en: 'An architecture overview is also available in the **System Architecture** tab
    so that you can verify the relations between the different application components:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**系统架构** 标签下也提供了架构概述，以便你可以验证不同应用组件之间的关系：'
- en: '![Figure 12.32 – The Jaeger UI showing the application components](img/B19845_12_32.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.32 – Jaeger UI 显示应用程序组件](img/B19845_12_32.jpg)'
- en: Figure 12.32 – The Jaeger UI showing the application components
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.32 – Jaeger UI 显示应用程序组件
- en: Notice that there’s a load generator workload, which is creating synthetic requests
    for us to be able to retrieve some statistics and traces from the demo environment.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里有一个负载生成工作负载，它正在为我们创建合成请求，以便能够从演示环境中检索一些统计信息和追踪数据。
- en: 'The demo deployment also installs Grafana and Prometheus. The Grafana UI is
    available at `http://localhost:8080/grafana` and Prometheus and Jaeger data sources
    are configured for us:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 演示部署还安装了 Grafana 和 Prometheus。Grafana 用户界面可以通过 `http://localhost:8080/grafana`
    访问，Prometheus 和 Jaeger 数据源已为我们配置好：
- en: '![Figure 12.33 – The Grafana UI showing the configured data sources](img/B19845_12_33.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.33 – Grafana 用户界面，显示已配置的数据源](img/B19845_12_33.jpg)'
- en: Figure 12.33 – The Grafana UI showing the configured data sources
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.33 – Grafana 用户界面，显示已配置的数据源
- en: 'Therefore, we can use Grafana to graph the data from both data sources and
    create an application dashboard. The people from OpenTelemetry have prepared some
    dashboards for us, showing the application’s metrics and traces:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以使用 Grafana 绘制来自这两个数据源的数据，并创建一个应用程序仪表板。OpenTelemetry 的团队为我们准备了一些仪表板，显示应用程序的度量指标和跟踪信息：
- en: '![Figure 12.34 – Grafana’s Dashboards page and the Spammetrics Demo Dashboard
    showing current requests per Service](img/B19845_12_34.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.34 – Grafana 的仪表板页面和 Spammetrics 演示仪表板，显示每个服务的当前请求量](img/B19845_12_34.jpg)'
- en: Figure 12.34 – Grafana’s Dashboards page and the Spammetrics Demo Dashboard
    showing current requests per Service
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.34 – Grafana 的仪表板页面和 Spammetrics 演示仪表板，显示每个服务的当前请求量
- en: We could have included Grafana Loki in this scenario, added some of the logging
    entries, and, finally, created a custom dashboard with all the relevant metrics,
    traces, and log entries. The Grafana platform can even include certain databases
    as data sources, which will improve the overall overview of our application’s
    health.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们本可以在此场景中加入 Grafana Loki，添加一些日志条目，并最终创建一个自定义仪表板，包含所有相关的度量指标、跟踪和日志条目。Grafana
    平台甚至可以将某些数据库作为数据源，从而改善我们应用程序健康状况的整体概览。
- en: Labs
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: This section will show you how to implement some of the techniques that were
    covered in this chapter using the `simplestlab` three-tier application in Kubernetes.
    We will deploy a complete observability platform, including Grafana, Prometheus,
    and Loki, and prepare some exporters for our application’s components.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将向你展示如何使用 Kubernetes 中的 `simplestlab` 三层应用程序实现本章中介绍的一些技术。我们将部署一个完整的可观测性平台，包括
    Grafana、Prometheus 和 Loki，并为我们的应用程序组件准备一些导出器。
- en: 'The code for these labs is available in this book’s GitHub repository at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git](https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git).
    Ensure you have the latest revision available by simply executing `git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git`
    to download all its content or `git pull` if you’ve already downloaded the repository
    before. All the manifests and steps required for running the labs are included
    in the `Containers-for-Developers-Handbook/Chapter12` directory. All the manifests
    required for the labs are included in the code repository. Detailed instructions
    for running the labs are included in the `Chapter12` directory, after you download
    the associated GitHub. Let’s take a brief look at the steps that are to be performed:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实验室的代码可以在本书的 GitHub 仓库中找到，地址是 [https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git](https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git)。通过执行
    `git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git`
    下载所有内容，或如果你之前已下载过该仓库，则执行 `git pull` 确保你获得最新版本。所有运行实验室所需的清单和步骤都包含在 `Containers-for-Developers-Handbook/Chapter12`
    目录中。实验所需的所有清单都包含在代码仓库中。下载相关 GitHub 后，`Chapter12` 目录中提供了详细的运行实验室的说明。让我们简要了解一下要执行的步骤：
- en: 'First, we will create a Minikube Kubernetes environment on our desktop computer.
    We will deploy a simple cluster with one node and ingress and metrics-server plugins:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将在桌面计算机上创建一个 Minikube Kubernetes 环境。我们将部署一个包含一个节点的简单集群，并启用 ingress 和 metrics-server
    插件：
- en: '[PRE13]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Chapter12$ kubectl create ns simplestlab
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Chapter12$ kubectl create ns simplestlab
- en: Chapter12$ kubectl create -f .\simplestlab\ /
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Chapter12$ kubectl create -f .\simplestlab\ /
- en: simplestlab application in the cluster.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集群中的 simplestlab 应用程序。
- en: '[PRE14]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we will deploy a functional monitoring and logging environment on top
    of our Kubernetes desktop platform. To do this, we will first deploy the Kubernetes
    Prometheus stack. We prepared a custom `kube-prometheus-stack.values.yaml` values
    file with appropriate content for deploying a small environment with Grafana and
    Prometheus. We’ve provided the required Helm Charts inside the `Chapter12/charts`
    directory. In this case, we will use the `kube-prometheus-stack` subdirectory.
    To deploy the solution, we will use the following command:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将在我们的Kubernetes桌面平台上部署一个功能完整的监控和日志记录环境。为此，我们将首先部署Kubernetes Prometheus栈。我们准备了一个自定义的`kube-prometheus-stack.values.yaml`值文件，包含适合部署小型环境（包括Grafana和Prometheus）的内容。我们已在`Chapter12/charts`目录中提供了所需的Helm
    Charts。在这种情况下，我们将使用`kube-prometheus-stack`子目录。要部署解决方案，我们将使用以下命令：
- en: '[PRE15]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: helm install loki --namespace logging /
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: helm install loki --namespace logging /
- en: 'Chapter12/charts/promtail directory. We will leave the default values as they
    are because the communication with Loki will only be internal:'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Chapter12/charts/promtail 目录。我们将保持默认值不变，因为与Loki的通信仅限于内部：
- en: '[PRE16]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: By the end of these labs, we will have modified our `simplestlab` application,
    adding some Prometheus exporters for monitoring different application components
    that will help us customize these components for the best performance. We will
    integrate a Postgres database exporter and the NGINX exporter for the `loadbalancer`
    component of `simplestlab`. Manifests for both integrations have been prepared
    for you in the `Chapter12/exporters` directory.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到本章实验结束时，我们将修改我们的`simplestlab`应用，添加一些Prometheus导出器来监控不同的应用组件，这将帮助我们定制这些组件，以达到最佳性能。我们将集成一个Postgres数据库导出器和NGINX导出器，后者用于`simplestlab`的`loadbalancer`组件。两者的集成清单已为你准备好，位于`Chapter12/exporters`目录中。
- en: 'Prometheus must be configured to poll these new targets – the Postgres database
    and NGINX exporters. We will prepare a ServiceMonitor resource for each one to
    inform Prometheus to retrieve metrics from these new sources. The ServiceMonitor
    resources manifests are included in the `Chapter12/exporters` directory. Here
    is the one that’s been prepared for you for the NGINX component:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必须配置Prometheus来轮询这些新的目标——Postgres数据库和NGINX导出器。我们将为每个目标准备一个ServiceMonitor资源，告知Prometheus从这些新源中获取指标。这些ServiceMonitor资源清单包含在`Chapter12/exporters`目录中。以下是为NGINX组件准备的清单：
- en: '[PRE18]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Detailed information about creating simple queries in Grafana to graph data
    using these new metrics is available in the `Readme.md` file for this chapter,
    in this book’s GitHub repository.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于如何在Grafana中使用这些新指标绘制数据的简单查询的详细信息，可以在本章的`Readme.md`文件中找到，该文件位于本书的GitHub仓库中。
- en: The labs we’ve prepared for you in this chapter will give you an overview of
    how to implement a simple monitoring and logging solution for your applications
    and prepare some metrics to review the performance of some of your application’s
    components.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为你准备的实验室将概述如何为你的应用程序实现一个简单的监控和日志记录解决方案，并准备一些指标来回顾你的一些应用组件的性能。
- en: Summary
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to implement some tools and techniques for monitoring,
    logging, and tracing our application workloads in Kubernetes. We also took a quick
    look at the load testing task, with an overview of what you should expect from
    your probes. We talked about Grafana, Prometheus, and Loki, among other tools,
    but the principles we discussed in this chapter can be applied to any monitoring,
    logging, or tracing tool you use.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何为在Kubernetes中的应用工作负载实现一些监控、日志记录和追踪的工具和技术。我们还快速浏览了负载测试任务，概述了你应从探针中预期的内容。我们讨论了Grafana、Prometheus和Loki等工具，但我们在本章讨论的原则可以应用于任何你使用的监控、日志记录或追踪工具。
- en: Monitoring how much of the hardware resources your application consumes and
    reading the logs of your application’s components in a unified environment can
    help you understand your application’s limits and requirements. If you test how
    it behaves under heavy load, it can help to improve your application’s logic and
    predict the performance under unexpected circumstances. Adding traces to your
    code manually or using some of the automation mechanisms seen in this chapter
    will help you go further with your application’s development by understanding
    their insights and integrations.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 监控应用程序消耗的硬件资源量，并在统一环境中查看应用程序组件的日志，可以帮助你了解应用程序的限制和需求。如果你测试应用程序在高负载下的表现，它可以帮助改进应用程序的逻辑，并预测在意外情况下的性能。手动添加跟踪到代码中，或使用本章中看到的一些自动化机制，将有助于通过理解洞察和集成，推动应用程序的进一步开发。
- en: In the next chapter, we will make all the concepts seen so far fit in the application’s
    life cycle management.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把到目前为止所见的所有概念整合到应用生命周期管理中。
- en: Part 4:Improving Applications’ Development Workflow
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4部分：改进应用开发工作流
- en: In this part, we will review some well-known application life cycle management
    phases and best practices. We will cover how working with containers improves
    them, reviewing some continuous integration and continuous deployment logical
    patterns.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分中，我们将回顾一些知名的应用生命周期管理阶段和最佳实践。我们将讨论如何通过容器化来改进这些阶段，并回顾一些持续集成和持续部署的逻辑模式。
- en: 'This part has the following chapter:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 13*](B19845_13.xhtml#_idTextAnchor287), *Managing the Application
    Life Cycle*'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B19845_13.xhtml#_idTextAnchor287)，*管理应用生命周期*'
