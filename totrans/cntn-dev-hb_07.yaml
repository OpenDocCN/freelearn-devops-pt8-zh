- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Orchestrating with Swarm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a developer, you can create your applications based on microservices. Using
    containers to distribute your applications into different components will allow
    you to provide them with different functionalities and capabilities, such as **scalability**
    or **resilience**. Working with a standalone environment is simple with tools
    such as Docker Compose, but things get difficult when containers can run cluster-wide
    on different hosts. In this chapter, we are going to learn how **Docker Swarm**
    will allow us to orchestrate our application containers with a full set of features
    for managing scalability, networking, and resilience. We will review how orchestration
    requirements are included in the Docker container engine and how to implement
    each of our application’s specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Docker Swarm cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing high availability with Docker Swarm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating tasks and services for your applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A review of stacks and other Docker Swarm resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Networking and exposing applications with Docker Swarm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating your application’s services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use open source tools to build, share, and run a simple but functional
    Docker Swarm environment. The labs included in this chapter will help you to understand
    the content presented, and they are published at https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter7\.
    The *Code In Action* video for this chapter can be found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Docker Swarm cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Docker Swarm** is the orchestration platform developed by Docker Inc. It
    is probably the simplest orchestration solution for beginning to deploy your containerized
    applications. It is included inside the Docker container runtime and no additional
    software is required to deploy, manage, and provide a complete and secure Docker
    Swarm cluster solution. However, before we learn how to do this, let’s explore
    the architecture of Docker Swarm.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Docker Swarm’s architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker Swarm’s architecture is based on the concepts of a **control plane**,
    **management plane**, and **data plane** or **workload plane**. The control plane
    supervises the status of the cluster, the management plane provides all the platform
    management features, and finally, the data plane executes the user-defined tasks.
    These planes can be isolated from each other using multiple network interfaces
    (but this should be completely transparent to you as a developer). This model
    is also present in other orchestrators, such as Kubernetes (simplified into **role
    nodes**). Different roles will be used to define the work associated with the
    nodes within the cluster. The main difference between Docker Swarm and other orchestrators
    is that these roles are easily interchangeable within nodes; hence, a control/management
    plane node can be converted into a workload-ready node with just a command. Docker
    Swarm manages all the control plane communications securely by using **Transport
    Layer Security** (**TLS**)-encrypted networks. The internal **certificate authority**
    (**CA**) and its certificates will be completely managed by Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Most container orchestration platforms will define **master nodes** as the nodes
    used to manage the platform, while **worker nodes** will finally execute all the
    workloads. These roles can also be shared and master nodes can execute some specific
    tasks. Docker Swarm allows us to completely change a node’s role with the command
    line without having to reinstall or recreate the node in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the concept of a **service** to define the workloads in our cluster.
    The services have different properties to modify and manage how traffic will be
    delivered to our applications’ workloads. We will define the number of **replicas**
    for a service to be considered alive. The orchestrator will be in charge of making
    sure this number of replicas is always running. With this in mind, to scale a
    service up or down, we will just modify the number of replicas required to be
    considered healthy. When a cluster node goes down, Docker Swarm will schedule
    its tasks on other available hosts.
  prefs: []
  type: TYPE_NORMAL
- en: Applications that use many different container-based components will require
    multiple services to run, which makes it important to define communications between
    them. Docker Swarm will manage both the workload states and the networking layer
    (**overlay networks**). Encryption can also be enabled for service communications.
    To ensure that all service replicas are reachable, Docker Swarm manages an internal
    DNS and load-balances service requests among all healthy replicas.
  prefs: []
  type: TYPE_NORMAL
- en: The cluster will also manage the application’s services’ rolling upgrades any
    time a change is made to any of the components. Docker Swarm provides different
    types of deployments for specific needs. This feature allows us to execute maintenance
    tasks such as updates by simply replacing or degrading a service, avoiding any
    possible outages.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can summarize all of Docker Swarm features in the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm is a built-in Docker container runtime and no additional software
    is required to deploy a container orchestrator cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A control plane, a management plane, and a data plane are deployed to supervise
    cluster states, manage all tasks, and execute our applications’ processes, respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster nodes can be part of the **control and management planes** (with a manager
    role), simply execute assigned workloads (with a worker or compute role), or have
    both roles. We can easily change a node’s role from manager to worker with the
    Docker client command line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An application’s workloads are defined as services, represented by a number
    of healthy replicas. The orchestrator will automatically oversee the execution
    of a reconciliation process when any replica fails to meet the service’s requirements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the cluster control plane and service communications (overlay networks)
    are managed by Docker Swarm, providing security by default with TLS in the control
    plane and with encryption features for services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Swarm provides internal service discovery and homogeneous load balancing
    between all service replicas. We define how service replicas will be updated when
    we change any content or workload features, and Docker Swarm manages these updates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we can advance in this section and learn how to deploy a Docker Swarm cluster
    and its architecture. You as a developer can apply your own knowledge to decide
    which cluster features and resources will help you run your applications with
    supervision from this orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm manager nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned earlier in this section, the control plane is provided by a set
    of hosts. These hosts are known as **manager nodes** in Swarm. These nodes in
    the cluster are critical for delivering all the control plane’s features. They
    all manage the Docker Swarm cluster environment. An internal key-value database
    is used to maintain the metadata of all the objects created and managed in the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: To provide high availability to your cluster, we deploy more than one manager
    node and we will share this key-value store to prevent a failure if a manager
    goes down. One of the manager nodes acts as the leader and writes all the objects’
    changes to its data store. The other managers will replicate this data into their
    own databases. The good thing here is that all this is managed internally by Docker
    Swarm. It implements the **Raft consensus algorithm** to manage and store all
    the cluster states. This ensures information distribution across multiple managers
    equally.
  prefs: []
  type: TYPE_NORMAL
- en: The first node created in a Docker Swarm cluster automatically becomes the cluster
    leader and an election process is always triggered when the leader fails. All
    healthy manager nodes vote for a new leader internally; hence, a consensus must
    be reached before electing a new one. This means that we need at least *N/2+1*
    healthy managers to elect a new leader. We need to deploy an odd number of manager
    nodes and they all maintain the cluster’s health, serve the Docker Swarm HTTP
    API, and schedule workloads on healthy, available compute nodes.
  prefs: []
  type: TYPE_NORMAL
- en: All the communications between manager and worker nodes are encrypted by using
    TLS (mutual TLS) by default. We don’t need to manage any of this encryption; an
    internal CA is deployed and servers’ certificates are rotated automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how the cluster is managed, let’s review how applications
    are executed in the compute nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm worker nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The leader of the manager nodes reviews the status of the platform and decides
    where to run a new task. All nodes report their statuses and loads to help the
    leader decide what the best location for executing the service replicas is. Worker
    nodes talk with manager nodes to inform them about the status of their running
    containers, and this information reaches the leader node.
  prefs: []
  type: TYPE_NORMAL
- en: Worker nodes will just execute containers; they never participate in any scheduling
    decisions and they are part of the data plane, where all services’ internal communications
    are managed. These communications (overlay networks) are based on UDP VXLAN tunneling
    and they can be encrypted, although this isn’t enabled by default since some overhead
    is expected.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is important to know that Docker Swarm manager nodes also have the worker
    role. This means that by default, any workload can run either on a manager node
    or a worker node. We will use additional mechanisms, such as workload locations,
    to avoid the execution of an application’s containers on manager nodes.
  prefs: []
  type: TYPE_NORMAL
- en: We can continue now and learn how to create a simple cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Docker Swarm cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker Swarm’s features are completely embedded into the Docker container runtime;
    hence, we don’t need any additional binaries to create a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: To create a Docker Swarm cluster, we will start by initializing it. We can choose
    any host interface for creating the cluster, and by default, the first one available
    will be used if none is selected. We will execute `docker swarm init` in a cluster
    node and this will become the leader. It is important to understand that we can
    have a fully functional cluster with just one node (leader), although we will
    not be able to provide high availability to our applications in this case. By
    default, any manager node, including the leader, will be able to run any application’s
    workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once a Docker Swarm cluster is created, the Docker container runtime starts
    to work in **swarm mode**. At this point, some new Docker objects become available,
    which may make it interesting for you as a developer to deploy your own cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Swarm**: This object represents the cluster itself, with its own properties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nodes**: Each node within the cluster is represented by a **node object**,
    no matter whether it’s a leader, manager, or worker node. It can be very useful
    to add some labels to each node to help the internal scheduler allocate workloads
    to specific nodes (remember that all nodes can run any workload).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Services**: The service represents the minimal workload scheduling unit.
    We will create a service for each application’s component, even if it just runs
    a single container. We will never run standalone containers in a Docker Swarm
    cluster, as these containers will not be managed by the orchestrator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secrets**: These objects allow us to securely store all kinds of sensitive
    data (up to a maximum of 500 KB). Secrets will be mounted and used inside service
    containers and the cluster will manage and store their content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configs**: Config objects will work like secrets, but they are stored in
    clear text. It is important to understand that configs and secrets are spread
    cluster-wide, which is critical, as containers will run in different hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stacks**: These are a new type of object used to deploy applications in Docker
    Swarm. We will use the Compose YAML file syntax to describe all the application’s
    components and their storage and networking configurations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The Docker Swarm cluster platform does not require as many resources as Kubernetes;
    hence, it is possible to deploy a three-node cluster on your laptop for testing.
    You will be able to verify how your applications work and maintain the service
    level when some of the application’s components fail or a cluster node goes completely
    offline. We use a standalone Docker Swarm cluster in order to use special objects
    such as **secrets** or **configs**.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned before in this section, we can just create a Docker Swarm cluster
    by executing `docker swarm init`, but many arguments can modify the default behavior.
    We will review a few of the most important ones just to let you know how isolated
    and secure a cluster can be:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--advertise-addr`: We can define the interface that will be used to initiate
    the cluster with this. All other nodes will use this IP address to join the recently
    created cluster. By default, the first interface will be used. This option will
    allow us to set which interface will be used to announce the control plane.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--data-path-addr` and `--data-path-port`: We can isolate the data plane for
    the applications by setting a host’s specific interface IP address and port using
    these arguments. Traffic can be encrypted, and this will be completely transparent
    to your applications. Docker Swarm will manage this communication; some overhead
    may be expected due to the encryption/decryption processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--listen-addr`: By default, the Docker Swarm API will be listening on all
    host interfaces, but we can secure the API by answering on a defined interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--autolock`: Docker Swarm will store all its data under `/var/lib/docker/swarm`
    (by default, depending on your runtime root data path). This directory contains
    the CA, used for creating all the nodes’ certificates, and the snapshots automatically
    created by Docker Swarm to preserve the data in case of failure. This information
    must be secure, and the `--autolock` option allows us to lock the content until
    a passphrase is provided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Locking Docker Swarm content may affect your cluster’s high availability. This
    is because every time the Docker runtime is restarted, you must use an unlock
    action to retrieve the directory’s content, and you will be asked for the autolock
    passphrase. Hence, an automatic restart of components is broken since manual intervention
    is required.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a Docker swarm is initialized, a couple of cluster tokens are created.
    These tokens should be used to join additional nodes to the cluster. One token
    should be used to join new manager nodes and the other one should only be used
    to integrate worker nodes. Remember that the node’s roles can be changed later
    if a manager node fails, for example. The following code shows how the tokens
    are presented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To add a worker to this swarm, you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To add a manager to this swarm, run `docker swarm join-token manager` and follow
    the instructions.
  prefs: []
  type: TYPE_NORMAL
- en: We use `docker swarm join` followed by `--token` and the appropriate token for
    a new manager or worker node. This token will be shown at cluster initialization,
    but it can be retrieved whenever needed by simply using `docker swarm join-token`.
    This action can also be used to rotate the current token (automatic rotation will
    be triggered by default every 90 days).
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm nodes can leave the cluster whenever it is needed by executing
    `docker swarm leave`. It is important to understand that losing one manager may
    leave your cluster in danger. Be careful with the manager nodes, especially when
    you change their role to a worker node or when you remove them from a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Some Swarm object properties, such as autolock or certificate expiration, can
    be modified by using `docker` `swarm update`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn what is required to provide high availability
    to a Docker Swarm cluster and the requirements for our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Providing high availability with Docker Swarm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Docker Swarm orchestrator will provide out-of-the-box **high availability**
    if we use an odd number of manager nodes. The **Raft protocol** used to manage
    the internal database requires an odd number of nodes to maintain it healthily.
    Having said that, the minimum number of healthy managers for the cluster to be
    fully functional is *N/2+1*, as discussed earlier in this chapter. However, no
    matter how many managers are working, your application’s functionality may not
    be impacted. Worker nodes will continue working even when you don’t have the minimum
    number of required manager nodes. An application’s services will continue running
    unless a container fails. In this situation, if the managers aren’t functional,
    your containers will not be managed by the cluster and thus your application will
    be impacted. It is important to understand this because it is the key to preparing
    your clusters for these situations.
  prefs: []
  type: TYPE_NORMAL
- en: Although your cluster runs with fully high availability, you must prepare your
    applications. By default, resilience is provided. This means that if a running
    container fails, a new one will be created to replace it, but this will probably
    impact your application even if you run a fully stateless service.
  prefs: []
  type: TYPE_NORMAL
- en: Services integrate **tasks** or **instances**, which finally represent a container.
    Hence, we must set the number of replicas (or tasks) required for a service to
    be considered healthy. The Docker container runtime running the workload will
    check whether the container is healthy by executing the health checks included
    within the container image or the ones defined at execution time (written using
    the Compose YAML file format in which the service is defined).
  prefs: []
  type: TYPE_NORMAL
- en: Definitely, the number of **replicas** will impact the outage of your service
    when things go wrong. Therefore, you should prepare your applications for this
    situation by executing, for example, more than one replica for your services.
    Of course, this requires that you think of your application’s components’ logic
    from the very beginning. For example, even if your application is completely stateless
    and uses a stateful service, such as a database, you will probably have to think
    about how to provide high availability or at least fault tolerance to this component.
    Databases can run inside containers but their logic may need some tweaks. Sometimes,
    you can just replace your SQL database with a NoSQL database distributed solution.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous application example, with a database component, we didn’t take
    into account the problem of managing the stateful data using volumes (even if
    using a distributed solution), but every stateful application should be able to
    move from one cluster node to another. This also affects the associated volumes
    that must be attached to containers wherever they run, no matter which node in
    the cluster receives a task. We can use remote storage filesystem solutions, such
    as NFS, or sync filesystems or folders between nodes. You as a developer don’t
    have to manage the infrastructure, but you must prepare your applications, for
    example, by verifying the existence of certain files. You should also ask yourself
    what will happen if more than one replica tries to access your data. This situation
    will definitely corrupt a database, for example. Other orchestrators, such as
    Kubernetes, provide more interesting solutions for these situations, as we will
    learn in [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170), *Deploying Applications
    with the* *Kubernetes Orchestrator*.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm nodes can be **promoted** from the worker role to the manager role,
    and vice versa, a manager can be **demoted** to a worker. We can also **drain**
    and **pause** nodes, which allows us to completely move all containers from a
    node to another available worker, and disable scheduling in the nodes defined,
    respectively. All these actions are part of infrastructure management. You should
    at least verify how your application will behave when a drain action is triggered
    and your containers stop on one node and start on another. How will your application’s
    components manage such circumstances? How will this affect component containers
    that consumed some of the affected services? This is something you have to solve
    in your application’s logic and code as a developer.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s learn how to schedule our applications in Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: Creating tasks and services for your applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first thing you should know is that we will never schedule containers on
    a Docker Swarm cluster. We will always run **services**, which are the minimal
    deployment units in a Docker Swarm cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Each service is defined by a number of replicas, known in Docker Swarm as **tasks**.
    And finally, each task will run one container.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm is based on Moby’s **SwarmKit** project, which was designed to
    run any kind of task cluster-wide (virtual machines, for example). Docker created
    Docker Swarm by implementing SwarmKit in the orchestrator, but specifically for
    running containers.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a **declarative model** to schedule services in our Docker Swarm
    cluster by setting the desired state for our services. Docker Swarm will take
    care of their state continuously and take corrective measures in case of any failure
    to reconcile its state. For example, if the number of running replicas is not
    correct because one container has failed, Docker Swarm will create a new one to
    correct the service’s state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue by creating a simple `webserver` service using an `nginx:alpine`
    container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We have just defined a service’s name and the image to be used for the associated
    containers. By default, services will be created with one replica.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can verify the service’s state by simply executing `docker service ls` to
    list all the Docker Swarm services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you may have noticed, a service ID is created (object ID) and we can use
    any of the actions learned about in [*Chapter 2*](B19845_02.xhtml#_idTextAnchor036)
    and [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096) for listing, inspecting, and
    removing Docker objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can verify in which node the service’s containers are running by using `docker
    node ps`. This will list all the containers running in the cluster that are associated
    with services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, one container is running in the `docker-desktop` host (Docker
    Desktop environment). We didn’t specify a port for publishing our web server;
    hence, it will work completely internally and will be unreachable to users. Only
    one replica was deployed because the default value was used when we didn’t set
    anything else. Therefore, to create a real service, we will usually need to specify
    the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: The repository from which the image should be downloaded
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of healthy replicas/containers required by our service to be considered
    alive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The published port, if the service must be reachable externally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also important to mention that Docker Swarm services can be either replicated
    (by default, as we have seen in the previous example) or global (run on all cluster
    nodes).
  prefs: []
  type: TYPE_NORMAL
- en: A **replicated service** will create a number of replicas, known as **tasks**,
    and each will create one container. You as a developer can prepare your application’s
    logic to run more than one replica per service to provide simple but useful high
    availability (this will help you lose half of your service in case of failure).
    This will reduce the impact in case of failure and really help with the upgrade
    processes when changes need to be introduced.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, a **global service** will run one replica of your service
    in each cluster node. This is very powerful but may reduce the overall performance
    of your cluster if you can distribute your application’s load into different processes.
    This type of service is used to deploy monitoring and logging applications, and
    they work as agents, automatically distributed in all nodes at once. It is important
    to notice that Docker Swarm will schedule a task for each service on any node
    joined to the cluster. You may use global services when you need to run agent-like
    applications on your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: You as a developer should think about which service type suits your application
    best and use the `--mode` argument to create an appropriate Docker Swarm service.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You may think that it’s a good idea to run a distributed database (MongoDB or
    any simpler key-value store) or a queue management solution (such as RabbitMQ
    or Apache Kafka) as a global service to ensure its availability, but you have
    to take care of the final number of running containers. Global services do not
    guarantee an odd number of containers/processes and may break your application
    if you join new nodes to the cluster. Every time you join a new node, a new container
    is created as part of the global service.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use labels to define locations for certain services. They will affect
    all the replicas at the same time. For example, we can create a global service
    that should only run on nodes labeled as `web`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The Docker Desktop environment works like a one-node Docker Swarm cluster;
    hence, the global service should be running if the appropriate label, `web`, is
    present:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s add the label to the only cluster node we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Automatically, Docker Swarm detected the node label change and scheduled the
    global service container for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, Docker Swarm allows us to change the default location of any
    service. Let’s review some of the options available to place our application’s
    tasks in specific nodes or pools of nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--constraint`: This option fixes where to run our service’s containers. It
    uses labels, as we saw in the previous example. We can verify the placement requirements
    of a service by using `docker` `service inspect`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`--replicas-max-per-node`: Another way of setting the location under certain
    circumstances will be to avoid more than a specific number of replicas per cluster
    node. This will ensure, for example, that replicas will not compete for resources
    in the same host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using placement constraints or preferred locations, you can ensure, for example,
    that your application will run in certain nodes with GPUs or faster disks.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You as a developer should design your application to run almost anywhere. You
    will need to ask your Docker Swarm administrators for any location labeling or
    preferences and use them in your deployments. These kinds of infrastructure features
    may impact how your applications run and you must be aware of them.
  prefs: []
  type: TYPE_NORMAL
- en: We can also execute `Completed` and no other container will be executed. Docker
    Swarm allows the execution of both global or replicated jobs, the `global-job`
    and `replicated-job` service types, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm services can be updated at any time, for example, to change the
    container image or other properties, such as their scheduling location within
    the cluster nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To update any available service’s property, we will use `docker service update`.
    In the following example, we will just update the number of replicas of the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have two replicas or instances running for the `webservice` service,
    we can verify how Docker Swarm will check and manage any failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `docker` runtime client, we can list all the containers running (this
    works because we are using just one node cluster, the `docker-desktop` host):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can kill one of the `webserver` service’s containers and verify that Docker
    Swarm will create a new container to reconcile the service’s status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'A second after the failure is detected, a new container runs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify that Docker Swarm managed the container issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The preceding snippet shows a short history with the failed container ID and
    the new one created to maintain the health of the service.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may have noticed, the containers created within Docker Swarm have the
    prefix of the service associated, followed by the instance number. These help
    us identify which services may be impacted when we have to execute maintenance
    tasks on a node. We can list current containers to view how services’ tasks are
    executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You must remember that we are running containers; hence, services can inherit
    all the arguments we used with containers (see [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096),
    *Running Docker Containers*). One interesting point is that we can include some
    Docker Swarm internal keys using the Go template format as variables for our application
    deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.Service.ID`, `.Service.Name`, and `.Service.Labels` keys. Using these service
    labels may be interesting for identifying or including some information in your
    application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.Node.ID` and `.Node.Hostname`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.Task.ID`, `.Task.Name`, and `.Task.Slot`, which may be interesting if you
    want to manage the behavior of your container within some application’s components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s see a quick example of how we can use such variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we update our service with a new hostname:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can now verify that the container’s hostname has changed.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s continue with the definition of a complete application, as we already
    did with Compose in standalone environments, but this time running cluster-wide.
  prefs: []
  type: TYPE_NORMAL
- en: A review of stacks and other Docker Swarm resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Swarm allows us to deploy applications with multiple services by running
    stacks. This new object defines, in a Compose YAML file, the structure, components,
    communications, and interactions with external resources of your applications.
    Therefore, we will use **infrastructure as code** (**IaC**) to deploy our applications
    on top of the Docker Swarm orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Although we use a Compose YAML file, not all the `docker-compose` keys are available.
    For example, the `depends_on` key is not available for stacks because they don’t
    include any dependency declarations. That’s why it is so important to prepare
    your application’s logic in your code. Health checks will let you decide how to
    break some circuits when some components fail, but you should include status verifications
    on dependent components when, for example, they need some time to start. Docker
    Compose runs applications’ containers on standalone servers while Docker Swarm
    stacks deploy applications’ services (containers) cluster-wide.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a stack YAML file, we will declare our application’s network, volumes, and
    configurations. We can use any Compose file with a few modifications. In fact,
    the Docker container runtime in swarm mode will inform you and fail if you use
    a forbidden key. Other keys, such as `depends_on`, are simply omitted when we
    use a `docker-compose` file with Docker Swarm. Here is an example using the Compose
    YAML file found in [*Chapter 5*](B19845_05.xhtml#_idTextAnchor118), *Creating
    Multi-Container Applications*. We will use `docker` `stack deploy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the container runtime informed us of an unsupported key, `Ignoring
    unsupported options: build`. You can use a Compose YAML file to build, push, and
    then use the container images within your application, but you must use a registry
    for your images. By using a registry, we can ensure that all container runtimes
    will get the image. You can download the images, save them as files, and copy
    them to all nodes, but this is not a reproducible process and it may cost some
    time and effort to synchronize all changes. It seems quite logical to use a registry
    to maintain all the images available to your clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now review the deployed stack and its services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the `REPLICAS` column shows `0/1` for all the services; this is
    because we are using a fake registry and repository. The container runtime will
    not pull images in this example because we are using an internal registry that
    doesn’t exist, but this still shows how to deploy a complete application. Working
    with registries may require the use of `--with-registry-auth` to apply certain
    authentications to our services. Credentials should be used to pull the images
    associated with each of your services if you are using private registries.
  prefs: []
  type: TYPE_NORMAL
- en: You will probably have also realized that all services have the stack’s name
    as a prefix, as we already learned about for projects and their services in [*Chapter
    5*](B19845_05.xhtml#_idTextAnchor118), *Creating* *Multi-Container Applications*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now quickly review how configurations are managed cluster-wide. As we’d
    expect, running applications cluster-wide may require a lot of synchronization
    effort. Every time we create a service with some configuration or persistent data,
    we will need to ensure its availability on any host. Docker Swarm helps us by
    managing the synchronization of all configurations within the cluster. Docker
    Swarm provides us with two types of objects for managing configurations: secrets
    and configs. As we have already learned how secrets and configs work with Compose,
    we will just have a quick review since we will use them in this chapter’s labs.'
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`tmpfs` on Linux hosts). This ensures that the information will be removed
    when the container dies. It may be considered volatile and therefore it is only
    available on running containers. By default, secrets are mounted as files in the
    form `/run/secrets/<SECRET_NAME>`, and they include the secret object’s content.
    This path can be changed, as well as the file permissions and ownership.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use secrets inside environment variables, which is fine because they
    are only visible inside containers. However, you can also use secrets to store
    a complete configuration file, even if not all its content must be secured. Secrets
    can only contain 500 KB of data; thus, you may need to split your configuration
    into different secrets if you think it may not be enough.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets can be created, listed, removed, inspected, and so on like any other
    Docker container object, but they can’t be updated.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: As secrets are encrypted, `docker secret inspect` will show you their labels
    and other relevant information, but the data itself will not be visible. It is
    important to also understand that secrets can’t be updated, so they should be
    recreated if need be (removed and created again).
  prefs: []
  type: TYPE_NORMAL
- en: Configs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Configs** are similar to secret objects, but they are not encrypted and can
    be updated. This makes them the perfect combination for easily reconfiguring your
    applications, but remember to always remove any sensitive information, such as
    connection strings where passwords are visible, tokens, and so on, that could
    be used by an attacker to exploit your application. Config objects are also stored
    in the Docker Swarm Raft Log database in clear text; therefore, an attacker with
    access to the Docker Swarm information can view them (remember that this information
    can be locked with a passphrase). These files can contain a maximum of 500 KB,
    but you can include even binary files.'
  prefs: []
  type: TYPE_NORMAL
- en: Config objects will be mounted inside containers as if they were bind-mounted
    files, owned by the main process user and with read-all permissions. As with secrets,
    config-mounted file permissions and ownership can be changed depending on your
    own needs.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, Docker Swarm takes care of syncing these objects cluster-wide
    without any additional action on our end.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, you can decide the path at which secret or config files will
    be mounted and its owner and permissions. Please take care of the permissions
    you give to your files and ensure that only the minimum necessary permissions
    for reading the file are granted.
  prefs: []
  type: TYPE_NORMAL
- en: We will now learn how our applications will be published internally and externally
    and how the application’s services will be announced cluster-wide.
  prefs: []
  type: TYPE_NORMAL
- en: Networking and exposing applications with Docker Swarm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We already learned how container runtimes provide network capabilities to our
    containers by setting network namespaces and virtual interfaces attached to the
    host’s bridge network interfaces. All these features and processes will also work
    with Docker Swarm but communication between hosts is also required, and this is
    where overlay networks come in.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Docker Swarm overlay network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To manage all communications cluster-wide, a new network driver, **overlay**,
    will be available. The overlay network works by setting UDP VXLAN tunnels between
    all the cluster’s hosts. These communications can be encrypted with some overhead
    and Docker Swarm sets the routing layer for all containers. Docker Swarm only
    takes care of overlay networks while the container runtime will manage all other
    local scope networks.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have initialized a Docker Swarm cluster, two new networks will appear,
    `docker_gwbridge` (bridge) and `ingress` (overlay), with two different functions.
    The first one is used to interconnect all container runtimes, while the second
    one is used to manage all service traffic. By default, all services will be attached
    to the `ingress` network if no additional network is provided during their creation.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you find issues with Docker Swarm, check whether your firewall blocks your
    overlay networking; `2377`/TCP (cluster management traffic), `7946`/TCP-UDP (node
    intercommunication), and `4789`/UDP (overlay networking) traffic should be permitted.
  prefs: []
  type: TYPE_NORMAL
- en: All services attached to the same overlay network will be reachable by other
    services also connected to the same overlay network. We can also run containers
    attached to these networks, but remember that standalone containers will not be
    managed by Docker Swarm. By default, all overlay networks will be unencrypted
    and non-attachable (standalone containers can’t connect); hence, we need to pass
    `--opt encrypted --attachable` arguments along with `--driver overlay` (required
    to create overlay networks) to encrypt them and make them attachable.
  prefs: []
  type: TYPE_NORMAL
- en: We can create different overlay networks to isolate our applications, as containers
    attached to one network will not see those attached to a different one. It is
    recommended to isolate your applications in production and define any allowed
    communication by connecting your services to more than one network if required.
    Configurations such as the subnet or IP address range within a subnet can be used
    to create your custom network, but remember to specify the `--driver` argument
    to ensure you create an overlay network.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see now how we can access our services and publish them.
  prefs: []
  type: TYPE_NORMAL
- en: Using service discovery and internal load balancing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker Swarm provides its own internal IPAM and DNS. Each service receives an
    IP address from the attached network range and a DNS entry will be created for
    it. An internal load-balancing feature is also available to distribute requests
    across service replicas. Therefore, when we access our service’s name, available
    replicas will receive our traffic. However, you as a developer don’t have to manage
    anything – Docker Swarm will do it all for you – but you must ensure that your
    application’s components are attached to appropriate networks and that you use
    the appropriate service’s names. The internal load balancer receives the traffic
    and routes your requests to your service’s task containers. Never use a container’s
    IP address in your applications as it will probably change (containers die and
    new ones are created), but a service’s IP addresses will stay as they are unless
    you recreate your service (as in, remove and create a new one again). A service’s
    IP addresses are assigned by an internal IPAM from a specific set.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing your applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may be asking yourself, what about the overlay `ingress` network created
    by default? Well, this network will be used to publish our applications. As we
    already learned for standalone environments, containers can run attached to a
    network and expose their processes’ ports internally, but we can also expose them
    externally by using `–publish` options. In Docker Swarm, we have the same behavior.
    If no port is exposed, the ports declared in the image will be published internally
    (you can override the ports’ definitions, but your application may not be reached).
    However, we can also publish our service’s containers externally, exposing its
    processes either in a random port within the `30000-32767` range or in a specifically
    defined port (as usual, more than one port can be published per container).
  prefs: []
  type: TYPE_NORMAL
- en: All nodes participate in the overlay `ingress` network, and the published container
    ports will be attached using the port NAT, in all available hosts. Docker Swarm
    provides internal OSI Layer 3 routing using a mesh to guide requests to all available
    services’ tasks. Therefore, we can access our services on the defined published
    port on any cluster host, even if they don’t have a running service container.
  prefs: []
  type: TYPE_NORMAL
- en: An external load balancer can be used to assign an IP address and forward the
    clients’ requests to certain cluster hosts (enough to provide high availability
    to our service).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see a quick example by creating a new service and publishing the container
    port, `80`, on the host port, `1080`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can verify its status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can test port `1080` on any cluster host (we only have one host on Docker
    Desktop):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As we have seen, containers are available on a host’s port. In fact, in a cluster
    with multiple hosts, this port is available on all hosts, and this is the default
    mechanism for publishing applications in Docker Swarm. However, there are other
    methods for publishing applications in this orchestrator:'
  prefs: []
  type: TYPE_NORMAL
- en: The `host` mode allows us to set the port only on those nodes actually running
    a service’s container. Using this mode, we can specify a set of cluster hosts
    where service instances will run by setting labels and then forward the clients’
    traffic to these hosts using an external load balancer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `dnsrr` mode allows us to avoid a service’s virtual IP address; hence, no
    IP address from the IPAM will be set and a service’s name will be associated directly
    with a container’s IP address. We can use the `--endpoint-mode` argument to manage
    the publishing mode when we create a service. In `dnsrr` mode, the internal DNS
    will use **round-robin resolution**. Cluster-internal client processes will resolve
    a different container IP address every time they ask the DNS for the service’s
    name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have learned how to publish applications running inside a Docker
    Swarm cluster to be consumed by applications inside and outside the cluster itself,
    let’s move on to review how service containers and other properties can be updated
    automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Updating your application’s services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to review how Docker Swarm will help our applications’
    stability and availability when we push changes to them. It is important to understand
    that whatever platform we are using to run our containers, we need to be able
    to modify our application content to fix issues or add new functionality. In production,
    this will probably be more restricted but automation should be able to do this
    too, ensuring a secure supply chain.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm provides a rolling update feature that deploys new changes without
    interrupting current replicas and automatically switches to an older configuration
    when the update goes wrong (rolls back).
  prefs: []
  type: TYPE_NORMAL
- en: You as a developer must think about which update method fits your application
    best. Remember to deploy multiple replicas if you want to avoid any outages. This
    way, by setting the update parallelism (`--update-parallelism`), the delay in
    seconds between container updates (`--update-delay`), and the order in which to
    deploy the change (`--update-order`) – which allows us to stop the previous container
    before starting a new one (default), or do the reverse – we can ensure our service
    health when we apply changes. It is very important to understand that your application
    must allow you to run more than one container replica at a time because this may
    be needed to access a volume at the same time. Remember, this may break your application
    data if your processes don’t allow it (for example, a database may get corrupted).
  prefs: []
  type: TYPE_NORMAL
- en: When our service deploys many replicas, for example, a stateless frontend service,
    it is very important to decide what to do when issues arise during the upgrade
    process.
  prefs: []
  type: TYPE_NORMAL
- en: By default, Docker Swarm will wait five seconds to start monitoring the status
    of each task update. If your application requires more time to be considered healthy,
    you may need to set up an appropriate value by using the `--``update-monitor`
    argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'The update process works by default as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker Swarm stops the first service’s container (the first replica/task; the
    container’s suffix shows the task number).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, the update is triggered for this stopped task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A new container starts to update the task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, two situations may occur:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the process goes fine, the update of a task returns `RUNNING`. Then, Docker
    Swarm waits for the defined delay time between updates and triggers the update
    process again for the next service task.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If the process fails, for example, the container doesn’t start correctly, the
    updated task returns `FAILED` and the current service update process is paused.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When the service update process is paused, we have to decide whether we have
    to manually roll back to a previous version (configurations, container images,
    and so on – in fact, any change deployed since the latest correct update) or execute
    a new update again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use the `--update-failure-action` argument to automate the process when
    something goes wrong during the updates. This option allows us to either *continue*
    with the update, even if some containers fail, *pause* the update process (default),
    or automatically trigger a *rollback* in case of any error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is really recommended to test your deployments and updates to have a clear
    idea of how your application can be compromised in case of failure.
  prefs: []
  type: TYPE_NORMAL
- en: All the options described to define the update process are also available for
    the rollback procedure; hence, we have a lot of options for managing our application
    stability even when we trigger service changes.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will prepare an application for Docker Swarm and
    review some of the features learned about in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Labs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following labs will help you deploy a simple demo application on top of
    a Docker Swarm cluster to review the most important features provided by this
    container orchestrator. The code for the labs is available in this book’s GitHub
    repository at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git](https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git).
    Ensure you have the latest revision available by simply executing `git clone https://github.com/PacktPublishing/Containers-for-Developers-Handbook.git`
    to download all its content or `git pull` if you have already downloaded the repository
    before. Additional labs are included in GitHub. All commands and content used
    in these labs will be located inside the `Containers-for-Developers-Handbook/Chapter7`
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by deploying our own Docker Swarm cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a single-node Docker Swarm cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this lab, we will create a one-node Docker Swarm cluster using the Docker
    Desktop environment.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a single-node cluster is enough to review the most important features
    learned about in this chapter but, of course, we wouldn’t be able to move service
    tasks to another node. If you are interested in a situation like that and want
    to review advanced container scheduling scenarios, you can deploy multiple-node
    clusters following any of the methods described in the specific `multiple-nodes-cluster.md`
    Markdown file located in this chapter’s folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a single-node Docker Swarm cluster, we will follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `docker` CLI with the `swarm` object. In this example, we will use
    default IP address values to initialize a Docker Swarm cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now verify the current Docker Swarm nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Overlay and specific bridge networks were created, as we can easily verify
    by listing the available networks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This cluster has one node; hence, this node is the manager (leader) and also
    acts as a worker (by default):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This cluster is now ready to run Docker Swarm services.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the main features of Docker Swarm services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we are going to review some of the features of the most important
    services by running a replicated and global service:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by creating a simple `webserver` service using Docker Hub’s `nginx:alpine`
    container image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker service ls
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ID             NAME        MODE         REPLICAS   IMAGE          PORTS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: m93gsvuin5vl   webserver   replicated   1/1        nginx:alpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $ docker service ps webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ID             NAME          IMAGE          NODE             DESIRED STATE   CURRENT
    STATE                ERROR     PORTS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'webserver.1 and it runs on the docker-desktop node; we can verify the associated
    container by listing the containers on that node:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It is easy to track the containers associated with services. We can still run
    containers directly using the container runtime, but those will not be managed
    by Docker Swarm.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s now replicate this service by adding a new task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker service ps webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ID             NAME          IMAGE          NODE             DESIRED STATE   CURRENT
    STATE               ERROR     PORTS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: l38u6vpyq5zo   webserver.1   nginx:alpine   docker-desktop   Running         Running
    about an hour ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: j0at9tnwc3tx   webserver.2   nginx:alpine   docker-desktop   Running         Running
    4 minutes ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: vj6k8cuf0rix   webserver.3   nginx:alpine   docker-desktop   Running         Running
    4 minutes ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Each container gets its own IP address and we will reach each one when we publish
    the service. We verify that all containers started correctly by reviewing the
    service’s logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker service update \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --publish-add published=8080,target=80 webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'overall progress: 3 out of 3 tasks'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '1/3: running   [==================================================>]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2/3: running   [==================================================>]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3/3: running   [==================================================>]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ docker service ps webserver
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ID             NAME              IMAGE          NODE             DESIRED STATE   CURRENT
    STATE             ERROR     PORTS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: u7i2t7u60wzt   webserver.1       nginx:alpine   docker-desktop   Running         Running
    26 seconds ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: l38u6vpyq5zo    \_ webserver.1   nginx:alpine   docker-desktop   Shutdown        Shutdown
    29 seconds ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: i9ia5qjtgz96   webserver.2       nginx:alpine   docker-desktop   Running         Running
    31 seconds ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: j0at9tnwc3tx    \_ webserver.2   nginx:alpine   docker-desktop   Shutdown        Shutdown
    33 seconds ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 9duwbwjt6oow   webserver.3       nginx:alpine   docker-desktop   Running         Running
    35 seconds ago
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '80 was assigned to a random host port):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ curl localhost:8080 -I
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: HTTP/1.1 200 OK
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Server: nginx/1.23.4'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '...'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: curl command a few times to access more than one service’s replica.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we can check the logs again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you may have noticed, multiple replicas were reached; hence, internal load
    balancing worked as expected.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We end this lab by removing the created service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This lab showed how to deploy and modify a simple replicated service. It may
    be interesting for you to deploy your own global service and review the differences
    between them.
  prefs: []
  type: TYPE_NORMAL
- en: We will now run a simple application using a Compose YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a complete application with Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this lab, we will run a complete application using a stack object. Take
    a good look at the YAML file that we will use to deploy our application:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We first create a couple of secret objects that we will use in the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create an initial database with our own data structure, we add a new config,
    `init-demo.sh`, to overwrite the file included in the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'version: "3.9"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'services:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'lb:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'image: frjaraur/simplestlab:simplestlb'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'environment: # This environment definitions are in clear-text as they don''t
    manange any sensitive data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- APPLICATION_ALIAS=app # We use the service''s names'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- APPLICATION_PORT=3000'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'networks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'simplestlab:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'ports:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- target: 80'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'published: 8080'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'protocol: tcp'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'db:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'image: frjaraur/simplestlab:simplestdb'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'environment: # Postgres images allows the use of a password file.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- POSTGRES_PASSWORD_FILE=/run/secrets/dbpasswd.env'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'networks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'simplestlab:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'secrets:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- dbpasswd.env'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'configs: # We load a initdb script to initialize our demo database.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- source: init-demo.sh'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'target: /docker-entrypoint-initdb.d/init-demo.sh'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'mode: 0770'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'volumes:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- pgdata:/var/lib/postgresql/data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'app:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'image: frjaraur/simplestlab:simplestapp'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'secrets: # A secret is used to integrate de database connection into our application.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- source: dbconfig.json'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'target: /APP/dbconfig.json'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'mode: 0555'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'networks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'simplestlab:volumes:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'pgdata: # This volume should be mounted from a network resource available to
    other hosts or the content should be synced between nodes'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'networks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'simplestlab:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'configs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'init-demo.sh:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'external: true'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'secrets:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'dbpasswd.env:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'external: true'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'dbconfig.json:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'external: true'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We haven’t used a network volume because we are using a single-node cluster,
    so it isn’t needed. But if you plan to deploy more nodes in your cluster, you
    must prepare either a network storage or a cluster-wide synchronization solution
    to ensure the data is available wherever the database component is running. Otherwise,
    your database server won’t be able to start correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can deploy the Compose YAML file as a Docker stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We verify the status of the deployed stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now review which ports are available for accessing our application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 7.1 – Application is accessible at http://localhost:8080](img/B19845_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Application is accessible at http://localhost:8080
  prefs: []
  type: TYPE_NORMAL
- en: Before removing the application using `docker stack rm chapter7`, it may be
    interesting for you to experiment with scaling up and down the app component and
    changing some content (you have the code, configurations, and secrets deployed).
    This will help you experiment with how rolling updates and rollbacks are managed
    by Docker Swarm.
  prefs: []
  type: TYPE_NORMAL
- en: This lab helped you understand how you can parametrize a Docker Compose file
    to deploy a complete application into a Docker Swarm cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the basic usage of Docker Swarm. We learned how
    to deploy a simple cluster and how to run our applications by taking advantage
    of Docker Swarm’s features. We learned how to use Compose YAML files to deploy
    stacks and define an application completely using services and tasks to finally
    execute its containers. Docker Swarm manages complicated networking communication
    cluster-wide, helping us to publish our applications for users or other applications
    to access. It also provides mechanisms to ensure the availability of our applications
    even when we trigger component updates, such as a change to a container image.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn the basics of Kubernetes, the most popular
    and advanced container orchestrator currently available.
  prefs: []
  type: TYPE_NORMAL
