- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running a Highly Available Cloud – Meeting the SLA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “The past resembles the future more than one drop of water resembles another.”
  prefs: []
  type: TYPE_NORMAL
- en: – Ibn Khaldun
  prefs: []
  type: TYPE_NORMAL
- en: One major aspect of successful cloud operating experiences is to prevent downtime
    and the failures of cloud resources and workloads. In [*Chapter 1*](B21716_01.xhtml#_idTextAnchor014)
    , *Revisiting OpenStack – Design Consideration* , we drafted an initial preparatory
    design to enable OpenStack services for redundancy. [*Chapter 3*](B21716_03.xhtml#_idTextAnchor108)
    , *OpenStack Control Plane – Shared Services* , and [*Chapter 4*](B21716_04.xhtml#_idTextAnchor125)
    , *OpenStack Compute – Compute Capacity and Flavors* , looked at some of the logical
    design patterns for OpenStack control plane deployments and various ways to segregate
    compute, such as cells and availability zones. OpenStack is designed to scale
    massively and providing hardware for dedicated OpenStack services can help isolate
    failures, but this requires mechanisms to keep services running during incidents.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring **high availability** ( **HA** ) in the OpenStack world does not differ
    too much from any other complex IT system. One obligatory practice is to find
    and eliminate, through the logical OpenStack setup, any possible **single points
    of failure** ( **SPOFs** ), which differ from one design to another. Our goal
    in this chapter is to achieve HA in each layer of the private cloud infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing HA and failover strategies to ensure business continuity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterating through OpenStack control plane HA design patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an OpenStack environment with additional cloud controllers for fault
    tolerance and redundancy using **kolla-ansible**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring different ways to achieve networking HA in Neutron with the latest
    OpenStack updates, including routing and distributed virtual router mechanisms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncovering native OpenStack solutions to ensure instances failover using the
    Masakari OpenStack project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring HA strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A robust OpenStack cloud platform includes fault tolerance at every level of
    its architecture. This can be very successful if it is planned in advance. Starting
    with a small cluster is easy and achievable, but growing it is a challenge. The
    hallmark of the basic OpenStack component is that it can run on commodity hardware.
    OpenStack is designed to scale massively and provide HA by leveraging more advanced
    HA techniques at each level of the infrastructure. This can include **automatic
    failover** and **geo-redundancy** . [*Chapter 4*](B21716_04.xhtml#_idTextAnchor125)
    , *OpenStack Compute – Compute Capacity and Flavors* , introduced the concepts
    of cells, regions, and availability zones, which provide more robust and advanced
    fault tolerance and availability capabilities for massive OpenStack deployment
    at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring HA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Service availability should be measured and defined by standard metrics. This
    can be summarized using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Availability = MTTF/ (MTTF +* *MTTR)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding equation, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean time to failure (MTTF)** : An estimate of the average time that a system
    is functional before its failure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean time to repair (MTTR)** : An estimate of the average time to repair
    a part or component of a system'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Measuring HA in complex environments such as OpenStack would require a good
    understanding of the deployed cloud environment capabilities that can be tracked
    through performance metrics and KPIs, such as response time, system uptime, and
    downtime, for the **Repair Time Objective** ( **RTO** ) and **Repair Point Objective**
    ( **RPO** ). What’s more critical to end users is to expose a **Service-Level
    Agreement** ( **SLA** ) from the gathered metrics and KPIs and improve against
    them. A SLA identifies areas of improvement based on routinely gathered metrics
    and will boost your business continuity strategy. Availability management is an
    integral pillar of IT best practices that cannot be skipped, especially when operating
    a cloud environment running dozens of services, as with OpenStack. Creating those
    SLAs for each service in more depth would fill an entire book. For the sake of
    simplicity, make sure you engage in availability management practices and update
    the SLA per service by assigning an availability level and availability and downtime
    percentages, as shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Service** | **Availability Level** | **Availability** | **Downtime/Day**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Compute | One 9 | 90 | ~ 2.4 hours |'
  prefs: []
  type: TYPE_TB
- en: '| Network | Two 9s | 99 | ~ 14 minutes |'
  prefs: []
  type: TYPE_TB
- en: '| Compute | Three 9s | 99.9 | ~ 86 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Block storage | Four 9s | 99.99 | ~ 8.6 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Object storage | Five 9s | 99.999 | ~ 0.86 seconds |'
  prefs: []
  type: TYPE_TB
- en: '| Image | Six 9s | 99.9999 | ~ 0.0086 seconds |'
  prefs: []
  type: TYPE_TB
- en: Table 7.1 – Example SLA with x-9s for OpenStack environment services
  prefs: []
  type: TYPE_NORMAL
- en: 'When designing the architecture for an HA OpenStack setup, failures should
    be planned for at every single layer of the cloud architecture. This can be achieved
    thanks to advanced HA models and techniques. The latest OpenStack releases are
    even richer, with built-in features that embrace availability not only for core
    components but also for user workloads. For example, if a host fails, the application
    running on it will not be accessible anymore. Nova supports the feature to recover
    a guest instance by relocating it to a new healthy host. For an extended OpenStack
    setup, the cloud environment could scale even more domain failures by recalling
    availability zones under the Nova service. The essence of the HA design patterns
    can be summarized in the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Eliminate any SPOF for the control and data planes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adopt a geo-replicated design whenever possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate monitoring and anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plan and automate fast disaster recovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decouple and isolate OpenStack components as much as possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the world of OpenStack, different levels of HA can be identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '**L1** : This includes physical hosts, network and storage devices, and hypervisors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L2** : This includes OpenStack services, including compute, network, and
    storage controllers, as well as databases and message queuing systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L3** : This includes the virtual machines running on hosts that are managed
    by OpenStack services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L4** : This includes applications running in the virtual machines themselves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main focus of supporting HA in OpenStack is on L1, L2, and L3.
  prefs: []
  type: TYPE_NORMAL
- en: Designing for HA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One key aspect when designing systems is to take into account every possibility
    where an element of the system could fail. Each element has limits of some kind
    and would not be able to recover within at least a short period, which would affect
    other parts of the system and lead to the whole system becoming unresponsive.
    When looking at common design patterns aimed at maximizing scalability and availability,
    it is important to identify two main classes of services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stateful service** : A service that depends on data from a previous request
    and interacts synchronously to preserve consistency. As such services rely on
    the state, a service failure can affect the whole system and require more backup
    and recovery mechanisms to maintain state information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stateless service** : A service that does not require data or needs to save
    information (state) from a previous request or event. As such services do not
    store states across requests, a sudden failure won’t affect the rest of the system,
    which can operate in a different handler instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As discussed in [*Chapter 3*](B21716_03.xhtml#_idTextAnchor108) , *OpenStack
    Control Plane – Shared Services* , the OpenStack control plane is mainly constructed
    of stateless services, including an API, scheduler, agents, and conductor components
    for all compute, network, image, monitoring, and storage services. The database
    and queuing message count as stateful services. This way, introducing HA into
    our initial setup would require verifying the right pattern for each service and
    component of the OpenStack deployment to ensure the continuity of the service
    during unexpected failures. There are a multitude of ways to achieve OpenStack
    control plane HA. This can be summarized in terms of the following design patterns,
    both of which were introduced in [*Chapter 3*](B21716_03.xhtml#_idTextAnchor108)
    , *OpenStack Control Plane –* *Shared Services* :'
  prefs: []
  type: TYPE_NORMAL
- en: '**Active/passive** : In the OpenStack control plane, failed services will be
    restarted on a second cloud controller node. With stateful services such as the
    database, the master node handles all read and write operations and a second node
    acts as a listener until a failover occurs, upon which the data entry point will
    be switched to the second node. This pattern is suitable for some stateful services
    but not for other stateless OpenStack services. Additionally, it does not fully
    comply with horizontal scaling in OpenStack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Active/active** : Here, the request load hitting the OpenStack control plane
    is distributed among active nodes that process in parallel. This mode in an OpenStack
    deployment brings the highest level of fault tolerance for the control and data
    plane services. In the event of one cloud controller failure, the rest of the
    load will be distributed to the second operational node, maintaining uninterrupted
    services. It is also suited to horizontal scaling as it adds a new node to accommodate
    any increased load without compromising the function of the cluster. As OpenStack
    core components are based on API calls and RPC to handle messages via the queue
    message system, performance is paramount. In active/active mode, service recovery
    has a shorter MTTR than active/passive mode, where a potentially long delay to
    failover can occur, causing some OpenStack services to time out.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the OpenStack reference architectures adopt an active/active ground
    setup for fault tolerance and failover, mainly due to the nature of the OpenStack
    services that can scale horizontally easily and do not require additional mechanisms.
    On the other hand, some services can be configured in active/passive mode, depending
    on the nature of the service. In the next section, we will look at the different
    services that can be used to enable HA.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for HA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each OpenStack control plane layer requires separate analysis to identify the
    best approaches to ensure its availability. Additional technical considerations
    will be taken into account when designing for fault tolerance in a production
    setup. It is important to note that a major factor in the different choices comes
    from the given cloud service provider’s experience with tooling or hardware solutions.
    In this section, we will go through some of the major adopted tools and design
    patterns to achieve a highly available and scalable OpenStack control plane.
  prefs: []
  type: TYPE_NORMAL
- en: Designing with load balancing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Load balancing solution services can be found everywhere and can be used to
    efficiently distribute and serve incoming requests across a server pool. HAProxy
    has been widely adopted on dozens of large OpenStack production deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HAProxy setup involves the following two types of servers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Frontend server** : This server listens for requests coming from a specific
    IP and port, and determines where the connection or request should be forwarded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backend server** : A pool of servers in the cluster receiving the forwarded
    requests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is also important to note the function layers that are involved in HAProxy
    load balancing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Layer 4** : Load balancing is performed in the transport layer in the OSI
    model. All the user traffic will be forwarded based on a specific IP address and
    port to the backend servers. For example, a load balancer might forward the internal
    OpenStack system’s request to the Horizon web backend group of backend servers.
    To do this, whichever backend Horizon is selected should respond to the request
    under scope. This is true in the case of all the servers in the web backend serving
    identical content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer 7** : The application layer will be used for load balancing. This is
    a good way to load balance network traffic. Simply put, this mode allows you to
    forward requests to different backend servers based on the content of the request
    itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HAProxy supports several load balancing algorithms to dispatch a request to
    a server in the backend pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Round robin** : Each server is exploited in turn. As a simple HAProxy setup,
    round robin is a dynamic algorithm that defines the server’s weight and adjusts
    it on the fly when the called instance hangs or starts slowly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leastconn** : The selection of the server is based on the node that has the
    lowest number of connections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Source** : This algorithm ensures that the request will be forwarded to the
    same server based on a hash of the source IP, so long as the server is still up.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Uniform resource identifier** ( **URI** ): This ensures that the request
    will be forwarded to the same server based on its URI. It is ideal to increase
    the cache hit rate in the case of proxy cache implementations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HAProxy keeps an eye on the nodes’ backend availability by running health checks
    on particular IP addresses and ports. It disables any backend node that fails
    the health checks and discards it from the backend pool until it is healthy enough
    to start serving requests again.
  prefs: []
  type: TYPE_NORMAL
- en: Armed with a load balancer, an OpenStack service that is deployed in two or
    more nodes will be exposed by a **Virtual IP** ( **VIP** ). In active/active mode,
    the VIP is managed by the load balancer, which makes sure that a node has sufficient
    availability before it forwards the request.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: If you consider separating the HAProxy deployment into its own physical setup,
    make sure that the VIPs can be reached over the public network.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the use of VIPs combined with HAProxy adds an extra layer to protect OpenStack
    services from failures, the load balancing layer should not present a single point
    of failure. Depending on which software or hardware-based load balancing solution
    you adopt, make sure you increase its redundancy level. That should be reviewed
    as a critical networking setup as it defines the first interface of the OpenStack
    environment. This can be achieved by using a VIP software management tool such
    as **Keepalived** or **Pacemaker** to ensure a highly available load balancing
    layer. Keepalived is free software and employs the **Virtual Router Redundancy
    Protocol** ( **VRRP** ) to eliminate SPOFs by making IPs highly available. As
    shown in the following diagram, VRRP implements virtual routing to perform failover
    tasks between two or more servers in a static, default-routed environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Load balancing and failover using HAProxy and Keepalived](img/B21716_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Load balancing and failover using HAProxy and Keepalived
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To ensure an easily determined quorum by Keepalived, we will empower our control
    plane with HA via three cloud controller nodes managed by Keepalived.
  prefs: []
  type: TYPE_NORMAL
- en: HA for the database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Databases have always been a critical subject when it comes to dealing with
    the growth of data being stored, along with performance and resiliency. This is
    because a database is not a simple service and does not scale as fast as a simple
    API. Any request that reaches an OpenStack API service results in the database’s
    size growing incrementally. In our deployment process, using a CI/CD pipeline
    will generate a few additional entries across several tables in each run. If not
    designed to scale and monitored closely, the database could be subject to failure
    and quickly become a bottleneck. Several open source and database vendors provide
    possible topologies to scale horizontally or vertically or both. The other factor
    is the type of database engine supported by OpenStack and the required experience
    of the cloud operation team to build and architect a highly available and scalable
    database solution in OpenStack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we’ve started our initial production draft with a single database based
    on MySQL, we can highlight the most commonly clustering topologies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Master/slave replication** : A VIP will be switched to a slave node when
    the master node fails. A delay in the health check on the master node at failover
    time and thus a delay in assigning the VIP to the slave node could potentially
    result in data inconsistencies, as shown here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Database master-slave replication](img/B21716_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Database master-slave replication
  prefs: []
  type: TYPE_NORMAL
- en: '**Multi-master replication manager** ( **MMM** ): By setting up two servers,
    both of them become masters by keeping only one acceptable write query at a given
    time. This is still not a very reliable solution for OpenStack database HA because
    in the event of failure of the master, it might lose a certain number of transactions,
    as illustrated here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Database MMM replication](img/B21716_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Database MMM replication
  prefs: []
  type: TYPE_NORMAL
- en: '**MySQL shared storage** : In this topology, both servers depend on redundant
    shared storage. As shown in the following figure, a separation is required between
    the servers processing the data and the storage devices. Note that an active node
    may exist at any point in time. If it fails, the other node will take over the
    VIP after checking the inactivity of the failed node, and turn it off. Such a
    solution is excellent in terms of uptime but may require a powerful storage/hardware
    system, which can be extremely expensive. The service will be resumed on a different
    node by mounting the shared storage within the taken VIP:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Database MySQL with shared storage](img/B21716_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Database MySQL with shared storage
  prefs: []
  type: TYPE_NORMAL
- en: '**Block-level replication** : One of the most adopted HA implementations is
    the **Distributed Replicated Block Device** ( **DRBD** ) replication. Simply put,
    it replicates data in the block device, which is the physical hard drive that’s
    shared between OpenStack MySQL nodes. DRBD can be a costless solution, but performance-wise,
    it is not sufficient when you’re relying on hundreds of nodes. It can also affect
    the scalability of the replicated cluster:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Database block-level replication](img/B21716_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Database block-level replication
  prefs: []
  type: TYPE_NORMAL
- en: '**MySQL multi-master replication with Galera** : Based on **multi-master replication**
    , the **Galera** solution has a few performance challenges within an MMM architecture
    for MySQL/InnoDB database clusters. A requirement for the Galera setup to run
    properly is the presence of at least three nodes. As shown in the following diagram,
    synchronous replication is managed by Galera, where data is replicated across
    the whole cluster:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Database multi-master with Galera replication](img/B21716_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Database multi-master with Galera replication
  prefs: []
  type: TYPE_NORMAL
- en: Regarding these topologies, any MySQL replication setup can be simple to set
    up and make HA-capable, but data can be lost during the failover process. MySQL
    multi-master replication with Galera is tightly designed to resolve such a conflict
    in the multi-master database environment. An issue you may face in a typical multi-master
    setup is that all the nodes try to update the same database with different data,
    especially when a synchronization problem occurs during the master failure. This
    is why Galera uses **certification-based replication** ( **CBR** ). The main mechanism
    of CBR is to assume that the database can roll back uncommitted changes and is
    transactional, in addition to applying replicated events in the same order across
    all the instances. Replication is truly parallel; each one has an ID check. The
    added value that Galera can bring to our MySQL (MariaDB in OpenStack) HA is the
    ease of scalability, such as joining a node to Galera in an automated fashion
    in a production environment. The end design brings an active/active multi-master
    topology with minimum latency and transaction losses. A best practice to ensure
    data consistency when implementing Galera for MariaDB in OpenStack is to keep
    writes committed to only one node of the three.
  prefs: []
  type: TYPE_NORMAL
- en: HA for the message bus
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'RabbitMQ is mainly responsible for communication between different OpenStack
    services. The issue is fairly simple: no queue, no OpenStack service intercommunication.
    RabbitMQ should be considered another critical service that needs to be available
    and survive failures.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A variety of queuing messages systems such as Qpid or ZeroMQ are mature enough
    to support their own cluster setup without the need for you to run other resource
    managers or clustering software solutions alongside them.
  prefs: []
  type: TYPE_NORMAL
- en: 'RabbitMQ is a robust messaging system that can achieve scalability in an active/active
    way through one of the following patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Clustering** : Any data or state needed for the RabbitMQ broker to be operational
    is replicated across all nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mirrored queues** : As the message queue cannot survive in the nodes in which
    it resides, RabbitMQ can act in active/active HA message queues. Simply put, queues
    will be mirrored on other nodes within the same RabbitMQ cluster. Thus, any node
    failure will lead to automatically switching to one of the queue mirrors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quorum queues** : This is a modern version of queues using a variant of the
    **Raft** protocol (enabling members of a distributed system to agree on a set
    of values and share data in the event of failure) with a distributed consensus
    algorithm and implementing replicated FIFO. Each quorum queue has a leader and
    multiple followers with replicated queues hosted in different hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RabbitMQ has deprecated the implementation of mirrored queues in favor of quorum
    queues due to the problems of its predecessor that it solves. This includes synchronization
    failing and performance issues. With the huge message bus traffic in OpenStack,
    quorum queues can boost not just availability but also the consistency of the
    messages, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – RabbitMQ broker quorum pattern](img/B21716_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – RabbitMQ broker quorum pattern
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will extend our deployment by introducing the aforementioned
    elements to enable HA and redundancy in the OpenStack environment.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying for HA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will extend our initial production deployment by extending
    our OpenStack control plane with a highly available configuration composed of
    the following set of nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Virtual** **IP** : **10.0.0.47**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HAProxy 01** ( **hap1.os.packtpub** ): **10.0.0.20**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HAProxy 02** ( **hap2.os.packtpub** ): **10.0.0.21**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Controller 01** ( **cc01.os.packtpub** ): **10.0.0.100**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Controller 02** ( **cc02.os.packtpub** ): **10.0.0.101**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud Controller 03** ( **cc03.os.packtpub** ): **10.0.0.102**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The HA version of our OpenStack environment will require that we apply the
    following configurations in the **globals.yml** file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enable HAProxy, which will use Keepalived by default for the HA settings:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign a VIP that is not used for the management network where the HAProxy
    hosts are connected and Keepalived is running. Optionally, the external and internal
    VIPs can be separated. The following setting will use the same internal VIP address:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The RabbitMQ quorum is the default implementation for message-queue HA in OpenStack.
    Some older versions in **kolla-ansible** use mirrored queues referenced with the
    **om_enable_rabbitmq_high_availability** setting. Make sure this is disabled and
    uses quorum queues instead by checking the **ansible/group_vars/all.yml** file
    or adding the following variable set if it does not exist in the **globals.yml**
    file:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Populating the quorum queues in a running environment requires manually restarting
    all OpenStack services using the **kolla-ansible stop --tags <service-tags>**
    and **kolla-ansible deploy --tags <service-tags>** command lines, where **<service-tags>**
    is the name of a given OpenStack service. It is recommended to automate the service
    restart using the pipeline for consistent configuration and durable queues.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next configuration update is to adjust the **multi_packtpub_prod** file.
    The following layout suggests the deployment of three cloud controller nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'A new host group of two load balancers will be added, running HAProxy and Keepalived:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As stated in [*Chapter 3*](B21716_03.xhtml#_idTextAnchor108) , *OpenStack Control
    Plane – Shared Services* , one of the best practices regarding production environments
    is to start hosting workloads in the cloud environment only when it is configured
    with HA (at a minimum) within its core services. As no production workload has
    been run yet, it is recommended to clean up the running environment by firing
    off the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This will clean up the OpenStack service containers and associated volumes.
    The new pipeline run will deploy all containers from the same image.
  prefs: []
  type: TYPE_NORMAL
- en: The database deployment for Galera InnoDB will run the **wsrep** service across
    the three controller nodes. One common issue when deploying additional nodes in
    a running environment is the failure of one or both nodes to read binary logs
    and update the replication status. RabbitMQ quorum also requires additional manual
    tweaks to clean the existing exchanges and move to durable queues while using
    quorum across different cloud controller nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Commit the changes before running the pipeline. Rolling out the new multi-node
    infrastructure will take longer than the very first run as the new cloud controller
    nodes and load balancers will be deployed in addition to multi-master database
    quorum queues deployment across different nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the pipeline finishes the multi-node deployment, observe the Docker images
    that have been loaded for HAProxy and Keepalived by running the following command
    line in any of the controller nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8 – Listing the HAProxy and Keepalived Kolla images](img/B21716_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – Listing the HAProxy and Keepalived Kolla images
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the different containers for OpenStack services, observe the
    container running HAProxy and Keepalived:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Listing the HAProxy and Keepalived Kolla containers](img/B21716_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – Listing the HAProxy and Keepalived Kolla containers
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, verify that all compute nodes can be listed as part of the OpenStack
    environment and check the service status, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10 – Listing the enabled Nova services in all OpenStack environments](img/B21716_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – Listing the enabled Nova services in all OpenStack environments
  prefs: []
  type: TYPE_NORMAL
- en: 'Each HAProxy instance that’s deployed in each cloud controller node is assigned
    a priority ID that’s used by Keepalived to refer to the elected master node. The
    generated file in each controller node can be found in the **/etc/kolla/keepalived/keepalived.conf**
    file. The following is a snippet of the Keepalived configuration that was generated
    on one of the cloud controller nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The **kolla_internal_vip_51** configuration block defines a random unique ID
    for the VIP that can be set in the **globals.yml** file by changing the **keepalived_virtual_router_id**
    variable. The default value that’s shown is **51** , which refers to the **virtual_router_id**
    value in the Keepalived configuration. Once a cluster managed by Keepalived is
    launched, a priority number will be assigned for each node, where the higher priority
    is the most preferred node to hold the VIP and hence is elected as the master.
    In this example, a priority of **40** has been assigned to the current cloud controller
    node. A quick check on the Kolla Keepalived container log is used to validate
    each cloud controller state. In the following example, the current cloud controller
    is assigned a master state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'And we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Validating the Keepalived master assignment](img/B21716_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – Validating the Keepalived master assignment
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon being elected as a master, Keepalived assigns a VIP of **10.0.0.47** to
    the cloud controller node. In this example, cloud controller 02 ( **10.0.0.101**
    ) has been assigned the VIP. This can be checked by firing off the following command
    line in the host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'It gives the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Checking the Keepalived VIP](img/B21716_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 – Checking the Keepalived VIP
  prefs: []
  type: TYPE_NORMAL
- en: Enabling HAProxy and Keepalived in our OpenStack deployment ensures HA for most
    OpenStack services. On the other hand, OpenStack networking may require additional
    hardening to enable the fault tolerance capability, as will be depicted in the
    following subsection.
  prefs: []
  type: TYPE_NORMAL
- en: HA for networking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The OpenStack network service involves different composites, including Neutron
    server L2, L3, metadata, and DHCP agents. L2 agents are installed on every compute
    node and there is no need to maintain their HA setup. The DHCP and metadata agents
    run across multiple nodes and support a highly available setup by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, L3 agents require more tweaking to attain HA as they are
    the ones responsible for the following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: Managing virtual routers per tenant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing external connectivity to instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing floating IPs to instances for external network access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Before the **Icehouse** release, there was no built-in solution to resolve
    the L3 agent HA issue. Some workarounds involve utilizing an external cluster
    solution using Pacemaker and **Corosync** . New HA modes adopted for Neutron in
    OpenStack have been introduced since the **Juno** release, including the following
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Virtual Router Redundancy** **Protocol** ( **VRRP** )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed Virtual** **Routing** ( **DVR** )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next few sections will look at how a redundant Neutron router setup can
    be achieved using VRRP and Keepalived.
  prefs: []
  type: TYPE_NORMAL
- en: Routing redundancy with VRRP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We briefly introduced the concept of VRRP earlier in this chapter. In the networking
    context, VRRP and Keepalived are configured in Neutron to fail over within a brief
    period between router namespaces. As shown in the following diagram, routers can
    be seen in the form of groups, where each group presents an active router that
    is currently forwarding traffic to instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.13 – Routing redundancy with VRRP](img/B21716_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 – Routing redundancy with VRRP
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the instance traffic is spread among all network nodes based on
    the scheduling for the master and the rest of the backup routers. Based on the
    same concept of the Keepalived mechanism, the master router configures its VIP
    internally and keeps informing the router group about its state and priority.
  prefs: []
  type: TYPE_NORMAL
- en: Each VRRP group elects a master router based on the assigned priorities, where
    the router with the highest ID will be selected as the master and the rest remain
    as backups. A new election poll will only take place when the master router stops
    sending its VRRP advertisements to the assigned group and will be marked as a
    failed master.
  prefs: []
  type: TYPE_NORMAL
- en: Every newly created HA router will add a new router namespace where its L3 agent
    starts Keepalived. Under the hood, routers configured in HA mode will be able
    to communicate via a specific HA network that is not visible to users. The HA
    network interface is denoted by **ha** .
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The active router needs to periodically inform the standby ones about its state,
    determined by the **advertisement interval timer** . If a backup router does not
    receive such information, it will start a new master router election process based
    on the last advertised VRRP. This election is based on priority, where the router
    with the highest value will be elected as the master. Priorities range from **0**
    to **255** , with **255** being the highest priority.
  prefs: []
  type: TYPE_NORMAL
- en: By default, Neutron automatically creates an HA pool range network of **169.254.192.0/18**
    , which is used by tenant routers with HA mode enabled. The next configuration
    demonstrates a router resiliency setup in Neutron using VRRP and Keepalived. Based
    on our initial design, a Neutron node will be added that runs an L3 agent and
    is configured with the Open vSwitch mechanism driver, which supports HA routers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a second network node to the inventory file that runs an L3 agent and,
    optionally, the DHCP and metadata agents, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the pipeline and make sure the L3 agent is up and running by running the
    following command line on the controller node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.14 – Listing the installed Neutron L3 agents](img/B21716_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 – Listing the installed Neutron L3 agents
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure the new network node is connected to the same network segment as the
    first network node, as illustrated in [*Chapter 1*](B21716_01.xhtml#_idTextAnchor014)
    , *Revisiting OpenStack – Design Considerations* . The second node will use the
    same Neutron mechanism driver for Open vSwitch, as configured in the **globals.yml**
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Set the following configuration to **yes** in the **globals.yml** file to enable
    the HA state for the Neutron L3 agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Run the pipeline to apply the new changes in the Neutron configuration file.
    The Neutron service should be restarted, with the **l3_ha** setting being set
    to **True** in the **/etc/neutron/neutron.conf** file. The default number of maximum
    L3 agents that will be scheduled on a virtual router is set to **3** to construct
    the VRRP virtual router. This can be modified in the **roles/neutron/defaults/main.yml**
    file by setting the value of **max_l3_agents_per_router** .
  prefs: []
  type: TYPE_NORMAL
- en: 'With these new settings, any newly created router is considered an HA router
    and not a legacy one. Create a new router by setting the **–** **ha** flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Walking through the different network nodes running an L3 agent, the newly
    created router can be observed via its created namespace in the first network
    node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once an HA router is created, the master router will be assigned a virtual
    IP of **169.254.0.1** at any given time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.15 – Listing the router namespaces and HA scope for the master router](img/B21716_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 – Listing the router namespaces and HA scope for the master router
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check the output in the second node running the backup router:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16 – Listing the router namespaces and HA scope for the backup router](img/B21716_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 – Listing the router namespaces and HA scope for the backup router
  prefs: []
  type: TYPE_NORMAL
- en: 'Neutron automatically reserves a new dedicated HA network that is only visible
    to administrators and does not belong to any OpenStack project upon the creation
    of HA routers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.17 – Listing the reserved HA network](img/B21716_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 – Listing the reserved HA network
  prefs: []
  type: TYPE_NORMAL
- en: 'Keepalived is configured to run in each namespace by using a persistent configuration
    file located at **/var/lib/neutron/ha_confs/ROUTER_NETNS/keepalived.conf** , where
    **ROUTER_NETNS** is the router namespace of the HA router. Failover events are
    also logged in **neutron-keepalived-state-change.log** under the same directory.
    The following extract from a log shows a switch router during a failover event
    on the first network node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.18 – Verifying router failover in log entries](img/B21716_07_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.18 – Verifying router failover in log entries
  prefs: []
  type: TYPE_NORMAL
- en: Neutron routing fault tolerance is a critical requirement to handle OpenStack
    networking availability. The OpenStack Neutron design was not limited only to
    router redundancy using VRRP. Later, Neutron introduced the DVR implementation.
    We’ll explore this in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Routing redundancy with DVR
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like HA routers, DVR operates across multiple compute nodes. Using DVR, network
    load is distributed across operating routers, reducing the traffic load on the
    network node. L3 agents run in compute nodes and traffic flows for *east-west*
    (instance-to-instance) and *north-south* (from an instance to external networks
    with floating IPs or vice versa) are routed across them instead of a single centralized
    network node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuring DVR in Neutron requires the usage of the Open vSwitch mechanism
    driver and the L3 agent to be installed on the compute nodes. Update the inventory
    file by adding the L3 agent to the desired compute nodes, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the pipeline and verify that the L3 agent is up and running in the compute
    nodes by running the following command line on the controller node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.19 – Listing the installed Neutron L3 agents](img/B21716_07_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.19 – Listing the installed Neutron L3 agents
  prefs: []
  type: TYPE_NORMAL
- en: 'Enable DVR routing in the **globals.yml** file by setting the following configuration
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the pipeline and observe the configuration updates in the **/etc/neutron/neutron.conf**
    Neutron configuration file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Each compute node with an installed L3 agent should host the **/etc/neutron/plugins/ml2/openvswitch_agent.ini**
    Open vSwitch agent configuration file with the following settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Run the pipeline to populate the DVR configuration in both the agent and Neutron
    server configuration settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an admin, create a new router by specifying the **--distributed** argument,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'In each compute node, validate the existence of the same **qrouter** namespace
    ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The router connecting both networks to different compute nodes is the same
    router instance with the same namespace created in each compute node. Typically,
    the **qr** interfaces corresponding to the same namespace will have the same interface
    names and IP addresses in the compute nodes. For **east-west** connectivity, the
    traffic flow between **instance01** hosted in **cn01.os** reaching **instance02**
    spawned in **cn02.os** can be visualized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.20 – East-west traffic in DVR mode](img/B21716_07_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.20 – East-west traffic in DVR mode
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the preceding diagram, traffic flowing from **instance01** and
    **instance02** (east-west) takes the following path:'
  prefs: []
  type: TYPE_NORMAL
- en: Traffic from **instance01** is forwarded from its local gateway through the
    router namespace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The router in **cn01.os** replaces the source MAC address with its interface
    MAC address.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The router forwards the traffic to the integration bridge in **cn01.os** .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Packets are then forwarded to the provider bridge in **cn01.os** .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The source MAC address of the router interface in the packet is replaced by
    the MAC address of the compute node, **cn01.os** .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic is forwarded to the destination compute node, **cn02.os** , through
    the physical network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic reaches the **cn02.os** host via the provider bridge.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic is forwarded to the integration bridge in the **cn02.os** host.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the integration bridge level, the source MAC address is replaced by the router
    MAC interface in **cn02.os** , as dictated in the router namespace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic is forwarded to the destination, **instance02** .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return traffic from **instance02** follows the routing path from **cn02.os**
    through its respective bridges and routers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The DVR implementation, much like using VRRP, is simple as it comes with Neutron’s
    built-in features.
  prefs: []
  type: TYPE_NORMAL
- en: This section outlined the building blocks of enabling HA in the underlying OpenStack
    infrastructure and control plane services. In the following section, we will deep
    dive into the different options to implement fault tolerance for workloads running
    in OpenStack.
  prefs: []
  type: TYPE_NORMAL
- en: Managing instance failover
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Providing HA to cloud resources is a critical topic that OpenStackers have had
    to handle since the early releases of OpenStack. Workload users seek different
    ways to increase the availability of their virtual machines through manual tooling
    and scripting, which can be overlooked if not efficiently managed. With the introduction
    of the **Masakari** project in OpenStack, cloud operators can offer workload users
    an automated service that ensures HA for KVM-based instances, reducing the need
    for manual scripting and seamlessly integrating within the OpenStack ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Masakari also uses Corosync and Pacemaker. As a native HA load balancing stack
    solution for the Linux platform, Pacemaker is a cluster resource manager that
    depends on Corosync to control and organize HA across the hosts in OpenStack.
    Corosync ensures that cluster communication is based on the messaging layer and
    manages the VIP assignment to one of the nodes. Once a cluster of workload instances
    is created, Masakari provides failure detection of the hosts running the instances,
    which is where Corosync comes into play by making sure a virtual IP is assigned
    to a functional host. Masakari is composed of an API that deals with REST requests
    and an engine component that executes recovery requests to the Nova service. As
    shown in the following figure, Masakari primarily provides instance HA via three
    forms of monitors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.21 – Instance HA monitors using Masakari](img/B21716_07_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.21 – Instance HA monitors using Masakari
  prefs: []
  type: TYPE_NORMAL
- en: 'The main Masakari components can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Instance restart** : An instance failure detected by an agent running in
    the compute node will be restarted. Instance restart is managed by the **masakari-instancemonitor**
    Masakari monitor process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instance evacuation** : Instances will be evacuated to another healthy compute
    node upon detection of hypervisor failure. The Masakari glossary defines a **failover
    segment** as a group of compute nodes that hosts evacuated instances if one of
    the compute nodes in the same segment goes down. Instance evacuation is managed
    by the **masakari-hostmonitor** Masakari process monitor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process monitor** : This is managed by the **masakari-processmonitor** service,
    which runs on the compute node to collect the status of the different processes
    running on the hypervisor machine, including libvirtd and the Nova compute service.
    The monitor makes sure that, during the failure of one process, no more instances
    are scheduled to run on the affected compute node and will instead be handled
    by other nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next section describes how to deploy the Masakari service in OpenStack using
    **kolla-ansible** .
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Masakari
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Masakari is composed of its API, monitors, and engine, all of which are installed
    across the cloud controller and compute nodes. Starting with the **globals.yml**
    file, enable the Masakari service by editing the following variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To control the instances’ HA using the instance evacuation option, enable the
    following setting in the **globals.yml** file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In the **multi_packtpub_prod** inventory file, assign the Masakari services
    to run the API and engine services in the cloud controller nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'At the cloud controller level, the instance evacuation monitor requires that
    the compute nodes that will deploy Peacemaker and Corosync under the hood to be
    monitored:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, **hacluster** is an extra Ansible role that provides support to Masakari
    for compute node failure monitoring and recovering instances on a healthy hypervisor
    node, as required for Pacemaker and Corosync:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The instance restart monitor requires the instance status to be monitored by
    the compute nodes themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the pipeline and make sure the Masakari containers are up and running by
    checking the new Masakari containers. To do so, run the following command line
    in a cloud controller node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.22 – Listing Masakari Kolla containers](img/B21716_07_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.22 – Listing Masakari Kolla containers
  prefs: []
  type: TYPE_NORMAL
- en: 'To simulate a VM HA scenario, we will spawn an instance in one compute node
    and use the Masakari instance restart monitor mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the **HA_Enabled** flag property of the created instance to **True** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Check which compute node the instance is running and kill the instance process
    ID to simulate an instance failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.23 – Listing the virtual machines for the HA test](img/B21716_07_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.23 – Listing the virtual machines for the HA test
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to the compute node and kill the instance PID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'By watching the Masakari log file outputs in **/var/log/kolla/masakari** ,
    observe the status of the instance reboot in the same hypervisor host:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.24 – Validating the Masakari instance respawning process in the
    log entries](img/B21716_07_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.24 – Validating the Masakari instance respawning process in the log
    entries
  prefs: []
  type: TYPE_NORMAL
- en: 'Within a few seconds, the killed instance will be spawned in the same compute
    node. This can be checked via the newly created instance PID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, Masakari can be a great addition to ensure workload fault tolerance
    without the need to operate the HA capability separately for each instance, thus
    avoiding heavy manual effort. Masakari is getting more popular, and several production
    deployments have proven its advantages in helping workload administrators and
    cloud developers tackle failover challenges at the instance level.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we enabled a critical architectural safeguard design in our
    OpenStack environment by covering the HA pillar across the control and data planes.
    We now have numerous ways to construct a highly available OpenStack environment,
    depending on which HA strategy is preferred. In this chapter, we empowered the
    control plane services using HAProxy and Keepalived. Other deployments could employ
    Corosync, Pacemaker, and a selection of vendor solutions for load balancing. As
    demonstrated in this chapter, more than a single design pattern can be applied
    for common infrastructure services, such as databases and message queues, to achieve
    failover at best. Networking HA in OpenStack has achieved another level of maturity
    that enables cloud operators to choose between two options to minimize any potential
    risks of connectivity loss for the tenant networks: routing with VRRP and DVR.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also explored an attractive capability for cloud users to achieve
    failover with native OpenStack services for their workloads running in instances
    using Masakari. We also showed some additional snippets for managing HA in OpenStack
    layers using **kolla-ansible** . There is still some ongoing amelioration on the
    infrastructure code using Kolla to automate cell and region deployments for compute
    services in OpenStack that was not covered in this chapter. HA and redundancy
    are critical elements that are required for you to start welcoming production
    workloads in your OpenStack environment and with this chapter, you should be ready
    to get started. Alongside ensuring the HA of services, we need to keep an eye
    on them and act proactively when things start to boil.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will discuss the next operational excellence pillar of the
    OpenStack journey. It will explore ways you can monitor your cloud environment
    for the early detection of anomalies and deep dive into more fine-grained options
    for introspection and the analysis of collected OpenStack services logs.
  prefs: []
  type: TYPE_NORMAL
