- en: Real-Time Data Analysis - Azure Stream Analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While some Azure components enable us to deliver data to the cloud, in most
    cases we also need something that is designed for analyzing and querying streamed
    data. One such service is Azure Stream Analytics, a real-time data analysis tool,
    which is able to read all messages sent through, for example, Event Hub, and transform,
    and save them using one of the predefined outputs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Working with Azure Stream Analytics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Available input and output types
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Querying data using the query language
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring the correct order of incoming data and performing checkpoints or replays
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To perform the exercises in this chapter, you will need:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2017 instance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure subscription
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Stream Analytics tools—[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Stream Analytics introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed Azure Event Hub, which is a solution for
    receiving and processing thousands of messages per second, by introducing the
    implementation of event processor hosts. While it is great for workloads such
    as big data pipelines or IoT scenarios, it is not a solution to everything, especially
    if you want to avoid hosting VMs. Scaling such architectures can be cumbersome
    and nonintuitive; this is why there is Azure Stream Analytics, which is an event-processing
    engine designed for high volumes of data. It fills a gap where other services
    such as Event Hub or IoT Hub do not perform well (or where to do so they require
    much more skill and/or more sophisticated architecture), particularly for real-time
    analytics, anomaly detection, and geospatial analytics. It is an advanced tool
    for advanced tasks, which will greatly improve your cloud and message-processing
    skills.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Stream ingestions versus stream analysis
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get started, we will compare two topics:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Stream ingestion**: This is a process where you introduce a service/API for
    receiving messages from your producers. Such a service is designed to ingest data
    only—it does nothing more (such as transforming or analyzing). To perform any
    kind of analysis of ingested data, you have to introduce your own processors.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stream analysis**: This is a process where you actually analyze the data.
    You search for anomalies, duplicates, or malformed data, process it, and push
    it further to other services for storing, presenting, and triggering other actions.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To make things even clearer, we can take a look at the following diagram:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b15af9bc-e1b6-4bf3-9539-95324c45e3d0.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: 'It shows the four steps of data processing:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '**Produce**: Where data is actually produced by different services, devices,
    and clients'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ingest**: This is when the data is consumed from different sources'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analyze**: During this step data is analyzed, transformed, and routed to
    appropriate services and components'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Analyze**: 在此步骤中，数据被分析、转换并路由到适当的服务和组件。'
- en: '**Use**: Storing, displaying, and processing data further in other services,
    such as PowerBI, Azure Functions, and many others'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Use**: 在其他服务中进一步存储、显示和处理数据，例如PowerBI、Azure Functions等等。'
- en: While Azure Event Hub or Azure IoT Hub is a part of the ingest step, Azure Stream
    Analytics is responsible for **analyzing**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure Event Hub或Azure IoT Hub作为摄入步骤的一部分时，Azure Stream Analytics负责**分析**。
- en: Note that you are not limited to Azure services when it comes to ingesting data.
    In such a scenario, you can also use any kind of queue or API, as long as it is
    capable of processing thousands of events per second.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在摄入数据时，您并不限于Azure服务。在这种情况下，只要它能够处理每秒数千个事件，您也可以使用任何类型的队列或API。
- en: Azure Stream Analytics concepts
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Stream Analytics概念
- en: 'In Azure Stream Analytics, the most important concept is a **stream**. You
    can think about it as a flow of many events carrying data—they do not necessarily
    have to be the same or share schema. Analyzing such a stream is not a trivial
    task. If you have to decode hundreds of thousands of events, the process has to
    be quick, robust, and reliable. We will discuss the main concepts of this service
    to verify whether it is capable of acting as our analyzing solution and the main
    events processor:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure Stream Analytics中，最重要的概念是**流**。您可以将其视为携带数据的许多事件的流——它们不一定相同或共享架构。分析这样的流不是一件简单的任务。如果您需要解码数十万个事件，该过程必须快速、稳健且可靠。我们将讨论该服务的主要概念，以验证它是否能够作为我们的分析解决方案和主要事件处理器：
- en: '**Fully managed**: Azure Stream Analytics is a fully managed platform as a
    service(PaaS), so you do not have to worry about provisioning resources and scaling
    it—the runtime will take care of that, so you can focus on providing optimal queries
    for data analysis.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fully managed**: Azure Stream Analytics 是一个完全托管的平台即服务（PaaS），因此您无需担心资源配置和扩展问题——运行时会自行处理，这样您就可以专注于为数据分析提供最佳查询。'
- en: '**An SQL-based query language**: To analyze data, Azure Stream Analytics uses
    an SQL-based query language, which enables developers to build advanced procedures
    quickly, which extract from a stream exactly what they want. Additionally, you
    can bring your own extensions such as ML solutions or user-defined aggregates
    to perform extra calculations, using tools unavailable to the service.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**An SQL-based query language**: 为了分析数据，Azure Stream Analytics使用基于SQL的查询语言，使开发人员能够快速构建高级程序，从流中精确提取所需内容。此外，您可以引入自己的扩展，如ML解决方案或用户定义的聚合，以执行额外的计算，使用服务不可用的工具。'
- en: '**Performance**: Azure Stream Analytics is focused on **streaming units **(**SUs**) instead
    of some hardcoded values of CPUs or memory. This is because it is designed to
    provide stable performance and recurrent execution time. What is more, thanks
    to this concept, you can easily scale your solution to meet your demands.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Performance**: Azure Stream Analytics专注于**流单元（SUs）**而不是一些硬编码的CPU或内存值。这是因为它设计用于提供稳定的性能和反复执行时间。此概念使得您可以轻松扩展解决方案以满足需求。'
- en: '**Low cost of ownership**: In Azure Stream Analytics you pay only for what
    you choose. As pricing depends on the number of SUs per hour, there is no additional
    cost to be incorporated in the overall payment.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Low cost of ownership**: 在Azure Stream Analytics中，您只需支付您选择的内容。由于定价取决于每小时的SUs数量，因此在总体付款中不会增加额外费用。'
- en: 'There are also some extra technical concepts (such as input/output types, checkpoints,
    or replays), which we will cover in the next parts of this chapter. To see the
    big picture of the whole pipeline using Azure Stream Analytics, please check the
    following image:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后续部分，我们将涵盖一些额外的技术概念（例如输入/输出类型、检查点或重播）。要了解使用Azure Stream Analytics的整个管道的全貌，请查看以下图片：
- en: '![](img/1e589130-614e-4d10-a8d3-2198eb66b992.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e589130-614e-4d10-a8d3-2198eb66b992.png)'
- en: Of course, there could be other references on this picture (additional services,
    user functions, and analyzers), but for the sake of simplicity, I did not include
    them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在这张图片上可能还有其他参考信息（附加服务、用户功能和分析器），但为了简单起见，我没有包括它们。
- en: Input and output types
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输入和输出类型
- en: Azure Stream Analytics offers a seamless integration with some native Azure
    services, such as Azure Event Hub, Azure IoT Hub, or Azure Blob Storage. Additionally,
    it can be easily configured to output data to an SQL database, Blob, or Event Azure
    Data Lake Store. To leverage those possibilities, you will have to define both
    input and output types, which you are interested in. This allows for data to be
    easily ingested (in the form of a stream), so a job, which you will write, can
    work on thousands of events, analyzing and processing them. In this section, you
    will learn how to get started with Azure Stream Analytics and to define both the
    inputsand outputs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Create Azure Stream Analytics in Azure portal
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get started, you will need to create an instance of Azure Stream Analytics.
    To do so, you have to click on + Create a resourceand search for `Stream Analytics
    job`. This will display a form, where you can enter all the necessary data to
    create a service:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e62ebf9-4ae7-4a9e-9fd8-6cd399f8efa2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: 'There are two fields, which at first you might overlook:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'Hosting environment: Azure Stream Analytics can be hosted in two ways: as a
    native Azure service or deployed to an on-premise IoT Edge gateway device. IoT
    Edge is a topic beyond the scope of this book, so the natural choice will be Cloud.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Streaming units (1 to 120): You have to select how many SUs you would like
    to provision for a job to process your events. The number of required SUs depends
    on the characteristics of your job, and additionally may vary depending on the
    input type of your choice. There is a link in the *Further reading*section, which
    describes in detail how many SUs you may need for your job.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember that you will pay €0.093/hour for each SU you choose, even when it
    is not working on a job.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you click Create and open the Overview blade, you will see an empty dashboard:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/989b4ee6-dfd4-4c1a-883a-91dcb9a90482.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, both Inputs and Outputsare empty for now—we have to change
    this, so we can use them in our query. Both of the features are available on the
    left, in the JOB TOPOLOGYsection:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb0061d0-855e-43dc-89ac-b6deb2a3dc9d.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Adding an input
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To add an input, click on the Inputs blade. It will display an empty screen,
    where you have two possibilities:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: + Add stream input: Here you can add a link to services that enable you to ingest
    a stream. Currently available Azure components are Azure Event Hub, Azure IoT
    Hub, and Azure Blob Storage. The inputs can live (or not) in the same subscription,
    and such a connection supports compression (so you can pass a compressed stream using,
    for example, GZip or deflate).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: + Add reference input: Instead of ingesting data from a real-time stream, you
    can also use Azure Blob Storage and add a reference to it, so you can ingest so-called reference
    data. In that scenario, Azure Stream Analytics will load the whole data into memory,
    so it can perform lookups on it. It is an ideal solution for static or slowly
    changing data, and supports data up to the maximum size of 300 MB
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here you can find an example of configuring Event Hub as an input:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79d74fab-61f3-495c-8db9-9616807fe09d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: 'Depending on your choices (whether you have an Event Hub in your subscription
    or not, whether it exists or not), there will be different options available.
    In the previous example, I configured a new hub (which was nonexistent) to be
    the source of my data. There are some fields, however, which I would like to cover
    now:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Event Hub consumer group: If you would like to make Azure Stream Analytics read
    data from the very beginning, enter a consumer group here. By default, it will
    use `$Default`, which is the default consumer group in Azure Event Hub.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Event serialization format: You can choose from JSON, Avro, and CSV. This allows
    you to deserialize events automatically, based on the used serialization format.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Event compression type: If you are using GZip or Deflate, here you can choose
    the right option, so the input will be automatically deserialized.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that you need an actual Azure Event Hub namespace to be able to  create
    a hub from Azure Stream Analytics automatically.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: After filling all the required fields, you will be able to click on the Create button
    to initialize the creation of a new input. Of course, you can add more than just
    one input as they will all be available in the input stream, so you will be able
    to work with the incoming events. Before you start your job, you will need at
    least one output, which we are about to add now.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Adding an output
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To add an output, you have to click on the Outputs blade. It is similar to
    the Inputs one, but there are different kinds of output available:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6df0fb16-6d94-4ad7-9180-e9f97ea21ce8.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, there are many different types of output available, which makes Azure
    Stream Analytics so flexible when it comes to pushing ingested data to different
    services. We can divide them into different categories:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Storage: SQL database, Blob storage, Table storage, Cosmos DB, and Data Lake
    Store
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reporting: Power BI
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute: Azure Functions
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Messaging: Event Hub, Service Bus
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Depending on the category, you will have different options for what you can
    do with the processed events:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'Storage: Storing data for further operations, archiving, and event log'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reporting: Near real-time reports
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute: An easy solution for achieving unlimited integration capabilities
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Messaging: Pushing events further for different pipelines and systems
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here you can find a configuration for integrating Azure Table storage as an
    output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/05d434e1-3b7e-4cdf-8b23-5bc4a81c4c3d.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: Available fields depend heavily on the selected output type, so I will not focus
    on them in this chapter. You can find a reference to them in the *Further reading*section.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可用字段很大程度上取决于所选的输出类型，因此我在本章中不会重点讨论这些内容。你可以在*进一步阅读*部分找到相关参考。
- en: Azure Stream Analytics query language
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Stream Analytics 查询语言
- en: The strength of Azure Stream Analytics, besides the rich selection of Azure
    services that seamlessly integrate with it, lies in its query language, which
    allows you to analyze an input stream easily and output it to a required service.
    As it is an SQL-like language, it should be intuitive and easy to learn for most
    developers using this service. Even if you are not familiar with SQL, the many
    examples available and its simple syntax should make it easy for you.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Azure Stream Analytics 丰富的 Azure 服务选择，可以无缝集成外，其强大之处还在于查询语言，它允许你轻松地分析输入流并将其输出到所需的服务。由于它是类似
    SQL 的语言，它应该对大多数使用该服务的开发者来说直观且容易学习。即使你不熟悉 SQL，提供的许多示例和简单的语法也应该使你容易掌握。
- en: Writing a query
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写查询
- en: 'In the Azure portal, the query window for Azure Stream Analytics can be found
    either in the Overview or Query blade:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure 门户中，Azure Stream Analytics 的查询窗口可以在概览或查询面板中找到：
- en: '![](img/ccdb9cfe-a9f2-4d77-9823-e423acf8c87c.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ccdb9cfe-a9f2-4d77-9823-e423acf8c87c.png)'
- en: 'In the preceding example, you can see a simple SQL-like query, which performs
    the following three things:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，你可以看到一个简单的类似 SQL 的查询，它执行以下三项操作：
- en: Selects data from the input using the given alias
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用给定的别名从输入中选择数据
- en: Chooses the particular columns
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择特定的列
- en: Pushes them into a specific output
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们推送到特定的输出中
- en: 'You can also click on the Edit querylink, so you will be routed to the Query screen:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以点击“编辑查询”链接，这样你将被引导到查询页面：
- en: '![](img/7414db1b-be82-4085-9504-6cd0af031699.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7414db1b-be82-4085-9504-6cd0af031699.png)'
- en: 'As you can see, to be able to actually work with a query, you will need both
    an input and an output, as without them you will not be able to save it. In general,
    a query consists of three elements:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，要实际使用查询，你需要同时拥有输入和输出，否则你将无法保存它。一般来说，查询由三个元素组成：
- en: '`SELECT`: Where you are selecting columns from the input you are interested
    in'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SELECT`：你从输入中选择你感兴趣的列'
- en: '`INTO`: Where you are telling the engine which output you are interested in'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`INTO`：你告诉引擎你感兴趣的输出'
- en: '`FROM`: Where you are selecting an input from which data should be fetched'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FROM`：你选择要从中提取数据的输入'
- en: 'Of course, the preceding statements are not the only ones, which are available—you
    can use plenty of different options, such as GROUP BY, LIKE, or HAVING. It all
    depends on the input stream and the schema of incoming data. For some jobs, you
    may only need to perform a quick transformation and extract the necessary columns;
    for others, you might require more sophisticated syntax for getting exactly what
    you want. You will find common query patterns in the link in the *Further reading*section.
    In the preceding example, in the `SELECT` part of the query, I have selected three
    columns, which are available when analyzing Azure Event Hub events. What is more,
    I used the `AS ` construct to tell the engine to actually rename fields to match
    those defined in the Outputs section. When I run my job, I can see that it actually
    passes events to my table:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，上述语句并不是唯一可用的—你可以使用许多不同的选项，如 GROUP BY、LIKE 或 HAVING。一切取决于输入流和传入数据的模式。对于某些任务，你可能只需要进行简单的转换并提取必要的列；而对于其他任务，你可能需要更复杂的语法来精确获取所需内容。你可以在*进一步阅读*部分的链接中找到常见的查询模式。在上面的示例中，在查询的
    `SELECT` 部分，我选择了三个在分析 Azure Event Hub 事件时可用的列。而且，我使用了 `AS` 构造，告诉引擎实际重命名字段以匹配 Outputs
    部分中定义的字段。当我运行作业时，我可以看到它确实将事件传递给了我的表：
- en: '![](img/79802b23-11fa-4186-8a01-2d5182fb8ea7.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79802b23-11fa-4186-8a01-2d5182fb8ea7.png)'
- en: 'However, there are some problems with the current setup:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当前配置存在一些问题：
- en: We rely on the Event Hub fields, which might change in the future.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们依赖于 Event Hub 字段，这些字段未来可能会发生变化。
- en: We are missing the actual data of an event.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们缺少事件的实际数据。
- en: There are duplicated columns.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在重复的列。
- en: 'Let''s assume each event has the following structure:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个事件具有以下结构：
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Of course, particular data changes over time. We can quickly change the query:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，特定数据会随时间变化。我们可以快速修改查询：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And adapt the configuration to change the output a little bit:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 并调整配置，稍微改变输出：
- en: '![](img/9668fd25-804b-4ef7-8cfa-e45792b367cf.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9668fd25-804b-4ef7-8cfa-e45792b367cf.png)'
- en: 'However, the basic constructs are only a few percent of the overall capability
    of the service. There are also inbuilt functions, which can be easily used in
    each query to enhance it, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematical functions:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Aggregate functions:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Analytic functions:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Geospatial functions:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'String functions:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In addition to these, there are some more such as record functions, date/time
    functions, conversion, or array functions. The preceding examples are of course
    not all the available functions. You can find them all in the *Further reading*section.
    The important thing here is that some functions are deterministic (this means
    that they always return the same result if the same input values are used), and
    some are not—this is especially important when handling high loads and trying
    to avoid possible anomalies.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Remember, you can merge different streams of data and push them to a single
    output (or vice versa—have a single input and distribute it to multiple outputs).
    This is a very powerful feature of this service, which makes ingesting and processing
    data much easier.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Event ordering, checkpoints, and replays
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous sections, we covered some basic topics of Azure Stream Analytics:
    how to configure inputs and outputs, querying data, and using the service. In
    the last part of this chapter, I will show you its more advanced features such
    as event ordering, checkpoints, and replays, which ensure that events are processed
    exactly in a way you would expect. These topics are in fact common subjects in
    many different messaging solutions, so you will be able to use knowledge from
    this chapter in your other projects.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Event ordering
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two concepts of events when it comes to their ordering:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Application (or event) time
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arrival time
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There is a clear distinction between them:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '**Application time**: This is a timestamp when an event was generated on the
    client (or application) side. It tells you exactly when it occurred.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Arrival time**: This is a system timestamp, which is not present in the original
    payload. It tells you when an event was received by a service and picked up for
    processing.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Depending on the input type, arrival time and application time will be different
    properties (`EventEnqueuedUtcTime `or `EnqueuedTime `for arrival time, whereas
    application time, in general, will be a generic property). What you have to remember
    is, depending on the selected scenario, you can process events as they come but
    out of order, or in order but delayed. This can be easily described using the
    following event sequence:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '**Arrival**: `2018-09-02T12:17:49` **Application**: `2018-09-02T12:17:48`'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Arrival**: `2018-09-02T12:17:50` **Application**:` 2018-09-02T12:17:44`'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Arrival**: `2018-09-02T12:17:51` **Application**:`2018-09-02T12:17:46`'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you process events as they come into the stream, they will be processed **out
    of order**—in fact, they occurred in a different order, so there is a possibility
    that some data will be outdated. The other option is to sort events by application
    time; in such a scenario, the process will be delayed, but the order will be preserved.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果按事件流到来的顺序处理，它们将被**无序处理**——实际上，它们发生的顺序不同，因此有可能某些数据会变得过时。另一种选择是按应用时间对事件进行排序；在这种情况下，处理会延迟，但顺序将得以保留。
- en: Whether you need to or not, processing events in order depends on the data schema
    and characteristics of the processed events. Processing them in order is more
    time-consuming, but sometimes you just cannot do it the other way.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 是否需要按顺序处理事件，取决于数据模式和已处理事件的特征。按顺序处理事件更耗时，但有时你根本无法采用其他方式。
- en: 'Azure Stream Analytics has a feature named Event ordering, which allows you
    to make a decision about what to do with events, which are either out of order
    or outdated:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**Azure Stream Analytics** 具有一个名为事件排序的功能，允许你决定如何处理无序或过时的事件：'
- en: '![](img/053f17d5-6cee-4585-a4ce-77f90fc5ddf0.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/053f17d5-6cee-4585-a4ce-77f90fc5ddf0.png)'
- en: 'There are two options available:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种可用选项：
- en: 'Events that arrive late: This one allows you to process outdated events (for
    which the application time does not match the one processed as the last one) within
    a defined time window.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟到达的事件：这一选项允许你在定义的时间窗口内处理过时的事件（即应用时间与最后处理的事件时间不匹配的事件）。
- en: 'Out of order events: It is possible that Azure Stream Analytics consider some
    of your events to be  out of order (this situation could happen, for instance,
    if your senders'' clocks are skewed). Here you can set a time window, during which
    this situation is acceptable).'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无序事件：可能会发生**Azure Stream Analytics** 将一些事件视为无序事件的情况（例如，如果发送方的时钟不一致）。在这种情况下，你可以设置一个时间窗口，在该时间窗口内可以接受此情况。
- en: Additionally, you can define an action, which will be performed if an event
    either arrived late or was out of order—for Drop, it will simply be removed, and
    if you select Adjust, processing will be suspended for some time when such situations
    occur.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以定义一个操作，如果事件迟到或无序，则会执行该操作——对于丢弃（Drop）操作，它将被简单移除，如果选择调整（Adjust），当这种情况发生时，处理将暂停一段时间。
- en: Checkpoints and replays
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查点和重放
- en: 'In fact, Azure Stream Analytics is a stateful service, which is able to track
    the event-processing progress. This makes it suitable for the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，**Azure Stream Analytics** 是一个有状态服务，能够跟踪事件处理进度。这使得它适用于以下场景：
- en: Job recovery
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业恢复
- en: Stateful query logic
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有状态查询逻辑
- en: Different job start modes (now, custom, and when last stopped)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的作业启动模式（现在、自定义和上次停止时）
- en: 'Of course, there is a difference between what is possible after the checkpoint
    and when a replay is necessary. There are situations when the data stored within
    a checkpoint is not enough, and the whole replay is required; however, this may
    differ depending on your query. In fact, it depends on the query parallelization
    factor and can be described using the following formula:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在检查点之后和重放时，情况是有所不同的。当检查点中存储的数据不足时，可能需要进行完整的重放；然而，这取决于你的查询。实际上，它依赖于查询的并行化因素，可以通过以下公式描述：
- en: '*[The input event rate] x [The gap length] / [Number of processing partitions]*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*[输入事件速率] x [间隔长度] / [处理分区数]*'
- en: The more processors you have, the faster you can recover when something goes
    wrong. A good rule of thumb is to introduce more SUs in case your job fails and
    you have to close the gap quickly.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器越多，出现问题时恢复得越快。一个好的经验法则是，当作业失败并且你需要快速填补间隙时，增加更多的 SUs。
- en: The important thing to consider when replaying data is the use of window functions in
    your queries (tumbling, hopping, sliding, or session)—they allow you to process
    data in different kinds of windows, but complicate the replay mechanism.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 重放数据时需要考虑的重要因素是查询中使用的窗口函数（滚动窗口、跳跃窗口、滑动窗口或会话窗口）——它们允许你在不同类型的窗口中处理数据，但也使得重放机制变得复杂。
- en: Summary
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered Azure Stream Analytics, a service for processing
    streams of data in near real time. You have learned what the available inputs
    and outputs are and how to configure them. What is more, you were able to write
    your first query, and check how the query language works for analyzing and processing
    incoming events. If you need a PaaS  that can quickly read and transform events
    and push them to many different Azure services, Azure Stream Analytics is for
    you.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 Azure Stream Analytics，这是一个用于近实时处理数据流的服务。你已经了解了可用的输入和输出，并学习了如何配置它们。而且，你也能够编写你的第一个查询，并查看查询语言如何用于分析和处理传入事件。如果你需要一个能够快速读取和转换事件，并将其推送到多个不同
    Azure 服务的 PaaS，Azure Stream Analytics 就是你需要的服务。
- en: In the next chapter, we will go through Azure Service Bus, an enterprise-class
    messaging solution that is in fact the foundation of Azure Event Hub, which we
    discussed previously.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讲解 Azure Service Bus，这是一种企业级的消息传递解决方案，实际上是我们之前讨论的 Azure Event Hub 的基础。
- en: Questions
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the payment model for Azure Stream Analytics?
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure Stream Analytics 的付费模型是什么？
- en: What is the difference between a stream and the reference output?
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流和引用输出有什么区别？
- en: What is the difference between application and arrival time?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用时间和到达时间有什么区别？
- en: Which query construct do you need to select an ID from an input and push it
    to an output?
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要使用哪个查询构造来选择输入中的 ID 并将其推送到输出？
- en: Can you process different inputs in the same query?
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能在同一个查询中处理不同的输入吗？
- en: When is an event considered out of order?
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时认为事件是无序的？
- en: Is it possible to get a substring from a property in a query? If so, which function
    can be used for that?
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否可以从查询中的某个属性提取子字符串？如果可以，应该使用哪个函数？
- en: Further reading
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Scaling and SUs: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption)
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展和 SUs：[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption)
- en: Different output types: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的输出类型： [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs)
- en: Common query patterns: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见查询模式：[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns)
- en: Window functions: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 窗口函数：[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)
