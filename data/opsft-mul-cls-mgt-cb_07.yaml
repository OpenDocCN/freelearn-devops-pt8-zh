- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: OpenShift Network
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenShift 网络
- en: As we know, networking can be the cause of big trouble if it is not well designed.
    From a traditional perspective, the network is the dorsal spine of every infrastructure.
    Networking equipment such as routers, modems, switches, firewalls, **Web Application
    Firewalls** (**WAFs**), **Intrusion Detection Systems/Intrusion Prevention Systems**
    (**IDSs/IPSs**), proxies, and **Virtual Private Networks** (**VPNs**) needs to
    be totally integrated, deployed, and maintained using best practices to ensure
    high performance and reliable network infrastructure. In this chapter, we will
    discuss important concepts related to networking on OpenShift that you need to
    take into consideration to make the best decisions for your case.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，如果网络设计不当，可能会引发大问题。从传统的角度来看，网络是每个基础设施的脊梁。路由器、调制解调器、交换机、防火墙、**Web 应用防火墙**（**WAFs**）、**入侵检测系统/入侵防御系统**（**IDSs/IPSs**）、代理和**虚拟专用网络**（**VPNs**）等网络设备需要通过最佳实践进行完全集成、部署和维护，以确保高性能和可靠的网络基础设施。本章将讨论与
    OpenShift 网络相关的重要概念，您需要考虑这些概念，以便做出最适合您情况的决策。
- en: 'This chapter covers the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: OpenShift networking
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenShift 网络
- en: Network policies
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络策略
- en: What is an Ingress controller?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 Ingress 控制器？
- en: Types of routes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由类型
- en: OpenShift networking
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenShift 网络
- en: Throughout this book, we continue to reaffirm the importance of choosing the
    right architecture as it directly impacts the way the cluster will work. We expect
    that, at this time, all the required network decisions have been made and implemented
    already – there are a lot of network changes that are not possible after cluster
    deployment.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将继续强调选择正确架构的重要性，因为它直接影响集群的工作方式。我们期望此时所有必要的网络决策都已经做出并实施——许多网络更改在集群部署后是无法进行的。
- en: Although we already discussed networks in [*Chapter 2*](B18015_02.xhtml#_idTextAnchor028),
    *Architecture Overview and Definitions*, and deployed our cluster, we believe
    that it is important to expand on this topic a bit more and include more details
    about the differences when considering network usage.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经在[*第 2 章*](B18015_02.xhtml#_idTextAnchor028)《架构概览与定义》中讨论了网络，并且已部署了我们的集群，我们认为有必要进一步扩展此主题，并包括更多关于考虑网络使用时差异的细节。
- en: Red Hat OpenShift uses a default **Software-Defined Network** (**SDN**) based
    on Open vSwitch ([https://github.com/openvswitch/ovs](https://github.com/openvswitch/ovs))
    that creates a multilayer network solution. This additional layer works as a virtual
    switch on top of the network layer, and it is responsible for creating, maintaining,
    and isolating traffic on the virtual LAN.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Red Hat OpenShift 使用基于 Open vSwitch 的默认**软件定义网络**（**SDN**）（[https://github.com/openvswitch/ovs](https://github.com/openvswitch/ovs)），该网络创建了一个多层次的网络解决方案。这个额外的层次作为网络层之上的虚拟交换机，负责在虚拟局域网内创建、维护和隔离流量。
- en: 'Because of its multiple-layer network capacity, Open vSwitch provides a way
    to control traffic coming in and out of the cluster. Refer to the following diagram
    to better understand network traffic between network layers:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其多层网络能力，Open vSwitch 提供了一种控制进出集群流量的方式。请参阅以下图示以更好地理解网络层之间的流量：
- en: '![Figure 7.1 – Overview of the networking layers ](img/B18015_07_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 网络层概览](img/B18015_07_01.jpg)'
- en: Figure 7.1 – Overview of the networking layers
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 网络层概览
- en: During the OpenShift cluster installation, some namespaces related to network
    functions are created; basically, the most important network project is `openshift-sdn`,
    which contains some pods for each node that will be responsible for the traffic
    between the nodes. It is relevant to also state that the traffic is running inside
    a virtual LAN operated by Open vSwitch. There are other network projects involved
    as well, such as `openshift-host-network` and `openshift-ingress`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenShift 集群安装过程中，会创建一些与网络功能相关的命名空间；基本上，最重要的网络项目是 `openshift-sdn`，它包含每个节点的一些
    pod，负责节点之间的流量。还需要指出的是，流量在由 Open vSwitch 操作的虚拟局域网内运行。还有其他网络项目涉及其中，如 `openshift-host-network`
    和 `openshift-ingress`。
- en: How does traffic work on Open vSwitch?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Open vSwitch 上的流量是如何工作的？
- en: To answer this question, we need to define where the traffic begins. Let’s start
    with the internal traffic, which means the communication between the application’s
    pods that are inside the OpenShift cluster.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，我们需要定义流量的起始点。让我们从内部流量开始，这意味着 OpenShift 集群内应用程序的 pod 之间的通信。
- en: To facilitate your understanding, consider two applications running on OpenShift;
    the first one is named `app-frontend` and the second `app-backend`. As the name
    suggests, `app-frontend` makes API calls to `app-backend` to process user requests.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助理解，可以考虑在 OpenShift 上运行的两个应用程序；第一个名为 `app-frontend`，第二个名为 `app-backend`。顾名思义，`app-frontend`
    通过 API 调用 `app-backend` 来处理用户请求。
- en: Therefore, when a pod from the `app-frontend` application makes a request to
    the `app-backend` application, this request will be sent to the internal service,
    in this case the `app-backend` service. The `app-backend` service is responsible
    for delivering that package to one of the `app-backend` pods. In the same way,
    the application handles its request and sends the result package back to the service
    network, which, at this point, already has a connection established with `app-frontend`.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当 `app-frontend` 应用中的一个 pod 向 `app-backend` 应用发出请求时，该请求会被发送到内部服务，这里是 `app-backend`
    服务。`app-backend` 服务负责将数据包传递给其中一个 `app-backend` pod。以同样的方式，应用程序处理请求并将结果数据包发送回服务网络，此时服务网络已经与
    `app-frontend` 建立了连接。
- en: '![Figure 7.2 – Service network layer ](img/B18015_07_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 服务网络层 ](img/B18015_07_02.jpg)'
- en: Figure 7.2 – Service network layer
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 服务网络层
- en: With that, we have briefly explained the traffic between applications inside
    the cluster. Now, let’s see how external-to-internal traffic is handled. When
    a request comes from outside the cluster, it goes initially to the external load
    balancer. As the load balancer receives a connection, it routes the request to
    one of the *OpenShift Ingress* pods, which sends it to the service of the destination
    application, which, in turn, routes it to the proper application’s pod.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过上述内容，我们简要解释了集群内应用之间的流量。现在，让我们来看看外部到内部流量是如何处理的。当请求来自集群外部时，首先会进入外部负载均衡器。当负载均衡器接收到连接时，它将请求路由到其中一个
    *OpenShift Ingress* pod，然后将请求转发到目标应用程序的服务，服务随后将请求路由到正确的应用程序 pod。
- en: '![Figure 7.3 – Route SDN networking ](img/B18015_07_03.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – 路由 SDN 网络 ](img/B18015_07_03.jpg)'
- en: Figure 7.3 – Route SDN networking
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – 路由 SDN 网络
- en: 'Now that you understand how traffic works in an OpenShift cluster, it is important
    to reinforce that OpenShift basically works with three network layers: the node
    network, the service network, and the cluster network (aka the pods network).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了 OpenShift 集群中的流量是如何工作的，重要的是要强调，OpenShift 基本上有三个网络层：节点网络、服务网络和集群网络（也就是
    pod 网络）。
- en: The **node network** is the physical network used to create and maintain machines.
    The **service network** is a virtual layer created by Open vSwitch that is responsible
    for routing traffic between pods and services. The **cluster network** is another
    Open vSwitch virtual layer responsible for creating subnets for the communication
    of pods – it allows isolating traffic between projects as needed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**节点网络**是用于创建和维护机器的物理网络。**服务网络**是由 Open vSwitch 创建的虚拟层，负责在 pod 和服务之间路由流量。**集群网络**是另一个由
    Open vSwitch 创建的虚拟层，负责为 pod 的通信创建子网 —— 它允许根据需要隔离项目之间的流量。'
- en: In the next sections, we will look deeper into the main available networking
    plugins for OpenShift. Keep in mind that there are subtle differences between
    the aforementioned plugins, so the decision between using one plugin and another
    must be taken into account according to the differences in functionality, which
    can somewhat affect the architecture of the cluster, and also the network functionality
    available to the applications. This is a decision that must be made together with
    the network and software architecture team, to understand the current use cases
    and planned future implementations, aiming for an efficient and functional cluster.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨 OpenShift 的主要网络插件。请记住，前面提到的插件之间存在细微的差异，因此在选择使用某一个插件时，必须根据其功能差异来做出决策，这些差异可能会影响集群的架构，同时也会影响应用程序可用的网络功能。这一决策需要与网络和软件架构团队共同商讨，以便了解当前的使用场景和未来计划的实施，旨在创建一个高效且功能齐全的集群。
- en: Network type – OpenShift SDN or OVN-Kubernetes
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络类型 – OpenShift SDN 或 OVN-Kubernetes
- en: OpenShift is a complete PaaS solution based on Kubernetes that provides several
    options other than its default components. For instance, OpenShift, by default,
    uses the Open vSwitch network plugin (OpenShift SDN), but you can use **OVN-Kubernetes**
    as an alternative.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift 是一个基于 Kubernetes 的完整 PaaS 解决方案，提供除了其默认组件之外的多种选项。例如，OpenShift 默认使用
    Open vSwitch 网络插件（OpenShift SDN），但您也可以使用 **OVN-Kubernetes** 作为替代方案。
- en: A network plugin is a feature that creates an overlay network using the Kubernetes
    **Container Network Interface** (**CNI**) that isolates the traffic between the
    virtual machines network and the OpenShift nodes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 网络插件是一种功能，使用 Kubernetes **容器网络接口**（**CNI**）创建覆盖网络，隔离虚拟机网络与 OpenShift 节点之间的流量。
- en: These two supported options offer a good and reliably performing network, but
    you can use other kinds of CNI depending on the scenario where OpenShift has been
    provisioned. Check the link for *OpenShift Tested Integrations* in the *Further
    reading* section of this chapter to see the options that are tested and supported
    by Red Hat.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种受支持的选项提供了良好的可靠网络性能，但您可以根据 OpenShift 部署的场景使用其他类型的 CNI。请查看本章“进一步阅读”部分中的 *OpenShift
    测试集成* 链接，以查看由 Red Hat 测试和支持的选项。
- en: Network policies
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络策略
- en: As we already mentioned, OpenShift uses an SDN, and preferably, the network
    traffic control should be done using the features the cluster provides itself.
    In our experience, having implemented OpenShift in many organizations, we have
    often heard doubts regarding how to control network traffic within the cluster,
    as most customers are used to doing it by using regular firewall devices. In this
    section, we will walk you through how to control network traffic to be able to
    allow or deny network traffic as needed. Before giving you some options to do
    that, we first need to differentiate the different traffic directions that we
    have in a cluster.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，OpenShift 使用软件定义网络（SDN），并且最好通过集群自身提供的功能来控制网络流量。在我们的经验中，已经在许多组织中实施了
    OpenShift，我们常常听到关于如何控制集群内网络流量的疑问，因为大多数客户习惯于使用常规的防火墙设备来控制流量。在本节中，我们将向您介绍如何控制网络流量，以便根据需要允许或拒绝网络流量。在为您提供一些选项之前，我们首先需要区分集群中不同的流量方向。
- en: North-south traffic
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 南北向流量
- en: OpenShift has been designed to cover the most common scenarios, even regarding
    networking. When an incoming connection comes from outside the cluster to an application,
    it is possible to control network traffic into the cluster using an external firewall
    and/or the **OpenShift Ingress** solution.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift 的设计旨在覆盖最常见的场景，甚至包括网络。在一个应用程序的传入连接来自集群外部时，可以使用外部防火墙和/或 **OpenShift
    Ingress** 解决方案来控制集群内部的网络流量。
- en: East-west traffic
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 东西向流量
- en: Initially, it may sound a little weird to say that there is also network traffic
    in east-west directions but east-west network traffic is nothing more than traffic
    between applications in different namespaces inside the same OpenShift cluster.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，可能会觉得东西向流量这个说法有点奇怪，但东西向网络流量实际上只是指在同一 OpenShift 集群中不同命名空间之间的应用程序之间的流量。
- en: 'The following diagram explains how these different types of traffic occur in
    a cluster:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了这些不同类型的流量是如何在集群中发生的：
- en: '![Figure 7.4 – North-south/east-west traffic flow ](img/B18015_07_04.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 南北/东西向流量](img/B18015_07_04.jpg)'
- en: Figure 7.4 – North-south/east-west traffic flow
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 南北/东西向流量
- en: You have seen the possible directions in which the traffic on the network can
    be controlled. In the next section, you will see how to control the network traffic
    in the cluster.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到了可以控制网络流量的可能方向。在下一节中，您将看到如何控制集群内的网络流量。
- en: Controlling network traffic
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制网络流量
- en: 'There are different options for controlling traffic on OpenShift:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenShift 中控制流量有不同的选项：
- en: For north-south traffic, you can either use an external firewall and load balancer
    to control the traffic before getting into the OpenShift cluster or use annotations
    in the OpenShift **route** object to control aspects such as the rate limit, timeout,
    and load balancing algorithm.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于南北向流量，您可以使用外部防火墙和负载均衡器在流量进入 OpenShift 集群之前控制流量，或者使用 OpenShift **路由**对象中的注释来控制速率限制、超时和负载均衡算法等方面。
- en: Use a proper **network policy** to allow or deny a traffic flow, as needed.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用合适的 **网络策略** 根据需要允许或拒绝流量流动。
- en: Use the **ovs-multitenant** network isolation mode. This mode was commonly used
    on OpenShift version 3 but is not encouraged on version 4, as the Network Policy
    plugin has become the standard.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **ovs-multitenant** 网络隔离模式。此模式曾在 OpenShift 3 版本中广泛使用，但在 4 版本中不再推荐使用，因为网络策略插件已成为标准。
- en: If you intend to use microservices with OpenShift, you may also choose to use
    a **service mesh** to control the east-west traffic, which uses the **istio-proxy**
    sidecar to give the lowest granularity of isolation mode. Service meshes are not
    the focus of this book, but if you want more information on them, check out the
    *Further reading* section of this chapter.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您打算在 OpenShift 上使用微服务，您还可以选择使用 **服务网格** 来控制东西向流量，它使用 **istio-proxy** sidecar
    提供最低粒度的隔离模式。服务网格不是本书的重点，但如果您想了解更多信息，请查看本章的 *进一步阅读* 部分。
- en: Note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you used to use **ovs-multitenant** on OpenShift 3.x and want to have similar
    functionality on version 4.x, we recommend you customize the project template,
    adding network policies to block traffic between different projects by default.
    The process to do that is simple and described at this link: [https://docs.openshift.com/container-platform/latest/networking/network_policy/default-network-policy.html](https://docs.openshift.com/container-platform/latest/networking/network_policy/default-network-policy.html).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您曾在 OpenShift 3.x 上使用过 **ovs-multitenant**，并希望在 4.x 版本上获得类似的功能，我们建议您自定义项目模板，默认添加网络策略以阻止不同项目之间的流量。实现这一目标的过程很简单，可以在这个链接中找到描述：[https://docs.openshift.com/container-platform/latest/networking/network_policy/default-network-policy.html](https://docs.openshift.com/container-platform/latest/networking/network_policy/default-network-policy.html)。
- en: In this chapter, we will focus on Network Policy, as this is the standard network
    plugin on OpenShift 4\. See next how to create a network policy to control the
    network traffic.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论网络策略，因为它是 OpenShift 4 中的标准网络插件。接下来看看如何创建一个网络策略来控制网络流量。
- en: Creating a network policy
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建网络策略
- en: As we already mentioned, with network policies, you can define rules to allow
    or block ingress network traffic in a cluster. With a network policy, you can,
    for instance, allow traffic between pods inside the same namespace but deny it
    from other namespaces. You may also allow traffic only on a specific port, and
    so on. Therefore, for a better understanding of network policies and the directions
    in which traffic is and isn’t allowed to flow, we will provide several diagrams
    and scenarios to clarify the importance of namespace isolation.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，借助网络策略，您可以定义规则来允许或阻止集群中的入口网络流量。使用网络策略，您可以例如允许同一命名空间内的 pod 之间的流量，但拒绝来自其他命名空间的流量。您还可以仅允许特定端口上的流量等等。因此，为了更好地理解网络策略以及流量允许和不允许流动的方向，我们将提供多个图表和场景来阐明命名空间隔离的重要性。
- en: 'For learning purposes, we will use three namespaces, named `bluepets`, `greenpets`,
    and `otherpets`. In the following diagram, we are illustrating the default **network
    policy**, which allows traffic between namespaces and traffic from a cluster ingress
    by default:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习目的，我们将使用三个命名空间，分别为 `bluepets`、`greenpets` 和 `otherpets`。在下面的图示中，我们展示了默认的
    **网络策略**，该策略默认允许命名空间之间以及来自集群入口的流量：
- en: '![Figure 7.5 – Default network policy – allow all ](img/B18015_07_05.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – 默认网络策略 – 允许所有](img/B18015_07_05.jpg)'
- en: Figure 7.5 – Default network policy – allow all
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – 默认网络策略 – 允许所有
- en: 'So, let’s go ahead and demonstrate connections allowed to these two namespaces:
    `bluepets` and `greenpets`. To facilitate your understanding, we are running tests
    in an external network with no direct route to the `rsh` on the `greenpets` namespace
    and try to reach the service IP of the `bluepets` namespace in our lab scenario
    discussed previously.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们继续演示这两个命名空间之间允许的连接：`bluepets` 和 `greenpets`。为了便于理解，我们在一个没有直接通向`greenpets`命名空间上`rsh`的外部网络中进行测试，并尝试在我们之前讨论的实验室场景中访问`bluepets`命名空间的服务
    IP。
- en: Before going into that, we must get the service IPs from both the namespaces
    to use later in the pod terminal and check the results accordingly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入之前，我们必须获取两个命名空间的服务 IP，以便稍后在 pod 终端中使用，并相应地检查结果。
- en: '![Figure 7.6 – Service IPs – bluepets and greenpets namespaces ](img/B18015_07_06.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.6 – 服务 IP – bluepets 和 greenpets 命名空间](img/B18015_07_06.jpg)'
- en: Figure 7.6 – Service IPs – bluepets and greenpets namespaces
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – 服务 IP – bluepets 和 greenpets 命名空间
- en: 'Take a look at the following screenshot. We `rsh` a pod under the `greenpets`
    namespace and run `curl` on the following endpoints:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下下面的截图。我们在 `greenpets` 命名空间下执行 `rsh` 命令并在以下端点上运行 `curl`：
- en: 'The service IP in `greenpets` (the same namespace): To check connectivity between
    a pod and service in the same namespace (highlighted with a green square in the
    following screenshot).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`greenpets`（同一命名空间）中的服务 IP：检查同一命名空间中 Pod 与服务之间的连接性（在下图中用绿色方框突出显示）。'
- en: 'The service IP in `bluepets` (a different namespace): We similarly call the
    service IP of the `bluepets` namespace and it also works fine (highlighted with
    a blue square in the following screenshot).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bluepets`（不同命名空间）中的服务 IP：我们类似地调用 `bluepets` 命名空间的服务 IP，它也能正常工作（在下图中用蓝色方框突出显示）。'
- en: '![Figure 7.7 – Testing connectivity between two namespaces ](img/B18015_07_07.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.7 – 测试两个命名空间之间的连接性](img/B18015_07_07.jpg)'
- en: Figure 7.7 – Testing connectivity between two namespaces
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – 测试两个命名空间之间的连接性
- en: 'In our next scenario, we will block all traffic on the `greenpets` namespace,
    for which the diagram looks like the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个场景中，我们将阻止 `greenpets` 命名空间中的所有流量，图示如下：
- en: '![Figure 7.8 – greenpets namespace – denying all traffic ](img/B18015_07_08.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.8 – greenpets 命名空间 – 拒绝所有流量](img/B18015_07_08.jpg)'
- en: Figure 7.8 – greenpets namespace – denying all traffic
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 – greenpets 命名空间 – 拒绝所有流量
- en: 'To accomplish this scenario, we apply a network policy manifest on the `greenpets`
    namespace:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这个场景，我们将在 `greenpets` 命名空间应用一个网络策略清单：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let’s perform the same tests again to demonstrate that all network traffic
    in `greenpets` (route and service) is denying connections:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们再次执行相同的测试，以演示 `greenpets` 中的所有网络流量（路由和服务）都被拒绝连接：
- en: '![Figure 7.9 – Deny all traffic test ](img/B18015_07_09.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.9 – 拒绝所有流量测试](img/B18015_07_09.jpg)'
- en: Figure 7.9 – Deny all traffic test
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 – 拒绝所有流量测试
- en: 'Now, we will go deeper and apply a rule that only allows traffic from ingress
    to flow to pods under the `greenpets` namespace. To do so, we are going to apply
    the following YAML file:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将深入探讨并应用一条规则，只允许来自入口的流量流向`greenpets`命名空间下的 Pods。为此，我们将应用以下 YAML 文件：
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'What this NP does is to only allow pods in the ingress namespace to communicate
    with pods in the `greenpets` namespace, all other traffic will be blocked. Check
    out the following diagram and notice that *east-west* traffic between namespaces
    is denied, but *north-south* traffic is allowed:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个网络策略的作用是只允许入口命名空间中的 Pods 与 `greenpets` 命名空间中的 Pods 通信，所有其他流量将被阻止。请查看下图并注意，命名空间之间的*东西向*流量被拒绝，但*南北向*流量是允许的：
- en: '![Figure 7.10 – greenpets namespace traffic only allowed for Ingress connections
    (external route) ](img/B18015_07_10.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.10 – 仅允许入口连接（外部路由）的 greenpets 命名空间流量](img/B18015_07_10.jpg)'
- en: Figure 7.10 – greenpets namespace traffic only allowed for Ingress connections
    (external route)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 – 仅允许入口连接（外部路由）的 greenpets 命名空间流量
- en: Notice now that the network communication between the external route (ingress)
    and the service is working; however, traffic between `bluepets` and `greenpets`
    is denied.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在外部路由（入口）与服务之间的网络通信是正常的；然而，`bluepets` 与 `greenpets` 之间的流量被拒绝。
- en: '![Figure 7.11 – Testing network traffic. 1) From bluepets namespace to greenpets
    namespace: Connection denied. 2) From external route (ingress) to greenpets namespace:
    Connection allowed. ](img/B18015_07_11.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.11 – 测试网络流量。1) 从 bluepets 命名空间到 greenpets 命名空间：连接被拒绝。2) 从外部路由（入口）到 greenpets
    命名空间：连接被允许。](img/B18015_07_11.jpg)'
- en: 'Figure 7.11 – Testing network traffic. 1) From bluepets namespace to greenpets
    namespace: Connection denied. 2) From external route (ingress) to greenpets namespace:
    Connection allowed.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – 测试网络流量。1) 从 bluepets 命名空间到 greenpets 命名空间：连接被拒绝。2) 从外部路由（入口）到 greenpets
    命名空间：连接被允许。
- en: 'Finally, we will take a look at the most common scenario: the least isolation
    configuration. This network policy scenario is based on a namespace label that
    we will apply in the `greenpets` namespace and will work as a key to configure
    the communication between namespaces.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将看看最常见的场景：最少隔离配置。这个网络策略场景基于一个命名空间标签，我们将在 `greenpets` 命名空间中应用该标签，并作为配置命名空间之间通信的关键。
- en: '![Figure 7.12 – Labeled namespaces allowing traffic ](img/B18015_07_12.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.12 – 已标记的命名空间允许流量](img/B18015_07_12.jpg)'
- en: Figure 7.12 – Labeled namespaces allowing traffic
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – 已标记的命名空间允许流量
- en: 'Looking at the previous diagram, you can see three different namespaces, `bluepets`,
    `greenpets`, and `otherpets`. A network policy will be applied to the `greenpets`
    namespace, which will use a label with the `join=greenpets` value. In other words,
    it means that only elements in namespaces labeled with `join=greenpets` can communicate
    with the application in the `greenpets` namespace. To implement this, we will
    apply the following manifest and commands:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图示中，你可以看到三个不同的命名空间：`bluepets`、`greenpets` 和 `otherpets`。一个网络策略将应用于 `greenpets`
    命名空间，并使用带有 `join=greenpets` 值的标签。换句话说，这意味着只有标记为 `join=greenpets` 的命名空间中的元素才能与
    `greenpets` 命名空间中的应用进行通信。为了实现这一点，我们将应用以下清单和命令：
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, check the connectivity between the namespaces `bluepets` and `greenpets`
    by running the following test:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过运行以下测试检查 `bluepets` 和 `greenpets` 命名空间之间的连接性：
- en: '![Figure 7.13 – Testing labeled namespace. Connection to a namespace that contains
    the proper label – connection allowed ](img/B18015_07_13.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.13 – 测试标记命名空间。连接到包含正确标签的命名空间 – 连接允许](img/B18015_07_13.jpg)'
- en: Figure 7.13 – Testing labeled namespace. Connection to a namespace that contains
    the proper label – connection allowed
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – 测试标记命名空间。连接到包含正确标签的命名空间 – 连接允许
- en: In *Figure 7.13,* you see that the connection was allowed as the namespace contains
    the label `join=greenpets`. However, in *Figure 7.14*, you can see the connection
    is denied, as the traffic flows from a namespace (`otherpets`) that doesn’t contain
    this label.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 7.13*中，你看到连接被允许，因为命名空间包含标签 `join=greenpets`。然而，在*图 7.14*中，你看到连接被拒绝，因为流量来自一个没有该标签的命名空间（`otherpets`）。
- en: '![Figure 7.14 – Testing non-labeled namespace denying traffic ](img/B18015_07_14.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.14 – 测试未标记命名空间拒绝流量](img/B18015_07_14.jpg)'
- en: Figure 7.14 – Testing non-labeled namespace denying traffic
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – 测试未标记命名空间拒绝流量
- en: Network policy is an important tool to isolate network traffic. It is important
    you consider the challenges that certain types of rules may bring, though. If
    not properly designed, standardized, and adopted, they may cause you headaches
    by allowing what should be blocked and blocking what shouldn’t be.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 网络策略是隔离网络流量的重要工具。然而，你需要考虑某些类型的规则可能带来的挑战。如果没有设计好、标准化并采用，它们可能会让你头疼，既允许本应阻止的流量，又阻止本应允许的流量。
- en: Also, you have to consider which types of workload will run in your cluster.
    For microservice-oriented applications, for instance, we recommend you look at
    the **Istio service mesh**, which in general is more appropriate and will bring
    more granular network access control.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还需要考虑集群中将运行的工作负载类型。例如，对于面向微服务的应用，我们建议你查看**Istio 服务网格**，它通常更合适并且能提供更细粒度的网络访问控制。
- en: So far, you have learned the definitions and important concepts of SDNs, such
    as controlling traffic in horizontal and vertical directions by applying policies
    using labels. Continue, next, to see more about routes and ingress controllers
    and learn how to use them for your applications.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经了解了 SDN 的定义和重要概念，比如通过使用标签应用策略来控制水平和垂直方向的流量。接下来，继续了解更多关于路由和 Ingress
    控制器的内容，并学习如何在你的应用中使用它们。
- en: What is an ingress controller?
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Ingress 控制器？
- en: An **Ingress controller** is a lightweight, self-healing load balancer that
    distributes network traffic from outside the cluster to a network service. Using
    an Ingress controller is a standard approach for providing and managing ingress
    traffic to containerized applications. The default ingress controllers on OpenShift
    use the mature and stable **HAProxy** under the hood. In OpenShift, when you deploy
    a cluster, the ingress controller is automatically created and hosted in two worker
    nodes by default.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ingress 控制器**是一个轻量级的自愈负载均衡器，将外部集群的网络流量分配到网络服务中。使用 Ingress 控制器是为容器化应用提供和管理入口流量的标准方法。OpenShift
    中的默认 Ingress 控制器在后台使用成熟且稳定的**HAProxy**。在 OpenShift 中，当你部署一个集群时，Ingress 控制器会默认自动创建并托管在两个工作节点上。'
- en: How does an ingress operator work?
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ingress 操作员是如何工作的？
- en: 'An Ingress operator acts similarly to almost all cluster operators in OpenShift:
    protecting the important settings of the operation of a cluster. The operator
    monitors the ingress pods running in the `openshift-ingress` namespace and protects
    the `IngressController` objects from wrong and non-compatible settings that can
    lead to problems with the cluster network.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress操作员的作用类似于OpenShift中几乎所有集群操作员的作用：保护集群操作中的重要设置。该操作员监控在`openshift-ingress`命名空间中运行的ingress
    pods，并保护`IngressController`对象免受错误和不兼容设置的影响，这些设置可能导致集群网络出现问题。
- en: Otherwise, you can create others `IngressController` objects in addition to
    the default one to isolate the traffic of certain groups of applications, using
    what is named **router sharding**.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，您可以创建其他`IngressController`对象，除了默认的IngressController外，用于隔离特定应用组的流量，这就是所谓的**路由器分片**。
- en: Different from traditional networking configuration, in which you need complex
    routing tables and firewall configuration, OpenShift abstracts this complex networking
    layer configuration, making it a much easier task.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的网络配置不同，后者需要复杂的路由表和防火墙配置，OpenShift抽象了这一复杂的网络层配置，使任务变得更加简单。
- en: Creating a new ingress controller
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建新的ingress控制器
- en: 'To create a new ingress controller, you must take the following steps:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 创建新的ingress控制器，您必须按照以下步骤进行操作：
- en: Define at least two nodes to host the new ingress controller.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至少定义两个节点来托管新的ingress控制器。
- en: Apply a new label to nodes.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将新标签应用于节点。
- en: Export the default `IngressController` object.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导出默认的`IngressController`对象。
- en: Change the name and desired settings of the newly created YAML manifest file.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改新创建的YAML清单文件的名称和所需设置。
- en: Deploy the new `IngressController` object by applying the YAML created previously.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过应用之前创建的YAML文件，部署新的`IngressController`对象。
- en: 'You can see in the following lines an example of the process mentioned previously:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下几行中，您可以看到之前提到的过程示例：
- en: '[PRE3]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the previous code, we have highlighted some parts with numbers. Let’s take
    a look:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，我们用数字突出显示了某些部分。我们来看一下：
- en: '*[1]: New IngressController name.*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*[1]: 新的IngressController名称。*'
- en: '*[2]: DNS domain for the new ingress.*'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*[2]: 新入站的DNS域名。*'
- en: '*[3]: A label that defines where the IngressController pods will run.*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*[3]: 定义IngressController pods将运行的位置的标签。*'
- en: '*[4]: To implement shards. It can be namespaceSelector or routeSelector.*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*[4]: 实现分片。可以是namespaceSelector或routeSelector。*'
- en: '*[5]: Used to filter the set of routes that are served by this IngressController.*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*[5]: 用于过滤由此IngressController提供的路由集。*'
- en: Namespace or Route Selector?
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间或路由选择器？
- en: The example you have seen uses the `routeSelector`. There is an alternative
    way to configure the IngressController, which is using `namespaceSelector`. It
    may seem confusing to define the right selector for your case, but it is not –
    `routeSelector` is a more granular option, allowing you to publish routes to different
    IngressControllers in the same namespace. The main decision factor is if, in your
    case, you need to be able to publish routes of a single namespace in different
    IngressControllers, you have to use `routeSelectors`. Otherwise, you will most
    likely use `namespaceSelectors`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您看到的示例使用了`routeSelector`。配置IngressController的另一种方法是使用`namespaceSelector`。定义适合您情况的选择器可能看起来令人困惑，但其实并不复杂——`routeSelector`是一种更细粒度的选择，允许您将路由发布到同一命名空间中的不同IngressController。主要的决策因素是，如果您需要能够将单个命名空间的路由发布到不同的IngressController中，您必须使用`routeSelectors`。否则，您很可能会使用`namespaceSelectors`。
- en: 'For example, consider a namespace called `APP` that contains two different
    routes:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个名为`APP`的命名空间，该命名空间包含两个不同的路由：
- en: Route A published in router 1 with the URL `app1.prod.hybridmycloud.com`
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 路由器1中发布的Route A，URL为`app1.prod.hybridmycloud.com`
- en: Route B published in router 2 with the URL `app1.qa.hybridmycloud.com`
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在路由器2中发布的Route B，URL为`app1.qa.hybridmycloud.com`
- en: This scenario is only possible if you use `routeSelector`. However, this is
    an unusual scenario; usually, routes in a single namespace are always published
    in the same IngressController, so for that reason, it is also very common to use
    `namespaceSelector`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 该场景只有在使用`routeSelector`时才可能。然而，这是一个不常见的场景；通常，单一命名空间中的路由始终会发布到相同的IngressController中，因此通常使用`namespaceSelector`。
- en: As previously mentioned, router sharding is a technique that allows creating
    an ingress for the purpose of segregating traffic, whether due to the need for
    isolation between environments or even for the traffic of a given application
    to be fully directed from this new ingress.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，路由分片是一种技术，允许为隔离流量创建入口，无论是由于需要在环境之间隔离，还是为了将给定应用程序的流量完全定向到这个新的入口。
- en: Testing the new ingress
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试新的入口
- en: 'After the ingress pods are created on the nodes, you can test the newly created
    ingress. We will create a route using the sample application named `hello-openshift`
    and apply the proper route selector label. Follow these steps to accomplish this
    task:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了节点上的入口 pod 后，您可以测试新创建的入口。我们将使用名为 `hello-openshift` 的示例应用程序创建路由，并应用适当的路由选择器标签。按照以下步骤完成此任务：
- en: '[PRE4]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The last line of the previous block of commands explicitly sets the `type=sharded`
    label, which we used in our example for `routeSelector`. When OpenShift sees this
    label, it will automatically publish this route in the new ingress.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个命令块的最后一行明确设置了 `type=sharded` 标签，我们在示例中用于 `routeSelector`。当 OpenShift 看到此标签时，它将自动在新的入口中发布此路由。
- en: Continue on to the following section to get a full understanding of how to use
    the recently created ingress with what is called a **route** in OpenShift.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前往下一节，全面了解如何使用 OpenShift 中所称的 **路由** 使用最近创建的入口。
- en: Types of routes
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路由类型
- en: Routes are the representation of a configuration on an ingress internal load
    balancer for a specific application to expose a Kubernetes service to a DNS name,
    such as `example.apps.env.hybridmycloud.com`. When a route is created, OpenShift
    automatically configures a frontend and backend in the Ingress’ HAProxy pod to
    publish the URL and make the traffic available from the outside world.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 路由是为了将 Kubernetes 服务暴露给 DNS 名称（例如 `example.apps.env.hybridmycloud.com`）而在入口内部负载均衡器上配置的特定应用程序的配置表示。创建路由时，OpenShift
    会自动在入口的 HAProxy pod 中配置前端和后端，以发布 URL 并使外部世界的流量可用。
- en: Routes can be published using either the HTTP or HTTPS protocol. For HTTPS,
    three different types of routes define how the TLS termination works in the SSL
    stream between the user and the pod. In the following subsections, we will walk
    you through each of them.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 路由可以使用 HTTP 或 HTTPS 协议发布。对于 HTTPS，三种不同类型的路由定义了 TLS 终止在用户和 pod 之间的 SSL 流中的工作方式。在以下小节中，我们将逐一介绍每一种。
- en: Passthrough routes
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 透传路由
- en: A **passthrough route**, as the name suggests, is a configuration in which the
    packages are forwarded straight to the network service without doing a TLS termination,
    acting as a Layer 4 load balancer. Passthrough is often used with applications
    that provide their own TLS termination inside the application’s pod, either by
    implementing it in the source code or using a middleware layer (such as JBoss
    or WebSphere).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**透传路由**，顾名思义，是一种配置，其中包裹直接转发到网络服务，而不进行 TLS 终止，充当第四层负载均衡器。透传通常与在应用程序的 pod 内提供其自身的
    TLS 终止的应用程序一起使用，无论是通过在源代码中实现还是使用中间件层（如 JBoss 或 WebSphere）。'
- en: '![Figure 7.15 – Passthrough route  ](img/B18015_07_15.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.15 – 透传路由  ](img/B18015_07_15.jpg)'
- en: Figure 7.15 – Passthrough route
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – 透传路由
- en: 'Next, you''ll see the second option you have: edge route.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将看到您有的第二个选项：边缘路由。
- en: Edge routes
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘路由
- en: 'In this route, the TLS termination is handled by OpenShift ingress and forwarded
    to the service as clear text. This kind of route is used very often as it is easy
    to use: a self-signed certificate automatically generated by OpenShift is applied
    to the ingress and it signs all the routes that use the default wildcard domain
    – this is performed by OpenShift automatically; no additional configuration is
    needed. However, you can replace the self-signed certificate with a custom digital
    certificate, if you don’t want to use the default self-signed certificate.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在此路由中，TLS 终止由 OpenShift 入口处理，并作为明文转发到服务。这种类型的路由经常被使用，因为它易于使用：OpenShift 自动为入口生成的默认通配符域使用自签名证书，它签署所有使用默认自签名证书的路由
    – 这是由 OpenShift 自动执行的；不需要额外的配置。但是，如果您不想使用默认自签名证书，您可以将其替换为自定义数字证书。
- en: '![Figure 7.16 – Edge route ](img/B18015_07_16.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.16 – 边缘路由 ](img/B18015_07_16.jpg)'
- en: Figure 7.16 – Edge route
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – 边缘路由
- en: An edge route is the most common and easy-to-implement model since the certificate
    chain terminates at the edge of the OpenShift network, which is the ingress. It
    is important to highlight that the traffic between the ingress and the application
    pods is not encrypted but occurs inside the OpenShift SDN, which means that the
    network packages are encapsulated using OVS. The last method available is reencrypted
    routes. You'll see how it works next.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘路由是最常见且最容易实现的模型，因为证书链终止于 OpenShift 网络的边缘，即 ingress。需要强调的是，ingress 和应用程序 Pod
    之间的流量没有加密，而是在 OpenShift SDN 内部进行传输，这意味着网络包是通过 OVS 封装的。最后一种方法是重新加密路由。接下来，你将看到它是如何工作的。
- en: Reencrypted routes
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新加密的路由
- en: 'Reencrypted routes offer two layers of TLS termination: traffic is decrypted
    using the certificate for the external FQDN (for example, `example.apps.env.hybridmycloud.com`)
    at the cluster edge (OpenShift Ingress), and then the traffic is re-encrypted
    again, but now using a different certificate. While this is a secure route, it
    has also a performance penalty due to the termination and re-encryption operation
    performed by the ingress.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 重新加密路由提供了两层 TLS 终止：流量首先使用外部 FQDN（例如 `example.apps.env.hybridmycloud.com`）的证书在集群边缘（OpenShift
    Ingress）解密，然后流量再次被重新加密，但这时使用的是不同的证书。虽然这是一种安全路由，但由于 ingress 执行终止和重新加密操作，它也带来了性能开销。
- en: '![Figure 7.17 – Reencrypted route ](img/B18015_07_17.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17 – 重新加密的路由 ](img/B18015_07_17.jpg)'
- en: Figure 7.17 – Reencrypted route
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – 重新加密的路由
- en: A reencrypted route takes a similar approach as an edge route but it goes through
    two layers of CAs. The first is related to the external public domain, for example,
    *hybridcloud.com*, and then the second layer of encryption is internal, known
    by OpenShift Ingress and the application.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 重新加密路由采用与边缘路由类似的方法，但它经过两层证书授权机构（CA）。第一层与外部公共域相关，例如 *hybridcloud.com*，然后第二层加密是内部的，由
    OpenShift Ingress 和应用程序所知。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'We have seen in this chapter some of the important aspects related to the OpenShift
    network. Now you are familiar with the two types of network plugins supported
    with OpenShift, OpenShift SDN and OVN-Kubernetes, and the different kinds of traffic
    you need to care about when managing the platform’s network. You have also seen
    how the ingress controller works, how to create a new one, and the three different
    types of secure routes you may use with your applications: passthrough, edge,
    and reencrypted.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了与 OpenShift 网络相关的一些重要方面。现在，你已经熟悉了 OpenShift 支持的两种网络插件：OpenShift SDN
    和 OVN-Kubernetes，以及在管理平台网络时需要关注的不同类型的流量。你还了解了 ingress 控制器的工作原理，如何创建一个新的控制器，以及你可能与应用程序一起使用的三种安全路由类型：透传路由、边缘路由和重新加密路由。
- en: You navigated through network policies to learn a bit more about how to control
    traffic and provide network isolation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你通过网络策略了解了如何控制流量并提供网络隔离的一些知识。
- en: As you know, security is a real concern in today's digital world. In the next
    chapter, we will cover important aspects you need to consider about security on
    OpenShift. So, go ahead and check it out!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，安全性在当今的数字化世界中是一个重要问题。在下一章中，我们将讨论你在 OpenShift 上需要考虑的安全方面。因此，继续阅读并查看吧！
- en: Further reading
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'If you want more information related to the concepts we covered in this chapter,
    check out the following references:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多本章中涵盖的概念，可以查看以下参考资料：
- en: '*Kubernetes Ingress controller*: [https://www.nginx.com/resources/glossary/kubernetes-ingress-controller](https://www.nginx.com/resources/glossary/kubernetes-ingress-controller)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes Ingress 控制器*: [https://www.nginx.com/resources/glossary/kubernetes-ingress-controller](https://www.nginx.com/resources/glossary/kubernetes-ingress-controller)'
- en: '*HAProxy documentation*: [https://www.haproxy.com/documentation/hapee/latest/onepage/](https://www.haproxy.com/documentation/hapee/latest/onepage/)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*HAProxy 文档*: [https://www.haproxy.com/documentation/hapee/latest/onepage/](https://www.haproxy.com/documentation/hapee/latest/onepage/)'
- en: '*Annotations used to override a route’s default configuration*: [https://docs.openshift.com/container-platform/4.10/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration](https://docs.openshift.com/container-platform/4.10/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于覆盖路由默认配置的注解*: [https://docs.openshift.com/container-platform/4.10/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration](https://docs.openshift.com/container-platform/4.10/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration)'
- en: '*Configuring ingress cluster traffic using an Ingress controller*: [https://docs.openshift.com/container-platform/4.10/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html](https://docs.openshift.com/container-platform/4.10/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 Ingress 控制器配置入口集群流量*: [https://docs.openshift.com/container-platform/4.10/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html](https://docs.openshift.com/container-platform/4.10/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html)'
- en: '*Creating secured routes*: [https://docs.openshift.com/container-platform/4.10/networking/routes/secured-routes.html](https://docs.openshift.com/container-platform/4.10/networking/routes/secured-routes.html)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*创建安全路由*: [https://docs.openshift.com/container-platform/4.10/networking/routes/secured-routes.html](https://docs.openshift.com/container-platform/4.10/networking/routes/secured-routes.html)'
- en: '*OpenShift Tested Integrations*: [https://access.redhat.com/articles/4128421](https://access.redhat.com/articles/4128421)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenShift 测试过的集成*: [https://access.redhat.com/articles/4128421](https://access.redhat.com/articles/4128421)'
- en: '*Service mesh*: [https://docs.openshift.com/container-platform/4.10/service_mesh/v2x/servicemesh-release-notes.html](https://docs.openshift.com/container-platform/4.10/service_mesh/v2x/servicemesh-release-notes.html)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务网格*: [https://docs.openshift.com/container-platform/4.10/service_mesh/v2x/servicemesh-release-notes.html](https://docs.openshift.com/container-platform/4.10/service_mesh/v2x/servicemesh-release-notes.html)'
