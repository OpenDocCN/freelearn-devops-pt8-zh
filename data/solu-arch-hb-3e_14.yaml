- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Generative AI Architecture
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成性 AI 架构
- en: Generative AI technology goes beyond mere industry jargon – that is, it is an
    advanced instrument used for reshaping business operations by automating essential
    tasks such as content generation, image creation, and knowledge assistance. Generative
    AI represents a thrilling leap forward in the tech world, igniting significant
    enthusiasm among those passionate about technological innovation. Referred to
    as GenAI, an abbreviation of Generative artificial intelligence, this form of
    technology stands out for its remarkable ability to independently produce new
    content, such as text, images, music, videos, coding, and so on, with capabilities
    that closely mimic human-like creativity.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性 AI 技术不仅仅是行业术语——它是一种先进的工具，用于通过自动化关键任务（如内容生成、图像创建和知识辅助）来重塑商业运营。生成性 AI 代表了技术世界的重大飞跃，激发了那些热衷于技术创新的人的极大热情。生成性人工智能（GenAI）作为这一技术的缩写，其显著特点在于能够独立地生成新内容，如文本、图像、音乐、视频、代码等，其能力与人类创造力十分相似。
- en: The use of generative AI is increasing in different business areas. It can greatly
    reduce the time, resources, and costs needed to operate a business when used well.
    For instance, ChatGPT can assist in creating marketing campaigns for products
    or serve as a travel planner, while Midjourney can generate images in just a second.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性 AI 在不同的商业领域中的使用正在增加。若使用得当，它可以大大减少运营业务所需的时间、资源和成本。例如，ChatGPT 可以协助创建产品的营销活动或充当旅行规划师，而
    Midjourney 可以在一秒钟内生成图像。
- en: You might have encountered generative AI applications like ChatGPT, Midjourney,
    Gemini (formerly Bard), Amazon Q, and Claude.ai, among others. This technology
    learns from a lot of information it gathers, including from the internet, and
    uses that knowledge to develop new content. It’s like having a smart assistant
    that can generate all sorts of things without needing human input for every detail.
    However, it’s crucial to understand that this isn’t magic – it’s the outcome of
    a great deal of smart thinking and advancements in the field of technology.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经接触过一些生成性 AI 应用，如 ChatGPT、Midjourney、Gemini（前身为 Bard）、Amazon Q 和 Claude.ai
    等。这项技术从大量收集的信息中学习，包括互联网信息，并利用这些知识创造新内容。就像拥有一个智能助手，能够在无需每个细节都由人类输入的情况下生成各种内容。然而，必须理解，这不是魔法——它是经过大量聪明思维和技术领域进步的结果。
- en: 'But the most exciting part is that we can use these foundation models in many
    ways. For instance, they can be used to generate creative content, automate customer
    service with chatbots, enhance data analysis, provide personalized recommendations,
    streamline language translations, and even aid in research by summarizing complex
    documents. In this chapter, you’ll learn about generative AI in more detail, including:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 但最令人兴奋的部分是，我们可以通过多种方式使用这些基础模型。例如，它们可以用于生成创意内容、通过聊天机器人自动化客户服务、增强数据分析、提供个性化推荐、简化语言翻译，甚至通过总结复杂文档来帮助研究。在本章中，你将更详细地了解生成性
    AI，包括：
- en: What is generative AI?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是生成性 AI？
- en: Generative AI use cases
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成性 AI 使用案例
- en: The basic architecture of generative AI systems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成性 AI 系统的基本架构
- en: Popular generative AI foundational models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流行的生成性 AI 基础模型
- en: How to start with generative AI
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何开始使用生成性 AI
- en: Generative AI reference architecture
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成性 AI 参考架构
- en: Challenges in implementing generative AI
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施生成性 AI 的挑战
- en: Get ready for an exciting journey into the world of generative AI. We will uncover
    the mysteries behind its remarkable abilities to influence the direction of our
    new world.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好踏上激动人心的生成性 AI 世界之旅吧。我们将揭开它在影响新世界发展方向方面的非凡能力背后的奥秘。
- en: What is generative AI?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是生成性 AI？
- en: Generative AI is artificial intelligence with the remarkable ability to develop
    new content and ideas. This includes things like having conversations, creating
    stories, producing images and videos, and even making music.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性 AI 是一种人工智能，具有非凡的能力，能够开发新内容和创意。这包括进行对话、创作故事、制作图像和视频，甚至创作音乐等。
- en: In December 2022, the design team at the **Laboratory for Artificial Intelligence
    in Design** (**AiDLab**) located in Hong Kong orchestrated a groundbreaking fashion
    exhibition titled Fashion X AI ([https://www.fashionxai.com/event-highlights-fashionshow](https://www.fashionxai.com/event-highlights-fashionshow)).
    This showcase was unique because every design featured in the event was created
    by AI, drawing inspiration from mood boards, color palettes, and concepts provided
    by human designers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年12月，位于香港的**人工智能设计实验室**（**AiDLab**）的设计团队策划了一场突破性的时尚展览——Fashion X AI（[https://www.fashionxai.com/event-highlights-fashionshow](https://www.fashionxai.com/event-highlights-fashionshow)）。这场展示的独特之处在于，展会中展示的每一件设计作品都是由人工智能创造的，灵感来自人类设计师提供的情感板、色彩调色板和概念。
- en: Like other types of AI, generative AI relies on **machine learning** (**ML**)
    models. These models are quite large and are pre-trained using vast amounts of
    data. We often call these models **foundation models** (**FMs**).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 像其他类型的人工智能一样，生成性人工智能依赖于**机器学习**（**ML**）模型。这些模型通常非常庞大，并且通过大量数据进行预训练。我们通常将这些模型称为**基础模型**（**FMs**）。
- en: The FMs we have today (like OpenAI GPT-4 or Google Gemini for large language
    tasks, Stable Diffusion from Stability AI for converting text into images, and
    the OpenAI Sora text-to-video generator) can perform various tasks across many
    different areas. They can write blog posts, generate images, solve math problems,
    hold conversations, and even answer questions based on information in a document.
    These models are incredibly versatile and have the potential to revolutionize
    how we create and interact with content.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有的FMs（例如用于大型语言任务的OpenAI GPT-4或Google Gemini，来自Stability AI的用于将文本转换为图像的Stable
    Diffusion，以及OpenAI的Sora文本到视频生成器）可以执行多个领域中的各种任务。它们可以撰写博客文章、生成图像、解答数学问题、进行对话，甚至根据文档中的信息回答问题。这些模型非常多功能，并有可能彻底改变我们创建和互动内容的方式。
- en: Generative AI has the potential to bring about sweeping changes to the global
    economy. According to Goldman Sachs, generative AI could drive a 7% (or almost
    $7 trillion) increase in global GDP and lift productivity growth by 1.5% over
    10 years. You can read more details in the Goldman Sachs **Artificial Intelligence**
    (**AI**) report at [https://www.goldmansachs.com/intelligence/artificial-intelligence/](https://www.goldmansachs.com/intelligence/artificial-intelligence/).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性人工智能有潜力对全球经济带来深远的变化。根据高盛的报告，生成性人工智能可能推动全球GDP增长7%（或近7万亿美元），并在10年内提升生产力增长1.5%。你可以在高盛的**人工智能**（**AI**）报告中了解更多详细信息，链接：[https://www.goldmansachs.com/intelligence/artificial-intelligence/](https://www.goldmansachs.com/intelligence/artificial-intelligence/)。
- en: FMs stand out due to their size and general-purpose nature, setting them apart
    from traditional ML models that are designed for specific tasks like sentiment
    analysis, image classification, and trend forecasting. Unlike these traditional
    models, which require gathering labeled data, training, and deployment for each
    task, FMs offer a more versatile approach. A single pre-trained FM can be adapted
    for various tasks. Moreover, these models can be tailored to perform domain-specific
    functions that are unique to individual businesses. Importantly, this customization
    can be achieved using only a fraction of the data, along with the computing resources
    that are needed to train a model from scratch.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: FMs因其规模和通用性而独树一帜，与传统的机器学习模型不同，后者通常是针对情感分析、图像分类和趋势预测等特定任务设计的。与这些传统模型不同，FMs不需要为每个任务收集标注数据、训练和部署，而是提供了更为多样化的处理方式。一个经过预训练的FM可以适应多种任务。此外，这些模型还可以针对特定领域的功能进行定制，以适应各个企业的独特需求。重要的是，这种定制化可以仅使用一小部分数据，并结合所需的计算资源，而无需从头开始训练一个全新的模型。
- en: 'The success of FMs can be attributed to three key reasons:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: FMs的成功可以归因于三个关键原因：
- en: '**Transformer architecture**: The transformer architecture, a type of neural
    network, plays a pivotal role. It is efficient, scalable, and parallelizable and
    can effectively model input and output data relationships.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变压器架构**：变压器架构是一种神经网络，发挥着至关重要的作用。它高效、可扩展且可并行化，能够有效地建模输入和输出数据之间的关系。'
- en: '**In-context learning**: A groundbreaking training paradigm called in-context
    learning has emerged. This approach allows pre-trained models to be equipped with
    instructions for new tasks or just a few examples. This eliminates the need for
    additional training on labeled data, enabling models to be immediately applied
    to new tasks.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文学习**：一种突破性的训练范式——上下文学习已经出现。这种方法允许预训练模型通过指令或少量示例来处理新任务。这消除了对标注数据额外训练的需求，使得模型能够立即应用于新任务。'
- en: '**Emergent behaviors at scale**: As model sizes increase and larger datasets
    are used, models begin to display previously unseen capabilities. This phenomenon
    is referred to as “emerging capabilities.” For example, larger models can generate
    more coherent and contextually relevant text, recognize complex patterns in data,
    and even perform tasks like image recognition and language translation with greater
    accuracy. They can also handle multi-step reasoning questions, provide detailed
    explanations, and generate creative content, such as writing music or creating
    artwork, with nuanced understanding and creativity. Larger models have the potential
    to perform tasks that are beyond their capabilities before reaching a critical
    size.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大规模的新兴行为**：随着模型规模的增大和使用更大的数据集，模型开始展现出以前未见的能力。这一现象被称为“新兴能力”。例如，更大的模型能够生成更连贯、与上下文更相关的文本，识别数据中的复杂模式，甚至执行图像识别和语言翻译等任务，且准确性更高。它们还能够处理多步骤推理问题，提供详细的解释，甚至生成创意内容，如作曲或创作艺术作品，展现出细腻的理解和创造力。更大的模型在达到临界规模之前，具有执行超出其能力范围的任务的潜力。'
- en: To understand better, let’s look at some use cases where generative AI can help.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解，让我们来看一些生成式人工智能可以帮助的使用案例。
- en: Generative AI use cases
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能使用案例
- en: 'Let’s look at various use cases across different categories such as customer
    experience, employee production, and business operations efficiency, and learn
    how generative AI is enhancing existing AI capabilities and bringing forth entirely
    new possibilities:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下不同类别的各种使用案例，如客户体验、员工生产力和业务运营效率，并了解生成式人工智能如何增强现有的人工智能能力，并带来全新的可能性：
- en: Customer experience transformation
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户体验转型
- en: 'Generative AI is changing the game in how customers interact with businesses.
    Imagine you’re shopping online for shoes. A generative AI-based virtual assistant
    on the website greets you and helps you find the perfect pair based on your style
    and size preferences. It can even show you images of the shoes and answer any
    questions you have. Let’s look at some more such use cases where generative AI
    can help to improve customer experience and engagement:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能正在改变客户与企业互动的方式。假设你在网上购买鞋子。一个基于生成式人工智能的虚拟助手会在网站上迎接你，并根据你的风格和尺码偏好帮助你找到完美的鞋子。它甚至可以展示鞋子的图片，并回答你任何问题。让我们来看一些更多这样的使用案例，看看生成式人工智能如何帮助提升客户体验和互动：
- en: '**Chatbots and virtual assistants**: Imagine you visit a website and a chatbot
    pops up to help you out. Generative AI powers these chatbots. They can talk to
    you like humans, understand your questions, and provide helpful answers.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天机器人和虚拟助手**：想象一下，你访问一个网站时，聊天机器人弹出来帮助你。生成式人工智能为这些聊天机器人提供支持。它们可以像人类一样与您对话，理解您的问题，并提供有帮助的答案。'
- en: '**Intelligent contact centers**: Generative AI is at work when you call a customer
    service hotline. It ensures that your interactions are more personalized, efficient,
    and satisfying. Your issues are addressed promptly and accurately.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能联络中心**：当你拨打客户服务热线时，生成式人工智能在发挥作用。它确保你的互动更加个性化、高效和令人满意。你的问题会迅速且准确地得到解决。'
- en: '**Personalization**: Have you noticed that recommendations on platforms like
    Netflix and Amazon understand your preferences? That’s generative AI in action.
    It learns from your behaviors and tailors its suggestions to match your tastes.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化**：你是否注意到像Netflix和Amazon这样的平台推荐能够理解你的偏好？这就是生成式人工智能的作用。它通过学习你的行为，并根据你的口味调整其推荐内容。'
- en: '**Content moderation**: Generative AI helps keep things clean and safe on social
    media and other platforms. It scans user-generated content, like comments and
    posts, to make sure they follow the rules and guidelines.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容审核**：生成式人工智能帮助社交媒体和其他平台保持清洁和安全。它扫描用户生成的内容，如评论和帖子，确保它们遵守规则和指导方针。'
- en: Employee productivity enhancement
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 员工生产力提升
- en: 'Generative AI isn’t just for customers; it’s also boosting employee productivity.
    Imagine you’re working on a project and need to write a report about it. Instead
    of starting from scratch, you use generative AI to help you write an introduction
    and critical points. This gives you a head start, and you can focus on adding
    your insights and expertise. Here are some use cases where generative AI helps
    to boost employee productivity:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能不仅仅适用于客户，它还提升了员工的生产力。想象一下，你正在处理一个项目，并且需要撰写关于它的报告。与其从头开始，你可以利用生成式人工智能帮助你撰写介绍和关键点。这让你提前了解情况，可以集中精力添加自己的见解和专业知识。以下是一些生成式人工智能帮助提升员工生产力的用例：
- en: '**Conversational search**: You might use a search system when you need information.
    Generative AI makes these systems smarter. You can ask questions in everyday language,
    and the AI will understand and give you the correct answers.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话式搜索**：当你需要信息时，可能会使用搜索系统。生成式人工智能使这些系统更加智能。你可以用日常语言提问，AI会理解并给出正确的答案。'
- en: '**Content creation**: Writing reports and articles can take a lot of time.
    Generative AI helps here, too. It can generate content sections, like summaries
    or explanations, which you can use to create polished documents.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容创作**：撰写报告和文章可能需要大量时间。生成式人工智能在这方面也大有帮助。它可以生成内容部分，如摘要或解释，帮助你创建精炼的文档。'
- en: '**Text summarization**: Imagine you’re reading a long research paper. Instead
    of going through all the pages, generative AI can summarize the main points. This
    saves time and helps you grasp the essential information faster.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本摘要**：想象一下你正在阅读一篇长篇研究论文。与其浏览所有页面，生成式人工智能可以总结主要观点。这样可以节省时间，并帮助你更快地掌握基本信息。'
- en: '**Code creation**: For programmers, writing code is a big part of the job.
    Generative AI can assist by suggesting code snippets based on what you’re trying
    to achieve. This speeds up coding tasks and makes development smoother.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：对于程序员来说，编写代码是工作的重要组成部分。生成式人工智能可以根据你想要实现的目标建议代码片段。这加快了编码任务，使开发过程更加顺畅。'
- en: When integrating generative AI into enterprise scenarios, it’s crucial to navigate
    legal considerations around the content it generates. You need to understand the
    source of the content, and establishing clear ownership rights is essential to
    prevent intellectual property disputes. There are potential barriers to adoption,
    such as concerns over copyright infringement and data privacy. To mitigate these
    risks, your enterprises can consider developing their own generative AI assistants
    using proprietary data. This approach not only helps avoid legal complications
    but also ensures that the generated content is aligned with the organization’s
    specific needs and retains its unique value.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成式人工智能整合到企业场景中时，重要的是要处理其生成内容周围的法律考虑。你需要理解内容的来源，建立清晰的所有权是防止知识产权纠纷的关键。采用这种方法可以帮助企业避免法律问题，同时确保生成的内容符合组织的特定需求并保持其独特价值。
- en: Optimizing business operations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化业务运营
- en: 'Generative AI isn’t limited to customer interactions; it also enhances various
    operational aspects. In a manufacturing plant, machines are monitored by sensors.
    Generative AI analyzes the data from these sensors and predicts when a machine
    will likely have issues. This allows maintenance to be scheduled proactively,
    preventing unexpected breakdowns and production interruptions. The following are
    some use cases where generative AI helps to improve business operations:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能不仅局限于客户互动，它还增强了各种运营方面。在制造厂中，机器通过传感器进行监控。生成式人工智能分析这些传感器的数据，并预测机器可能出现问题的时间。这使得维护可以主动安排，预防意外故障和生产中断。以下是一些生成式人工智能帮助改善业务运营的用例：
- en: '**Intelligent document processing**: In businesses, there are many documents
    to handle. Generative AI can read and understand these documents, extracting meaningful
    information automatically. This saves time and reduces errors. For example, the
    generative AI model can ingest mortgage lending documents and answer questions
    about mortgage rates, payment terms, duration, etc.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能文档处理**：在企业中，有许多文件需要处理。生成式人工智能可以自动读取和理解这些文件，提取有意义的信息。这节省时间并减少错误。例如，生成式人工智能模型可以处理抵押贷款文件，并回答关于抵押利率、付款条件、期限等的问题。'
- en: '**Predictive maintenance**: For companies that use machinery, predicting when
    equipment needs maintenance is crucial. Generative AI analyzes data from machines
    and systems to forecast maintenance requirements, preventing breakdowns and minimizing
    downtime.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测性维护**：对于使用机器的公司来说，预测设备何时需要维护至关重要。生成型AI分析来自机器和系统的数据，以预测维护需求，防止故障发生并最小化停机时间。'
- en: '**Quality control and visual inspection**: Ensuring products meet high standards
    is essential in manufacturing. Generative AI can examine images of products, identifying
    defects or inconsistencies that human eyes might miss.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量控制与视觉检查**：确保产品符合高标准是制造业中的重要环节。生成型AI可以检查产品的图像，识别出人眼可能忽略的缺陷或不一致之处。'
- en: '**Data augmentation**: Training AI models requires a lot of data. Generative
    AI helps here by creating synthetic data that can be used to improve the accuracy
    and reliability of these models.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据增强**：训练AI模型需要大量的数据。生成型AI通过创建合成数据来帮助提高这些模型的准确性和可靠性。'
- en: In this section, you learned about generative AI use cases. Now, let’s learn
    what goes on behind the scenes by learning about generative AI architecture.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你了解了生成型AI的应用场景。现在，让我们通过了解生成型AI的架构，来探究背后的原理。
- en: The basic architecture of generative AI systems
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成型AI系统的基本架构
- en: 'At the heart of generative AI systems is a massive FM. FMS are large-scale,
    pre-trained models that have been trained on vast datasets and can be fine-tuned
    or adapted for a wide range of tasks and applications. To understand the architecture
    of generative AI systems, let’s break it down into simple components:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型AI系统的核心是一种大规模的FM。FM是经过大规模数据集预训练的大型模型，可以针对各种任务和应用进行微调或适配。为了理解生成型AI系统的架构，让我们将其拆解为简单的组成部分：
- en: '**Generator**: The core element that generates new data, whether it’s images,
    text, music, or other forms of content. The generator learns patterns and relationships
    from existing data and uses this knowledge to produce new, similar content. For
    example, the generator takes random noise in image generation and produces images
    that resemble the training data.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器**：生成新数据的核心元素，无论是图像、文本、音乐还是其他形式的内容。生成器从现有数据中学习模式和关系，并利用这些知识生成新的、相似的内容。例如，生成器在图像生成中接受随机噪声，然后生成类似训练数据的图像。'
- en: '**Latent space**: A conceptual space where the model represents data in a compressed
    form. It’s like a compact representation of the data that the generator uses to
    create new content. This is a lower-dimensional vector space from which the generator
    generates data. This is like the secret recipe book an artist uses. It helps the
    generator come up with different types of creations. For instance, the latent
    space could represent different writing styles in text generation. In image synthesis,
    the latent space might represent different features like color and texture.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在空间**：一个概念空间，在这个空间中，模型以压缩形式表示数据。这就像是生成器用来创造新内容的数据的紧凑表示。它是一个低维向量空间，生成器从中生成数据。这就像是艺术家使用的秘密食谱本。它帮助生成器创作出不同类型的作品。例如，在文本生成中，潜在空间可以代表不同的写作风格；在图像合成中，潜在空间可能代表颜色和纹理等不同特征。'
- en: '**Loss function**: A measure of how well the generated content matches the
    desired output. The loss function helps the model learn and improve over time
    by minimizing the difference between generated and real data. Imagine a coach
    telling an artist how close their work is to perfection. The artist learns and
    gets better by following this guidance.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失函数**：衡量生成内容与期望输出之间匹配程度的指标。损失函数通过最小化生成数据与真实数据之间的差异，帮助模型随着时间推移不断学习和改进。可以想象，一位教练在告诉艺术家他们的作品与完美之间的差距。艺术家通过遵循这个指导，不断学习并提高。'
- en: '**Training data**: The existing data that the model learns from. It could be
    images, text, audio, or any other type of content that is available from which
    the model learns. Just like a chef learns by tasting different foods, the generator
    learns what it should create from examples. For instance, if it’s creating songs,
    it learns from listening to existing songs.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据**：模型学习的现有数据。它可以是图像、文本、音频或任何其他类型的内容，模型从中学习。就像厨师通过品尝不同的食物来学习一样，生成器通过示例学习应该创造什么。例如，如果生成器正在创作歌曲，它就会通过聆听现有的歌曲来学习。'
- en: Types of generative models
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成模型的类型
- en: Before learning about the generative models, let’s learn how they differ from
    the typical ML discriminating model. A typical ML discriminating model, also known
    as a discriminative model, is designed to differentiate between different classes
    or categories of data. Unlike generative models that aim to generate new data
    points, discriminative models focus on distinguishing existing data points based
    on their features. These models predict the probability of a given outcome based
    on the input data. Common examples of discriminating ML models include logistic
    regression, support vector machines, and so on. You learned about this concept
    in detail in *Chapter 13*, *Machine Learning Architecture*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解生成模型之前，我们先了解它们与典型的机器学习判别模型有何不同。典型的机器学习判别模型，也称为判别模型，旨在区分不同类别或种类的数据。与目标是生成新数据点的生成模型不同，判别模型的重点是根据数据的特征区分现有数据点。这些模型基于输入数据预测某个结果的概率。常见的判别性机器学习模型包括逻辑回归、支持向量机等。你在*第13章*《机器学习架构》中详细学习了这个概念。
- en: Generative models distinguish themselves from discriminating models, which are
    tailored to categorize or tag text based on predefined groupings. Discriminating
    models are commonly deployed in applications such as facial recognition, where
    their training focuses on identifying specific features or attributes within a
    person’s visage.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型与判别模型有所不同，后者专门用于根据预定义的分组对文本进行分类或标注。判别模型通常应用于面部识别等任务，在这些任务中，模型的训练重点是识别一个人面部的特定特征或属性。
- en: '![](img/B21336_14_01.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21336_14_01.png)'
- en: 'Figure 14.1: Generative models versus discriminating models'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1：生成模型与判别模型
- en: As shown in the preceding diagram, generative models try to understand the patterns
    and structure within the data. It’s like they are learning the hidden rules of
    a game and then using those rules to create something new that looks like the
    original game. Discriminating models, on the other hand, focus on telling things
    apart. They are like detectives who are trained to recognize differences between
    things. Discriminative models are typically chosen for supervised learning tasks
    where the goal is classification or regression, whereas generative models are
    selected when the goal is to understand data distribution or generate new data
    points.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的图示所示，生成模型试图理解数据中的模式和结构。就像它们在学习游戏的潜规则，然后用这些规则创造出一个看起来像原始游戏的新事物。而判别模型则侧重于区分不同的事物。它们就像是侦探，训练用来识别事物之间的差异。判别模型通常用于监督学习任务，其中目标是分类或回归，而生成模型则用于理解数据分布或生成新数据点。
- en: Generative AI encompasses various models that create new content. We’ll look
    at some notable types in the following subsections.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性人工智能涵盖了各种创建新内容的模型。我们将在接下来的子章节中讨论一些重要的类型。
- en: Generative Adversarial Networks (GANs)
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成对抗网络（GAN）
- en: 'GANs are made up of two components: the generator and the discriminator. The
    generator’s role is to produce content, and the discriminator’s job is to judge
    the authenticity of that content, determining whether it’s real or counterfeit.
    They engage in a sort of “competition,” where the generator aims to create content
    convincing enough to deceive the discriminator. As this process continues, the
    generator progressively improves at crafting content that appears increasingly
    realistic. The following diagram shows the workings of the GAN model:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: GAN由两个组件组成：生成器和判别器。生成器的角色是生成内容，而判别器的任务是判断该内容的真实性，确定其是“真”还是“假”。它们进行一种“竞争”，生成器的目标是创造出足够有说服力的内容以欺骗判别器。随着这个过程的进行，生成器会逐渐提高其创造出看起来越来越逼真的内容的能力。下面的图示展示了GAN模型的工作原理：
- en: '![](img/B21336_14_02.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21336_14_02.png)'
- en: 'Figure 14.2: Training flow of GANs'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2：GAN的训练流程
- en: 'The preceding diagram represents the basic structure of a GAN. Let’s look at
    each step with the example of image creation:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图示表示了生成对抗网络（GAN）的基本结构。我们以图像创作为例，逐步了解每个步骤：
- en: '**Generator**: This component of the GAN takes in random noise as its input.
    This noise is often referred to as a “latent random variable.” The generator’s
    role is to produce data that is similar to the real data it has been trained on.
    Imagine this as an artist in training, initially creating random sketches based
    on some basic patterns of artwork. For example, the generator starts by creating
    random images that are intended to look like famous paintings.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器**：GAN的这个组件接收随机噪声作为输入。这种噪声通常被称为“潜在随机变量”。生成器的作用是生成与它所接受的真实数据相似的数据。可以把它想象成一个正在学习的艺术家，最初根据一些基本的艺术模式创作随机草图。例如，生成器开始通过创建随机图像，试图让它们看起来像著名的画作。'
- en: '**Real data samples**: These are authentic data instances that the GAN is designed
    to mimic. They serve as the benchmark for the quality of the data that the generator
    creates. In our example, these are actual famous paintings from history, the masterpieces
    that the generator is attempting to emulate. For example, authentic paintings
    by artists like Van Gogh or Picasso are fed into the GAN as examples of “real”
    artwork.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真实数据样本**：这些是GAN设计来模仿的真实数据实例。它们作为生成器创建的数据质量的基准。在我们的例子中，这些是真正的历史名画，是生成器尝试模仿的艺术杰作。例如，像梵高或毕加索这样的艺术家的真实画作被输入到GAN中，作为“真实”艺术作品的例子。'
- en: '**Generated fake samples**: The generator uses the input noise to create new
    data samples. These samples are intended to be indistinguishable from the real
    data samples, although they are entirely generated by the model. These are the
    new images the generator creates, trying to replicate the quality and style of
    the real artwork samples. For example, the generator produces images that mimic
    the brushstrokes and color schemes of Van Gogh or Picasso’s works.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成的虚假样本**：生成器使用输入的噪声生成新的数据样本。这些样本旨在与真实数据样本难以区分，尽管它们完全是由模型生成的。这些是生成器创建的新图像，试图复制真实艺术作品的质量和风格。例如，生成器生成的图像模仿梵高或毕加索作品的笔触和色调。'
- en: '**Discriminator**: This component takes in both real data samples and fake
    data samples generated by the generator. Its job is to distinguish between the
    two, effectively deciding whether each sample it receives is real or fake. Think
    of this as an art critic who examines both the real masterpieces and the generated
    images to decide whether the new images are genuine artworks or imitations. For
    example, the discriminator reviews the images, trying to determine which ones
    are the actual Van Gogh or Picasso paintings and which are the imitations.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**判别器**：这个组件接收来自真实数据样本和生成器生成的虚假数据样本。它的工作是区分这两者，决定它收到的每个样本是现实的还是伪造的。可以把它看作一个艺术评论家，检查真实的艺术杰作和生成的图像，以判断新的图像是原作还是仿制品。例如，判别器审查这些图像，试图确定哪些是梵高或毕加索的真实画作，哪些是模仿品。'
- en: '**Condition**: The discriminator makes a decision on whether the data is real
    or fake and provides this information as feedback to the generator. The art critic
    (discriminator) assesses the generated images and gives feedback, such as pointing
    out which aspects make them look fake. For example, the discriminator notes that
    the color palette in a generated image doesn’t quite match the original artist’s
    style and labels it as fake.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件**：判别器对数据是否真实或虚假做出判断，并将此信息作为反馈提供给生成器。艺术评论家（判别器）评估生成的图像并给予反馈，例如指出哪些方面让图像看起来像假的。例如，判别器注意到生成图像中的色调与原艺术家的风格不完全匹配，并将其标记为伪造。'
- en: '**Fine-tune training**: Based on the discriminator’s assessments, the generator
    adjusts its parameters in an effort to create better fake samples that are more
    likely to fool the discriminator. This feedback loop continues with the discriminator
    also improving its ability to discern real from fake. This adversarial process
    continues until the generator becomes adept at creating realistic data. Based
    on the feedback, the artist in training (generator) learns from the criticism
    and improves its technique to create more convincing artwork. For example, taking
    the feedback into account, the generator adjusts its technique, maybe altering
    the color mix or brushstroke style to better imitate the masterpieces.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调训练**：根据判别器的评估，生成器调整其参数，努力生成更有可能骗过判别器的更好的假样本。这个反馈回路继续进行，判别器也在不断提高自己辨别真实与虚假的能力。这个对抗过程持续进行，直到生成器能够熟练地生成逼真的数据。根据反馈，正在训练中的艺术家（生成器）从批评中学习，并改进技巧，以创作出更具说服力的艺术作品。例如，考虑到反馈，生成器调整技巧，可能改变颜色搭配或画笔风格，更好地模仿大师级作品。'
- en: The generator and the discriminator are essentially in a continuous game, with
    the generator trying to produce increasingly realistic data, and the discriminator
    striving to get better at telling real data from fake. The “training” is complete
    when the discriminator can no longer reliably distinguish fake data from real
    data, meaning the generator’s output is convincingly realistic.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器本质上处于一个持续的博弈中，生成器试图生成越来越逼真的数据，而判别器努力提高自己区分真实数据和虚假数据的能力。 “训练”完成的标志是判别器无法可靠地区分真假数据，这意味着生成器的输出足够逼真。
- en: GANs have several practical applications across business domains; many popular
    tools leverage this model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: GAN（生成对抗网络）在各个商业领域有许多实际应用，许多流行工具都利用了这一模型。
- en: Variational Autoencoders (VAEs)
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变分自编码器（VAE）
- en: 'Imagine you have a massive pile of Lego blocks in various shapes and sizes,
    and your task is to store them neatly in a small box. But there’s a catch: you
    can only store instructions on how to rebuild the original Lego structures, not
    the blocks themselves. This is similar to what VAEs do with data.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有一堆各种形状和大小的乐高积木，你的任务是把它们整齐地存放在一个小盒子里。但有一个限制：你只能存放关于如何重建原始乐高结构的说明，而不能存放这些积木本身。这就类似于VAE处理数据的方式。
- en: In this analogy, the “encoder” is like you taking each Lego structure, figuring
    out the best way to rebuild it using fewer blocks, and then writing down those
    instructions. The space inside your small box, where you keep these instructions,
    is like the “latent space” – a compressed version of the original structures.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类比中，“编码器”就像你将每个乐高结构拆解，找出用更少积木重新构建它的最佳方法，然后将这些说明写下来。你放置这些说明的盒子里的空间，就像是“潜在空间”——原始结构的压缩版本。
- en: Later, when you want to rebuild a Lego structure, you look at your instructions
    in the box. The “decoder” is like you following those instructions to build a
    new Lego structure that looks very similar to the original one using a new set
    of blocks.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，当你想重建一个乐高结构时，你会查看盒子里的说明书。“解码器”就像你按照那些说明书，用一套新的积木来建造一个与原始结构非常相似的新乐高结构。
- en: 'So, a VAE takes large, complex data (the original Lego structures), compresses
    it into a simpler, smaller form (instructions in the box), and then uses that
    compressed form to generate new data that resembles the original data (rebuilding
    the Lego structures). This process is useful in technology for tasks like creating
    new images, music, or any digital content that mimics the original data’s style.
    As shown in the following diagram, a handwritten image is encoded and decoded
    using VAEs:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，VAE将大型复杂的数据（原始乐高结构）压缩成一个更简单、更小的形式（盒子里的说明），然后利用这个压缩后的形式生成类似原始数据的新数据（重建乐高结构）。这个过程在技术领域非常有用，适用于创建新图像、音乐或任何模仿原始数据风格的数字内容。如下图所示，一个手写图像通过VAE进行编码和解码：
- en: '![](img/B21336_14_03.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21336_14_03.png)'
- en: 'Figure 14.3: Image reconstruction flow using VAEs'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3：使用VAE进行图像重建的流程
- en: 'The preceding diagram depicts the process flow of image reconstruction using
    VAEs. Here’s an explanation of how VAEs typically work for this task with an example
    of reconstructing a person’s face:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图示描述了使用变分自编码器（VAE）进行图像重建的流程。以下是VAE如何通常在这个任务中工作的解释，举一个重建人脸的例子：
- en: '**Input images**: These are the original images that you feed into the VAE
    system. The goal is to be able to reconstruct these images after they’ve been
    encoded and decoded. Let’s say we have a set of face photographs. Each image is
    a clear, high-resolution photo of a person’s face.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入图像**：这些是你输入到VAE系统中的原始图像。目标是能够在编码和解码之后重建这些图像。假设我们有一组面部照片。每张图像都是一个清晰的高分辨率人脸照片。'
- en: '**Encoder**: The encoder part of a VAE takes the input images and compresses
    them into a smaller, more compact representation known as the latent space or
    image encodings. This process involves learning the essential features and patterns
    present in the input images. The encoder analyzes input photographs and compresses
    each one into a smaller set of numbers that describe the key features of the faces,
    like the shape of the eyes, nose, and mouth. Imagine it like creating a unique
    code that could represent a face in much less space than the original picture.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器**：VAE的编码器部分接收输入图像，并将其压缩成一个更小、更紧凑的表示，称为潜在空间或图像编码。这个过程涉及学习输入图像中的基本特征和模式。编码器分析输入的照片，将每张图像压缩成一个包含面部关键特征的数字集，如眼睛、鼻子和嘴巴的形状。可以将其想象为创建一个独特的编码，能够代表一个面孔，而占用的空间远小于原始图片。'
- en: '**Image encodings**: At this stage, the encoder has translated the input images
    into a set of encodings that represent the key features of the images in a much-reduced
    dimensionality compared to the original images. In the context of VAEs, these
    encodings also capture the probability distribution of the input data. These sets
    of numbers (encodings) are the essence of the photographs, stored in a compact
    form, which we can think of as the detailed features of the images. In the case
    of faces, these features might capture variations in facial features among different
    individuals.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像编码**：在这一阶段，编码器已将输入图像转换为一组编码，这些编码代表图像的关键特征，相比原始图像，维度大大缩小。在变分自编码器（VAE）的背景下，这些编码还捕捉了输入数据的概率分布。这些数字集（编码）是照片的精髓，以紧凑的形式存储，可以看作是图像的详细特征。在面部的情况下，这些特征可能捕捉到不同个体之间面部特征的变化。'
- en: '**Decoder**: The decoder takes these encodings and attempts to reconstruct
    the original images. It uses the compressed data to generate images that are as
    close as possible to the original input images. The decoder acts like an artist
    given the task of drawing a person’s face. It takes these numerical codes and
    uses them to recreate the photographs of the faces. It tries to draw each face
    as accurately as possible, just from this compact code.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器**：解码器接收这些编码，并尝试重建原始图像。它使用压缩数据生成尽可能接近原始输入图像的图像。解码器的作用就像一位艺术家，任务是绘制一个人的面部。它接收这些数字编码，并利用它们重建面部的照片。它尝试仅凭这些紧凑的编码尽可能准确地绘制每一张面孔。'
- en: '**Reconstructed images**: The final output of a VAE. These are the images that
    have been reconstructed by the decoder from the image encodings. The quality of
    these images is dependent on how well the VAE has learned to compress and reconstruct
    the data. The result is a series of new face photographs generated by the VAE.
    These reconstructed images should closely resemble the original input photos.
    If you were to compare them side by side with the originals, you would find them
    similar, though they might be slightly blurry or have minor differences due to
    the loss of detail during the compression process.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重建图像**：VAE的最终输出。这些是由解码器从图像编码中重建的图像。这些图像的质量取决于VAE压缩和重建数据的能力。结果是一系列由VAE生成的新面部照片。这些重建的图像应该与原始输入照片非常相似。如果将它们与原始图像并排比较，你会发现它们很相似，尽管由于压缩过程中的细节损失，它们可能略显模糊或有轻微的差异。'
- en: In essence, the flow describes a VAE’s ability to learn efficient representations
    of data and generate new data that resembles the original input. This process
    is used in various applications, including image denoising, inpainting, and as
    a generative model to create new images that share properties with the training
    dataset.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，流程描述了VAE学习高效数据表示的能力，并生成与原始输入相似的新数据。这个过程广泛应用于各种场景，包括图像去噪、图像修复，并作为生成模型创建与训练数据集具有相似特征的新图像。
- en: Transformer-based generative models
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Transformer的生成模型
- en: 'These models, such as GPT-4, are built upon the transformer architecture, which
    excels in understanding and generating data sequences, such as text. They learn
    patterns in language and context, allowing them to generate coherent and contextually
    relevant text. The following diagram shows the working of the transformer in the
    model:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型，如GPT-4，基于变压器架构构建，擅长理解和生成文本序列等数据。它们学习语言和上下文中的模式，使其能够生成连贯和上下文相关的文本。以下图显示了模型中变压器的工作方式：
- en: '![](img/B21336_14_04.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21336_14_04.png)'
- en: 'Figure 14.4: Component of transformer-based generative models'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4：基于变压器的生成模型组件
- en: 'The preceding diagram shows the workflow of a transformer model, which is an
    advanced type of neural network used in **Natural Language Processing** (**NLP**)
    tasks such as translation, text generation, and more. Let’s look at each step
    with the example of language translation:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了变压器模型的工作流程，这是一种用于**自然语言处理**（**NLP**）任务，如翻译、文本生成等的先进神经网络类型。让我们通过语言翻译的示例来看每个步骤：
- en: '**Input embedding layer**: The process begins with the input embedding layer,
    where individual elements (like words in a sentence) are transformed into numerical
    vectors that the model can process. For example, the sentence “How are you?” enters
    the model, and each word is turned into a numerical vector. This is like giving
    each word a unique, identifiable badge number so the model can understand and
    manipulate them.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入嵌入层**：过程始于输入嵌入层，其中单个元素（如句子中的单词）被转换为模型可以处理的数值向量。例如，句子“How are you?”输入模型，每个单词转换为数值向量。这就像给每个单词分配一个唯一的可识别的徽章编号，以便模型可以理解和处理它们。'
- en: '**Positional encoding**: Positional encoding is added to these vectors to give
    the model information about the position of each word within the sentence since
    transformers do not inherently understand the order of words. For instance, along
    with the badge number, each word is given a position tag. “How” is tagged as the
    first word, “are” as the second, and “you” as the third. This helps the model
    consider the order of words.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**位置编码**：将这些向量添加到位置编码中，以向模型提供有关句子中每个单词位置的信息，因为变压器本身并不理解单词的顺序。例如，除了徽章编号外，每个单词还分配了一个位置标签。“How”标记为第一个单词，“are”标记为第二个，“you”标记为第三个。这帮助模型考虑单词的顺序。'
- en: '**Encoder**: The combined embeddings (input embeddings plus positional encoding)
    are then fed into the encoder. The encoder processes the input data, capturing
    the context of each word relative to the others in the sequence. It’s like the
    encoder reads the sentence and understands the meaning of each word in the context
    of the entire sentence. The encoder reviews the words with their badge numbers
    and position tags to understand the sentence’s meaning. For example, it notes
    that “How” in the first position usually starts a question.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器**：将组合的嵌入（输入嵌入加上位置编码）输入编码器。编码器处理输入数据，捕获每个单词相对于序列中其他单词的上下文。就像编码器阅读句子并理解每个单词在整个句子上下文中的含义。编码器通过它们的徽章编号和位置标签来理解句子的含义。例如，它注意到第一个位置的“How”通常用于开头问句。'
- en: '**Multi-head self-attention mechanism**: Within the encoder, the multi-head
    self-attention mechanism allows the model to weigh the influence of different
    parts of the input differently. It’s as if the model is considering different
    aspects of the meaning of a word by looking at the other words around it. The
    encoder pays special attention to how each word in the sentence relates to every
    other word. It notices, for example, that “How” is connected to “you” to form
    a polite inquiry about someone’s well-being.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多头自注意机制**：在编码器内部，多头自注意机制允许模型以不同方式权衡输入的影响。就像模型通过观察周围的其他单词考虑单词含义的不同方面。编码器特别关注句子中每个单词如何与其他单词相关联。例如，它注意到“How”与“you”相连形成一个有礼貌的询问关于某人的健康状况。'
- en: '**Feed-forward neural networks**: Next, the processed information passes through
    feed-forward neural networks, which further process the data sequentially in each
    layer to refine and abstract the representation. These networks refine the information
    from the attention mechanism, almost like a group of editors polishing a draft
    to better convey a sentence’s intent.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前馈神经网络**：接下来，处理后的信息通过前馈神经网络传递，这些网络在每一层顺序处理数据，以精炼和抽象表达。这些网络从注意机制中细化信息，几乎像一组编辑人员在修改草稿以更好地传达句子意图。'
- en: '**Normalization and residual connections**: Along the way, normalization and
    residual connections are applied to help maintain data flow and mitigate the risk
    of data transformation errors in deeper layers of the network. These elements
    ensure that the information flowing through the model is neither too dampened
    nor too amplified. To prevent errors from growing through the network layers,
    these components act like checkpoints that keep the data on the right track.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化和残差连接**：在此过程中，应用归一化和残差连接，以帮助保持数据流并减少在网络深层中的数据变换错误的风险。这些元素确保通过模型流动的信息既不被削弱也不被放大。为了防止错误在网络层中扩展，这些组件像是检查点，确保数据沿着正确的轨迹前进。'
- en: '**Decoder**: After the encoder has processed the input, the decoder uses this
    information to generate the output. It receives the processed data from the encoder
    and starts producing the transformed sequence, such as translating the sentence
    into another language or generating a response in a dialogue. The decoder takes
    the processed information from the encoder and begins generating the output. If
    it’s translating, it will start producing the translated sentence.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器**：在编码器处理完输入后，解码器使用这些信息来生成输出。它接收来自编码器的处理数据，并开始生成转换后的序列，如将句子翻译成另一种语言或在对话中生成回应。解码器从编码器接收处理过的信息，并开始生成输出。如果正在进行翻译，它会开始生成翻译后的句子。'
- en: '**Output layer**: The final output of the decoder is sent to the output layer,
    which translates the advanced neural network output back into a readable format,
    like a sentence in human language. This is where the final output begins to take
    shape. If the model is translating the sentence, this layer starts building the
    translation based on all the processed information.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层**：解码器的最终输出会发送到输出层，输出层将高级神经网络的输出转回可读格式，如人类语言的句子。此时，最终的输出开始形成。如果模型正在翻译句子，这一层将根据所有处理过的信息开始构建翻译。'
- en: The transformer model reads and understands the input data (sentence, paragraph,
    etc.), processes it to understand the context, and generates a relevant output
    based on that understanding. For “How are you?”, the encoder part of the model
    processes the question, while the decoder generates a response or a translation,
    one word at a time, considering both the information from the encoder and what
    it has already generated.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 模型读取并理解输入数据（如句子、段落等），处理这些数据以理解上下文，并根据这些理解生成相关的输出。对于“你好吗？”，模型的编码器部分处理问题，而解码器则根据编码器提供的信息以及已生成的内容，一次生成一个单词的回答或翻译。
- en: Think of the encoder as the part that looks at the input information and the
    decoder as the part that creates the output. For example, GPT-4 is based on the
    transformer model. When you give it a starting point, it can generate text that
    makes sense and fits the context.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 可以把编码器看作是负责查看输入信息的部分，而解码器则是负责生成输出的部分。例如，GPT-4 就是基于 Transformer 模型的。当你给它一个起始点时，它可以生成符合上下文且有意义的文本。
- en: This model uses “self-attention” to determine which words in the starting point
    are important and how they connect. This way, it can really understand what you’re
    asking for and give you a good response.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型使用“自注意力”来确定起始点中的哪些单词是重要的，以及它们之间是如何连接的。通过这种方式，模型能够真正理解你的需求并给出合适的回答。
- en: Other important generative models
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他重要的生成模型
- en: 'Apart from the types mentioned, there are other notable generative models:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前面提到的类型外，还有其他值得注意的生成模型：
- en: '**PixelCNN and PixelRNN**: These models generate images pixel by pixel, capturing
    intricate details and dependencies within the image. Imagine drawing a picture
    pixel by pixel, ensuring each pixel fits with the ones around it.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PixelCNN 和 PixelRNN**：这些模型像素逐个生成图像，捕捉图像中的细节和相互依赖关系。可以想象你在逐个像素地绘制一幅画，确保每个像素都与周围的像素相协调。'
- en: '**Flow-based models**: These models learn how to transform one data distribution
    into another, allowing them to generate samples matching the desired distribution.
    This is a recipe that turns simple ingredients into a fancy dish following specific
    instructions.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于流的模型**：这些模型学习如何将一种数据分布转换为另一种数据分布，使其能够生成与目标分布匹配的样本。这就像是根据具体的步骤，用简单的原料制作一道精美的菜肴。'
- en: These generative models have strengths and applications, making them suitable
    for a large range of tasks, from image generation to text creation. Their diverse
    capabilities contribute to the rich landscape of generative AI.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这些生成模型具有优势和应用，使其适用于从图像生成到文本创作的广泛任务。它们的多样化能力为生成式 AI 的丰富领域做出了贡献。
- en: Importance of hyperparameter tuning and regularization in architectures
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调优和正则化在架构中的重要性
- en: Hyperparameter tuning and regularization are fine-tuning and safety measures
    for generative AI architectures. For example, in image generation, you might adjust
    hyperparameters such as the learning rate, which determines how fast the model
    learns; if it’s too high, the model might learn the wrong patterns, like someone
    learning to play a song on the piano but pressing the keys too hard or too softly.
    Regularization might involve techniques like dropout, where you randomly ignore
    some of the model’s neurons during training to make the model robust, much like
    training a football team with some players sitting out so the team doesn’t rely
    too much on any one player. They play a crucial role in making these systems work
    well and create high-quality content. Let’s understand their importance.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优和正则化是生成式 AI 架构的微调和安全措施。例如，在图像生成中，您可能会调整诸如学习率等超参数，学习率决定了模型学习的速度；如果学习率过高，模型可能会学习到错误的模式，就像有人在钢琴上弹奏一首曲子时按键力度过大或过小。正则化可能涉及像
    dropout 这样的技术，在训练过程中随机忽略模型的一些神经元，以使模型更强健，就像训练一支足球队时让一些球员休息，这样球队就不会过于依赖某一个球员。它们在使这些系统良好运作并生成高质量内容方面起着至关重要的作用。让我们理解它们的重要性。
- en: Hyperparameter tuning
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超参数调优
- en: Think of hyperparameters as knobs and switches that control how the generative
    AI system learns and creates. They affect things like the speed of learning, the
    level of detail in the output, and the balance between creativity and accuracy.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 可以把超参数看作是控制生成式 AI 系统学习和创造方式的旋钮和开关。它们会影响学习速度、输出的细节程度，以及创造力与准确性之间的平衡。
- en: Imagine trying to find the perfect oven temperature for baking a cake. Too hot
    and it burns; too cold and it stays gooey. Hyperparameter tuning is similar. It
    helps adjust the parameters so that the AI system learns in the best way, creating
    content that’s just right.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，您正在寻找烘焙蛋糕的最佳烤箱温度。温度太高会烧焦；温度太低则会保持黏糊糊的状态。超参数调优类似于此。它有助于调整参数，以便 AI 系统以最佳方式学习，创造出恰到好处的内容。
- en: For example, hyperparameters might control the length of melodies, the tempo,
    or the instruments used in a music generation system. Tuning them ensures that
    the music sounds harmonious and matches the desired style.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，超参数可能控制音乐生成系统中旋律的长度、节奏或所用的乐器。调整这些超参数可以确保音乐听起来和谐，并且与期望的风格相匹配。
- en: Regularization
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正则化
- en: Regularization is like adding safety nets to a tightrope walker. It prevents
    the AI system from getting too carried away and creating too wild or unrealistic
    content. It’s a way to keep the output in check and ensure it is well-behaved.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化就像给走钢丝的人加上安全网。它防止 AI 系统过于放纵，生成过于夸张或不真实的内容。它是一种控制输出并确保其行为得当的方式。
- en: In a generative AI system, regularization helps prevent overfitting. Overfitting
    is when the system becomes too good at mimicking the training data but needs help
    with new, unseen data. Regularization techniques simulate adding minor penalties
    to certain parts of the learning process, helping the system generalize better
    and create more diverse and creative content.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式 AI 系统中，正则化有助于防止过拟合。过拟合是指系统在模拟训练数据时过于优秀，但在处理新的、未见过的数据时表现不佳。正则化技术通过模拟对学习过程中的某些部分施加轻微惩罚，帮助系统更好地泛化，创造出更具多样性和创意的内容。
- en: For instance, regularization in an image generation system might ensure that
    the generated images have consistent colors and shapes, preventing them from looking
    too noisy or strange.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在图像生成系统中，正则化可以确保生成的图像具有一致的颜色和形状，防止它们看起来过于嘈杂或奇怪。
- en: Hyperparameter tuning and regularization matter as they fine-tune the generative
    AI system’s performance and ensure it produces high-quality, consistent, and realistic
    content. Without them, the system might either create content that’s too boring
    or content that’s too chaotic and nonsensical.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优和正则化很重要，因为它们微调生成式 AI 系统的性能，确保其生成高质量、一致且真实的内容。如果没有它们，系统可能会创造出过于单调的内容，或是过于混乱且毫无意义的内容。
- en: Just like a chef adjusts the cooking time and adds the right spices to make
    a perfect dish, hyperparameter tuning and regularization fine-tune the generative
    AI system to create content that’s creative and aligned with the desired output.
    They ensure the system stays on the right track, creating exciting and reliable
    content.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 就像厨师调整烹饪时间并加入合适的调味料来制作完美的菜肴一样，超参数调整和正则化会微调生成性人工智能系统，创造出既富有创意又符合预期输出的内容。它们确保系统始终保持正确的轨道，创作出令人兴奋且可靠的内容。
- en: Popular generative AI FMs
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行的生成性人工智能基础模型
- en: 'The field of generative AI is rapidly evolving, with various organizations
    pushing the boundaries and launching powerful foundation models to drive innovation.
    The launch of models like ChatGPT has undoubtedly contributed to the acceleration
    of this trend. Both established tech giants and emerging start-ups are actively
    participating in the generative AI boom, aiming to develop more sophisticated
    and capable FMs. Here’s a list of some of the most popular FMs in generative AI:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性人工智能领域正在迅速发展，各种组织推动技术边界，并推出强大的基础模型以促进创新。像ChatGPT这样的模型的发布无疑加速了这一趋势。无论是已有的科技巨头，还是新兴的初创公司，都在积极参与生成性人工智能的浪潮，旨在开发更复杂、更强大的基础模型。以下是一些在生成性人工智能中最受欢迎的基础模型：
- en: '**Amazon**: **Amazon Web Services** (**AWS**) is one of the top cloud providers
    and has a large set of offerings in ML and generative AI. AWS has launched a generative
    AI service called AWS Bedrock with accessibility to popular FM models using APIs
    in a serverless manner. Amazon SageMaker JumpStart is another offering that provides
    access to a wide range of FM models and the ability to tune them as needed. Amazon
    Titan is AWS’s flagship generative AI model. Amazon’s Titan suite encompasses
    a series of FMs that cater to a variety of generative tasks, including:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon**：**亚马逊网络服务**（**AWS**）是全球顶级的云服务提供商之一，并在机器学习和生成性人工智能领域提供大量产品。AWS推出了一项生成性人工智能服务，名为AWS
    Bedrock，用户可以通过API以无服务器的方式访问流行的基础模型。Amazon SageMaker JumpStart是另一项服务，提供访问各种基础模型的功能，并可以根据需要对其进行调优。Amazon
    Titan是AWS的旗舰生成性人工智能模型。亚马逊的Titan套件包括一系列适用于各种生成任务的基础模型，其中包括：'
- en: '**Titan Text Embeddings**: For contextual text representations'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Titan文本嵌入**：用于上下文文本表示'
- en: '**Titan Multimodal Embeddings**: For interpreting data across text and images'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Titan多模态嵌入**：用于解读文本和图像之间的数据'
- en: '**Titan Text Lite**: For efficient text processing in resource-constrained
    environments'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Titan文本精简版**：用于资源受限环境中的高效文本处理'
- en: '**Titan Text Express**: For rapid text processing tasks'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Titan文本极速版**：用于快速文本处理任务'
- en: '**Titan Image Generator**: For creating or modifying visual content from textual
    inputs'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Titan图像生成器**：用于根据文本输入创建或修改视觉内容'
- en: 'You can learn about Amazon title models and keep an eye on upcoming developments
    by visiting the Amazon Bedrock page here: [https://aws.amazon.com/bedrock/titan/](https://aws.amazon.com/bedrock/titan/).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问亚马逊床岩（Amazon Bedrock）页面来了解亚马逊标题模型，并关注未来的相关发展：[https://aws.amazon.com/bedrock/titan/](https://aws.amazon.com/bedrock/titan/)。
- en: '**OpenAI**: OpenAI is a research organization that creates and promotes open
    and ethical AI. It has created several generative AI models, such as:'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenAI**：OpenAI是一个致力于创建和推广开放且符合道德标准的人工智能的研究机构。它已经创建了多个生成性人工智能模型，包括：'
- en: '**DistilGPT2**: Efficient text generation model'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DistilGPT2**：高效的文本生成模型'
- en: '**GPT-3**: Versatile model for text generation and question-answering'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-3**：多功能文本生成与问答模型'
- en: '**GPT NeoXT**: Advanced model for diverse language tasks'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT NeoXT**：用于多样语言任务的先进模型'
- en: '**GPT-3.5**: Generates longer, coherent texts with efficiency'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-3.5**：高效地生成更长、更连贯的文本'
- en: '**GPT-4**: Multimodal model with human-like performance'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4**：具有类人表现的多模态模型'
- en: '**CLIP**: Learns relationships between text and images'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CLIP**：学习文本与图像之间的关系'
- en: '**CLIP-Guided Diffusion**: Creates images aligned with text prompts'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CLIP引导扩散**：根据文本提示创建对齐的图像'
- en: '**DALL·E**: Generates images from natural language prompts'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DALL·E**：根据自然语言提示生成图像'
- en: '**MuZero**: Learns to play games through self-play'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MuZero**：通过自我对弈学习玩游戏'
- en: '**Text-to-Speech (TTS)**: Converts text to natural-sounding speech'
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本转语音（TTS）**：将文本转化为自然听起来的语音'
- en: '**Whisper**: Audio-to-text transcription model'
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Whisper**：音频转文本的转录模型'
- en: '**Embeddings**: Converts text into numerical data'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入**：将文本转换为数值数据'
- en: '**Moderation**: Assesses text for sensitive content'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容审核**：评估文本中的敏感内容'
- en: '**Sora**: Generates videos from written prompts'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sora**：根据书面提示生成视频'
- en: 'OpenAI is working on GPT-5, which is their latest and most advanced model in
    training. To learn more about OpenAI’s models, you can visit their official website
    here: [https://openai.com/](https://openai.com/). OpenAI provides detailed information
    about their models, research, publications, and API access on their platform.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI正在开发GPT-5，这是他们最新且最先进的训练模型。要了解更多关于OpenAI模型的信息，您可以访问他们的官方网站：[https://openai.com/](https://openai.com/)。OpenAI在其平台上提供了关于模型、研究、出版物和API访问的详细信息。
- en: '**Google**: Google is a pioneer in AI and ML. It has developed several generative
    AI models, such as:'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google**：Google是AI和机器学习的先驱。它已经开发出多个生成型AI模型，如：'
- en: '**Google Gemini**: A large language model for language translation, content
    creation, and query answering'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Gemini**：用于语言翻译、内容创作和查询回答的大型语言模型'
- en: '**BERT**: A model that improved contextual understanding in language processing'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BERT**：一种提高语言处理中的上下文理解的模型'
- en: '**BigGAN**: Generates high-resolution, realistic images for visual content
    creation'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BigGAN**：生成高分辨率、逼真的图像，用于视觉内容创作'
- en: '**Text-to-Text Transfer Transformer (T5)**: Automates content generation for
    various NLP tasks'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Text-to-Text Transfer Transformer (T5)**：自动化生成各种NLP任务的内容'
- en: '**Flan T-5 models**: Tailored for specific language processing tasks including
    text and code'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Flan T-5模型**：针对特定语言处理任务，包括文本和代码进行定制'
- en: '**Pathway Language Model (PaLM)**: Among the largest language models, excelling
    in text generation and translation'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pathway Language Model (PaLM)**：其中之一最大的语言模型，在文本生成和翻译方面表现出色'
- en: '**LaMDA**: Designed for dialogue applications, mimicking human conversation'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LaMDA**：为对话应用设计，模拟人类对话'
- en: '**Falcon-7B and Falcon-40B**: Models designed for language translation, question-answering,
    and text generation'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Falcon-7B和Falcon-40B**：专为语言翻译、问答和文本生成设计的模型'
- en: '**Chinchilla by DeepMind**: A massive language model focused on text generation
    and language translation tasks'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Chinchilla by DeepMind**：一个专注于文本生成和语言翻译任务的大型语言模型'
- en: Google is now focusing on Gemini and building a more advanced version of it
    extending to a subscription model. You can learn more about Google’s AI models
    and research by visiting the Google AI website ([https://ai.google/](https://ai.google/))
    or the DeepMind website ([https://deepmind.com/](https://deepmind.com/)).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Google目前专注于Gemini，并正在构建一个更先进的版本，扩展到订阅模型。您可以通过访问Google AI网站([https://ai.google/](https://ai.google/))或DeepMind网站([https://deepmind.com/](https://deepmind.com/))，了解更多关于Google的AI模型和研究。
- en: '**Anthropic**: Anthropic is a research organization that aims to create general
    and scalable AI that can align with human values and preferences. It has recieved
    significant investments from various large tech companies, including Amazon (which
    invested $5 billion) and Google (which invested $2 billion). It has developed
    a generative AI model family called Claude, which includes the following models:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic**：Anthropic是一个研究机构，致力于创建能够与人类价值观和偏好对齐的通用和可扩展AI。它已获得来自多家大型科技公司，包括Amazon（投资50亿美元）和Google（投资20亿美元）的重大投资。它已开发出一个名为Claude的生成型AI模型系列，包括以下模型：'
- en: '**Claude**: An FM offering advanced language understanding and generation capabilities'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude**：一个提供先进语言理解和生成能力的FM'
- en: '**Claude 2**: An enhanced version of Claude with improved language processing
    abilities and context understanding'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude 2**：Claude的增强版本，具有改进的语言处理能力和上下文理解'
- en: '**Claude 2.1**: A further refined version offering more nuanced language generation
    and comprehension'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude 2.1**：进一步优化的版本，提供更细腻的语言生成和理解能力'
- en: '**Claude Instant**: Designed for speed, delivering fast responses while maintaining
    effective language understanding'
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude Instant**：为速度而设计，提供快速响应，同时保持有效的语言理解'
- en: '**Claude 3**: The latest model family, which sets new industry benchmarks across
    various cognitive tasks and comes in three variations – Haiku, Sonnet, and Opus.'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude 3**：最新的模型系列，设定了各类认知任务的新行业基准，并且提供三种变体——Haiku、Sonnet和Opus。'
- en: Anthropic made these models available via different platforms, such as Amazon
    Bedrock and Google Vertex AI, in addition to their own Claude AI web chat interface**.**
    For the most current and comprehensive list of models, please visit Anthropic’s
    website directly at [https://www.anthropic.com/claude](https://www.anthropic.com/claude).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Anthropic通过不同平台提供这些模型，例如Amazon Bedrock和Google Vertex AI，以及他们自己的Claude AI网页聊天界面**。**
    要了解最最新、最全面的模型列表，请直接访问Anthropic的官方网站：[https://www.anthropic.com/claude](https://www.anthropic.com/claude)。
- en: '**Meta (Facebook) AI**: Meta AI is a research organization that develops and
    applies AI for various products and services related to social media, communication,
    content creation, and more. It has developed generative AI models such as:'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Meta (Facebook) AI**：Meta AI是一个研究组织，开发并应用AI技术用于与社交媒体、通讯、内容创作等相关的各种产品和服务。它开发了多个生成式AI模型，如：'
- en: '**RoBERTa**: An enhanced BERT model that achieves better performance through
    more extensive training and fine-tuning'
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RoBERTa**：一种增强版的BERT模型，通过更广泛的训练和微调实现了更好的性能'
- en: '**DETR:** Simplifies object detection in images by combining convolutional
    neural networks with the transformer architecture'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DETR**：通过将卷积神经网络与Transformer架构结合，简化了图像中的目标检测'
- en: '**Llama**: A range of language models designed for understanding and generating
    human-like text, available in various sizes to suit different computational and
    application needs'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Llama**：一系列旨在理解和生成类人文本的语言模型，提供不同大小的版本以满足不同的计算和应用需求'
- en: '**BlenderBot**: Conversational AI that can engage in meaningful and coherent
    interactions, simulating human-like dialogue'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BlenderBot**：一种对话AI，可以进行有意义且连贯的互动，模拟类人对话'
- en: '**Faiss**: A library for efficient similarity search and clustering, ideal
    for handling large datasets and complex similarity tasks'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Faiss**：一个用于高效相似度搜索和聚类的库，特别适合处理大规模数据集和复杂的相似性任务'
- en: You can learn about the latest developments in the area of generative AI from
    Meta by visiting their website at [https://ai.meta.com/](https://ai.meta.com/).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以访问Meta的官方网站，了解其在生成式AI领域的最新发展：[https://ai.meta.com/](https://ai.meta.com/)。
- en: '**Microsoft**: Microsoft uses OpenAI offerings extensively and has made a $10
    billion investment and offers the **OpenAI Model as a Service** (**MaaS**). However,
    it has also developed generative AI models such as **Turing-NLG** and **MPT-7B**.
    Under Microsoft’s MaaS model, it offers OpenAI models such as GPT4, GPT3.5, DALL-E,
    and Whisper. You can learn about the Microsoft Azure model catalog by visiting
    their generative AI offering page here: [https://azure.microsoft.com/en-us/products/machine-learning/generative-ai](https://azure.microsoft.com/en-us/products/machine-learning/generative-ai).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft**：Microsoft广泛使用OpenAI的产品，并进行了100亿美元的投资，同时提供**OpenAI模型即服务**（**MaaS**）。然而，它也开发了生成式AI模型，如**Turing-NLG**和**MPT-7B**。在Microsoft的MaaS模型下，它提供OpenAI模型，如GPT4、GPT3.5、DALL-E和Whisper。你可以访问他们的生成式AI产品页面，在这里了解Microsoft
    Azure模型目录：[https://azure.microsoft.com/en-us/products/machine-learning/generative-ai](https://azure.microsoft.com/en-us/products/machine-learning/generative-ai)。'
- en: '**AI21 Labs**: AI21 Labs is a research organization focusing on natural language
    understanding and generation. It has created several generative AI models, such
    as **Deep Extension of Latent Logic** (**DELL**), **Jurassic-1**, and **Jurassic-2**.
    It launchedAI21 Studio to democratize access to its models and also partnered
    with Amazon to make them available through Amazon Bedrock. You can learn about
    the latest offerings of AI21 by visiting its official blog website here: [https://www.ai21.com/blog](https://www.ai21.com/blog).'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI21 Labs**：AI21 Labs是一个专注于自然语言理解和生成的研究组织。它创建了多个生成式AI模型，如**潜在逻辑深度扩展**（**DELL**）、**Jurassic-1**和**Jurassic-2**。它推出了AI21
    Studio来普及其模型的使用，并与Amazon合作通过Amazon Bedrock提供这些模型。你可以在这里访问AI21的官方博客，了解最新的产品：[https://www.ai21.com/blog](https://www.ai21.com/blog)。'
- en: '**Nvidia**: Nvidia specializes in **graphics processing units** (**GPUs**),
    gaming, cloud computing, AI, and more. It has created several generative AI models,
    such as StyleGAN2 and **GANVerse3D**. You can learn more about Nvidia models here:
    [https://www.nvidia.com/en-us/ai-data-science/generative-ai/](https://www.nvidia.com/en-us/ai-data-science/generative-ai/).'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nvidia**：Nvidia专注于**图形处理单元**（**GPU**）、游戏、云计算、AI等领域。它开发了多个生成式AI模型，例如StyleGAN2和**GANVerse3D**。你可以在这里了解更多关于Nvidia模型的信息：[https://www.nvidia.com/en-us/ai-data-science/generative-ai/](https://www.nvidia.com/en-us/ai-data-science/generative-ai/)。'
- en: '**Jasper.ai**: Jasper.ai is a technology company that provides generative AI
    solutions for marketers. It has developed a generative AI model called Jasper.
    They launched Jasper AI Copilot to extend their offering. You can learn more about
    Jasper here: [https://www.jasper.ai/](https://www.jasper.ai/).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jasper.ai**：Jasper.ai是一家为市场营销人员提供生成式AI解决方案的科技公司。它开发了一个名为Jasper的生成式AI模型，并推出了Jasper
    AI Copilot以扩展其产品。你可以在这里了解更多关于Jasper的信息：[https://www.jasper.ai/](https://www.jasper.ai/)。'
- en: '**Hugging Face**: Hugging Face is a technology company that provides open-source
    tools and platforms for NLP. It has created several generative AI models, such
    as **Bloom models**, **BloomZ 176B**, **Lyra-Fr 10B**, and **Lyra-Mini.** To learn
    more about Hugging Face and its range of generative AI models, you can visit its
    official website and explore its Model Hub, where it provides detailed information
    and access to its models. Here’s the link to get you started: [https://huggingface.co/docs/hub/en/models-the-hub](https://huggingface.co/docs/hub/en/models-the-hub).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hugging Face**：Hugging Face是一家提供开源工具和平台的科技公司，专注于自然语言处理（NLP）。它创造了多个生成式AI模型，如**Bloom模型**、**BloomZ
    176B**、**Lyra-Fr 10B**和**Lyra-Mini**。想要了解更多关于Hugging Face及其生成式AI模型的内容，可以访问其官方网站并探索Model
    Hub，在那里可以获取详细信息并访问其模型。以下是帮助你入门的链接：[https://huggingface.co/docs/hub/en/models-the-hub](https://huggingface.co/docs/hub/en/models-the-hub)。'
- en: The above list is not complete but it talks about some of the most popular models.
    Massive developments are going on for FMs in generative AI. As research in this
    area continues, we can expect to see even more powerful and versatile models being
    developed in the future.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表并不完整，但涵盖了一些最流行的模型。生成式AI中的FM（功能模型）正在经历巨大的发展。随着这一领域的研究不断深入，我们可以期待未来会开发出更强大、更通用的模型。
- en: How to start with generative AI
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何开始使用生成式AI
- en: Starting with generative AI involves selecting the right tools and platforms
    that suit your needs. Whether you’re an end user looking to engage in AI-generated
    conversations or a developer/ML scientist aiming to create sophisticated applications,
    numerous resources are available from different providers to help you embark on
    your generative AI journey. Getting started with generative AI can be exciting!
    The following subsections provide a breakdown of how different types of users
    can begin their exploration into generative AI.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用生成式AI需要选择适合自己需求的工具和平台。无论你是希望参与AI生成对话的终端用户，还是作为开发者/机器学习科学家想要创建复杂应用程序，许多不同提供商的资源都可以帮助你踏上生成式AI的旅程。开始使用生成式AI是令人兴奋的！以下小节将介绍不同类型的用户如何开始探索生成式AI。
- en: For end users
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向终端用户
- en: 'For individuals seeking to harness the capabilities of generative AI in their
    day-to-day activities such as content creation, marketing materials, email composition,
    and efficient learning, several accessible tools can be employed:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于希望在日常活动中利用生成式AI的个人，如内容创作、营销材料、电子邮件撰写和高效学习，可以使用几种易于访问的工具：
- en: '**ChatGPT** offers a user-friendly chatbot experience driven by GPT-3.5, an
    advanced language model. This tool responds with natural language based on the
    input it receives, enabling engaging conversations on various topics. At the time
    of writing, ChatGPT can be accessed at [https://chat.openai.com](https://chat.openai.com/auth/login)
    for free, with the option to upgrade to GPT-4 for more advanced features for a
    monthly subscription of $20\. You can also explore various purpose-built custom
    applications available in the GPT Store created by the builder community.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ChatGPT**提供了一个由GPT-3.5驱动的用户友好型聊天机器人体验。该工具根据接收到的输入以自然语言进行响应，从而使各种话题的互动对话成为可能。在撰写时，ChatGPT可以免费访问，网址为[https://chat.openai.com](https://chat.openai.com/auth/login)，也可以选择升级到GPT-4，获得更多高级功能，月费为20美元。你还可以探索GPT商店中由开发者社区创建的各种定制应用程序。'
- en: '**Claude** is a generative AI model developed by Anthropic. Claude specializes
    in generating text for emails, summaries, stories, and more. Its capabilities
    can be found at [https://claude.ai/chat/](https://claude.ai/chat/), contributing
    to content creation while aligning with human values.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude**是由Anthropic开发的生成式AI模型。Claude专门生成电子邮件、摘要、故事等文本。它的功能可以在[https://claude.ai/chat/](https://claude.ai/chat/)找到，旨在支持内容创作，并与人类价值观相一致。'
- en: '**Google Gemini (formerly Bard)** is a chatbot offered by Google. Like ChatGPT,
    Gemini can answer your questions comprehensively and informally and generate different
    creative text formats, like poems, code, scripts, musical pieces, emails, letters,
    etc. You can explore its capabilities at [https://gemini.google.com/app](https://gemini.google.com/app).
    Gemini is the successor of Google’s first Q&A app, which was formerly known as
    Bard.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Gemini（前身为Bard）**是谷歌推出的一款聊天机器人。像ChatGPT一样，Gemini能够全面且非正式地回答你的问题，并生成各种创意文本格式，如诗歌、代码、脚本、音乐作品、电子邮件、信件等。你可以在[https://gemini.google.com/app](https://gemini.google.com/app)探索它的功能。Gemini是谷歌首个问答应用的继任者，原名为Bard。'
- en: '**Copilot** provides a generative AI service by Microsoft, utilizing models
    like GPT-4\. It facilitates conversations using natural language, making it easier
    to interact and communicate with an AI-driven system. This service is accessible
    at [https://www.bing.com/chat](https://www.bing.com/chat), allowing users to engage
    in conversations seamlessly and intuitively.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Copilot**是由微软提供的生成式AI服务，利用如GPT-4等模型。它通过自然语言促进对话，使得与AI驱动系统的互动和沟通变得更加容易。此服务可以通过[https://www.bing.com/chat](https://www.bing.com/chat)访问，用户可以无缝、直观地进行对话。'
- en: '**Amazon Q**, a service offered by AWS, is designed to significantly enhance
    productivity and decision-making within organizations. It serves as an advanced
    tool that can quickly provide relevant answers to urgent queries, assist in problem-solving,
    generate content, and execute tasks by tapping into the wealth of knowledge contained
    within a company’s databases, code bases, and enterprise systems. You can learn
    more about Amazon Q by visiting the AWS page here: [https://aws.amazon.com/q/](https://aws.amazon.com/q/).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Q**，由AWS提供的服务，旨在显著提升组织内的生产力和决策能力。它作为一种先进工具，可以迅速提供相关答案，帮助解决问题、生成内容并执行任务，利用公司数据库、代码库和企业系统中丰富的知识。你可以通过访问AWS页面了解更多关于Amazon
    Q的信息：[https://aws.amazon.com/q/](https://aws.amazon.com/q/)。'
- en: '**Perplexity AI** represents a breakthrough in search technology, functioning
    as an advanced AI-driven chat tool that goes beyond traditional search engines.
    Acting as a conversational search engine, Perplexity AI employs NLP and ML techniques
    to accurately respond to a wide array of questions. It offers users quick access
    to information across various subjects, simplifying the search process. Moreover,
    it invites users to delve deeper into topics of interest by asking follow-up questions
    or seeking additional details, thereby enriching the user’s understanding and
    learning experience. You can explore it by visiting [https://www.perplexity.ai/](https://www.perplexity.ai/).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Perplexity AI**代表了搜索技术的突破，作为一个先进的AI驱动聊天工具，它超越了传统搜索引擎。作为一个对话式搜索引擎，Perplexity
    AI运用NLP和ML技术，准确地回应各种问题。它为用户提供了快速访问各类主题信息的途径，简化了搜索过程。此外，它邀请用户通过提问后续问题或寻求更多细节，深入了解感兴趣的主题，从而丰富用户的理解和学习体验。你可以通过访问[https://www.perplexity.ai/](https://www.perplexity.ai/)来探索它。'
- en: There are many other AI apps available for different purposes from companies
    like Jasper, Midjourney, Canva, and Luminar. By leveraging these generative AI
    tools, individuals can streamline tasks, foster creativity, and enhance productivity
    in their daily endeavors, from crafting content to having interactive dialogues.
    Each tool brings its own set of unique features, making them versatile assets
    for simplifying and enhancing various aspects of daily life.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他AI应用可用于不同的目的，来自像Jasper、Midjourney、Canva和Luminar等公司。通过利用这些生成式AI工具，个人可以简化任务，激发创造力，并提高日常工作的生产力，从创作内容到进行互动对话。每个工具都有其独特的功能，使其成为简化和提升日常生活各个方面的多功能资产。
- en: For builders
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对于开发者
- en: 'Builders such as app developers, data scientists, and ML engineers can use
    generative AI to increase their productivity multi-fold with the help of generating
    code, tuning already developed models, and accessing existing models through APIs.
    Let’s learn more:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 像应用开发者、数据科学家和机器学习工程师等开发者可以利用生成式AI通过生成代码、调整已开发模型和通过API访问现有模型，将他们的生产力提高多倍。让我们深入了解一下：
- en: '**Increasing productivity through code generation**: Generative AI tools provide
    the ability to generate code so that you can focus on business logic rather than
    writing repeated code. Some of the most popular code-generation tools are:'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过代码生成提高生产力**：生成式AI工具提供了生成代码的能力，使你能够专注于业务逻辑，而不是编写重复的代码。一些最受欢迎的代码生成工具包括：'
- en: '**Amazon CodeWhisperer**: AWS provides this service, which uses NLP and ML
    to generate code snippets based on natural language queries. For example, you
    can ask CodeWhisperer to create a Lambda function that sends an email using SES,
    and it will generate the following code for you:'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon CodeWhisperer**：AWS提供的这项服务使用自然语言处理（NLP）和机器学习（ML）技术，根据自然语言查询生成代码片段。例如，你可以让CodeWhisperer创建一个使用SES发送电子邮件的Lambda函数，它会为你生成以下代码：'
- en: '[PRE0]'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'CodeWhisperer works with 15+ programming languages, including Python, Java,
    and JavaScript, and popular **integrated development environments** (**IDEs**),
    including VS Code, IntelliJ IDEA, AWS Cloud9, the AWS Lambda console, JupyterLab,
    and Amazon SageMaker Studio. You can learn more about Amazon CodeWhisperer here:
    [https://aws.amazon.com/pm/codewhisperer/](https://aws.amazon.com/pm/codewhisperer/).'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: CodeWhisperer 支持 15 种以上的编程语言，包括 Python、Java 和 JavaScript 等，以及流行的 **集成开发环境**
    (**IDEs**)，如 VS Code、IntelliJ IDEA、AWS Cloud9、AWS Lambda 控制台、JupyterLab 和 Amazon
    SageMaker Studio。你可以在这里了解更多关于 Amazon CodeWhisperer 的信息：[https://aws.amazon.com/pm/codewhisperer/](https://aws.amazon.com/pm/codewhisperer/)。
- en: '**Azure Copilot**: This tool uses OpenAI Codex, a large language model trained
    on billions of lines of code, to generate code suggestions within VS Code. You
    can use Azure Copilot to write code in multiple languages, such as Python, JavaScript,
    TypeScript, and others. Here is an example of how Azure Copilot works:'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Copilot**：此工具使用 OpenAI Codex，一种经过数十亿行代码训练的大型语言模型，在 VS Code 中生成代码建议。你可以使用
    Azure Copilot 编写多种语言的代码，如 Python、JavaScript、TypeScript 等。以下是 Azure Copilot 工作的示例：'
- en: '[PRE1]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**ChatGPT interpreter**: This tool uses ChatGPT, a chatbot based on GPT-3,
    to generate code interactively based on natural language input. You can use the
    ChatGPT interpreter to write code in Python, Java, and C#. Here is an example
    of how the ChatGPT interpreter works:'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ChatGPT 解释器**：此工具使用基于 GPT-3 的聊天机器人 ChatGPT，根据自然语言输入交互式地生成代码。你可以使用 ChatGPT
    解释器编写 Python、Java 和 C# 等语言的代码。以下是 ChatGPT 解释器工作原理的示例：'
- en: '[PRE2]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Google Codey**: Codey is capable of supporting more than 20 programming languages,
    including popular ones like Python, Java, JavaScript, and Go. Codey’s main objective
    is to significantly speed up the software development life cycle. It achieves
    this through real-time code completion and generation functionalities. Developers
    have the flexibility to tailor Codey to fit their specific code bases, enhancing
    its utility across a wide array of coding projects.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Codey**：Codey 支持超过 20 种编程语言，包括 Python、Java、JavaScript 和 Go 等流行语言。Codey
    的主要目标是显著加快软件开发生命周期。它通过实时代码完成和生成功能来实现这一目标。开发人员可以根据具体的代码库定制 Codey，从而增强其在各种编程项目中的实用性。'
- en: If you’re interested in harnessing the power of generative AI FMs for your applications,
    you’re in luck! Many of these models are easily accessible through APIs offered
    by renowned cloud platforms and organizations. Let’s look at them in detail.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣在应用程序中利用生成式 AI FMs 的强大功能，恭喜你！许多这些模型可以通过著名云平台和组织提供的 API 轻松访问。让我们详细了解一下它们。
- en: Using generative AI FMs in your applications with public cloud providers
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用公共云服务商提供的生成式 AI FMs 在你的应用程序中。
- en: 'Integrating generative AI FMs into your applications is now more accessible
    than ever, thanks to a range of cloud platforms offering APIs. Here’s a closer
    look at some of these popular platforms and how you can utilize them:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 由于一系列云平台提供 API，将生成式 AI FMs 集成到你的应用程序中现在比以往任何时候都更容易了。下面我们将详细了解一些这些流行的平台，以及如何利用它们：
- en: '**AWS**: AWS introduced the general availability of Amazon Bedrock and Agents
    for Amazon Bedrock as part of their commitment to leading the cloud AI space by
    offering advanced AI solutions and partnerships with industry-leading FM providers.
    Amazon Q, a new generative AI-powered assistant tailored for professional use
    and trained on over 17 years of AWS expertise, exemplifies AWS’s innovative approach
    to integrating AI into the workplace, promising to enhance productivity and creativity
    within enterprises.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS**：AWS 推出了 Amazon Bedrock 和 Amazon Bedrock 代理的正式发布，作为其致力于引领云 AI 领域的承诺的一部分，通过提供先进的
    AI 解决方案和与行业领先的 FM 提供商的合作伙伴关系。Amazon Q 是一款新的生成式 AI 助手，专为专业用途设计，并在超过 17 年的 AWS 专业知识基础上进行训练，展示了
    AWS 将 AI 集成到工作场所的创新方法，承诺提升企业的生产力和创造力。'
- en: '**Amazon Bedrock**: Amazon Bedrock is a robust cloud-based platform provided
    by AWS, designed for training, building, and deploying ML models. It offers an
    extensive suite of APIs for various tasks, including NLP, computer vision, and
    speech recognition. Bedrock provides access to FMs from Amazon and leading AI
    organizations such as AI21 Labs, Anthropic, Cohere, Meta, and Stability AI. To
    start developing a generative AI application using Amazon Bedrock, you’ll first
    select an FM suitable for your needs. This can be done through the Amazon Bedrock
    Console or API. Once you’ve chosen an FM, you can seamlessly integrate it into
    your application using the Amazon Bedrock API. Examples of available FMs include
    Amazon Titan for text summarization, Jurassic-2 for instruction-following language
    models, and Claude 3 for thoughtful dialogue and content creation. You can start
    using Amazon Bedrock by using the link here: [https://aws.amazon.com/bedrock/](https://aws.amazon.com/bedrock/).'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Bedrock**：Amazon Bedrock是AWS提供的一个强大的基于云的平台，旨在训练、构建和部署机器学习模型。它提供了广泛的API套件，支持包括自然语言处理、计算机视觉和语音识别等多种任务。Bedrock还提供访问来自Amazon和领先AI组织的基础模型（FM），如AI21
    Labs、Anthropic、Cohere、Meta和Stability AI。要开始使用Amazon Bedrock开发生成式AI应用程序，首先需要选择一个适合你需求的基础模型。这可以通过Amazon
    Bedrock控制台或API完成。选择基础模型后，你可以通过Amazon Bedrock API轻松将其集成到你的应用程序中。可用的基础模型示例包括Amazon
    Titan用于文本摘要、Jurassic-2用于遵循指令的语言模型，以及Claude 3用于深思熟虑的对话和内容创作。你可以通过以下链接开始使用Amazon
    Bedrock：[https://aws.amazon.com/bedrock/](https://aws.amazon.com/bedrock/)。'
- en: '**SageMaker JumpStart**: SageMaker JumpStart is another offering from AWS aimed
    at simplifying the ML development process. It provides pre-built ML models and
    workflows to accelerate your ML projects. SageMaker JumpStart offers APIs for
    various tasks, such as NLP, computer vision, and speech recognition. To start
    with generative AI applications through SageMaker JumpStart, you’ll choose a pre-trained
    model that aligns with your project’s requirements. Once selected, you can deploy
    this model within your application using the SageMaker JumpStart API. Available
    models include Hugging Face for NLP, ImageNet for image classification, and YOLOv5
    for object detection. You can learn how to start with SageMaker JumpStart by using
    this link: [https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SageMaker JumpStart**：SageMaker JumpStart是AWS的另一项服务，旨在简化机器学习开发过程。它提供了预构建的机器学习模型和工作流，加速你的机器学习项目。SageMaker
    JumpStart为各种任务提供API，例如自然语言处理（NLP）、计算机视觉和语音识别。要通过SageMaker JumpStart开始使用生成式AI应用程序，你需要选择一个与项目需求相匹配的预训练模型。选择后，你可以通过SageMaker
    JumpStart API将该模型部署到你的应用程序中。可用的模型包括Hugging Face用于NLP、ImageNet用于图像分类，以及YOLOv5用于目标检测。你可以通过以下链接了解如何开始使用SageMaker
    JumpStart：[https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)。'
- en: '**Microsoft Azure**: Microsoft is proactively embedding generative AI technologies
    across its entire suite of solutions, including Azure, M365, Dynamics 365, Power
    Platform, Windows, and GitHub, showcasing the transformative power of generative
    AI on its product lines. For enterprise clients, Microsoft has launched its generative
    AI initiatives through Azure OpenAI Service, setting its offerings apart from
    those directly available from OpenAI by focusing on features such as private networking,
    top-tier security, scalability, and regional service availability.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft Azure**：微软正在积极将生成式AI技术嵌入其整个产品套件，包括Azure、M365、Dynamics 365、Power
    Platform、Windows和GitHub，展示生成式AI对其产品线的变革性影响。对于企业客户，微软通过Azure OpenAI服务推出了其生成式AI计划，与OpenAI直接提供的服务不同，它专注于私有网络、顶级安全性、可扩展性和区域服务可用性等特性，从而将其服务与众不同。'
- en: '**Azure OpenAI**: Azure OpenAI is Microsoft’s offering, providing access to
    various foundation models for NLP, computer vision, and speech recognition. You
    can utilize the Azure OpenAI API to access models like GPT-3 for NLP, DALL-E for
    image generation from textual descriptions, and Speech Services for speech recognition
    and synthesis tasks. Azure AI Studio includes a model catalog, similar to Amazon
    SageMaker JumpStart. Microsoft introduced MaaS in Azure AI with similar features
    to Amazon Bedrock with ready-to-use APIs, hosted fine-tuning, and integration
    tools. You can sign up for Azure OpenAI by following this link: [https://azure.microsoft.com/en-us/products/ai-services/openai-service](https://azure.microsoft.com/en-us/products/ai-services/openai-service).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure OpenAI**：Azure OpenAI是微软的产品，提供访问各种基础模型，用于自然语言处理、计算机视觉和语音识别。你可以利用Azure
    OpenAI API，接入像GPT-3这样的NLP模型、DALL-E的基于文本描述的图像生成模型，以及Speech Services的语音识别和合成任务模型。Azure
    AI Studio包括一个模型目录，类似于亚马逊的SageMaker JumpStart。微软在Azure AI中引入了MaaS，具有与亚马逊Bedrock相似的功能，包括即用型API、托管微调和集成工具。你可以通过此链接注册Azure
    OpenAI：[https://azure.microsoft.com/en-us/products/ai-services/openai-service](https://azure.microsoft.com/en-us/products/ai-services/openai-service)。'
- en: '**Google Cloud Platform (GCP)**: GCP has integrated its generative AI capabilities
    into Vertex AI, showcasing its commitment to enhancing its suite of solutions.
    The cornerstone of its AI initiative is the PaLM 2 FM, which now supports over
    25 Google products and is available to GCP customers through the PaLM API. Google
    has developed industry-specific FMs, including Med-PaLM for healthcare and Sec-PaLM
    for security applications, and has introduced a collection of AI assistants branded
    as Duet AI within Google Workspace and Google Cloud.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谷歌云平台（GCP）**：GCP将其生成性AI能力集成到Vertex AI中，展示了其增强解决方案套件的承诺。其AI计划的基石是PaLM 2 FM，现在支持超过25个谷歌产品，并通过PaLM
    API向GCP客户提供。谷歌还开发了行业特定的FM，包括用于医疗的Med-PaLM和用于安全应用的Sec-PaLM，并推出了一系列名为Duet AI的AI助手，涵盖了Google
    Workspace和Google Cloud。'
- en: 'In a significant expansion of their FM portfolio, Google Cloud announced Gemini,
    its latest first-party FM. Gemini will be available in various configurations,
    including Ultra, Pro, and Nano, to cater to a broad spectrum of applications.
    Additionally, Google Cloud offers Model Garden and Generative AI Studio on Vertex
    AI, which facilitate access to both in-house and third-party models. Despite the
    wide range of models available, as of now, Google Cloud provides direct access
    only to its in-house PaLM 2 models via an API for hosted use, highlighting its
    strategy to blend proprietary technology with open innovation for generative AI
    solutions. Google Cloud is dividing its Duet AI product strategy into two offerings:
    Duet AI for Google Workspace and Duet AI for Google Cloud. Duet AI for Google
    Workspace will compete directly with Microsoft’s M365 Copilot. Duet AI for Google
    Workspace is generally available and, curiously, is priced at exactly the same
    cost as M365 Copilot at the time of writing.'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在其FM产品组合的重要扩展中，谷歌云宣布了Gemini，这是其最新的第一方FM。Gemini将以多种配置形式提供，包括Ultra、Pro和Nano，以满足广泛的应用需求。此外，谷歌云还提供了Model
    Garden和Generative AI Studio，它们通过Vertex AI促进了对自家和第三方模型的访问。尽管提供了广泛的模型，但目前谷歌云仅通过API提供自家PaLM
    2模型的直接访问，用于托管使用，这突显了其将专有技术与开放创新相结合，推动生成性AI解决方案的战略。谷歌云将其Duet AI产品策略分为两个部分：Duet
    AI for Google Workspace和Duet AI for Google Cloud。Duet AI for Google Workspace将直接与微软的M365
    Copilot竞争。Duet AI for Google Workspace已经全面发布，并且有趣的是，它的定价恰好与M365 Copilot相同，至本文写作时为止。
- en: '**Google Cloud Generative AI**: Google Cloud Generative AI opens the door to
    Google’s powerful generative pre-trained transformer models. You can leverage
    the Google Cloud Generative AI API to tap into models like DALL-E 2 for image
    generation, T5 for NLP tasks, and BigGAN for generating high-resolution images
    from simple natural language prompts. Get started with the Google AI service by
    referring to the link here: [https://cloud.google.com/ai/generative-ai](https://cloud.google.com/ai/generative-ai).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谷歌云生成性AI**：谷歌云生成性AI为谷歌强大的生成预训练变换器模型打开了大门。你可以利用谷歌云生成性AI API，接入像DALL-E 2这样的图像生成模型、T5的NLP任务模型以及BigGAN的高分辨率图像生成模型，通过简单的自然语言提示生成图像。欲了解更多关于谷歌AI服务的信息，请访问此链接：[https://cloud.google.com/ai/generative-ai](https://cloud.google.com/ai/generative-ai)。'
- en: 'The following table shows the FMs available from major public cloud providers
    through APIs at the time of writing:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了目前主要公共云服务提供商通过API提供的FM模型：
- en: '| **Public Cloud Providers** | **Available FM Providers** | **Available FMs**
    |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| **公共云提供商** | **可用的FM提供商** | **可用的FM** |'
- en: '| AWS | Amazon AnthropicAI21 LabsCohereMetaStability.ai | Titan Text EmbeddingsTitan
    Multimodel EmbeddingsTitan Text LiteTitan Text ExpressTitan Image GeneratorJurassic-2
    UltraJurassic-2 MidClaude 2Claude 2.1Claude InstantCohere CommandCohere Command
    LightCohere EmbedLlama 2Llama 2 13BLlama 2 70BStable Diffusion XL 1.0 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| AWS | Amazon AnthropicAI21 LabsCohereMetaStability.ai | Titan文本嵌入Titan多模型嵌入Titan文本轻量版Titan文本快递版Titan图像生成器侏罗纪-2超版侏罗纪-2中版Claude
    2Claude 2.1Claude即时版Cohere命令Cohere命令轻量版Cohere嵌入Llama 2Llama 2 13BLlama 2 70B稳定扩散XL
    1.0 |'
- en: '| Microsoft Azure | OpenAIModels as a ServiceMeta | GPT-4GPT-4 Turbo,GPT-4
    Vision,GPT-3.5GTP-3.5 TurboEmbeddings modelsDALL-EWhisperLlama |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Microsoft Azure | OpenAI作为服务的模型Meta | GPT-4GPT-4 Turbo,GPT-4视觉版,GPT-3.5GTP-3.5
    Turbo嵌入模型DALL-EWhisperLlama |'
- en: '| GCP | Google | PaLM 2ImagenCodeyEmbeddings |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| GCP | Google | PaLM 2ImagenCodey嵌入模型 |'
- en: 'Table 14.1: FMs accessible through public cloud providers'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.1：通过公共云提供商访问的FM
- en: While these platforms are among the top choices for GenAI application development,
    several other cloud providers offer similar capabilities, including IBM Cloud,
    Alibaba Cloud, and Tencent Cloud.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些平台是GenAI应用开发的顶级选择，但还有其他一些云服务商提供类似的能力，包括IBM云、阿里云和腾讯云。
- en: The optimal platform for your project will depend on your specific requirements,
    whether you need a serverless environment (Amazon Bedrock), a wide range of pre-trained
    models (SageMaker JumpStart), access to OpenAI’s GPT-3 models (Azure OpenAI),
    or Google’s LaMDA models (Google Cloud Generative AI). Each platform brings unique
    strengths to the table, empowering you to create generative AI applications catering
    to diverse use cases and industries. While you can access many FMs, choosing the
    suitable model is essential for your application’s success. Let’s learn how to
    choose the best FM for your needs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的项目选择最佳平台将取决于您的具体需求，无论您是需要无服务器环境（Amazon Bedrock）、广泛的预训练模型（SageMaker JumpStart）、访问OpenAI的GPT-3模型（Azure
    OpenAI），还是Google的LaMDA模型（Google Cloud生成AI）。每个平台都具有独特的优势，可以帮助您创建适应多种用例和行业的生成AI应用程序。虽然您可以访问许多FM，但选择适合的模型对于应用程序的成功至关重要。让我们一起学习如何根据您的需求选择最佳FM。
- en: Choosing the right FM
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择合适的FM
- en: 'Choosing the right FM for your project is a crucial step in ensuring the success
    of your generative AI application. Here are some key factors to consider when
    selecting the most suitable FM:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 选择适合您项目的FM是确保生成AI应用成功的关键步骤。以下是选择最合适FM时需要考虑的一些关键因素：
- en: '**Problem identification**: Begin by clearly defining the problem you intend
    to solve with generative AI. Determine whether your project involves NLP, computer
    vision, speech recognition, or other tasks. This initial step helps narrow down
    your options to FMs designed for your specific domain. Suppose you are developing
    an agent assistant for a customer support application. Identify the problem as
    an NLP task focused on chat and call interactions. Look for FMs specifically designed
    for NLP tasks.'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问题识别**：首先明确您希望通过生成AI解决的具体问题。确定您的项目是涉及自然语言处理（NLP）、计算机视觉、语音识别还是其他任务。这一步有助于将您的选择范围缩小到专为您的特定领域设计的FM。假设您正在为客户支持应用程序开发智能助手，将问题识别为一个专注于聊天和通话交互的NLP任务。寻找专门为NLP任务设计的FM。'
- en: '**Data consideration**: The nature and volume of your available data are critical.
    Some FMs require extensive datasets to train effectively, while others can work
    well with smaller or specialized datasets. Ensure that you have access to the
    appropriate data resources for training and evaluation. For your agent assistant
    app, get access to a large dataset of customer inquiries and responses. If the
    dataset is extensive and diverse, you can consider FMs that excel with ample data.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据考虑因素**：可用数据的性质和规模至关重要。一些FM需要大量数据集才能有效训练，而其他模型则能在较小或专门的数据集上表现良好。确保您拥有适当的数据资源进行训练和评估。对于您的智能助手应用程序，获取一个包含大量客户询问和回应的数据集。如果数据集庞大且多样化，您可以考虑那些在大量数据上表现优秀的FM。'
- en: '**Performance evaluation**: Once you’ve identified potential FMs that align
    with your problem and data, assess their performance on a validation dataset.
    This evaluation provides insight into how well each FM addresses your challenge
    and data characteristics. Look for FMs that demonstrate strong performance metrics
    for your use case. Suppose you shortlist GPT-3, GPT-4, and BERT as potential FMs
    for your application. Evaluate each FM’s performance on a validation dataset by
    measuring metrics like response coherence, accuracy, and user satisfaction. Choose
    the FM that achieves the highest scores for your specific chatbot requirements.
    This ensures that your chatbot provides valuable and contextually relevant responses
    to customers.'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**性能评估**：一旦你确定了与你的问题和数据相符的潜在 FM，就需要在验证数据集上评估它们的表现。这项评估能帮助你了解每个 FM 在解决你的挑战和数据特点方面的效果。寻找在你的使用案例中表现出色的
    FM。假设你将 GPT-3、GPT-4 和 BERT 列为应用程序的潜在 FM。通过衡量诸如响应连贯性、准确性和用户满意度等指标，在验证数据集上评估每个 FM
    的性能。选择为你的特定聊天机器人需求获得最高分的 FM。这能确保你的聊天机器人为客户提供有价值且与上下文相关的回应。'
- en: '**Fine-tuning**: Fine-tuning involves training the FM on your dataset to enhance
    its performance and align it with your problem domain. This process helps tailor
    the model to produce more accurate and relevant outputs. Let’s say you decide
    to use GPT-4 as your FM but you notice it needs help understanding customer-specific
    jargon. Fine-tune GPT-4 on your customer support dataset to enhance its understanding
    of industry-specific terms and phrases. This adaptation ensures that your chatbot
    provides more accurate and relevant responses, improving the overall user experience.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调**：微调是指在你的数据集上训练 FM，以提高其性能并使其与问题领域对接。这个过程有助于定制模型，以生成更准确和相关的输出。假设你决定使用 GPT-4
    作为你的 FM，但你发现它在理解客户特定的行话时有困难。你可以对 GPT-4 进行微调，使用客户支持数据集，以增强其对行业特定术语和短语的理解。这种适应确保你的聊天机器人能提供更准确和相关的响应，从而改善整体用户体验。'
- en: '**Iteration**: ML is inherently iterative. Be prepared to iterate on your model
    as needed. This may involve refining your dataset, adjusting hyperparameters,
    or experimenting with different FMs to achieve the desired level of performance.
    Continuous refinement is often necessary to optimize your generative AI application.
    Your agent assistance application is deployed but you receive user feedback about
    occasional irrelevant responses. Continuously iterate on your FM by refining the
    dataset, adjusting hyperparameters, and addressing specific issues raised by users.
    This iterative process helps maintain and enhance chatbot performance over time,
    ensuring ongoing customer satisfaction.'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代**：机器学习本质上是一个迭代过程。准备好根据需要对模型进行迭代。这可能涉及改进数据集、调整超参数，或尝试不同的 FM，以达到预期的性能水平。持续的改进通常是优化生成型
    AI 应用程序所必需的。假设你的代理助手应用已部署，但你收到关于偶尔出现不相关响应的用户反馈。通过改进数据集、调整超参数以及解决用户提出的具体问题，持续迭代你的
    FM。这一迭代过程有助于随着时间的推移保持和提升聊天机器人的表现，确保持续的客户满意度。'
- en: '**Prompt engineering**: Prompt engineering is a technique where humans skillfully
    craft prompts to direct generative AI models, like chatbots or text generators,
    towards generating specific, desired outcomes. This **Human-in-the-loop** (**HITL**)
    approach is crucial because the phrasing of prompts can greatly affect the AI’s
    responses, ensuring they are pertinent, precise, and context-sensitive. It plays
    an essential role in refining interactions with AI, customizing its responses
    to suit particular tasks or objectives effectively.'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示工程**：提示工程是一种技巧，通过精心设计提示词来引导生成型 AI 模型，如聊天机器人或文本生成器，生成特定的、期望的结果。这个**人类参与**（**HITL**）的方法至关重要，因为提示词的措辞会极大地影响
    AI 的响应，确保其相关、准确且与上下文相符。它在优化与 AI 的交互中发挥着重要作用，能够有效地根据特定任务或目标定制其响应。'
- en: By following these expanded steps, you can effectively navigate the process
    of choosing, adapting, and optimizing the right FM for your generative AI project
    while considering real-world examples and use cases. As the FM trains with a very
    large dataset, it can get confused and provide inaccurate responses. Let’s learn
    about how to prevent it in more detail.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些扩展步骤，你可以有效地导航选择、调整和优化适合你生成型 AI 项目的 FM，同时考虑现实世界的例子和使用案例。当 FM 在一个非常大的数据集上进行训练时，它可能会产生混淆并给出不准确的回答。接下来，我们将更详细地了解如何防止这种情况的发生。
- en: Preventing model hallucinations
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 防止模型幻觉
- en: Model hallucinations, in the context of generative AI models, refers to situations
    where the model generates responses or outputs that are incorrect, irrelevant,
    or imaginary. These responses are often produced when the model encounters input
    that it cannot adequately comprehend or when it extrapolates beyond the scope
    of its training data. Model hallucinations can result in misleading, nonsensical,
    or potentially harmful information being presented to users. For instance, consider
    a medical diagnosis AI tool based on a generative model. If the model starts hallucinating,
    it might provide incorrect or irrelevant medical advice or diagnosis based on
    a patient’s symptoms, leading to potentially dangerous health outcomes. Similarly,
    in the financial sector, an AI model used for predicting market trends might hallucinate
    and produce inaccurate forecasts, causing significant financial losses for users
    relying on its predictions. Addressing model hallucinations is crucial to ensure
    the trustworthiness and reliability of AI systems, especially in critical domains
    where decisions can have significant consequences.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成型 AI 模型中，模型幻觉是指模型生成不正确、不相关或虚构的响应或输出的情况。当模型遇到无法充分理解的输入，或超出其训练数据范围进行推断时，往往会产生幻觉。模型幻觉可能导致错误、荒谬或潜在有害的信息呈现给用户。例如，考虑一个基于生成模型的医学诊断
    AI 工具。如果模型开始出现幻觉，可能会根据患者的症状提供错误或不相关的医学建议或诊断，导致潜在的危险健康后果。同样，在金融领域，某个用于预测市场趋势的 AI
    模型可能会产生幻觉，给出不准确的预测，导致依赖其预测的用户遭受重大财务损失。解决模型幻觉问题对于确保 AI 系统的可信度和可靠性至关重要，特别是在那些决策可能带来重大后果的关键领域。
- en: 'To prevent model hallucinations and enhance the accuracy and reliability of
    generative AI models, several techniques and strategies can be employed, such
    as:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止模型出现幻觉并提高生成型 AI 模型的准确性和可靠性，可以采用一些技术和策略，例如：
- en: '**Data quality and quantity**: Ensure that the training data used for the model
    is of high quality, diverse, and representative of the intended application domain.
    Having a large and varied dataset helps the model understand a wide range of contexts
    and reduces the likelihood of hallucinations. A diverse dataset may include text
    from various domains, languages, and styles in NLP. When training a chatbot, a
    diverse dataset can help the model understand different user queries and provide
    contextually relevant responses.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量和数量**：确保用于训练模型的数据具有高质量、多样性，并且能够代表目标应用领域。拥有一个庞大且多样化的数据集有助于模型理解广泛的上下文，并减少出现幻觉的可能性。多样化的数据集可能包括来自不同领域、语言和风格的文本。在训练聊天机器人时，丰富的数据集有助于模型理解不同的用户查询并提供上下文相关的回应。'
- en: '**Fine-tuning**: After the initial training on a large dataset, fine-tune the
    model on domain-specific data. Fine-tuning adapts the model to the specific task
    or knowledge domain, reducing the chances of generating hallucinatory content.
    An example is fine-tuning a pre-trained language model like Amazon Titan or GPT-4
    on medical literature to create a medical chatbot that can answer questions, provide
    information, and assist healthcare professionals in understanding complex medical
    texts.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**：在对大规模数据集进行初步训练后，对模型进行领域特定的数据微调。微调使模型适应特定任务或知识领域，减少生成幻觉内容的机会。例如，将预训练语言模型如
    Amazon Titan 或 GPT-4 微调到医学文献上，从而创建一个医学聊天机器人，能够回答问题、提供信息并帮助医疗专业人员理解复杂的医学文本。'
- en: '**Prompt engineering**: Craft clear and contextually relevant prompts or input
    queries when interacting with the model. Well-structured prompts can guide the
    model to produce more accurate responses aligned with user expectations. Instead
    of a vague prompt like “Tell me about history,” a structured prompt could be “Summarize
    key events of World War II.” Content generation for educational materials benefits
    from clear and specific prompts to ensure accurate information delivery.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示工程**：在与模型交互时，编写清晰且具有上下文相关性的提示或输入查询。结构良好的提示能够引导模型生成更准确的响应，符合用户期望。例如，避免使用模糊的提示“告诉我关于历史的事”，可以改为“总结第二次世界大战的关键事件”。针对教育材料的内容生成，使用清晰和具体的提示有助于确保信息传递的准确性。'
- en: '**Retrieval-Augmented Generation (RAG)**: Implement techniques like RAG to
    retrieve relevant information from a knowledge base or documents and use this
    retrieved context to generate responses. This approach helps in grounding the
    model’s output in factual and domain-specific information, reducing hallucinations,
    retrieving relevant product details from a database, and using them to generate
    accurate product descriptions. E-commerce platforms can implement RAG to create
    detailed and factual product descriptions.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索增强生成（RAG）**：实施诸如RAG之类的技术，从知识库或文件中检索相关信息，并利用检索到的上下文生成响应。这种方法有助于将模型的输出基于事实和领域特定信息，减少幻觉，从数据库中检索相关产品详情，并用于生成准确的产品描述。电子商务平台可以实施RAG以创建详细且真实的产品描述。'
- en: '**Threshold filtering**: Set a threshold for response quality or relevance.
    Only accept responses from the model that meet a certain level of confidence or
    relevance, and discard or re-prompt for responses that fall below this threshold—rejecting
    responses with a confidence score below 0.8 ensures high-quality answers. Customer
    support chatbots can use threshold filtering to provide reliable responses to
    user inquiries.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**阈值过滤**：为响应质量或相关性设置阈值。仅接受模型输出达到一定置信度或相关性水平的响应，并丢弃或重新提示那些低于此阈值的响应。拒绝置信度低于0.8的响应可以确保高质量的答案。客服聊天机器人可以使用阈值过滤来为用户查询提供可靠的响应。'
- en: '**Human review**: Incorporate human review and moderation to filter out potentially
    hallucinatory responses. Human reviewers can assess and correct model outputs
    to ensure accuracy and safety. Content generation platforms can employ human review
    to maintain content quality and prevent misinformation.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工审查**：整合人工审查和审核，以过滤潜在的幻觉响应。人工审查员可以评估和纠正模型输出，确保准确性和安全性。内容生成平台可以使用人工审查来维护内容质量并防止误导信息。'
- en: '**Continual monitoring and feedback**: Monitor the model’s performance and
    gather user feedback. Use this feedback to identify and address instances of model
    hallucinations and improve the model over time. Gather user feedback on chatbot
    interactions and analyze it for improvements. Chatbots and virtual assistants
    can continually evolve based on user feedback to provide better assistance.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续监控和反馈**：监控模型的性能并收集用户反馈。利用这些反馈来识别和解决模型幻觉的情况，并随时间改进模型。收集关于聊天机器人交互的用户反馈，并分析以进行改进。聊天机器人和虚拟助手可以基于用户反馈持续演进，以提供更好的帮助。'
- en: '**Safety measures**: Implement safety measures and constraints within the model
    to prevent it from generating harmful, biased, or inappropriate content and implement
    profanity filters in chatbots to block offensive language. Online communities
    and social platforms employ safety measures to maintain a respectful and safe
    environment.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全措施**：在模型内部实施安全措施和限制，防止其生成有害、偏见或不适当的内容，并在聊天机器人中实施脏话过滤器，以屏蔽冒犯性语言。在线社区和社交平台采用安全措施维护尊重和安全的环境。'
- en: '**Domain limitations**: Clearly define and communicate the scope and limitations
    of the model to users. This helps manage user expectations and reduces the chances
    of the model providing hallucinatory responses when faced with out-of-scope queries.
    It informs users that a weather chatbot can’t provide medical advice. Specialized
    chatbots, such as weather or travel assistants, benefit from setting clear boundaries
    to avoid misleading users.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域限制**：明确定义并向用户传达模型的范围和限制。这有助于管理用户期望，并减少当面对超出范围查询时模型产生幻觉响应的可能性。它告知用户天气聊天机器人无法提供医疗建议。专门的聊天机器人，如天气或旅行助手，通过设定清晰的界限来避免误导用户。'
- en: '**Regular updates and maintenance**: Keep the model up to date with the latest
    data and advancements in the field of AI. Regular updates and maintenance can
    improve its overall performance and reduce the occurrence of hallucinations. Update
    a language model with the latest vocabulary and language trends. News agencies
    use updated language models to generate real-time news summaries.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定期更新和维护**：保持模型与AI领域的最新数据和进展同步。定期更新和维护可以提高模型的整体性能并减少幻觉的发生。更新语言模型的最新词汇和语言趋势。新闻机构使用更新的语言模型生成实时新闻摘要。'
- en: By combining these strategies, developers and organizations can minimize the
    risk of model hallucinations and create more reliable and trustworthy generative
    AI systems.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合这些策略，开发人员和组织可以最小化模型幻觉的风险，并创建更可靠和值得信赖的生成式AI系统。
- en: Enterprises are strategically deploying generative AI applications internally
    as a prudent initial step before wider external deployment. This approach serves
    as a buffer, reducing the risk of delivering incorrect or inappropriate content
    to customers. This internal deployment allows organizations to refine the AI models
    in a controlled environment, where the consequences of errors are less severe
    and can be quickly addressed. Employees, who are familiar with the business context
    and nuances, can provide valuable feedback on the model’s outputs, identifying
    any irrelevant or incorrect responses generated by the AI.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 企业在内部战略性地部署生成式 AI 应用程序，作为在更广泛的外部部署之前的谨慎初步步骤。这种方法充当了缓冲区，降低了向客户提供错误或不适当内容的风险。内部部署使组织能够在受控环境中优化
    AI 模型，在这里错误的后果较为轻微，且可以迅速解决。熟悉业务背景和细微差别的员工能够为模型的输出提供有价值的反馈，识别 AI 生成的任何不相关或不正确的回应。
- en: For instance, a company could deploy an AI-powered chatbot internally to assist
    with IT support or HR inquiries. As employees interact with the chatbot, they
    can report any anomalies or instances where the bot provides bizarre or inaccurate
    answers. This feedback loop enables the company to fine-tune the AI model, improving
    its accuracy and relevance before rolling it out to customer-facing scenarios.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一家公司可以内部部署一个 AI 驱动的聊天机器人来协助 IT 支持或人力资源咨询。随着员工与聊天机器人的互动，他们可以报告任何异常或机器人提供奇怪或不准确答案的情况。这个反馈循环使公司能够微调
    AI 模型，在推出到面向客户的场景之前提高其准确性和相关性。
- en: Such a phased approach not only mitigates the risks associated with AI hallucinations
    but also builds confidence in the technology, both within the organization and
    among its customers. By the time the generative AI application is introduced to
    external users, it has undergone extensive validation and refinement, ensuring
    a more reliable and effective user experience.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分阶段的方法不仅减轻了与 AI 幻觉相关的风险，而且还增强了对技术的信心，无论是在组织内部，还是在其客户之间。到生成式 AI 应用程序面向外部用户时，它已经经过了广泛的验证和优化，从而确保了更加可靠和有效的用户体验。
- en: Let’s learn about a reference architecture that will help you to build a generative
    AI -based application.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解一个参考架构，它将帮助您构建基于生成式 AI 的应用程序。
- en: Generative AI reference architecture for building a mortgage assistant app
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建房贷助手应用的生成式 AI 参考架构
- en: The homebuying process can often appear daunting to prospective buyers, primarily
    due to the overwhelming amount of paperwork involved. Frequently, buyers find
    themselves needing more time and an in-depth understanding of the intricate details
    within these documents. Consequently, they experience feelings of being overwhelmed,
    confused, and occasionally frustrated as they grapple with grasping the significance
    of what they are signing, particularly in the context of mortgage-related paperwork.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 购房过程通常对于潜在买家来说显得令人生畏，主要是因为涉及大量的文书工作。买家经常发现自己需要更多的时间来深入理解这些文件中的复杂细节。因此，他们常常感到不知所措、困惑，甚至偶尔会因难以理解所签署内容的意义而感到沮丧，尤其是在涉及按揭相关文件时。
- en: Addressing these challenges becomes paramount in enhancing the overall customer
    experience and building trust between buyers and lenders throughout the loan application
    and closing process. To alleviate this burden and empower homebuyers, a generative
    AI solution can assist them in comprehending their loan terms and conditions better
    without relying on mortgage experts or attorneys.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些挑战对于提升整体客户体验至关重要，并且在贷款申请和结算过程中建立买方与贷方之间的信任。为了减轻这种负担并赋能购房者，生成式 AI 解决方案可以帮助他们更好地理解贷款条款和条件，而无需依赖按揭专家或律师。
- en: This section delves into the architecture of constructing a virtual home lending
    agent application. At its core, this application revolves around the text summarization
    of critical mortgage documents. The architecture, as presented, adopts a serverless
    approach using AWS and harnesses Amazon Bedrock to access the generative AI FM.
    It’s worth noting that you can implement this architecture with the technology
    you choose.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 本节深入探讨了构建虚拟房贷代理应用程序的架构。该应用的核心是对关键按揭文件的文本摘要。所呈现的架构采用了无服务器方法，使用 AWS 并借助 Amazon
    Bedrock 访问生成式 AI FM。值得注意的是，您可以使用您选择的技术实现此架构。
- en: '![](img/B21336_14_05.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21336_14_05.png)'
- en: 'Figure 14.5: Generative AI-based home lending virtual assistant app'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.5：基于生成式 AI 的房贷虚拟助手应用
- en: We devised an Amazon Lex-based **Virtual Assistant** (**VA**) application within
    the preceding architecture diagram. Amazon Lex is a service provided by AWS to
    build a serverless chatbot. This VA is an intuitive interface where users can
    interact and seek specific answers regarding their mortgage documents. Leveraging
    natural language understanding and processing capabilities, the VA interprets
    users’ questions and prompts, subsequently gaining access to domain-specific document
    excerpts indexed by Amazon Kendra.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前述架构图中设计了一个基于 Amazon Lex 的**虚拟助手**（**VA**）应用程序。Amazon Lex 是 AWS 提供的一个服务，用于构建无服务器的聊天机器人。这个虚拟助手是一个直观的界面，用户可以在其中互动并寻求有关他们抵押贷款文档的具体答案。通过自然语言理解和处理功能，虚拟助手可以解读用户的问题和提示，随后访问由
    Amazon Kendra 索引的领域特定文档片段。
- en: Amazon Kendra’s intelligent search capabilities are pivotal in efficiently retrieving
    relevant document excerpts. These carefully curated excerpts are then transmitted
    to the Amazon Bedrock FM Claude 2, generating informative and coherent responses
    to the users’ queries. In this manner, the generative AI solution simplifies the
    comprehension of complex mortgage documents. It elevates the overall homebuying
    experience by providing buyers with a reliable and knowledgeable resource throughout
    the process. This, ultimately, culminates in heightened customer satisfaction
    and greater trust in the lending institution.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kendra 的智能搜索功能对于高效检索相关文档片段至关重要。这些精心策划的文档片段随后被传输到 Amazon Bedrock FM Claude
    2，生成具有信息性且连贯的回答来回应用户的查询。通过这种方式，生成式 AI 解决方案简化了复杂抵押贷款文档的理解。它通过为购房者提供可靠且知识丰富的资源，提升了整体购房体验，最终增加了客户满意度，并增强了借贷机构的信任度。
- en: Implementing the generative AI solution places significant emphasis on ensuring
    that users exclusively receive responses that strictly adhere to the scope of
    the documents utilized. To preempt any instances of model hallucinations or inaccurate
    responses, the architecture utilizes RAG. An instrumental facet of the RAG-based
    approach is integrating the company’s distinctive knowledge base or content as
    an integral context component. This knowledge base is seamlessly integrated with
    the user’s request, thereby forming a comprehensive prompt. This consolidated
    prompt is subsequently relayed to the Amazon Bedrock FM, generating highly accurate
    and concise summaries as responses.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 实施生成式 AI 解决方案时，重点确保用户仅接收到严格符合所使用文档范围的回答。为预防模型幻想或不准确回答的发生，该架构利用了 RAG。RAG 基于的方法的一个关键部分是将公司独特的知识库或内容作为一个重要的上下文组件进行整合。该知识库与用户请求无缝结合，形成一个全面的提示。然后，这个综合的提示被传递给
    Amazon Bedrock FM，生成高准确度和简洁的总结作为回应。
- en: Harnessing the capabilities of RAG while seamlessly incorporating domain-specific
    knowledge ensures that users consistently receive responses that are not only
    contextually relevant but also exceptionally precise. This precision serves as
    a linchpin in delivering a superior user experience and bolstering the trustworthiness
    of the generative AI application throughout the mortgage document review process.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 RAG 的能力，同时无缝结合领域特定的知识，确保用户始终获得不仅与上下文相关而且非常精确的回答。这种精确度是提供卓越用户体验并增强生成式 AI 应用程序在整个抵押贷款文档审查过程中可信度的关键。
- en: This solution streamlines and simplifies the content within these documents,
    ensuring that home buyers can rapidly access the pertinent information they require.
    This not only saves time but also aids in significantly reducing confusion.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 该解决方案简化并优化了这些文档中的内容，确保购房者能够快速访问他们所需的相关信息。这不仅节省了时间，还帮助显著减少了混乱。
- en: Challenges in implementing generative AI
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现生成式 AI 的挑战
- en: Implementing generative AI, while highly promising, comes with its set of challenges
    and considerations. In the following subsections, we delve into some of the primary
    challenges associated with generative AI.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 实施生成式 AI，尽管前景广阔，但也面临一系列挑战和考虑事项。在以下小节中，我们将深入探讨与生成式 AI 相关的主要挑战。
- en: Training stability issues
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 培训稳定性问题
- en: One of the significant challenges encountered in generative AI is training stability
    issues. These issues can manifest as convergence problems, slow training, or even
    divergence, making it difficult to obtain high-quality generative models.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式 AI 中遇到的一个重大挑战是培训稳定性问题。这些问题可能表现为收敛问题、训练缓慢，甚至发散，导致很难获得高质量的生成模型。
- en: One prevalent application of generative AI involves using a GAN to create high-definition
    images. Training stability issues may arise during the training of a GAN for image
    generation. For instance, the generator may produce nonsensical or highly distorted
    images. These issues can hinder the GAN from converging to a satisfactory solution,
    leading to poor image generation quality.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 的一个常见应用是使用生成对抗网络（GAN）创建高清图像。在训练 GAN 进行图像生成时，可能会出现训练稳定性问题。例如，生成器可能会生成没有意义或高度扭曲的图像。这些问题可能会阻碍
    GAN 收敛到一个令人满意的解决方案，导致图像生成质量差。
- en: Addressing and preventing training stability issues in generative AI involves
    a multifaceted approach. Techniques such as spectral normalization and progressive
    growing can stabilize training processes. Proper weight initialization and careful
    monitoring of loss curves help prevent issues like mode collapse and slow convergence.
    Additionally, the use of batch normalization and regularization techniques can
    contribute to training stability. By combining these strategies and fine-tuning
    hyperparameters, developers can enhance the stability of generative AI models,
    ensuring more reliable and robust performance across various applications.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 解决和防止生成式 AI 训练稳定性问题需要多方面的方法。技术如谱归一化和渐进式生长可以稳定训练过程。适当的权重初始化和仔细监控损失曲线有助于防止像模式崩溃和收敛过慢的问题。此外，使用批量归一化和正则化技术可以促进训练的稳定性。通过结合这些策略并微调超参数，开发者可以增强生成式
    AI 模型的稳定性，确保其在各种应用中的更可靠和更强的性能。
- en: Mode collapse
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模式崩溃
- en: Generative AI has made remarkable strides in creating human-like content across
    various domains. It does, however, face difficulties such as mode collapse, which
    has an impact on the variety and caliber of outputs produced. When a generative
    model generates few or repetitive outputs due to its inability to fully capture
    the diversity of the target distribution, mode collapse occurs. The model becomes
    fixated on a subset of possible data, neglecting the broader spectrum of variations
    within the dataset.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 在各个领域创造类人内容方面取得了显著进展。然而，它仍然面临一些困难，比如模式崩溃，这会影响输出结果的多样性和质量。当生成模型由于无法完全捕捉目标分布的多样性而产生少量或重复的输出时，就会发生模式崩溃。模型会集中在一个数据子集上，忽视数据集内更广泛的变异性。
- en: Imagine a scenario where you’re training a text generation model to produce
    diverse content, such as generating news articles. In this context, mode collapse
    could manifest as the model repeatedly generating the same headline or content,
    failing to explore the vast array of possible articles.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一种场景，你正在训练一个文本生成模型来生成多样化的内容，比如创作新闻文章。在这种情况下，模式崩溃可能表现为模型反复生成相同的标题或内容，未能探索大量可能的文章。
- en: Suppose you’re using a text generator to create news articles. Despite having
    access to a diverse dataset of news topics, the model consistently generates headlines
    with only a few variations, presenting the same news story repeatedly, greatly
    diminishing the quality and utility of the generated content.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在使用文本生成器来创作新闻文章。尽管拥有多样化的新闻主题数据集，模型却总是生成只有少数几种变化的标题，反复呈现相同的新闻故事，极大地降低了生成内容的质量和实用性。
- en: By incorporating diversity-promoting objectives, fine-tuning hyperparameters,
    and introducing randomness, developers can effectively address and prevent mode
    collapse, enhancing generative AI’s utility and richness across numerous applications.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入多样性促进目标、微调超参数以及加入随机性，开发者可以有效应对并防止模式崩溃，从而增强生成式 AI 在众多应用中的实用性和丰富性。
- en: Latent space interpolation challenges
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 潜在空间插值挑战
- en: Latent space interpolation is a fascinating aspect of generative AI that allows
    models to generate intermediate outputs between two points in the latent space.
    However, it comes with challenges related to the meaningfulness and quality of
    the generated outputs. The core challenge with latent space interpolation is that
    generating outputs between points in the latent space may only sometimes result
    in semantically meaningful or coherent content. In essence, the generated transitions
    may need more continuity and relevance.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在空间插值是生成式 AI 中一个引人入胜的方面，它允许模型在潜在空间的两个点之间生成中间输出。然而，它也带来了与生成输出的意义性和质量相关的挑战。潜在空间插值的核心挑战在于，在潜在空间的两个点之间生成输出可能并不总是能产生语义上有意义或连贯的内容。实质上，生成的过渡可能缺乏连续性和相关性。
- en: Consider a scenario where you aim to create a generative model that produces
    images with smooth transitions between different artistic styles—for example,
    transitioning an image from the style of Van Gogh to the style of Picasso while
    maintaining visual coherence. When interpolating between two images of distinct
    styles, the resulting transitions might appear blurred, distorted, or semantically
    incoherent. This diminishes the artistic quality and intended smoothness of the
    style transitions.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想创建一个生成式模型，能够生成不同艺术风格之间平滑过渡的图像——例如，在保持视觉一致性的前提下，将一幅图像从梵高风格过渡到毕加索风格。当在两种风格迥异的图像之间进行插值时，生成的过渡可能显得模糊、扭曲或语义不连贯。这会削弱艺术质量和风格过渡的平滑感。
- en: 'To make generative models work better, especially when creating intermediate
    results, developers use specific techniques to improve how these models learn
    and create outputs. Here’s a simple breakdown:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使生成式模型表现得更好，特别是在创建中间结果时，开发者使用特定技术来改善这些模型的学习和输出方式。以下是一个简单的概述：
- en: '**Disentangled representation learning**: This method helps the model learn
    features in a way that separates them clearly. For example, if the model is learning
    about faces, it learns to distinguish features like age, hairstyle, or glasses
    independently. This clarity helps the model generate more accurate and realistic
    transitions or changes.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解耦表示学习**：这种方法帮助模型以清晰分离的方式学习特征。例如，如果模型正在学习人脸，它会学会独立区分年龄、发型或眼镜等特征。这种清晰度有助于模型生成更准确和逼真的过渡或变化。'
- en: '**Fine-tuning interpolation methods**: Interpolation is like filling in the
    gaps between two known points. In the context of generative models, fine-tuning
    these methods means making the steps or transitions between one output and another
    smoother and more logical. This helps avoid sudden, unrealistic changes when the
    model generates a series of images or sounds.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调插值方法**：插值就像是填补两个已知点之间的空白。在生成式模型的上下文中，微调这些方法意味着使一个输出与另一个输出之间的步骤或过渡更加平滑和合理。这有助于避免模型生成一系列图像或声音时出现突兀、不真实的变化。'
- en: '**Leveraging semi-supervised learning**: This technique uses a mix of labeled
    (known) and unlabeled (unknown) data during training. It helps the model make
    better guesses about the unlabeled data by learning from the patterns it saw in
    the labeled data. This approach can improve how the model fills in gaps or transitions,
    making the output more coherent and realistic.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用半监督学习**：这种技术在训练过程中使用已标注（已知）和未标注（未知）数据的混合。它通过从已标注数据中学习模式，帮助模型更好地推测未标注数据。这种方法有助于模型在填补空白或进行过渡时，生成更连贯和逼真的输出。'
- en: By using these techniques, developers ensure that when a generative model produces
    a series of outputs (like frames in a video or steps in a transformation), the
    results change smoothly and make sense, enhancing the overall quality and usefulness
    of the model in creative tasks.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这些技术，开发者确保当生成式模型生成一系列输出（如视频中的帧或转换中的步骤）时，结果能够平滑过渡并且合乎逻辑，从而提升模型在创作任务中的整体质量和实用性。
- en: Ethical concerns and misuse
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理问题和滥用
- en: Ethical concerns and the potential misuse of generative AI technologies have
    emerged as critical challenges in today’s digital landscape. Generative AI’s remarkable
    content creation and manipulation capabilities can be exploited for malicious
    purposes, such as creating deepfake videos, spreading misinformation, or generating
    offensive content. These activities raise serious ethical concerns and pose threats
    to trust and integrity.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今的数字环境中，生成式 AI 技术的伦理问题和潜在滥用已成为重要挑战。生成式 AI 强大的内容创建和操控能力可能会被恶意利用，比如制作深度伪造视频、传播虚假信息或生成令人反感的内容。这些行为引发了严重的伦理问题，并对信任和公正构成威胁。
- en: Consider a scenario where generative AI creates deepfake videos that impersonate
    individuals, including public figures, celebrities, or politicians. Malicious
    actors may create deepfake videos featuring politicians making false statements
    or engaging in inappropriate behavior. These videos can weaponize disinformation,
    manipulate public opinion, or damage reputations.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个场景，生成式 AI 创建深度伪造视频，冒充个人，包括公众人物、名人或政治人物。恶意行为者可能会制作包含政治人物发表虚假言论或进行不当行为的深度伪造视频。这些视频能够武器化虚假信息，操控公众舆论或破坏声誉。
- en: Addressing ethical concerns and preventing misuse in generative AI is critical
    to maintaining trust and integrity in the digital age. By combining strict content
    moderation, authentication measures, responsible AI guidelines, regulatory frameworks,
    counter-forensic techniques, and public education, we can safeguard against the
    malicious misuse of generative AI technologies. This collective effort ensures
    that generative AI benefits society responsibly and ethically.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 解决生成式 AI 中的伦理问题和防止滥用是保持数字时代信任与诚信的关键。通过结合严格的内容审核、身份验证措施、负责任的 AI 指南、监管框架、反取证技术和公众教育，我们可以防范生成式
    AI 技术的恶意滥用。这种集体努力确保生成式 AI 以负责任和伦理的方式造福社会。
- en: These challenges highlight the complexities of working with generative AI. Addressing
    them involves a combination of technical enhancements, ethical considerations,
    and regulatory measures. Additionally, continuous research and development in
    AI are essential to mitigate these challenges and ensure the responsible and beneficial
    use of generative models.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战突显了使用生成式 AI 的复杂性。应对这些挑战需要技术增强、伦理考量和监管措施的结合。此外，AI 领域的持续研究与发展对于缓解这些挑战、确保生成模型的负责任和有益使用至关重要。
- en: Summary
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we delved into the fascinating world of generative AI, starting
    with a comprehensive exploration of what it is. We explored the diverse use cases
    that generative AI enables, from transforming customer experiences to enhancing
    employee productivity and optimizing various aspects of business operations.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了生成式 AI 的迷人世界，从全面探索它是什么开始。我们探讨了生成式 AI 启用的多样化应用场景，从转变客户体验到提升员工生产力，再到优化业务运营的各个方面。
- en: To understand the basic architecture of generative AI systems, we broke down
    the different types of generative models, including GANs, VAEs, and transformer-based
    models. We highlighted the importance of hyperparameter tuning and regularization
    in constructing effective generative AI architectures.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解生成式 AI 系统的基本架构，我们分解了不同类型的生成模型，包括 GANs、VAEs 和基于变换器的模型。我们强调了超参数调优和正则化在构建有效生成式
    AI 架构中的重要性。
- en: In the context of FMs, we provided insights into some of the popular generative
    AI FMs offered by key players in the field, such as Amazon, OpenAI, Google, Nvidia,
    and several others. These models serve as the backbone of generative AI applications.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在 FMs 的背景下，我们提供了对一些由该领域主要参与者提供的流行生成式 AI FMs 的深入分析，如 Amazon、OpenAI、Google、Nvidia
    等。这些模型是生成式 AI 应用的支柱。
- en: For those eager to start their journey with generative AI, we offered guidance
    tailored to different user groups. End users can explore generative AI through
    chatbots, builders can leverage it to generate code, and developers can integrate
    generative AI FMs into their applications.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些渴望开始生成式 AI 之旅的人，我们提供了针对不同用户群体的指导。最终用户可以通过聊天机器人体验生成式 AI，开发者可以利用它生成代码，而开发人员可以将生成式
    AI FMs 集成到他们的应用程序中。
- en: We also discussed the critical aspect of selecting the right FM for your project,
    ensuring it aligns with the specific requirements and data characteristics. To
    maintain model accuracy and prevent model hallucinations, we explored strategies
    to guide your generative AI endeavors.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了选择合适 FM 对于项目的关键性，确保它与特定要求和数据特征一致。为了保持模型的准确性并防止模型幻觉，我们探讨了指导生成式 AI 工作的策略。
- en: Furthermore, we introduced a reference architecture for building a mortgage
    assistant app using generative AI. This architecture streamlines the understanding
    of complex mortgage documents, enhancing the overall homebuying experience.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们介绍了使用生成式 AI 构建抵押贷款助手应用程序的参考架构。这个架构简化了复杂抵押贷款文档的理解，提升了整体购房体验。
- en: Lastly, we examined the challenges of implementing generative AI, including
    training stability issues, mode collapse, latent space interpolation challenges,
    and ethical concerns related to potential misuse.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查了实施生成式 AI 的挑战，包括训练稳定性问题、模式崩溃、潜在空间插值问题，以及与潜在滥用相关的伦理问题。
- en: Throughout this chapter, we have laid the groundwork for a comprehensive understanding
    of generative AI, its applications, models, and challenges, setting the stage
    for further exploration and practical implementation in the world of artificial
    intelligence.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为全面理解生成式 AI、其应用、模型和挑战奠定了基础，为进一步探索和在人工智能领域的实际应用奠定了基础。
- en: Leave a review!
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下评论！
- en: Enjoying this book? Help readers like you by leaving an Amazon review. Scan
    the QR code below to get a free eBook of your choice.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 喜欢这本书吗？通过留下亚马逊评论来帮助像你一样的读者。扫描下面的二维码，获得你选择的免费电子书。
- en: '![](img/Image.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image.png)'
