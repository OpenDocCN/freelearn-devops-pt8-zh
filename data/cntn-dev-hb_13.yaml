- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Managing the Application Life Cycle
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理应用生命周期
- en: 'In this book, we’ve reviewed some modern architectures and the microservices
    concept, understanding how containers fit into this new application development
    logic and covering how to create applications using different containers to provide
    their differing functionalities. This concept really is a game changer: we can
    implement an application’s components using different deployment strategies and
    scale processes up or down as needed. We used container registries for storing
    and managing the new artifacts and container images, which in turn are used for
    creating containers. Container runtimes allow us to run such components. We then
    introduced orchestration, which allows us to manage application availability and
    updates easily. Container orchestration requires new resources to solve different
    issues that arise from these new architectures. In this chapter, we will cover
    how all these pieces fit together in the management of your application life cycle.
    Then, we will learn how the automation of such actions allows us to provide a
    complete application **supply chain**, running **continuous integration/continuous
    delivery** (**CI/CD**) on Kubernetes.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书回顾了一些现代架构和微服务概念，理解容器如何适应这种新的应用开发逻辑，并介绍了如何使用不同的容器来创建应用程序，以提供其不同的功能。这个概念真的改变了游戏规则：我们可以使用不同的部署策略来实现应用程序的组件，并根据需要扩展或缩减过程。我们使用容器注册中心来存储和管理新的工件和容器镜像，这些镜像又用于创建容器。容器运行时允许我们运行这些组件。然后，我们介绍了编排，它让我们轻松管理应用的可用性和更新。容器编排需要新的资源来解决这些新架构中出现的各种问题。在本章中，我们将探讨如何将所有这些部分结合起来，管理应用生命周期。接着，我们将学习如何通过自动化这些操作来提供一个完整的应用**供应链**，在Kubernetes上运行**持续集成/持续交付**（**CI/CD**）。
- en: 'The following are the main topics covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章涵盖的主要主题：
- en: Reviewing the application life cycle
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾应用生命周期
- en: Shifting our application’s security left
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将我们应用的安全性左移
- en: Understanding CI patterns
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解CI模式
- en: Automating continuous application deployment
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化持续应用部署
- en: Orchestrating CI/CD with Kubernetes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes编排CI/CD
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术需求
- en: You can find the labs for this chapter at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13),
    where you will find some extended explanations, omitted in the chapter’s content
    to make it easier to follow. The *Code In Action* video for this chapter can be
    found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的实验室内容可以在[https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter13)找到，那里包含了一些扩展的解释，这些内容在本章中被省略，以便更容易跟随。此章的*Code
    In Action*视频可以在[https://packt.link/JdOIY](https://packt.link/JdOIY)找到。
- en: Reviewing the application life cycle
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾应用生命周期
- en: 'When we talk about how applications are created and evolve, we have to consider
    all the creative and maintenance processes involved. The application life cycle
    includes the following stages:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论应用程序如何创建和演变时，必须考虑所有相关的创作和维护过程。应用生命周期包括以下阶段：
- en: '**Planning** of a software solution'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 软件解决方案的**规划**
- en: '**Development** of the application’s components'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用组件的**开发**
- en: Different **testing** phases, including component integration and performance
    tests
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同的**测试**阶段，包括组件集成和性能测试
- en: '**Deployment** of the solution'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解决方案的**部署**
- en: '**Maintenance**'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**维护**'
- en: 'As we can see, a lot of people, processes, and tools are involved across the
    whole life cycle of an application. In this book, however, we will only cover
    those that can be resolved technically with the use of software containers. We
    can use the following schema to situate the aforementioned processes within a
    broader context:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，整个应用生命周期涉及了大量的人、流程和工具。然而，本书将只涵盖那些可以通过软件容器技术解决的问题。我们可以使用以下架构图来将上述流程放置在更广泛的背景中：
- en: '![Figure 13.1 – Basic application life cycle schema](img/B19845_13_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1 – 基本应用生命周期架构图](img/B19845_13_01.jpg)'
- en: Figure 13.1 – Basic application life cycle schema
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – 基本应用生命周期架构图
- en: Let’s think now about which of these phases can be implemented using software
    containers.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们思考一下，哪些阶段可以使用软件容器来实现。
- en: Planning a software solution
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规划软件解决方案
- en: This phase covers the early stages of a software solution when an idea becomes
    a project. It includes the collection and analysis of the **requirements** of
    the users, customers, and other project stakeholders. These requirements will
    always need validation to ensure the final characteristics of the developed solution.
    Depending on the size of the project, an exploration of alternatives currently
    available on the market and the viability of the solution may call a stop to the
    process. The success of the project is usually directly related to the effectiveness
    of the planning phase, in which different teams propose the architecture, infrastructure,
    software frameworks, and other resources that may be key for the resulting solution.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段涵盖了软件解决方案的早期阶段，即一个想法转变为项目的过程。它包括收集和分析用户、客户及其他项目相关方的**需求**。这些需求始终需要验证，以确保最终开发解决方案的特性。根据项目的规模，可能会需要对目前市场上可用的替代方案以及解决方案的可行性进行探索，可能会因此暂停该过程。项目的成功通常与规划阶段的有效性直接相关，在这个阶段，不同的团队提出架构、基础设施、软件框架和其他可能对最终解决方案至关重要的资源。
- en: Important note
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In this book, all the content presented is intended for working on either cloud
    environments or an on-premises data center infrastructure. You will be able to
    use your desktop computer for developing your application code and can use a variety
    of workflows to interact with different infrastructure platforms through the different
    project phases, as we will learn in this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中展示的所有内容都适用于在云环境或本地数据中心基础设施上工作。你可以使用桌面计算机来开发你的应用程序代码，并且可以通过不同的项目阶段使用各种工作流与不同的基础设施平台进行交互，正如我们将在本章中学习的那样。
- en: Developing a good **timeline** for the project is always critical, and working
    with containers helps you improve delivery times, as they don’t require dedicated
    or overly specific infrastructure. You can even start your project on one platform
    and then move to a new completely different one. Containers mitigate any friction
    and remove infrastructure vendor lock-in.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为项目制定一个良好的**时间表**总是至关重要的，而使用容器有助于改善交付时间，因为容器不需要专门或过于具体的基础设施。你甚至可以在一个平台上启动项目，然后迁移到一个完全不同的平台。容器减少了任何摩擦，消除了基础设施供应商的锁定。
- en: In this phase, you will also decide on the **architecture** for your application.
    Dividing your application into small, code-independent but cooperative services
    allows different groups of developers to work in parallel, which will always speed
    up project delivery. Working with microservices lets you as a developer focus
    on specific functionality and deliver your component following defined guidelines
    to ensure proper integrations. It is important to prepare the logic for scaling
    up or down any application’s process if needed and to ensure components’ **high
    availability** (**HA**) and resilience. This will add flexibility to your solution
    and increase overall availability for your users.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，你还需要为你的应用程序决定**架构**。将应用程序划分为小型、代码独立但能够协作的服务，可以让不同的开发团队并行工作，这将始终加快项目的交付速度。使用微服务架构可以让你作为开发者专注于特定的功能，并按照定义的规范交付你的组件，以确保正确的集成。如果需要，还必须为应用程序的任何进程进行扩展或缩减的逻辑准备，并确保组件的**高可用性**（**HA**）和韧性。这将为你的解决方案增加灵活性，并提高用户的整体可用性。
- en: Developing the application’s components
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发应用程序的组件
- en: This stage involves writing the code for your application. When you are developing
    microservices applications, you can choose the most appropriate language for your
    code, but you must be aware of any issues in the dependencies you use and understand
    the risks that come with using certain components instead of others. Using open
    source libraries or frameworks always requires a good knowledge of the maintainer’s
    activity and the maturity of their code.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段涉及为你的应用程序编写代码。当你开发微服务应用程序时，可以选择最适合的编程语言，但你必须注意所使用的依赖关系中的问题，并理解使用某些组件而不是其他组件所带来的风险。使用开源库或框架总是需要对维护者的活动和其代码的成熟度有良好的了解。
- en: In the microservices model, your applications serve their APIs, and resources
    and other components use them. If you plan to enable multiple instances, you must
    ensure that your application’s logic allows this situation. To avoid infrastructure
    friction and provide maximum availability, ensure your application runs in different
    circumstances, manage its dependencies, and enable some circuit breakers. You
    will need to figure out how your processes behave when some components are down,
    how to reconnect in case some connection is lost and recovered, what will happen
    if you decide to execute your application’s components in a cloud platform or
    on a different cluster, and so on.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务模型中，你的应用程序提供其API，资源和其他组件使用它们。如果计划启用多个实例，必须确保应用程序的逻辑允许这种情况。为避免基础设施摩擦并提供最大可用性，确保应用程序在不同情况下运行，管理其依赖关系，并启用一些熔断器。你需要弄清楚当某些组件出现故障时，处理过程的行为，如何在丢失连接并恢复时重新连接，如果决定在云平台或不同集群中执行应用程序的组件时会发生什么，等等。
- en: Testing your application
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试你的应用程序
- en: 'Once your development is finished, a selection of test stages will be triggered.
    As this is an iterative process, you can deliver certain components of the application
    (or even the full solution), but it won’t truly be finished until all the tests
    return positive results. We must always consider the following principles when
    preparing and running our tests:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦开发完成，测试阶段的选择将被触发。由于这是一个迭代过程，你可以交付应用程序的某些组件（甚至完整解决方案），但直到所有测试返回正面结果之前，应用程序都不会真正完成。我们在准备和执行测试时必须始终考虑以下原则：
- en: Tests must meet the expected requirements
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试必须满足预期要求
- en: They should be executed by third-party groups, not involved in the design or
    development of the application to keep these tests independent
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试应由第三方团队执行，这些团队未参与应用程序的设计或开发，以保持测试的独立性
- en: Automation helps to reproduce tests under the same circumstances in different
    iterations
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化有助于在不同的迭代中在相同的情况下重现测试
- en: Tests must be executed on either small components or a set of components running
    together
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试必须在小组件或一组一起运行的组件上执行
- en: 'Let’s see some of the testing types and how containers can integrate them:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些测试类型以及容器如何将它们集成：
- en: '**Unit testing**: This type tests the *individual* components of an application.
    It is usually generated and executed in the *development phase* because developers
    need to know whether their code is working as expected. Depending on the complexity
    of the component’s code and the returned objects of the requests, they may be
    included in the container probes. Components will not be considered healthy if
    the returned status isn’t valid, although further pattern matching can be included
    in the validation of the returned data. If you are developing a component that
    works via an API, you should consider having a test request that always returns
    a valid value, or alternatively, you could use mock data. Unit tests will help
    you validate your code whenever changes have to be made to fix an issue, and they
    also make your code modular (microservices). Each component should include its
    own unit tests, and we can also include some code quality verification against
    defined standards.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单元测试**：这种测试类型测试应用程序的*单个*组件。通常在*开发阶段*生成和执行，因为开发人员需要知道他们的代码是否按预期工作。根据组件代码的复杂性和请求返回的对象，它们可能会被包括在容器探针中。如果返回的状态无效，则该组件将不被认为是健康的，尽管可以在验证返回数据时包括进一步的模式匹配。如果你正在开发一个通过API工作的组件，应该考虑有一个始终返回有效值的测试请求，或者使用模拟数据。单元测试有助于在修复问题时验证代码的有效性，它们还使你的代码更加模块化（微服务）。每个组件都应包含自己的单元测试，我们还可以根据定义的标准进行一些代码质量验证。'
- en: '**Integration testing**: These tests validate how *different* components of
    your software solution work together. They help us to identify issues between
    components and fix the delivery and interaction of all the components. So, this
    type of test needs to be arranged between the developers of the different components
    and planned consistently. If our application’s components run within containers,
    it would be very easy to prepare Docker Compose or some Kubernetes manifests to
    run all the required components together in our development environment – although
    these tests can also be automated on a remote CI/CD platform, as we will see later
    in this chapter in the *Orchestrating CI/CD within Kubernetes* section. If some
    components are key for your application’s health, their endpoints or probes can
    be integrated into the monitoring platform to ensure everything works as expected.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成测试**：这些测试验证你的软件解决方案中*不同*组件是如何协同工作的。它们帮助我们识别组件之间的问题，并修复所有组件的交付和交互。因此，这类测试需要在不同组件的开发者之间进行安排，并且需要一致地规划。如果我们的应用程序组件在容器中运行，那么准备
    Docker Compose 或某些 Kubernetes 清单以在开发环境中同时运行所有必需的组件将变得非常容易——尽管这些测试也可以在远程 CI/CD
    平台上自动化执行，正如我们稍后在本章的 *Kubernetes 中的 CI/CD 编排* 部分中所看到的那样。如果某些组件对于应用程序的健康至关重要，它们的端点或探针可以集成到监控平台中，以确保一切按预期工作。'
- en: '**Regression testing**: These tests validate that new changes made don’t introduce
    new issues or break the overall project. Working with containers in these tests
    can significantly improve the overall process. We can go forward with new container
    image builds or roll backward using a previous image. If your code has changed
    significantly between releases, maybe having a completely different development
    platform as a result of moving to a new version of Python or Java, this can be
    tricky, but using containers makes it smooth and simple. Regression tests help
    us solve any issues related to advancements or changes in our code (evolution
    of the solution) that can break the current application’s behavior.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归测试**：这些测试验证新的更改不会引入新的问题或破坏整体项目。在这些测试中使用容器可以显著改善整体过程。我们可以使用新的容器镜像构建进行前进，或使用先前的镜像进行回滚。如果你的代码在发布之间发生了重大变化，比如因为升级到了新的
    Python 或 Java 版本而导致完全不同的开发平台，可能会比较棘手，但使用容器可以使这一过程变得顺畅简单。回归测试帮助我们解决与代码进展或更改（解决方案的演变）相关的任何问题，这些更改可能会破坏当前应用程序的行为。'
- en: '`depends_on` key, but it’s recommended to solve any dependency order issues
    in your code because commonly used container orchestrators don’t include such
    keys, requiring other mechanisms to manage dependencies. You can include additional
    `init` containers or sidecar containers that will check for the required components
    before other containers actually start.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depends_on` 键，但建议在你的代码中解决任何依赖顺序问题，因为常用的容器编排器不包含这种键，通常需要其他机制来管理依赖关系。你可以包含额外的
    `init` 容器或侧车容器，它们将在其他容器启动之前检查所需的组件。'
- en: '**Stress testing**: These tests validate your application’s component under
    stress or heavy load. We learned in [*Chapter 12*](B19845_12.xhtml#_idTextAnchor267)
    how to make tests using third-party tools. These tools can be deployed within
    containers and automated to create thousands of requests for our application’s
    components. If we’ve already dealt with the monitoring of the application’s components,
    we can get a good overview of the hardware requirements of our processes and use
    this to minimize resource usage within our container orchestrator clusters.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**压力测试**：这些测试验证你的应用程序组件在压力或高负载下的表现。我们在 [*第12章*](B19845_12.xhtml#_idTextAnchor267)中学到了如何使用第三方工具进行测试。这些工具可以部署在容器中并自动化生成成千上万的请求，测试应用程序的组件。如果我们已经处理了应用程序组件的监控，我们可以很好地概览我们进程的硬件需求，并利用这些信息在容器编排集群中最小化资源使用。'
- en: '**Performance testing**: Once you have integrated all your components and tested
    the requirements for each one, you can go further and verify different contexts
    for your application. You can test, for example, how your application behaves
    with multiple frontend components or work out how to distribute load between multiple
    databases. You can prepare both the application and the tests within containers,
    scale certain components up or down, and analyze the performance outcomes. This
    lets you distribute load automatically and add dynamism to your software solutions
    – but you do have to ensure that your code allows multiple instances at once of
    certain components. For example, you can have multiple instances of a distributed
    NoSQL database or multiple static frontends, but you can’t run multiple database
    instances at once and write to the same data file. This also applies to your application’s
    code. You can’t simultaneously execute multiple instances of a process that write
    to a file if you don’t block the file, so just one gets complete access to it.
    Another example is to allow requests from users on different instances without
    managing the response in a central database. You have to atomize the requests
    or integrate mechanisms to distribute them across the different instances.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能测试**：一旦你整合了所有组件并测试了每个组件的需求，你可以进一步验证应用程序在不同环境下的表现。例如，你可以测试应用程序在多个前端组件的情况下如何运行，或者研究如何在多个数据库之间分配负载。你可以在容器内准备应用程序和测试，按需扩展或缩减某些组件，并分析性能结果。这可以让你自动分配负载，并为你的软件解决方案增添动态性——但你需要确保代码能够支持某些组件的多个实例同时运行。例如，你可以有多个分布式NoSQL数据库实例或多个静态前端实例，但无法同时运行多个数据库实例并写入同一数据文件。这也适用于你的应用程序代码。如果你不阻止文件，无法同时执行多个写入同一文件的进程，因为只有一个进程可以完全访问它。另一个例子是允许来自不同实例的用户请求，而不通过中央数据库管理响应。你必须将请求进行原子化，或者集成机制将请求分发到不同实例。'
- en: '**Acceptance testing**: You should always define **user acceptance tests**
    (**UATs**) before delivering your solution because these will ensure that your
    code fits the requirements exposed at the beginning of the project. Multiple tests
    can be included in this stage (alpha, beta tests) depending on the complexity
    of your solution. New issues may arise in these tests, hence multiple iterations
    will probably be required. The automation of delivery and the simplicity inherited
    from working with software containers both help you to provide different testing
    environments to your users in a short period of time.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验收测试**：在交付解决方案之前，你应始终定义**用户验收测试**（**UATs**），因为这些测试可以确保你的代码符合项目初期提出的需求。根据解决方案的复杂性，这一阶段可以包括多个测试（如alpha测试、beta测试）。在这些测试中可能会出现新的问题，因此可能需要进行多次迭代。交付的自动化和使用软件容器带来的简便性，都有助于你在短时间内为用户提供不同的测试环境。'
- en: The testing phase is very important for a project because it helps you improve
    the quality and reliability of your software delivery, identify and fix problems
    before going to production, and increase the visibility of the project, improving
    stakeholders’ confidence and user satisfaction. We can also reduce the maintenance
    costs of the solution because it was designed and tested with all the requirements
    in mind and validated multiple times, so errors that arise should have been ironed
    out before they impact production. On the other hand, testing is always time-consuming,
    but making different tests using containers will reduce both costs (as fewer environments
    are required for tests) and the time spent on each test (as we can deploy multiple
    releases at the time and test in parallel).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 测试阶段对于项目非常重要，因为它有助于提高软件交付的质量和可靠性，提前识别并修复问题，增加项目的可见性，提高利益相关者的信任度和用户满意度。我们还可以减少解决方案的维护成本，因为它在设计和测试时考虑了所有要求，并进行了多次验证，因此在影响生产之前，出现的错误应该已经被解决。另一方面，测试总是费时的，但通过使用容器进行不同的测试，将减少成本（因为测试所需的环境更少）和每次测试所花费的时间（因为我们可以同时部署多个版本并行测试）。
- en: Deploying the solution
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署解决方案
- en: 'In this phase, we actually deploy our software solution in production. The
    solution often goes through multiple environments before this step is complete.
    For example, we can have a preproduction environment for validating certain releases
    and **Quality Assurance** (**QA**) environments where other more specific tests
    can be run. Using containers makes deployments in these testing stages simple
    – we just change our configuration; all the container images will be the same.
    Using containers as new **deployment artifacts** makes things easier. Let’s quickly
    introduce some packaging solutions for containers:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们实际上将我们的软件解决方案部署到生产环境中。这个解决方案通常会经历多个环境，直到此步骤完成。例如，我们可以有一个预生产环境来验证某些版本，以及**质量保证**（**QA**）环境，在这些环境中可以进行其他更具体的测试。使用容器使得这些测试阶段的部署变得简单——我们只需更改配置；所有容器镜像将保持一致。将容器作为新的**部署工件**可以简化流程。让我们快速介绍一些容器的打包解决方案：
- en: '**Helm charts**: This package solution only works with Kubernetes. A Helm chart
    is just a packaged set of manifests that includes variables for modifying the
    deployment of an application and its components. Version-3-compatible Helm charts
    are the go-to now. A previous version of Helm that was deprecated some time ago
    used the Tiller privileged component for deploying manifests, which may affect
    cluster integrity and security. Newer releases simplify how applications are deployed
    without having to create any Helm-specific resources in your Kubernetes cluster.
    Helm charts are very popular, and software vendors provide their own supported
    chart repositories for installing their applications directly from the internet
    into your own Kubernetes clusters.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Helm charts**：这个打包解决方案仅适用于 Kubernetes。Helm chart 只是一个打包好的清单集，其中包含修改应用程序及其组件部署的变量。现在，兼容版本
    3 的 Helm charts 是主流。Helm 的旧版本在一段时间前被弃用，使用了 Tiller 特权组件来部署清单，这可能会影响集群的完整性和安全性。较新的版本简化了应用程序的部署方式，无需在
    Kubernetes 集群中创建任何 Helm 特定的资源。Helm charts 非常流行，软件供应商为其应用程序提供了自己支持的 chart 仓库，用户可以直接从互联网上将其应用程序安装到自己的
    Kubernetes 集群中。'
- en: '`kubectl` command line includes Kustomize functionality, which makes it very
    usable out of the box without having to include new binaries in our environment.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl` 命令行包括 Kustomize 功能，使得它开箱即用，无需在环境中包含新的二进制文件。'
- en: '**Cloud-Native Application Bundle** (**CNAB**): CNAB goes a step further than
    Helm and Kustomize. It is designed to include the infrastructure and services
    required by our application to work. Multiple tools work together to provide both
    the infrastructure (with the Porter component providing integration of Helm, HashiCorp
    Terraform, and the cloud provider’s API) and the application (managed by Duffle
    and Docker). This solution is not really in use today and many of its components
    have been deprecated, but it is worth mentioning as it can give you some ideas
    for fully packaging your software solutions (that is, the infrastructure and the
    application together).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cloud-Native Application Bundle**（**CNAB**）：CNAB 比 Helm 和 Kustomize 更进一步。它的设计目标是包含我们的应用程序运行所需的基础设施和服务。多个工具协同工作，提供基础设施（由
    Porter 组件集成 Helm、HashiCorp Terraform 和云提供商的 API）和应用程序（由 Duffle 和 Docker 管理）。这个解决方案目前并未广泛使用，许多组件已被弃用，但值得一提的是，它可以为你提供将软件解决方案（即基础设施和应用程序一起）完全打包的一些思路。'
- en: '**Kubernetes operators**: Kubernetes operators are controllers that deploy
    and manage specific application deployments and have become very popular these
    days. An operator deploys its own specific controllers inside a Kubernetes cluster
    to manage application instances. Kubernetes operators are intended to self-manage
    all the tricky parts of your application’s management and upgrades. You as a user
    just need to define certain required values for your instance, and the operator
    will handle installing the required components and dependencies and manage any
    upgrade during its lifetime. If you are planning to develop your application using
    a Kubernetes operator, make sure to include all the manifests of your application,
    dependencies, and the automation required for the application to come up. Third-party
    Kubernetes operators run as black boxes in your Kubernetes cluster and may not
    include all the functionality you expect for your applications to work; therefore,
    it may be worth reading the documentation before deploying a third-party Kubernetes
    operator.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes 操作员**：Kubernetes 操作员是部署和管理特定应用程序部署的控制器，近年来已变得非常流行。操作员会在 Kubernetes
    集群内部署自己的特定控制器，以管理应用实例。Kubernetes 操作员旨在自我管理应用程序管理和升级中的所有复杂部分。作为用户，你只需要为实例定义某些必需的值，操作员会处理所需组件和依赖项的安装，并在其生命周期内管理任何升级。如果你计划使用
    Kubernetes 操作员开发应用程序，确保包含所有应用程序的清单、依赖项以及使应用程序能够启动所需的自动化。第三方 Kubernetes 操作员作为黑盒在
    Kubernetes 集群中运行，可能不会包含你期望的所有功能，因此在部署第三方 Kubernetes 操作员之前，阅读文档可能是值得的。'
- en: Deploying your application using a microservices architecture allows you to
    integrate different components’ releases. Depending on your software solution,
    you might use one full deployment or multiple small ones for each component of
    your application. Either way, the solution must provide all the functionality
    called for by your users and stakeholders in the project planning stage.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用微服务架构部署应用程序可以让你整合不同组件的发布。根据你的软件解决方案，你可能会使用一个完整的部署，或者为应用程序的每个组件使用多个小型部署。无论哪种方式，解决方案必须提供项目规划阶段用户和利益相关者所要求的所有功能。
- en: Maintaining the application
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维护应用程序
- en: We might think that the deployment of the solution is the last phase, but it
    isn’t. Once the application is in production, new functionalities may be required,
    new improvements to current functionality may be called for, and inevitably, new
    errors will appear. If your application is monitored, you can obtain feedback
    on the status of different components before actual errors appear. **Logging**
    also helps to identify problems, and tracing allows you to improve your code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会认为解决方案的部署是最后一个阶段，但事实并非如此。一旦应用程序进入生产环境，可能需要新增功能、对现有功能进行改进，并且不可避免地会出现新的错误。如果你的应用程序被监控，你可以在实际错误出现之前获得有关不同组件状态的反馈。**日志记录**有助于识别问题，而追踪则可以帮助你改进代码。
- en: But in any case, the application’s life cycle continues, and a new project may
    start adding new functionalities while issues are repaired for the current release.
    Monolithic architectures require multiple environments for such processes. Working
    on two releases at the same time will double the efforts for maintaining environments.
    Microservices architecture allows us to distribute the work according to the different
    components, and thus mitigate the need for having dedicated environments for building
    each component. And, more importantly, we can change one component at a time and
    focus on solving a specific issue, or have each application component managed
    by a different team with different release times. These teams develop their code
    using the programming language that best fits the functionality of their requirements,
    taking into account release times and proper integration within the application.
    However, note that each team also has to keep track of vulnerabilities and security
    issues in their implementation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但无论如何，应用程序的生命周期继续进行，新项目可能会开始增加新功能，同时修复当前版本中的问题。单体架构需要多个环境来进行这些过程。与此同时，处理两个版本将加倍环境维护的工作量。微服务架构使我们能够根据不同的组件分配工作，从而减少需要为每个组件建立独立环境的需求。更重要的是，我们可以一次更改一个组件，专注于解决特定问题，或者让不同的团队管理每个应用组件，并安排不同的发布时间。这些团队使用最适合其需求功能的编程语言开发代码，同时考虑发布时机和与应用程序的适当集成。然而，值得注意的是，每个团队还需要跟踪其实现中的漏洞和安全问题。
- en: 'Throughout this book, we have learned some security practices that will make
    our applications safer when we work within containers ([*Chapter 2*](B19845_02.xhtml#_idTextAnchor036)
    and [*Chapter 3*](B19845_03.xhtml#_idTextAnchor082)) and with container orchestrators
    ([*Chapter 6*](B19845_06.xhtml#_idTextAnchor134), [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147),
    and [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170)). **Shift-left security**
    goes beyond these recommendations and includes security from the very beginning
    of the project. We can consider shift-left security as a practice where we don’t
    wait to address software security vulnerabilities until it’s too late: when the
    application is already developed, built, and packaged. In the next section, we
    will learn how taking care of security from the very first phases of the application
    life cycle can significantly improve the overall security of the solution.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们学习了一些安全实践，这些实践将在我们在容器内工作时（[*第2章*](B19845_02.xhtml#_idTextAnchor036) 和
    [*第3章*](B19845_03.xhtml#_idTextAnchor082)）以及与容器编排工具一起使用时（[*第6章*](B19845_06.xhtml#_idTextAnchor134)，[*第7章*](B19845_07.xhtml#_idTextAnchor147)，和
    [*第8章*](B19845_08.xhtml#_idTextAnchor170)）使我们的应用程序更安全。**左移安全**超越了这些建议，包括从项目一开始就注重安全。我们可以将左移安全视为一种实践，意味着我们不会等到应用程序已经开发、构建并打包完毕后，才去解决软件安全漏洞。在下一部分，我们将学习如何从应用程序生命周期的最初阶段开始处理安全问题，从而显著提高解决方案的整体安全性。
- en: Shifting our application’s security left
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将我们的应用程序安全性向左移动
- en: '**Shift-left security** refers to the practice of starting security checks
    as early as possible in the development of our application. This doesn’t mean
    we don’t apply any security measures at other stages but that it will start improving
    security from the very beginning of the application life cycle. Shifting security
    left allows us to identify any vulnerabilities and other problems before it’s
    too late and the application is already running in production. The benefits of
    shifting our security left include the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**左移安全**是指在应用程序开发的早期阶段尽早开始进行安全检查的实践。这并不意味着我们在其他阶段不应用任何安全措施，而是指安全性将从应用程序生命周期的最初阶段开始得到改善。左移安全使我们能够在应用程序进入生产环境之前识别出任何漏洞和其他问题。将安全性左移的好处包括以下几点：'
- en: It improves the delivery of software solutions because bugs are detected and
    fixed in early development stages
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过在开发初期阶段就发现并修复错误，改善了软件解决方案的交付
- en: It distributes application security into different stages, allowing different
    actions at each stage, starting from the code and ending in the infrastructure
    where the application will finally be deployed
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将应用程序安全性分布到不同的阶段，在每个阶段采取不同的措施，从代码阶段开始，直到应用程序最终部署到基础设施上
- en: Different groups can implement different security policies and mechanisms, furthering
    the creation of a security culture in your organization
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的团队可以实施不同的安全策略和机制，进一步促进组织内安全文化的建设
- en: It reduces overall development time and the costs of pushing back applications
    because of poor security
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过减少因安全性差导致推迟应用程序交付的时间和成本，从而缩短了整体开发周期
- en: Now, let’s understand some different methodologies for tackling the software
    development life cycle and how they impact security.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解一些不同的软件开发生命周期方法论，以及它们如何影响安全性。
- en: Software life cycle methodologies
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软件生命周期方法论
- en: 'Let’s introduce some software life cycle methodologies here that will help
    us understand the importance of security when things begin to move faster in the
    stages of development:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里介绍一些软件生命周期方法论，帮助我们理解在开发阶段加速推进时，安全性的重要性：
- en: '**Waterfall model**: In this model, stages must run *linearly*, hence a new
    stage begins when the previous one finishes. This model works very well when we
    don’t expect to have many modifications from the planned requirements and our
    project tasks are well defined. However, this model lacks flexibility, which makes
    changes harder to implement, and issues usually remain hidden until the end of
    the project.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**瀑布模型**：在此模型中，各个阶段必须*线性*进行，因此一个新阶段必须在前一个阶段结束后开始。该模型在我们不预期有许多需求变动，且项目任务明确时非常有效。然而，该模型缺乏灵活性，使得实施变更变得困难，问题通常会被隐藏，直到项目结束时才暴露。'
- en: '**Agile model**: In this model, we *iterate* over stages to improve the final
    software solution. Flexibility and quick response times are key in this model.
    Iterations allow the introduction of new changes and the resolution of any issue
    found in the previous review. The main problem of this model is that it requires
    lots of collaboration between the groups or people involved in each stage, hence
    it may not work in big projects, but microservices architectures fit very well
    into this development model.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**敏捷模型**：在这个模型中，我们通过*迭代*各个阶段来改进最终的软件解决方案。灵活性和快速响应是这个模型的关键。迭代允许引入新的变化并解决在前一次审查中发现的问题。这个模型的主要问题是它需要各个阶段之间有大量的协作，因此可能不适用于大型项目，但微服务架构非常适合这种开发模型。'
- en: '**Spiral model**: This model can be considered a *mixture* of both the Waterfall
    and Agile models. The final software solution will be the result of different
    iterations that can be considered a complete software development cycle. In each
    iteration, we start from the very beginning, taking user requirements, designing
    a solution, developing the code, and testing, implementing, and maintaining the
    solution as is, before moving on to the next iteration. The Agile and spiral development
    models allow us to review and solve issues before the next iteration, which both
    accelerates the development process and makes the solution more secure.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**螺旋模型**：该模型可以被视为瀑布模型和敏捷模型的*混合体*。最终的软件解决方案将是不同迭代的结果，可以看作是一个完整的软件开发周期。在每一次迭代中，我们从头开始，收集用户需求、设计解决方案、开发代码、进行测试、实施并维护解决方案，然后再进入下一个迭代。敏捷和螺旋开发模型让我们可以在下一次迭代前审查和解决问题，这不仅加快了开发过程，也使解决方案更加安全。'
- en: Of these methods, Agile methodologies in particular have really changed how
    software is developed and delivered. Their adoption allows teams to go faster
    and swiftly adapt software solutions when users require new features. However,
    in such scenarios, the security team can be a bottleneck. These teams receive
    a software solution just before it goes into production, seeking to identify and
    resolve any vulnerabilities and security issues before malicious users find them
    in production. If we decouple our application into small pieces (that is, microservices),
    then the work required in the security review task is multiplied by the number
    of pieces, even if they are small. It gets even worse when we realize that most
    of the legacy tools used for reviewing security on monolith applications don’t
    work on highly distributed and dynamic environments such as Kubernetes.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些方法中，尤其是敏捷方法已经彻底改变了软件的开发和交付方式。它们的采用使团队能够更快速地工作，并在用户要求新特性时迅速调整软件解决方案。然而，在这种情况下，安全团队可能成为瓶颈。这些团队在软件解决方案进入生产之前进行审查，旨在识别并解决任何漏洞和安全问题，以防恶意用户在生产环境中发现这些问题。如果我们将应用程序拆解成小块（即微服务），那么安全审查任务所需的工作量将乘以拆解后的各个小块数量，即使它们很小。当我们意识到大多数用于审查单体应用程序安全性的传统工具无法在像Kubernetes这样的高度分布式和动态环境中使用时，情况变得更糟。
- en: It is also the case that software containers and open source solutions have
    become so widely used in data centers and cloud platforms that we can find ourselves
    deploying third-party software solutions while barely even knowing their contents.
    Even software vendors provide open source products inside their own complex software
    solutions. Therefore, we cannot just keep using the same old security methodologies
    at the infrastructure and application levels.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，软件容器和开源解决方案已经在数据中心和云平台中得到广泛应用，以至于我们在部署第三方软件解决方案时，几乎无法了解其内部内容。即使是软件供应商，也会将开源产品嵌入到自己的复杂软件解决方案中。因此，我们不能继续在基础设施和应用层面上使用陈旧的安全方法。
- en: Security at the application level
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用层的安全性
- en: As discussed earlier, shifting the security of our applications left implies
    integrating security mechanisms and best practices as early as possible in our
    software development model. But this doesn’t mean we leave security to the developers.
    We will prepare automated security validations in the testing phase and implement
    security policies in both the development environments and production clusters.
    This will ensure that everyone knows the security measures applied and how to
    implement them. The DevSecOps team prepares infrastructure and application rules
    and shares them with all the developer teams. Infrastructure rules include all
    policy enforcements in your execution environment, which is usually your Kubernetes
    cloud or on-premises platform. These policies may include, for example, the denial
    of any privileged container, the denial of Pods without limited resources, and
    the denial of access to hosts’ filesystems. However, note that these rules are
    not part of the code, although they do affect the execution of your applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，将应用程序的安全性左移意味着尽可能早地将安全机制和最佳实践融入我们的软件开发模型中。但这并不意味着我们将安全问题完全交给开发人员。我们将在测试阶段准备自动化的安全验证，并在开发环境和生产集群中实施安全政策。这将确保每个人都知道已应用的安全措施以及如何实施它们。DevSecOps
    团队准备基础设施和应用规则，并与所有开发团队共享。基础设施规则包括在执行环境中强制执行的所有政策，通常是 Kubernetes 云或本地平台。这些政策可能包括，例如，拒绝任何特权容器，拒绝没有资源限制的
    Pods，拒绝访问主机文件系统。但请注意，这些规则不属于代码的一部分，尽管它们确实影响应用程序的执行。
- en: 'If we consider security from the application perspective, there are several
    techniques we can apply:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从应用程序的角度考虑安全性，我们可以应用多种技术：
- en: '**Software composition analysis** (**SCA**): When we add open source libraries
    or other components to our code, we unconsciously add risk to our application.
    SCA tools help us identify these risks and in some cases mitigate them with patches
    and updates. While **static application security testing** (**SAST**) tools (which
    we will discuss next) are used to find vulnerabilities in the development cycle,
    within your code, SCA tools provide continuous vulnerability monitoring.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件组成分析**（**SCA**）：当我们将开源库或其他组件添加到代码中时，我们无意中为应用程序增加了风险。SCA 工具帮助我们识别这些风险，在某些情况下，通过补丁和更新来缓解这些风险。虽然
    **静态应用程序安全测试**（**SAST**）工具（我们接下来会讨论）用于在开发周期中查找漏洞，检查代码中的问题，但 SCA 工具提供了持续的漏洞监控。'
- en: '**SAST**: These tests are used to find vulnerabilities in our code before it
    is actually compiled, hence they are run in the early stages of our development
    phase. The tools running these tests will search for well-known insecure patterns
    in our code and report them to us. Any hardcoded secret data and misconfigurations
    will be reported as issues in the analysis.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SAST**：这些测试用于在代码实际编译之前发现漏洞，因此它们在开发阶段的早期执行。运行这些测试的工具会在我们的代码中搜索已知的不安全模式，并将其报告给我们。任何硬编码的机密数据和配置错误将作为问题在分析中被报告。'
- en: '**Dynamic application security testing** (**DAST**): These tests are executed
    when the application is running, in the testing phase. They involve the execution
    of simulated attacks against our application’s components. These tests can include
    code injection or malformed requests that may break your application at some point.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态应用程序安全测试**（**DAST**）：这些测试在应用程序运行时执行，即在测试阶段。它们涉及对应用程序组件进行模拟攻击的执行。这些测试可能包括代码注入或格式错误的请求，这些请求可能在某些时刻使你的应用程序崩溃。'
- en: These three types of tests are very valuable in identifying vulnerabilities
    in our application before moving it to production, but SAST and SCA are the ones
    to focus on when talking about shifting security left. When automation is put
    in place, we can execute these tests continuously and use **integrated development
    environment** (**IDE**) plugins to help figure out problems before they are actually
    stored in our code. To start, we can use any good linter for our specific programming
    language. Let’s discuss these next.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种测试在将应用程序迁移到生产环境之前，非常有价值地帮助识别漏洞，但在谈论“安全左移”时，SAST 和 SCA 是重点。当自动化到位时，我们可以持续执行这些测试，并使用
    **集成开发环境**（**IDE**）插件，在问题实际存入代码之前帮助发现问题。首先，我们可以为特定的编程语言使用任何合适的代码检查工具。接下来我们将讨论这些工具。
- en: Introducing linters
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入代码检查工具
- en: A **linter** is a tool used to analyze our code looking for problems. Depending
    on the quality of the given linter, it can identify things from simple code improvements
    to more advanced issues. It is usual to use specific linters for different programming
    languages. You can check the extensions available in your favorite IDE.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码检查工具**是用来分析我们的代码，寻找问题的工具。根据给定检查工具的质量，它可以从简单的代码改进到更高级的问题进行识别。通常会为不同的编程语言使用特定的代码检查工具。你可以查看你喜欢的
    IDE 中可用的扩展。'
- en: Linters help us reduce the amount of code errors in the development stage, and
    improve our code style, construction consistency, and performance.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 代码检查工具帮助我们减少开发阶段的代码错误，改善代码风格、构建一致性和性能。
- en: 'A simple code linter will do the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的代码检查工具将执行以下操作：
- en: Check for syntax errors
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查语法错误
- en: Verify code standards
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证代码标准
- en: Review *code smells* (well-known signs that something will go wrong in your
    code)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查 *代码异味*（代码中表明某些地方可能出错的常见标志）
- en: Verify security checks
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证安全性检查
- en: Make your code look as if it were written by a single person
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让你的代码看起来像是由一个人编写的
- en: 'You should include linters in your code environment, but your specific choice
    will depend on the language you use. Good linters can be categorized based on
    the aspects they focus on, as outlined here:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在代码环境中包含检查工具，但具体选择将取决于你使用的编程语言。优秀的代码检查工具可以根据它们关注的方面进行分类，如下所述：
- en: '**Standardized coding**: Examples include SonarLint, Prettier, StandardJS,
    Brakeman, and StyleCop. Some languages such as .NET even include their own linter
    (Format).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化编码**：例如 SonarLint、Prettier、StandardJS、Brakeman 和 StyleCop。一些编程语言如 .NET
    甚至包括它们自己的代码检查工具（Format）。'
- en: '**Security**: GoSec, ESLint, or Bandit (Python module).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：GoSec、ESLint 或 Bandit（Python 模块）。'
- en: What’s more, some linters can be used for both of these aspects when the appropriate
    configurations are used. You can check for additional code analysis tools at [https://owasp.org/www-community/Source_Code_Analysis_Tools](https://owasp.org/www-community/Source_Code_Analysis_Tools).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，一些代码检查工具在使用适当的配置时，可以同时用于这两个方面。你可以访问 [https://owasp.org/www-community/Source_Code_Analysis_Tools](https://owasp.org/www-community/Source_Code_Analysis_Tools)
    来查看额外的代码分析工具。
- en: 'Let’s see a quick example using a Dockerfile linter, **Hadolint** ([https://github.com/hadolint/hadolint](https://github.com/hadolint/hadolint)).
    We will simply check a valid Dockerfile that does not include the best practices
    we learned in [*Chapter 1*](B19845_01.xhtml#_idTextAnchor015), *Modern Infrastructure
    and Applications with Docker*. Let’s see this in the following screenshot:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个使用 Dockerfile 检查工具 **Hadolint**（[https://github.com/hadolint/hadolint](https://github.com/hadolint/hadolint)）的快速示例来看看。我们将简单地检查一个有效的
    Dockerfile，它没有包含我们在[*第 1 章*](B19845_01.xhtml#_idTextAnchor015)中学到的最佳实践，*《现代基础设施与
    Docker 应用》*。让我们看看下面的屏幕截图：
- en: '![Figure 13.2 – Local Hadolint installation reviewing a simple Dockerfile](img/B19845_13_02.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – 本地 Hadolint 安装检查简单的 Dockerfile](img/B19845_13_02.jpg)'
- en: Figure 13.2 – Local Hadolint installation reviewing a simple Dockerfile
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – 本地 Hadolint 安装检查简单的 Dockerfile
- en: 'But the good thing here is that we can include this linter, or any other, inside
    container images and have a collection of linters ready to use for any language
    we might encounter. Let’s see how this works within a container using `docker
    run –i hadolint/hadolint` `hadolint -`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里的好处是，我们可以将这个检查工具或任何其他检查工具，包含在容器镜像中，并为我们可能遇到的任何语言准备一组现成的检查工具。让我们看看如何在容器中使用
    `docker run –i hadolint/hadolint` `hadolint -` 来实现：
- en: '![Figure 13.3 – Docker-based Hadolint execution reviewing a simple Dockerfile](img/B19845_13_03.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – 基于 Docker 的 Hadolint 执行检查简单的 Dockerfile](img/B19845_13_03.jpg)'
- en: Figure 13.3 – Docker-based Hadolint execution reviewing a simple Dockerfile
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – 基于 Docker 的 Hadolint 执行检查简单的 Dockerfile
- en: Important note
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: There are tools such as **Conftest** ([https://www.conftest.dev/](https://www.conftest.dev/))
    that can be integrated with different **Infrastructure as Code** (**IaC**) solutions
    and used to validate infrastructure scripts before they are deployed in our platform.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些工具，如**Conftest**（[https://www.conftest.dev/](https://www.conftest.dev/)），可以与不同的**基础设施即代码**（**IaC**）解决方案集成，并在将基础设施脚本部署到平台之前用于验证这些脚本。
- en: Linting tools can be executed automatically within our development processes
    to improve security. We will see this in action when we talk about CI/CD workflows.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 代码检查工具可以在我们的开发过程中自动执行，以提高安全性。我们将在讲解 CI/CD 工作流时看到它的实际应用。
- en: In the next section, we will introduce simple methodologies and practices to
    learn how CI can help us manage the life cycle of our applications.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将介绍简单的方法和实践，了解CI如何帮助我们管理应用程序的生命周期。
- en: Understanding CI patterns
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解CI模式
- en: CI refers to the practice of automating the integration of code changes from
    multiple contributors (or even multiple projects) into a single project. These
    automated processes may happen once a day or several times per hour. We can consider
    CI as the part of the software supply chain where we build our application (or
    its components) and launch different tests before moving to production. The second
    part of this process is deploying the application or its components into production,
    although some intermediate environments can also be employed to test the quality
    of the solution or certification in special circumstances (for example, integrating
    our solution with a third-party solution release from a vendor).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: CI指的是自动化将多个贡献者（甚至多个项目）的代码更改集成到单个项目中的实践。这些自动化过程可能每天发生一次，也可能每小时发生多次。我们可以将CI视为软件供应链的一部分，在这里我们构建我们的应用程序（或其组件）并在进入生产之前执行不同的测试。这个过程的第二部分是将应用程序或其组件部署到生产环境中，尽管在特殊情况下也可以使用一些中间环境来测试解决方案的质量或认证（例如，将我们的解决方案与来自供应商的第三方解决方案集成发布）。
- en: In this section, we are going to review some of the most common patterns used
    for CI in the most intuitive logical order. Developers should always get the last
    version of their code to start developing a new feature or start over the creation
    of a new component, or new release with fixes. Therefore, we will start our development
    process by pulling the code from a **version control** **system** (**VCS**).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将按照最直观的逻辑顺序审查一些用于CI的最常见模式。开发人员应始终获取他们的代码的最新版本来开始开发新功能，或者重新创建新组件，或者修复新版本。因此，我们将通过从**版本控制系统**（**VCS**）中拉取代码来开始我们的开发过程。
- en: Versioning the code
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码的版本控制
- en: A VCS is a tool that stores file and directory changes over time, allowing us
    to recover a specific version later. This tool is crucial from the developer’s
    perspective as it allows multiple developers to work together and track the changes
    made to application code over time. Versioning the code and the artifacts created
    allows us to run specific integration tests and deploy a specific release of our
    code.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: VCS是一个工具，可以随时间存储文件和目录的更改，使我们能够以后恢复特定版本。从开发者的角度来看，这个工具至关重要，因为它允许多个开发人员共同工作，并跟踪应用程序代码随时间所做的更改。对代码和创建的构件进行版本控制使我们能够运行特定的集成测试，并部署我们代码的特定发布版本。
- en: These tools usually run in *client-server* mode. Users interact using the relevant
    commands to push and pull the changes. The VCS stores and manages these changes.
    Once all the changes are synced (committed), you can proceed to build your applications’
    artifacts. This step may not be necessary if you are using an interpreted scripting
    language, although some bytecode artifacts may be created to speed up the application’s
    execution. We can automate this process and trigger a compilation of our code
    in certain circumstances – for example, when we do a commit (synchronization of
    the code). As a result, we get a **binary artifact** with all its dependencies
    every time we simply commit our code. But we can go further and create different
    branches on our code repository to allow different users to interact with the
    code at the same time or solve different code functionalities. Once all required
    changes are made, we can consolidate these branches into a common one and build
    the artifact again. Depending on the final product, the issues found, and the
    functionalities required, this process can be complicated, but automation can
    be used to create a common workflow that is much easier to follow and reproduce.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具通常以*客户端-服务器*模式运行。用户使用相关命令进行推送和拉取更改。VCS存储和管理这些更改。一旦所有更改都同步（提交），您就可以继续构建应用程序的构件。如果使用解释性脚本语言，则可能不需要此步骤，尽管可能会创建一些字节码构件以加速应用程序的执行。我们可以自动化此过程，并在特定情况下触发代码的编译
    - 例如，当我们提交（同步代码）时。因此，每次仅仅提交我们的代码时，我们就会获得一个带有所有依赖项的**二进制构件**。但是，我们可以进一步在我们的代码仓库上创建不同的分支，以允许不同的用户同时与代码交互或解决不同的代码功能。一旦完成所有所需的更改，我们可以将这些分支
    consol 统合到一个共同的分支，并再次构建构件。根据最终产品、找到的问题和所需的功能，这个过程可能很复杂，但是可以使用自动化来创建一个更容易遵循和重现的常规工作流。
- en: When a project is developed by multiple developers or teams, certain types of
    management are required to avoid collisions between changes. VCSs offer mechanisms
    to resolve incompatibilities between different pulls when multiple developers
    change the same files at the same time. `MAJOR.MINOR.PATCH` versioning syntax,
    where `MAJOR` indicates changes that may break compatibilities with previous releases,
    `MINOR` indicates that some functionality was added without breaking compatibility,
    and `PATCH` is used when some issues were solved without actually modifying any
    of the previous functionality. On the other hand, branch names can be used to
    reference any issues found and their solutions in the code.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个项目由多个开发者或团队共同开发时，必须进行一定类型的管理，以避免更改之间的冲突。版本控制系统（VCS）提供了机制来解决当多个开发者同时更改相同文件时不同拉取请求之间的不兼容问题。`MAJOR.MINOR.PATCH`
    版本语法，其中 `MAJOR` 表示可能会破坏与之前版本的兼容性的更改，`MINOR` 表示添加了某些功能且没有破坏兼容性，而 `PATCH` 用于解决某些问题，但实际上并没有修改任何先前的功能。另一方面，分支名称可以用来引用在代码中发现的任何问题及其解决方案。
- en: At this early stage, we can add some **validation tests** using linters to ensure
    proper code syntax, code quality, and the presence of security features (such
    as valid external dependencies) and exclude any sensitive information that may
    have made its way into the code.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个早期阶段，我们可以使用代码检查工具添加一些 **验证测试**，以确保代码语法的正确性、代码质量以及安全功能（如有效的外部依赖项）的存在，并排除任何可能已经进入代码的敏感信息。
- en: If we work with containers, our code should include at least one **Dockerfile**
    to allow us to create our container image artifact. Versioning of this file is
    also required, and thus it will be stored in our code repository (which is a VCS).
    Validation tests can be automated and executed to verify certain patterns such
    as the user executing the container’s main process or exposed ports.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用容器，我们的代码应至少包含一个 **Dockerfile**，以便创建我们的容器镜像文件。该文件也需要进行版本管理，因此它将存储在我们的代码仓库中（即版本控制系统）。验证测试可以自动化并执行，以验证某些模式，例如用户执行容器的主要进程或暴露的端口。
- en: A CI pipeline, therefore, is a group of workflow processes intended to automate
    software application code validation, construction, and integration. Accordingly,
    let’s quickly introduce the concept of DevOps here.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，CI 管道是一组旨在自动化软件应用程序代码验证、构建和集成的工作流过程。相应地，我们在这里简要介绍 DevOps 的概念。
- en: Introducing DevOps methodology
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入 DevOps 方法论。
- en: '**DevOps** is a methodology that improves software engineering by integrating
    and automating some of the stages of software development, the operational tasks
    related to the operation and maintenance of the systems where the applications
    run, and the applications themselves. We should think of DevOps as a culture that
    goes *beyond* groups or teams in your organization; it applies to your entire
    organization with the goal of minimizing time and friction between the development,
    deployment, and maintenance stages.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**DevOps** 是一种通过整合和自动化软件开发的某些阶段、与应用程序运行的系统的操作和维护任务以及应用程序本身的相关操作，来改善软件工程的方法论。我们应该把
    DevOps 看作是一种文化，它*超越*了你组织中的小组或团队；它适用于整个组织，目的是最小化开发、部署和维护阶段之间的时间和摩擦。'
- en: 'The following list shows some of the key features of the DevOps methodology:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了 DevOps 方法的一些关键特性：
- en: Automate as many tasks as possible in the software life cycle
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化软件生命周期中的尽可能多的任务。
- en: Collaboration between different teams as part of this culture makes things work
    more effectively
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同团队之间的协作，作为这种文化的一部分，使事情变得更加高效。
- en: Continuous revision and feedback from tasks, automation, and code quality, all
    of which are key to improving the software development processes
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续的任务修订和反馈、自动化以及代码质量，所有这些都是改进软件开发流程的关键。
- en: Monitoring and logging are part of the application life cycle, and they are
    important for improving its performance and finding code issues
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和日志记录是应用程序生命周期的一部分，它们对于提高性能和发现代码问题非常重要。
- en: 'Since DevOps covers a lot of tasks and disciplines, there are many tools available
    to help you with different tasks and stages. For example, for VCSs and code repositories,
    you can use very popular **cloud services** such as GitHub (acquired by Microsoft
    in 2018), Atlassian’s Bitbucket, or GitLab, among others. If you are looking for
    **on-premise solutions**, you can use open source offerings such as Gitea, GitLab,
    or Azure DevOps Server. Choosing the right tool for your organization can be complicated
    because many tools offer multiple features. The following schema represents some
    of the more popular DevOps tools related to the application development stage,
    showing where they fit in best:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 DevOps 涉及大量任务和学科，市面上有许多工具可以帮助你完成不同任务和阶段。例如，对于版本控制系统和代码库，你可以使用非常流行的**云服务**，如
    GitHub（2018 年被微软收购）、Atlassian 的 Bitbucket 或 GitLab 等。如果你在寻找**本地解决方案**，你可以使用开源工具，如
    Gitea、GitLab 或 Azure DevOps Server。为你的组织选择合适的工具可能会很复杂，因为许多工具提供了多种功能。以下示意图展示了与应用开发阶段相关的部分流行
    DevOps 工具，并显示它们最佳的适用位置：
- en: '![Figure 13.4 – Most popular DevOps tools](img/B19845_13_04.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.4 – 最受欢迎的 DevOps 工具](img/B19845_13_04.jpg)'
- en: Figure 13.4 – Most popular DevOps tools
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4 – 最受欢迎的 DevOps 工具
- en: Important note
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: A new methodology was recently introduced that focuses heavily on the security
    of development, deployment, and maintenance processes, called **DevSecOps**. This
    methodology emphasizes an extension of security as part of the culture of the
    different teams involved in the process. This is why we reviewed shift-left security
    practices, which are an aspect of DevSecOps that lies closer to the development
    teams. A DevSecOps culture breaks the old mindset in which a singular team is
    given the security role and participates in the development process only at the
    end, validating the code just before the software is moved into production.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最近推出了一种新的方法论，重点关注开发、部署和维护过程的安全性，称为**DevSecOps**。该方法论强调将安全性作为不同团队文化的一部分，延伸至整个过程。这也是我们回顾“左移安全”实践的原因，左移安全是
    DevSecOps 的一部分，更接近开发团队。DevSecOps 文化打破了传统的思维方式，以往只有一个单独的团队负责安全，并且仅在软件进入生产环境前的最后阶段参与开发过程，验证代码。
- en: Once the code is synced and validated, we are able to build our software solution.
    Let’s discuss this process next.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦代码同步并验证通过，我们就能构建我们的软件解决方案。接下来我们将讨论这一过程。
- en: Building artifacts
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建工件
- en: Depending on the programming language and its dependencies, it may be tricky
    to prepare environments for different releases. For example, moving from one previous
    Node.js release to a newer one may require separate build environments, even if
    the language is interpreted and not compiled.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 根据编程语言及其依赖项的不同，准备不同版本的环境可能会很棘手。例如，从一个较旧的 Node.js 版本迁移到较新的版本，可能需要独立的构建环境，即使该语言是解释型的，而非编译型的。
- en: Imagine a situation where different code developers need to compile their software
    at the same time in the same environment. It would be complete chaos, and errors
    from different releases would appear. Automation allows us to package environments
    and build our software using the appropriate environment. But we can go further
    by using software containers because these environments need only to exist at
    runtime, specifically when required, and we can use software containers to build
    our software using the required builder environment. The resulting container images
    of the complete build process are stored in a container image registry right after
    the successful building and validation of the new artifact.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一种情况，不同的代码开发人员需要在同一环境中同时编译他们的软件。这将是一场完全的混乱，且来自不同版本的错误会接踵而至。自动化可以让我们打包环境并使用合适的环境来构建软件。但我们可以进一步通过使用软件容器来实现，因为这些环境只需要在运行时存在，特别是在需要时。我们可以利用软件容器来构建我们的软件，使用所需的构建环境。成功构建并验证新工件后，完整构建过程的容器镜像会被存储在容器镜像注册中心。
- en: What is even more important is that we can prepare a full workflow in which
    all code is validated using our rules (code syntax, code quality, non-privileged
    execution, and so on), then the workflow triggers the build of the code, and finally,
    different tests (unity, integration, stress, performance, and so on) are triggered
    using the container images generated. We can forbid the execution of any application
    in production if it doesn’t come from this standardized construction workflow.
    You as a developer are able to code on your laptop and test your application,
    but you must pass all the corporate validation checks on a shared environment
    or platform before actually deploying in production (or sometimes even earlier,
    in the quality or certification stages).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，我们可以准备一个完整的工作流程，其中所有代码都通过我们的规则进行验证（代码语法、代码质量、非特权执行等），然后工作流程触发代码的构建，最后，使用生成的容器镜像触发不同的测试（单元测试、集成测试、压力测试、性能测试等）。如果某个应用程序的执行不来自这个标准化的构建工作流程，我们可以禁止其在生产环境中的执行。作为开发人员，你可以在笔记本电脑上编写代码并测试你的应用程序，但在实际部署到生产环境之前，你必须通过所有公司验证检查，在共享环境或平台上进行测试（有时甚至在质量或认证阶段之前）。
- en: Testing your application’s components
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试你的应用程序组件
- en: As mentioned before, automating different tests allows us to break the workflow
    whenever any test fails before moving on to the next step. To achieve this with
    containers, we can prepare some integrated processes using Docker Compose (for
    example) and validate how they work together. This can be done on your own desktop
    environment or using shared services, triggering the execution of the components
    by using defined tasks. These tasks also can be defined in Docker Compose format
    and be stored with your code. There are tools such as Jenkins that help us define
    these automated jobs and execute them on different systems. This tool is a very
    popular CI/CD orchestration tool created for managing build tasks on different
    systems that can be evolved to integrate the use of containers to simplify the
    overall workflow. Instead of having different nodes with separate releases for
    different languages or compilers, we can use software containers executed on a
    unique container runtime.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，自动化不同的测试可以让我们在任何测试失败时中断工作流程，避免进入下一步。为了通过容器实现这一点，我们可以使用 Docker Compose（例如）准备一些集成的流程，验证它们如何协同工作。这可以在你自己的桌面环境中完成，或者使用共享服务，借助定义的任务触发组件的执行。这些任务也可以在
    Docker Compose 格式中定义，并与代码一起存储。有些工具如 Jenkins 可以帮助我们定义这些自动化作业，并在不同的系统上执行它们。这个工具是一个非常流行的
    CI/CD 协调工具，旨在管理不同系统上的构建任务，并可以扩展到整合容器的使用，从而简化整体工作流程。我们可以通过使用唯一的容器运行时，利用软件容器，而不是为不同的语言或编译器拥有不同的节点和单独的发布版本。
- en: Monitoring the build processes and tests
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控构建过程和测试
- en: To understand how changes can improve or have a negative impact on our applications,
    we need to continuously measure the performance and output of the different tests.
    We must always ensure we monitor the workflow processes because this will help
    us to improve the overall development process thanks to the iteration of the different
    tests. Popular CI orchestration tools always measure the build time, and we can
    retrieve the time spent during the execution of chained jobs, hence we will be
    able to trace how a certain change in our code (for example, the addition of new
    dependencies) impacts the build and modify the tests accordingly.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解变化如何改善或对我们的应用程序产生负面影响，我们需要持续测量不同测试的性能和输出。我们必须始终确保监控工作流程过程，因为这将通过不同测试的迭代帮助我们改进整体开发过程。流行的
    CI 协调工具总是会测量构建时间，我们可以检索执行链式作业时所花费的时间，因此我们将能够追踪代码中的某个变化（例如，添加新的依赖项）如何影响构建并相应地修改测试。
- en: Sharing information about the development process
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分享开发过程中的信息
- en: DevOps culture is all about communicating changes, exchanging feedback, and
    sharing information about any issues that arise to align all the teams involved
    in the process. Automation will avoid many misunderstandings; everything should
    be reproducible, hence the same results will be expected if we don’t change anything.
    All changes must be traceable to allow us to quickly identify issues related to
    any given change and apply the appropriate patches. As we saw in *Figure 13**.4*,
    there are many tools available to assist us in keeping our teams informed. One
    good practice is to implement automatic notifications sent by the different tools
    whenever a development task is executed (code changes, validated tests, and so
    on).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 文化强调沟通变更、交换反馈以及共享有关出现问题的信息，以确保参与过程的所有团队达成一致。自动化将避免许多误解；所有操作都应该是可重现的，因此如果我们没有更改任何内容，期望结果应该是相同的。所有更改必须可追溯，以便我们能迅速识别与特定更改相关的问题并应用适当的修补程序。正如我们在*图
    13**.4*中所看到的，有许多工具可以帮助我们保持团队的知情。一项好的实践是实现自动通知，每当开发任务执行时（如代码更改、验证测试等），由不同工具自动发送通知。
- en: Excluding configurations from code
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从代码中排除配置
- en: Although it might be obvious, we should keep any configuration or sensitive
    information for the application out of the code. It would be nice to include a
    set of default values and some documentation covering how to change them, but
    keep in mind that your application will pass through several phases and maybe
    different environments. In this book, we have looked at multiple mechanisms used
    to include sensitive information and configurations within containers ([*Chapter
    2*](B19845_02.xhtml#_idTextAnchor036), [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096),
    and [*Chapter 5*](B19845_05.xhtml#_idTextAnchor118)). Never include certificates,
    even if they are just required for a simple step in which you download some artifact
    from a self-signed or corporate server. It is important to understand that sometimes,
    it is even necessary to use versioning for configurations. If you change the way
    you use a variable in your code, it may break a rollback to a previous release.
    In such cases, you may also need to store configurations in the versioning system.
    But keep in mind that the audience of this repository is probably different from
    the repository that stores your code. Automation helps us to keep track of the
    different code releases with the appropriate configurations and ensure that every
    task runs smoothly.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能显而易见，但我们应该将应用程序的任何配置或敏感信息排除在代码之外。最好包括一组默认值以及一些文档，说明如何更改这些值，但请记住，您的应用程序将经历多个阶段，可能还有不同的环境。在本书中，我们探讨了多种机制，用于在容器中包含敏感信息和配置（[*第二章*](B19845_02.xhtml#_idTextAnchor036)，[*第四章*](B19845_04.xhtml#_idTextAnchor096)，以及[*第五章*](B19845_05.xhtml#_idTextAnchor118)）。绝不应包含证书，即使它们只是用于从自签名或公司服务器下载某些工件的简单步骤。重要的是要理解，有时需要为配置使用版本控制。如果您更改了代码中变量的使用方式，可能会导致回滚到先前版本时失败。在这种情况下，您可能还需要将配置存储在版本控制系统中。但请记住，这个仓库的受众可能与存储代码的仓库不同。自动化帮助我们跟踪不同版本的代码和相应配置，并确保每个任务顺利进行。
- en: Now that we have reviewed the first part of the development process, where the
    application is coded, compiled, and validated, we can move on to the delivery
    stage.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们回顾了开发过程的第一部分（即应用程序的编码、编译和验证）之后，我们可以进入交付阶段。
- en: Automating continuous application deployment
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化持续应用部署
- en: In this section, we are going to examine the second part of the software development
    process – the delivery of the product. Many organizations invest all their efforts
    into CI, leaving the determination of whether or not software should be executed
    in production to a manual decision.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论软件开发过程的第二部分——产品交付。许多组织将所有精力投入到持续集成（CI）中，而将是否在生产环境中执行软件的决定交给人工来做。
- en: 'A CD pipeline gets changes from the artifacts and code repositories, including
    required configurations, and deploys them into production in a fluent and continuous
    way. To achieve this, we need to somehow package all these artifacts and configurations
    in a reproducible and deployable state, aiming to keep the maximum stability and
    reliability in our systems. The following list shows some of the most notable
    benefits of using CD:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: CD管道从工件和代码仓库获取更改，包括所需的配置，并以流畅和持续的方式将它们部署到生产环境中。为了实现这一目标，我们需要以某种方式将所有这些工件和配置打包成可复现且可部署的状态，旨在保持我们系统的最大稳定性和可靠性。以下列表展示了使用CD的一些最显著的好处：
- en: We mitigate the risks of deploying new releases because automation ensures a
    quick rollback in case something goes wrong
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们降低了部署新版本的风险，因为自动化确保了在出现问题时能够快速回滚
- en: Automation may use blue–green and canary deployments, enabling new application
    releases while older processes are still serving
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化可以使用蓝绿部署和金丝雀部署，在较旧的进程仍在提供服务的同时启用新的应用程序发布。
- en: Lower **time to market** (**TTM**) and reduced costs can be reliably expected
    due to the level of confidence generated by the application’s life cycle
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于应用程序生命周期所带来的信任度，**市场上线时间**（**TTM**）缩短和成本降低是可以可靠预期的
- en: While CI automates the build and testing stages, CD on the other hand continues
    the process and goes a step further, automating the packaging, deployment, and
    testing throughout the rest of the life cycle.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CI自动化了构建和测试阶段，但CD则继续这个过程并更进一步，自动化整个生命周期中打包、部署和测试的工作。
- en: While the benefits of CI are for developers, we might think that CD is more
    targeted at operations teams. However, in the DevOps culture, many stages are
    shared between the two groups. The major benefits of using CD extend even to the
    end users because applications are always kept updated and don’t suffer outages
    between changes. Additionally, new functionalities can be added with less friction.
    Users can provide feedback using the defined channels (see the tools presented
    in *Figure 13**.4*), and monitoring, logging, and tracing the software allows
    us to enrich this feedback, and then the cycle starts again to keep improving
    the application’s code.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管持续集成（CI）的好处主要面向开发人员，但我们可能认为持续交付（CD）更侧重于运维团队。然而，在DevOps文化中，很多阶段是两个团队共享的。使用CD的主要好处甚至扩展到最终用户，因为应用程序始终保持更新，并且在变更之间不会发生停机。此外，新功能的添加也更少遇到阻力。用户可以通过定义的渠道提供反馈（请参见*图13.4*），而监控、日志记录和追踪软件使我们能够丰富这些反馈，然后循环重新开始，不断改进应用程序的代码。
- en: If we give some thought to how can we implement the different stages of CD automation,
    containers fit perfectly as we can package container images and the application’s
    configurations for different environments and deploy the software solution. In
    case of errors, container runtimes provide **resilience**, and container orchestrators
    allow us to roll back to the previous release in seconds, informing us of the
    issues encountered during deployment. As mentioned before, blue–green and canary
    deployments allow us to progressively deploy a new release or test it with just
    a few users to avoid a massive outage if anything goes wrong.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们思考如何实现CD自动化的不同阶段，容器非常适合这一需求，因为我们可以为不同环境打包容器镜像和应用程序的配置，并部署软件解决方案。如果出现错误，容器运行时提供**弹性**，而容器编排工具则允许我们在几秒钟内回滚到之前的版本，并告知我们部署过程中遇到的问题。如前所述，蓝绿部署和金丝雀部署使我们能够逐步部署新版本，或仅通过少数用户进行测试，以避免发生大规模停机。
- en: Important note
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Modern application life cycle models, such as **GitOps**, manage the deployment
    of software releases by defining a repository as the **source of truth** (**SOT**).
    Any change within our applications or even the Kubernetes clusters themselves
    are managed as out-of-sync situations, requiring either manual intervention or
    automatic triggers to apply the appropriate changes and synchronize the situation
    with the required configuration (SOT). In such scenarios, we will just customize
    how the deployment packages will be executed on each environment by setting a
    required state for the application. Resource upgrades or rollbacks will be executed
    to synchronize the current status with the required one.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现代应用程序生命周期模型，如**GitOps**，通过将存储库定义为**真相源**（**SOT**）来管理软件发布的部署。我们应用程序内部的任何更改，甚至是Kubernetes集群本身，都被视为不同步的情况，需要手动干预或自动触发器来应用适当的更改并将情况与所需配置（SOT）同步。在这种情况下，我们将根据应用程序的所需状态自定义如何在每个环境中执行部署包。资源升级或回滚将被执行，以将当前状态与所需状态同步。
- en: Monitoring the actual performance of the new deployment is key in situations
    where you are limiting access to a new release while most users are still using
    the old one. Should we go further with our new release, we must have a reliable
    **performance baseline** to fully understand how the changes are impacting our
    application’s services. Although we may have passed all our performance tests
    successfully, deploying a new release may show different behaviors when accessed
    by real users. The better the tests in the testing stages, the lower the gap between
    the real user experience and the automated test, which lowers the risks of releasing
    a new version.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 监控新部署的实际性能对于在大多数用户仍在使用旧版本的情况下限制对新版本的访问至关重要。如果我们要继续使用新版本，我们必须有可靠的**性能基线**，以充分了解变更如何影响我们应用程序的服务。尽管我们可能已经成功通过了所有性能测试，但部署新版本可能会在真实用户访问时显示不同的行为。在测试阶段测试越好，真实用户体验与自动化测试之间的差距就越小，这降低了发布新版本的风险。
- en: '**Logging** is also important. We use logs to search for well-designed error
    patterns. The log standardization in your corporation can be used to easily implement
    common patterns for all your application’s components and provide a single logging
    control plane for all processes at once, which will make it easy to find errors
    across multiple logs and verify how some requests affect different components
    at specific time frames.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**日志记录**也很重要。我们使用日志搜索设计良好的错误模式。您公司的日志标准化可用于轻松为所有应用程序组件实施常见模式，并为所有进程提供单一的日志控制平面，这将使跨多个日志轻松查找错误，并验证某些请求如何在特定时间段影响不同组件。'
- en: Tracing in production is *not* recommended unless you have some dedicated instances
    of your project for that purpose or you are reviewing a critical error.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中进行跟踪*不*推荐，除非您有专门用于此目的的项目实例，或者您正在审查关键错误。
- en: Retrieving **user feedback** is the final step of the complete application’s
    life cycle. User feedback, alongside monitoring and logging (and eventually tracing)
    of the application components, feeds into the next iteration of the application’s
    life cycle process to improve its overall performance and behavior, and the process
    starts over.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 检索**用户反馈**是完整应用程序生命周期的最后一步。用户反馈，连同应用程序组件的监控和日志记录（最终跟踪）一起，进入应用程序生命周期流程的下一次迭代，以改善其整体性能和行为，然后流程重新开始。
- en: We examined some open source monitoring, logging, and tracing tools back in
    [*Chapter 12*](B19845_12.xhtml#_idTextAnchor267), *Gaining Application Insights*.
    To get users’ feedback, any ticketing software will be fine, but the smoother
    it integrates into the full DevOps paradigm, the better. In *Figure 13**.4*, we
    showed some of the most common and popular DevOps tools. All serious code repositories
    include an **issue tracking system** with which you can align users’ comments
    and issues with actual code commits, solving these issues or adding requested
    functionalities.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[*第12章*](B19845_12.xhtml#_idTextAnchor267)中审查了一些开源监控、日志记录和跟踪工具，*获得应用洞察*。要获得用户反馈，任何故障跟踪软件都可以，但它与完整的DevOps范式集成得越顺畅，越好。在*图13**.4*中，我们展示了一些最常见和流行的DevOps工具。所有严肃的代码存储库都包括一个**问题跟踪系统**，您可以将用户的评论和问题与实际的代码提交对齐，解决这些问题或添加请求的功能。
- en: As you can imagine, some of these tools can be deployed on and integrated into
    Kubernetes. The next section presents a sample DevOps environment in which we
    will use some of the tools presented in *Figure 13**.4* to provide a full application
    life cycle management platform.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所想，一些工具可以部署到Kubernetes中并进行集成。下一节将展示一个示例DevOps环境，在这个环境中，我们将使用*图13.4*中展示的一些工具来提供完整的应用程序生命周期管理平台。
- en: Orchestrating CI/CD with Kubernetes
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes协调CI/CD
- en: This section will help us understand the full life cycle of an application prepared
    and managed within a Kubernetes cluster. Let’s start by reviewing the CI part.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将帮助我们理解在Kubernetes集群中准备和管理的应用程序的完整生命周期。让我们从回顾CI部分开始。
- en: Understanding the CI component of the workflow
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解工作流中的CI组件
- en: The CI part of our workflow is where we code, build, and test our solution.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工作流中的CI部分是我们编码、构建和测试解决方案的地方。
- en: At the beginning of the project, user requirements are collected. Subsequently,
    during the development stage, you can use your favorite code editor. Depending
    on the programming language you use, compilation may be necessary, which requires
    you to have installed compilers. Instead of that, you can use software containers
    to run the actual compilation steps. You will be able to use different releases
    of code compilers, with different environments and sets of tools at the same time
    without actually having to install any of them. Indeed, managing multiple releases
    of certain code environments on a single computer can be tricky. Building your
    application’s code using containers will help you decide which container images
    would best fit your needs for each stage (building the application’s artifacts,
    and running them for either testing or production).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目开始时，会收集用户需求。随后，在开发阶段，您可以使用自己喜欢的代码编辑器。根据您使用的编程语言，可能需要进行编译，这就要求您安装编译器。您也可以使用软件容器来执行实际的编译步骤。这样，您将能够同时使用不同版本的代码编译器，享受不同环境和工具集，而不需要实际安装任何一个。事实上，在一台计算机上管理多个版本的代码环境可能会很棘手。使用容器构建应用程序代码将帮助您决定在每个阶段（构建应用程序的构件以及用于测试或生产的运行）哪些容器镜像最适合您的需求。
- en: Next, in the CI workflow, you build your binaries and prepare the Dockerfiles
    for your application’s components. Multiple Dockerfiles can be created for a single
    component, specifying things such as the inclusion or omission of some debugging
    tools or flags that could be very useful during the testing stages.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在CI工作流中，您将构建二进制文件并准备应用程序组件的Dockerfile。可以为单个组件创建多个Dockerfile，指定是否包括某些调试工具或标志，这些工具或标志在测试阶段可能非常有用。
- en: Then, you build your container images. Production images must be clean and only
    include the binaries and libraries required for running your application’s processes.
    You can build your code artifacts and container images for testing the application
    in your coding environment, although you may already have a shared environment
    for such tasks.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要构建容器镜像。生产镜像必须是干净的，仅包含运行应用程序进程所需的二进制文件和库。您可以为应用程序在编码环境中构建代码构件和容器镜像进行测试，尽管您可能已经有了一个共享的环境来执行这些任务。
- en: With containers, it becomes possible to locally test each application component
    (unit tests) or even the full application stack (integration tests) using Docker
    Compose. In such a case, you will need access to the other application components’
    container images and some mock configurations that will help you run a sample
    environment more easily. It’s usual to include some mocked-up default values and
    perhaps some test connection strings, authentications, and tokens (which will
    be overwritten during execution with real values). Having *sample values* is key
    when you work in a team, and other developers may need to execute your artifacts
    and adjust their parameters to meet their needs.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用容器后，您可以使用Docker Compose本地测试每个应用程序组件（单元测试），甚至是完整的应用程序堆栈（集成测试）。在这种情况下，您需要访问其他应用程序组件的容器镜像和一些模拟配置，这些配置将帮助您更轻松地运行示例环境。通常会包含一些模拟的默认值，也许还有一些测试连接字符串、认证和令牌（这些将在执行过程中被真实值覆盖）。拥有*示例值*在团队合作中至关重要，其他开发者可能需要执行您的构件并调整其参数以满足他们的需求。
- en: You are likely to work on a specific branch of the code depending on the development
    stage you are in. Code branches are usually used to either fix issues or develop
    new functionalities and allow multiple developers to code in parallel on different
    resources at the same time. Once a given issue is solved and tested successfully,
    the code can be committed, pushed, and finally merged into the main code.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你所在的开发阶段，你可能会在代码的特定分支上工作。代码分支通常用于修复问题或开发新功能，允许多个开发人员在不同的资源上并行编码。一旦某个问题得到解决并成功测试，代码就可以提交、推送，并最终合并到主代码中。
- en: You may have your own code routine, but chances are it is quite similar to the
    one described here (the order of steps may vary, but ultimately the main code
    should contain your changes), and you probably apply similar steps for adding
    some new functionality or fixing an issue.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能有自己的代码流程，但很可能它与你这里描述的流程非常相似（步骤的顺序可能不同，但最终主要代码应包含你的更改），而且你可能会应用类似的步骤来添加一些新功能或修复问题。
- en: Pushing the new code to the code repository will trigger automation mechanisms
    that create appropriate artifacts (binaries, libraries, and container images)
    using tags and labels to help you track the changes associated and the issues
    or functionalities included. This allows you to either use your own built artifacts
    or those created by the automation system using your build rules and the Dockerfiles
    included in your code. It is recommended to use the artifacts created by the automated
    build environment because your DevOps team has most likely created a full supply
    chain, and this step is just the beginning of a longer process in which they will
    use these automatically created artifacts.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 将新代码推送到代码库时，将触发自动化机制，这些机制使用标签和标签来创建适当的工件（如二进制文件、库和容器镜像），帮助你追踪相关的更改以及包括的问题或功能。这使得你可以使用自己构建的工件，或使用自动化系统根据你的构建规则和代码中包含的
    Dockerfiles 创建的工件。建议使用自动化构建环境创建的工件，因为你的 DevOps 团队很可能已经创建了一个完整的供应链，这一步只是一个更长过程的开始，在这个过程中他们将使用这些自动创建的工件。
- en: Code repositories will probably run on top of Kubernetes in your on-premise
    infrastructure, although you could use SaaS services instead. Depending on the
    integrations required for the different steps, it may be difficult to fully integrate
    cloud solutions with on-premises tools without taking on risks such as having
    certain data center credentials stored on your cloud platform (integration from
    cloud repositories to your on-premises Kubernetes clusters, for example). You
    should always ensure minimal required privileges for all your platform integrations,
    no matter whether they run on the cloud or your own data center.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 代码库很可能会在你本地基础设施上的 Kubernetes 之上运行，尽管你也可以选择使用 SaaS 服务。根据不同步骤所需的集成，完全将云解决方案与本地工具集成可能会很困难，因为这样可能会带来一定的风险，比如某些数据中心凭证存储在你的云平台上（例如，从云代码库到你本地
    Kubernetes 集群的集成）。你应始终确保所有平台集成的最小所需权限，无论它们是运行在云端还是你自己的数据中心。
- en: Once your code is pushed to the code repository, different triggers can be configured
    to first validate the quality of your code, the maturity and security of the dependencies
    included in your project, and the security itself of your code and built binaries.
    For these tasks, the different tools presented in *Figure 13**.4* can be used.
    For example, we can configure some container images with programming language
    linters and rules, and execute containers injecting our code for its validation.
    The process can be stopped whenever any test isn’t passed or just inform us at
    the end of the check about some minor or major improvements we can make to our
    code. These tasks can be configured as jobs in our favorite CI/CD orchestration
    environment, probably also running on Kubernetes to leverage the availability
    of the cluster container runtimes. Some of the most popular CI/CD orchestrators
    are presented in *Figure 13**.4*, but many advanced code repositories include
    task management functionality of their own, which simplifies the number of tools
    required for running our complete CI/CD workflows. For example, we can use GitLab
    for storing and versioning our code, storing and managing our artifacts (built
    artifacts and container images), and executing different CI/CD tasks. We will
    see platforms such as this in action in the *Labs* section with a full example.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的代码推送到代码仓库，可以配置不同的触发器，首先验证代码的质量、项目中所包含的依赖项的成熟度和安全性，以及代码本身和构建的二进制文件的安全性。为了完成这些任务，可以使用*图
    13**.4*中展示的不同工具。例如，我们可以配置一些带有编程语言代码检查器和规则的容器镜像，并执行注入我们代码进行验证的容器。该过程可以在任何测试未通过时停止，或者在检查结束时通知我们有关代码改进的建议，无论是小改动还是大改进。这些任务可以作为作业配置在我们喜欢的CI/CD编排环境中，可能还会运行在Kubernetes上，以利用集群容器运行时的可用性。*图
    13**.4*中展示了一些最流行的CI/CD编排工具，但许多高级代码仓库已经包括了自己的任务管理功能，这简化了执行完整CI/CD工作流所需的工具数量。例如，我们可以使用GitLab来存储和版本化代码，存储和管理构建产物（构建的产物和容器镜像），并执行不同的CI/CD任务。我们将在*实验*部分通过完整示例看到这些平台的实际应用。
- en: As mentioned before, consecutive validation tasks (tests) can be triggered,
    and as a final step, we can build a container image ready for production. At this
    time, new tests can be executed for testing the integration of the new component
    release with other application components and validate the performance of the
    solution. Depending on the required integrations, this pipeline (that is, the
    definition of the different concatenated tasks to be executed) can be complex.
    It is usually recommended to group tasks and prepare the output of the different
    processes involved to provide easy-to-read reports. Most of the tools mentioned
    in the validation group of *Figure 13**.4* provide summary reports that can be
    parsed to find any errors that should stop the workflow. The tasks associated
    with the pipeline can be executed within containers (isolated Pods on Kubernetes),
    and their logs should be available in the CI/CD orchestrators as these containers
    will be volatile.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，可以触发连续的验证任务（测试），作为最终步骤，我们可以构建一个准备好生产环境的容器镜像。此时，可以执行新的测试，验证新组件发布与其他应用组件的集成，并验证解决方案的性能。根据所需的集成，整个流水线（即定义不同的串联任务以执行）可能会很复杂。通常建议将任务进行分组，并准备不同过程的输出，以提供易于阅读的报告。*图
    13**.4*中验证组提到的大多数工具提供了总结报告，这些报告可以解析，查找任何应停止工作流的错误。与流水线相关的任务可以在容器中执行（Kubernetes上的隔离Pod），并且这些容器的日志应该在CI/CD编排工具中可用，因为这些容器将是易失性的。
- en: Depending on the complexity of the application, it might be worthwhile to package
    the required components before the tests. You probably wouldn’t execute simple
    manifests in your Kubernetes environments, and you would use Helm charts or Kustomize
    to create packages for either your full application or each component.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 根据应用的复杂性，可能值得在执行测试之前先打包所需的组件。你可能不会在Kubernetes环境中执行简单的清单，而是会使用Helm Charts或Kustomize为你的整个应用或每个组件创建包。
- en: Important note
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Some tools such as **Argo CD** can use Helm charts as templates for application
    deployments. Although we do not really deploy our application using a Helm chart,
    it will be used by the process to manage and manipulate the Kubernetes resources
    associated with your application. That’s why it is always worthwhile preparing
    your applications as packages: it allows someone else to easily deploy your full
    application or some components therein without really knowing the contents back
    to front.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工具，如**Argo CD**，可以将 Helm 图表用作应用程序部署的模板。尽管我们并不直接使用 Helm 图表来部署应用程序，但该过程将使用它来管理和操作与您的应用程序相关的
    Kubernetes 资源。这就是为什么将应用程序准备为包总是值得的原因：它允许其他人轻松部署您的完整应用程序或其中的一些组件，而无需真正了解内容的细节。
- en: Before we continue, let’s see some of the most important features of Helm and
    how to create a simple manifests package.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们看看 Helm 的一些重要功能，以及如何创建一个简单的清单包。
- en: Using Helm to package our application’s resource manifests
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Helm 打包我们的应用程序资源清单
- en: '**Helm** is a tool that packages Kubernetes resource manifests using templated
    YAML files and automation scripts that allow us to completely configure and deploy
    applications using a simple command line and a configuration file.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**Helm** 是一个工具，它使用模板化的 YAML 文件和自动化脚本打包 Kubernetes 资源清单，允许我们通过简单的命令行和配置文件完全配置和部署应用程序。'
- en: Using Helm charts, we can replace all application resource manifests at once
    or only those that were changed, with a simple path to roll them back to a previous
    release at any time. Helm keeps track of all the changes made to a Helm instance
    and is capable of reverting those changes by applying a previously stored release
    version.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Helm 图表，我们可以一次性替换所有应用程序资源清单，或者仅替换那些已经更改的部分，并通过简单的路径随时将其回滚到之前的版本。Helm 会跟踪所有对
    Helm 实例所做的更改，并能够通过应用先前存储的发布版本来恢复这些更改。
- en: 'When we execute `helm create <NAME_OF_THE_CHART>`, Helm creates a directory
    structure that contains some example manifests and other files used to create
    a new Helm chart package:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行 `helm create <NAME_OF_THE_CHART>` 时，Helm 会创建一个包含一些示例清单和其他文件的目录结构，这些文件用于创建一个新的
    Helm 图表包：
- en: '![Figure 13.5 – Helm chart file structure](img/B19845_13_05.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.5 – Helm 图表文件结构](img/B19845_13_05.jpg)'
- en: Figure 13.5 – Helm chart file structure
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – Helm 图表文件结构
- en: 'In this code snippet, we used `helm create` to create a Helm chart tree structure.
    You may have noticed the existence of the `charts` directory. A Helm chart can
    contain other Helm charts as dependencies. This way, we can create an `Chart.yaml`
    file describes the dependencies of your package and its version. You will find
    two versioning properties in your `Chart.yaml` file:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们使用了 `helm create` 来创建 Helm 图表树结构。您可能注意到 `charts` 目录的存在。一个 Helm 图表可以包含其他
    Helm 图表作为依赖项。这样，我们可以创建一个 `Chart.yaml` 文件，描述您的包及其版本的依赖关系。在您的 `Chart.yaml` 文件中，您将找到两个版本控制属性：
- en: The `version` key, which indicates the package release number
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version` 键，表示包的发布版本号'
- en: The `appVersion` key, which is used to identify your application release
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`appVersion` 键，用于标识您的应用程序发布版本'
- en: Important note
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Helm charts can be uploaded to repositories for storage and to share with other
    users. This way, your applications can be deployed by anyone authorized to pull
    and execute the Helm chart containing the manifests. Many vendors and open source
    projects offer their Helm charts as a way to deploy their applications, and some
    community-driven repositories host thousands of charts ready to use in your projects.
    Two of the most popular repositories are *ArtifactHub* ([https://artifacthub.io](https://artifacthub.io))
    and *Bitnami Application* *Stacks* ([https://bitnami.com/stacks/helm](https://bitnami.com/stacks/helm)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 图表可以上传到仓库进行存储并与其他用户共享。通过这种方式，任何被授权拉取并执行包含清单的 Helm 图表的用户都可以部署您的应用程序。许多供应商和开源项目提供他们的
    Helm 图表，作为部署其应用程序的一种方式，一些社区驱动的仓库托管着成千上万的图表，供您在项目中使用。两个最受欢迎的仓库是 *ArtifactHub* ([https://artifacthub.io](https://artifacthub.io))
    和 *Bitnami 应用程序* *堆栈* ([https://bitnami.com/stacks/helm](https://bitnami.com/stacks/helm))。
- en: The magic behind the management and composition of some key variables, such
    as the instance name, is included in the `_helpers.tpl` file, and the composed
    variables will be used in all the YAML manifest files included within the `templates`
    directory. We will include all the manifests required for our application or its
    components to work. All the PersistentVolumeClaims, Deployments, StatefulSets,
    DaemonSets, Secrets, and ConfigMaps should be included. Indeed, if our application
    requires specific permissions, we must also include ServiceAccounts and the appropriate
    Role and RoleBinding manifests. The `values.yaml` file included by default is
    used to validate the manifests that will be created with the `helm` command with
    a set of default values. This is another validation test that can be included
    in our pipeline just before the creation of the Helm chart package. If this `values.yaml`
    file implements all the required values (a mocked version), the pipeline process
    can continue and create the Helm chart package. The Helm chart’s files should
    also be managed using a versioning system; hence, we will store them in our code
    repository. Whether or not to use a different repository depends on you as a developer,
    but it would be nice to manage different releases for the application’s components
    and the Helm charts that deploy them, and it will be easier if we use different
    repositories.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一些关键变量的管理和组合背后的魔法，比如实例名称，包含在`_helpers.tpl`文件中，组合后的变量将用于`templates`目录中的所有 YAML
    清单文件。我们将包含所有使应用程序或其组件能够正常工作的清单。所有的 PersistentVolumeClaims、Deployments、StatefulSets、DaemonSets、Secrets
    和 ConfigMaps 都应该被包括在内。事实上，如果我们的应用程序需要特定的权限，我们还必须包括 ServiceAccounts 以及相应的 Role
    和 RoleBinding 清单。默认包含的`values.yaml`文件用于验证通过`helm`命令创建的清单，这些清单会使用一组默认值。这是另一个可以在我们管道中包含的验证测试，测试可以在创建
    Helm 图表包之前进行。如果这个`values.yaml`文件实现了所有必需的值（一个模拟版本），管道过程可以继续并创建 Helm 图表包。Helm 图表的文件也应该使用版本控制系统进行管理，因此我们将它们存储在我们的代码仓库中。是否使用不同的仓库取决于您作为开发人员的决定，但如果我们使用不同的仓库来管理应用程序组件和部署它们的
    Helm 图表的不同版本，那会更好。
- en: In the *Labs* section, you will work through a full example using the `simplestlab`
    application. We prepared a Helm chart for each application’s component and an
    umbrella chart that deploys the full application.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在*实验室*部分，您将通过使用`simplestlab`应用程序的完整示例进行操作。我们为每个应用程序的组件准备了一个 Helm 图表，以及一个部署完整应用程序的伞形图表。
- en: 'Let’s summarize the steps described so far before continuing with the rest
    of the pipeline chain that describes the application’s life cycle:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续描述应用程序生命周期的管道链的其余部分之前，让我们总结一下到目前为止描述的步骤：
- en: Write your code and push it to the code repository. Our code should include
    at least one Dockerfile for building the container image or images for the application’s
    component. Although it is not required, it is recommended to maintain a separate
    code repository for storing your Helm chart files. This way, you can follow the
    same code workflow for both the application’s code and the Helm chart’s code,
    but isolating each repository allows us to manage a different release for the
    code and the Helm chart’s package.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写代码并将其推送到代码仓库。我们的代码应至少包含一个用于构建应用程序组件容器镜像的 Dockerfile。尽管不是强制要求，但建议为存储 Helm 图表文件维护一个单独的代码仓库。这样，您可以对应用程序代码和
    Helm 图表代码遵循相同的代码工作流，但将每个仓库隔离开来可以让我们管理代码和 Helm 图表包的不同版本。
- en: Code will be validated using the relevant linters to verify its quality, its
    compliance with your organization’s coding rules, its dependencies, and its inner
    security (do not include sensitive information unless it is mocked).
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将使用相关的 linter 来验证代码，确保其质量、符合组织的编码规范、其依赖关系以及内在安全性（除非是模拟的，否则不要包含敏感信息）。
- en: Different artifacts will be created and stored in your repositories. When your
    code is built, the resulting artifacts (binaries and libraries) will be stored
    (in our example, in GitLab). Storing artifacts is important if they are shared
    between components, such as binaries and client libraries, for example. Container
    images are also stored in GitLab as it additionally provides image registry capabilities.
    You can use a different repository for each type of artifact, but GitLab is a
    good catch-all solution because it offers storage for code, artifacts, and container
    images.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同的制品将会在你的代码仓库中创建并存储。当代码构建完成时，生成的制品（如二进制文件和库文件）将被存储（在我们的示例中，是在GitLab中）。如果制品在组件之间共享，例如二进制文件和客户端库等，那么存储这些制品是非常重要的。容器镜像也会存储在GitLab中，因为GitLab还提供了镜像注册表功能。你可以为每种制品使用不同的仓库，但GitLab是一个很好的通用解决方案，因为它提供了代码、制品和容器镜像的存储。
- en: When all the artifacts (the build and container images) are created, we can
    either automate the execution of the unit tests or pull the resulting release
    images (with fixes or new functionalities) and test them on our development computer,
    or even do both.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当所有的制品（构建和容器镜像）都创建完成后，我们可以自动执行单元测试，或者将生成的发布镜像（包括修复或新功能）拉取到开发计算机上进行测试，甚至可以两者兼顾。
- en: Integration tests may require packaging the application’s components. If this
    is the case, validation of the Helm chart code will be triggered, and then the
    package will be created. Sometimes, we just change the application’s container
    image (that is, we change some code, which triggers a new artifact build and a
    new image is created) without actually changing the application’s Helm charts.
    That’s why it is always useful to keep track of Helm chart package template changes
    in a different repository from the application’s code. You may need to upgrade
    your application’s code without changing the templated deployment manifests. Here,
    we would just need the customized values for deploying a new container image and
    the `appVersion` key on your `Chart.yaml` file. This is a good practice because
    you will be able to track your package and application release at the same time.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集成测试可能需要打包应用程序的组件。如果是这种情况，则会触发Helm图表代码的验证，随后创建包。有时，我们只是更改应用程序的容器镜像（即，我们更改一些代码，触发新的制品构建并创建新的镜像），而不实际更改应用程序的Helm图表。因此，始终保持跟踪Helm图表包模板的更改，并将其存放在与应用程序代码不同的仓库中是非常有用的。你可能需要在不更改模板化部署清单的情况下升级应用程序代码。在这种情况下，我们只需要用于部署新容器镜像的自定义值和`Chart.yaml`文件中的`appVersion`键。这是一个好的做法，因为你将能够同时跟踪你的包和应用程序的发布。
- en: Once the container images are created and stored correctly in the images registry,
    and the Helm chart packages are created, the application is ready to be deployed.
    Additional vulnerability tests can be triggered using the container images. Some
    tools such as AquaSec’s Trivy use a **bill of materials** (**BOM**), which is
    a list of all the files included in all the container image layers, and search
    for known issues using both their own and internet-based vulnerability databases.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦容器镜像正确创建并存储在镜像注册表中，且Helm图表包创建完成，应用程序就可以进行部署了。可以使用容器镜像触发额外的漏洞测试。一些工具，如AquaSec的Trivy，会使用**材料清单**（**BOM**），即列出所有包含在容器镜像层中的文件，并利用它们自己的漏洞数据库和基于互联网的漏洞数据库来搜索已知问题。
- en: Let’s continue now with the second part of the pipeline. As you can see, we
    usually refer to the complete CI/CD workflow because CI and CD are often concatenated
    automatically one after the other.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续处理管道的第二部分。如你所见，我们通常会提到完整的CI/CD工作流，因为CI和CD经常是自动连接在一起的。
- en: Adding CD to the workflow
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将CD添加到工作流中
- en: Different integration and performance tests can be executed by using the container
    images directly using Docker Compose or Kubernetes manifests, or via the Helm
    chart packages, which provide a more customizable solution.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通过直接使用Docker Compose或Kubernetes清单，或者通过Helm图表包执行不同的集成和性能测试，Helm图表包提供了一个更具可定制性的解决方案。
- en: 'The CI/CD workflow continues with the tests, as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD工作流继续进行测试，如下所示：
- en: Deployments for the different tests are triggered using the custom value files
    stored in the code repository. It is important to understand that we should never
    store sensitive data in clear text in our code repositories. Instead, use solutions
    such as HashiCorp’s Vault or Bitnami’s SealedSecrets to store sensitive data under
    encryption. Both solutions enable data decryption during the deployment stages.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同测试的部署是通过存储在代码仓库中的自定义值文件触发的。需要理解的是，我们绝不应该在代码仓库中以明文存储敏感数据。相反，应该使用像 HashiCorp
    的 Vault 或 Bitnami 的 SealedSecrets 这样的解决方案，在加密下存储敏感数据。这两种解决方案都支持在部署阶段进行数据解密。
- en: The application’s performance and workflow task metrics can be integrated into
    your favorite dashboard environment. Most of the tests in this stage provide helpful
    summaries of the validation tasks executed, with which we can get a good overview
    of the impact of newly added changes. Logs will highlight any errors from either
    the tasks or the application’s processes. We should separate these into different
    dashboards because they will probably have different end users.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序的性能和工作流任务指标可以集成到你喜欢的仪表板环境中。大多数阶段中的测试会提供有用的总结，列出已执行的验证任务，我们可以通过这些总结很好地概览新添加更改的影响。日志将突出显示来自任务或应用程序进程的任何错误。我们应该将这些错误分开显示在不同的仪表板中，因为它们可能有不同的终端用户。
- en: Once all the tests are passed, we are ready to deploy the new release in production.
    Whether or not to automatically trigger this process depends on how your organization
    manages the changes in production. If your applications are governed using a GitOps
    model, use your configurations repository as the SOT, and the CI/CD orchestrator
    will push the changes into the Kubernetes platform. The current state of the application’s
    components may necessitate an upgrade to a new release or a rollback to a previous
    version to synchronize the desired state of the application. This model allows
    you to manage all your applications by changing their deployment configurations.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有测试通过，我们就可以准备在生产环境中部署新的版本。是否自动触发此过程取决于你们组织如何管理生产环境中的更改。如果你的应用程序采用 GitOps
    模型进行管理，可以将你的配置仓库用作单一数据源（SOT），CI/CD 编排器将把更改推送到 Kubernetes 平台。应用程序组件的当前状态可能需要升级到新版本或回滚到旧版本，以便同步应用程序的期望状态。此模型允许通过更改其部署配置来管理所有应用程序。
- en: Important note
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: The **GitOps** model extends the use of repositories to improve the tracking
    of infrastructure and application changes by using custom values repositories
    as a **single SOT** (**SSOT**) to trigger the delivery process. We can include
    automation for requiring specific security configurations, solving application
    or infrastructure dependencies before they are deployed, or any other requirement
    for the applications to work. All changes made to code and the values used for
    deploying the applications are tracked, making updates and rollbacks easier than
    ever.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '**GitOps** 模型通过使用自定义值仓库作为**单一数据源**（**SSOT**）来触发交付流程，从而扩展了仓库的使用，以改进基础设施和应用程序更改的跟踪。我们可以包括自动化，要求在部署之前解决特定的安全配置、应用程序或基础设施的依赖关系，或者任何其他应用程序正常工作的需求。所有对代码及用于部署应用程序的值所做的更改都被跟踪，使得更新和回滚变得比以往任何时候都更加容易。'
- en: Automating the deployment of our applications requires access and authorization
    to our Kubernetes environment. We include the required credentials for a deployment
    user in our CI/CD platform. We can use Argo CD to implement a simple GitOps working
    model. This way, a simple change in the custom package parameters will trigger
    the deployment of a new release using updated manifests. As a result, the new
    application release will be delivered with the given fixes or new requested features.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动化部署我们的应用程序需要访问和授权我们的 Kubernetes 环境。我们将在 CI/CD 平台中为部署用户提供所需的凭据。我们可以使用 Argo
    CD 实现一个简单的 GitOps 工作模型。通过这种方式，在自定义包参数中进行简单的更改将触发使用更新的清单部署新版本。结果，新的应用程序版本将交付，包含给定的修复或新增的功能。
- en: 'The new release deployed will be kept in the maintenance stage until a new
    one is released to replace it. Monitoring the application and retrieving and analyzing
    feedback from the users will end this iteration. The process will start over,
    with the team planning the implementation of newly requested features and fixes
    to issues not yet solved in the latest release. The following schema represents
    the workflow presented in the preceding bullet points:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署的新版本将在维护阶段保持，直到发布新版本来替代它。监控应用程序并从用户那里获取并分析反馈将结束这一迭代。该过程将重新开始，团队会计划实施新请求的功能和解决尚未解决的最新版本中的问题。以下架构图表示前面提到的工作流：
- en: '![Figure 13.6 – Schema of the workflow followed to deliver a new application
    release](img/B19845_13_06.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – 用于交付新应用程序版本的工作流架构](img/B19845_13_06.jpg)'
- en: Figure 13.6 – Schema of the workflow followed to deliver a new application release
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 用于交付新应用程序版本的工作流架构
- en: We will now review some of the aforementioned stages in the following *Labs*
    section, using a GitLab platform deployed on a Minikube desktop environment.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的*实验室*部分回顾一些前面提到的阶段，使用部署在 Minikube 桌面环境上的 GitLab 平台。
- en: Labs
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验室
- en: 'In this lab, we will reproduce a very simplified supply chain using automation
    and the GitOps deployment model by installing and configuring GitLab and Argo
    CD in a test environment for building, testing, and deploying the `simplestlab`
    application. You can use a fully working Kubernetes platform (on the cloud or
    on-premises) or a simplified Kubernetes desktop environment. The fully detailed
    steps of the process are explained in the GitHub repository of this book, in the
    `Chapter13` folder, but here is the summary of the processes and some notable
    configurations you will find there:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验室中，我们将通过安装和配置 GitLab 和 Argo CD，在一个测试环境中重现一个非常简化的供应链，采用自动化和 GitOps 部署模型来构建、测试和部署
    `simplestlab` 应用程序。你可以使用一个完全可用的 Kubernetes 平台（无论是云上还是本地）或简化的 Kubernetes 桌面环境。该过程的详细步骤已在本书的
    GitHub 仓库中说明，位于 `Chapter13` 文件夹，但以下是该过程的总结以及你在其中找到的一些显著配置：
- en: First, we will prepare our environment with the tools required for the lab (Helm,
    `kubectl`, and the Argo CD CLI), and we will also use some environment variables
    for easier configuration of the Ingress resources and CA certificates for each
    application.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将准备实验室所需的工具（Helm、`kubectl` 和 Argo CD CLI），并且我们还将使用一些环境变量，以便更轻松地配置每个应用程序的
    Ingress 资源和 CA 证书。
- en: You will find complete Helm charts for the `simplestlab` application, alongside
    some value configurations for deploying the application. The specific values used
    in this file will depend on your environment, and we have provided an explanation
    to help. You can test and deploy the Helm charts using local configurations.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将找到完整的 `simplestlab` 应用程序的 Helm 图表，以及一些用于部署该应用程序的值配置。文件中使用的具体值将取决于你的环境，我们已经提供了解释以帮助你理解。你可以使用本地配置来测试和部署
    Helm 图表。
- en: We will deploy and use GitLab to store all the application code, Helm charts,
    container images, and application configurations. Steps to create groups, subgroups,
    repositories, and required users are included.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将部署并使用 GitLab 来存储所有应用程序代码、Helm 图表、容器镜像和应用程序配置。包括创建组、子组、仓库以及所需用户的步骤。
- en: The code and Helm charts folders included in the `Chapter13` repository come
    with a `.gitlab-ci.yml` file that describes and prepares CI automation to validate
    our Dockerfile using **Hadolint** (a Docker linter) and finally build our image
    using **Kaniko** (a tool to build container images from a Dockerfile inside a
    container or Kubernetes cluster). This tool doesn’t depend on the Docker container
    runtime and executes each command within a Dockerfile completely in user space,
    which is great for security. This way, we can build images inside any standard
    Kubernetes cluster.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Chapter13` 仓库中包含的代码和 Helm 图表文件夹带有一个 `.gitlab-ci.yml` 文件，该文件描述并准备 CI 自动化，用于验证我们的
    Dockerfile 是否通过 **Hadolint**（一个 Docker 语法检查工具），最后使用 **Kaniko**（一个从 Dockerfile
    内部的容器或 Kubernetes 集群中构建容器镜像的工具）来构建镜像。这个工具不依赖于 Docker 容器运行时，并且在用户空间内完全执行 Dockerfile
    中的每个命令，这对安全性非常有利。这样，我们就可以在任何标准 Kubernetes 集群中构建镜像。'
- en: We will use `git` commands, different branches, and tags to trigger the different
    automations included in the example pipeline for the code and the Helm charts.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 `git` 命令、不同的分支和标签来触发示例管道中包含的不同自动化操作，涵盖代码和 Helm 图表。
- en: The automation creates `dev` and `release` images using different container
    image tags. Development images will be added to the code repositories, but the
    release images will be considered ready for production and will be stored in a
    separate container images repository.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动化过程使用不同的容器镜像标签创建`dev`和`release`镜像。开发镜像将被添加到代码库中，而发布镜像将被视为生产环境准备就绪，并存储在单独的容器镜像库中。
- en: Helm charts are created using an umbrella structure; hence, the `simplestlab`
    chart deploys all the components at once. This chart includes dependencies for
    different applications’ components, and these dependencies should be solved before
    it is deployed. We will see how this works with a local example and then automate
    the Helm chart creation.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Helm charts采用伞式结构创建；因此，`simplestlab` chart一次性部署所有组件。此chart包括不同应用组件的依赖关系，这些依赖关系应该在部署前解决。我们将通过本地示例来看这个过程，并接着自动化Helm
    chart的创建。
- en: Argo CD provides the CD part. While GitLab can be used to deploy directly on
    your Kubernetes cluster, Argo CD works by following the GitOps model. We will
    configure Argo CD to review any change in the `values` repository, and it will
    deploy the application using the resources stored in GitLab (container images,
    Helm charts, and the file with the values required for deploying the application).
    We will give you a brief discussion of the steps included in this lab and recommend
    you follow the full description written in the `Chapter13/Readme.md` file.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Argo CD提供了CD部分。虽然GitLab可以直接部署到Kubernetes集群上，但Argo CD遵循GitOps模型工作。我们将配置Argo CD以检查`values`仓库中的任何更改，并使用存储在GitLab中的资源（容器镜像、Helm
    charts和部署应用所需的文件）来部署应用。我们将简要讨论本实验中的步骤，并建议你参考`Chapter13/Readme.md`文件中的完整描述。
- en: 'We have prepared for you three main directories:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们为你准备了三个主要目录：
- en: '`ArgoCD`: Contains the installation of the Argo CD component and the Application
    resource we will use to deploy our `simplestlab` application'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ArgoCD`：包含Argo CD组件的安装和我们将用来部署`simplestlab`应用的Application资源。'
- en: '`GitLab`: Contains the installation of GitLab components'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GitLab`：包含GitLab组件的安装。'
- en: '`simplestlab`: This directory contains all the code, Helm charts, and values
    used for deploying a `simplestlab` application instance'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab`：此目录包含用于部署`simplestlab`应用实例的所有代码、Helm charts和配置值。'
- en: 'We will need the following tools in our environment:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将需要以下工具在环境中：
- en: '`base64` strings in case you don’t have `Base64`'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base64`字符串（如果你没有`Base64`工具）'
- en: '`kubectl`: To connect to our Kubernetes cluster'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`：用于连接我们的Kubernetes集群。'
- en: '`Base64`: For decoding some strings'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Base64`：用于解码某些字符串'
- en: 'Detailed steps for installing these tools are included in the code repository.
    We will start the lab by setting up a Minikube environment. We will use Linux
    and Docker for running this environment to be able to set up a fixed IP address.
    This will help you in case you decide to take your time for the lab and start
    and stop the Minikube environment without changing the setup. Follow these steps:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这些工具的详细步骤包含在代码库中。我们将通过设置Minikube环境来开始实验。我们将使用Linux和Docker来运行此环境，以便能够设置一个固定的IP地址。如果你决定花时间进行实验，并且希望在启动和停止Minikube环境时保持设置不变，这会帮助你。请按以下步骤操作：
- en: 'Start `minikube` using the following command line:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令行启动`minikube`：
- en: '[PRE0]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: .git folders in the Simplestlab_WORKSPACE folder and subfolders (if any) every
    time you start with the lab. We will use these folders to push some code changes
    inside Code/simplestapp, push Helm charts included in the HelmCharts directory,
    and push deployment values included inside the Values folder.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每次启动实验时，Simplestlab_WORKSPACE文件夹及其子文件夹（如果有的话）中的.git文件夹都会被使用。我们将使用这些文件夹推送一些代码更改到Code/simplestapp中，推送Helm
    charts到HelmCharts目录中，并推送包含在Values文件夹中的部署值。
- en: '[PRE1]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Install GitLab following the instructions included in the code repository. We
    have prepared a setup script to help you customize the values file for deploying
    GitLab using Helm. The chart is included under the `chapter13/GitLab` directory.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照代码库中包含的说明安装GitLab。我们已准备好一个设置脚本，帮助你自定义用于通过Helm部署GitLab的配置文件。该chart包含在`chapter13/GitLab`目录下。
- en: Once it is installed, we will review the secret created with the credentials
    and log in to the GitLab web UI, published at [https://gitlab.172.31.255.254.nip.io](https://gitlab.172.31.255.254.nip.io).
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，我们将查看使用凭据创建的密钥，并登录到发布在[https://gitlab.172.31.255.254.nip.io](https://gitlab.172.31.255.254.nip.io)上的GitLab网页UI。
- en: Important note
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We used the [nip.io](http://nip.io) domain to simplify all the qualified domain
    names for your environment. You can read more about this simplified domain at
    [https://nip.io/](https://nip.io/).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 [nip.io](http://nip.io) 域名来简化您环境中所有的合格域名。您可以在 [https://nip.io/](https://nip.io/)
    阅读更多关于这个简化域名的内容。
- en: We include our GitLab environment inside the Minikube setup to allow Kubernetes
    to download images. Complete steps are described in the GitLab repository.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Minikube 设置中包含 GitLab 环境，以允许 Kubernetes 下载镜像。完整的步骤描述见 GitLab 仓库。
- en: We will then install Argo CD using a setup script and Helm. The script will
    customize a values file for your environment, and we will use it to deploy Argo
    CD using the Helm chart included in the `Chapter13/ArgoCD` directory.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将使用安装脚本和 Helm 安装 Argo CD。该脚本会根据您的环境定制一个值文件，我们将用它通过 `Chapter13/ArgoCD` 目录中的
    Helm chart 部署 Argo CD。
- en: Detailed steps are provided in the code repository. Once installed, you will
    be able to access Argo CD at [https://argocd.172.31.255.254.nip.io](https://argocd.172.31.255.254.nip.io).
    You will use the admin user with the password obtained from the deployment secret,
    following the procedure described in the code repository.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 详细步骤可在代码仓库中找到。安装完成后，您将能够访问 Argo CD，网址为 [https://argocd.172.31.255.254.nip.io](https://argocd.172.31.255.254.nip.io)。您将使用管理员用户，并使用从部署秘密中获取的密码，按照代码仓库中描述的流程进行操作。
- en: We will then upload the code included in `SimplestLab/Code` directory to GitLab.
    But first, we will create a user (`coder` user) with developer privileges in GitLab.
    This user will be used to pull and push code only, without privileged access.
    Steps for creating this user and the different projects for managing the code,
    Helm charts, images, and the values for deploying the application are described
    in the code repository.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将把 `SimplestLab/Code` 目录中的代码上传到 GitLab。但首先，我们将在 GitLab 中创建一个具有开发者权限的用户（`coder`
    用户）。该用户将仅用于拉取和推送代码，而没有特权访问权限。有关创建此用户和管理代码、Helm charts、镜像以及部署应用所需值的不同项目的步骤，已在代码仓库中描述。
- en: Important note
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Different permissions will be declared for different projects in GitLab. We
    have simplified the environment, setting up some projects as `Public`. Follow
    the instructions detailed in the `Chapter13` repository.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GitLab 中，将为不同的项目声明不同的权限。我们简化了环境，将一些项目设置为 `Public`。请按照 `Chapter13` 仓库中的详细说明进行操作。
- en: Using this `coder` user, we will push the code for the `simplestapp` component,
    included in the `Chapter13/Simplestlab/Code/simplestapp` directory, to our GitLab
    instance.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此 `coder` 用户，我们将把 `Chapter13/Simplestlab/Code/simplestapp` 目录中的 `simplestapp`
    组件代码推送到我们的 GitLab 实例。
- en: 'Automation of a Docker image build is triggered thanks to the existence of
    the `.gitlab-ci.yml` file in our code repository. This file describes the automated
    process and steps for verifying and building a custom image using our code. We
    included three stages in the file:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker 镜像构建的自动化是通过我们代码仓库中存在的 `.gitlab-ci.yml` 文件触发的。该文件描述了验证和构建自定义镜像的自动化过程和步骤。我们在文件中包含了三个阶段：
- en: '`test` (which basically validates our Dockerfile syntax)'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test`（基本上是验证我们的 Dockerfile 语法）'
- en: '`security` (which reviews the content of the files to be included in the image
    before it is built)'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`security`（在构建镜像之前审核要包含的文件内容）'
- en: '`build` (using Kaniko instead of Docker to improve security, avoiding the need
    to use the Kubernetes host’s Docker or `containerd` engine)'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`build`（使用 Kaniko 而不是 Docker 来提高安全性，避免使用 Kubernetes 主机的 Docker 或 `containerd`
    引擎）'
- en: The process is described in detail in the `Readme.md` file included in the code
    repository.
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该过程的详细描述可以在代码仓库中包含的 `Readme.md` 文件中找到。
- en: Important note
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: To avoid the need to add the GitLab environment SSL certificate to our client
    environment, we will configure Git to skip SSL verification (steps are included
    in the code repository).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免将 GitLab 环境的 SSL 证书添加到我们的客户端环境中，我们将配置 Git 跳过 SSL 验证（步骤已包括在代码仓库中）。
- en: 'This automation will use the following variables for executing the tasks defined
    in the `.``gitlab-ci.yaml` file:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该自动化将使用以下变量来执行 `.gitlab-ci.yaml` 文件中定义的任务：
- en: '`PROJECTGROUP_USERNAME`: `coder`'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PROJECTGROUP_USERNAME`: `coder`'
- en: '`PROJECTGROUP_PASSWORD`: `C0der000`'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PROJECTGROUP_PASSWORD`: `C0der000`'
- en: '`LABS_LOCAL_GITLAB_CERTIFICATE`: Complete GitLab TLS certificate chain `Base64`-decoded
    value, obtained using the following command:'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LABS_LOCAL_GITLAB_CERTIFICATE`: 完整的 GitLab TLS 证书链的 `Base64` 解码值，可以通过以下命令获取：'
- en: '[PRE2]'
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`Images` project repository'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Images` 项目仓库'
- en: We will create `dev` and `main` code branches, change some code, push it to
    GitLab, and switch between branches to see whether changes will trigger the build
    process or not. Once we are ready to build a release image, we will tag the commit
    with a release name, push it to GitLab, and verify how the automated pipeline
    will create the appropriate release image inside the image project in GitLab.
    Described steps for these tasks are included in the `Chapter13/Readme.md` file.
    Please follow them carefully, and review the pipeline results and files generated
    during the process in the different GitLab projects (`Code` and `Images`). Get
    familiar with the processes before continuing with the next step, in which we
    will push and build the Helm charts for deploying the different applications’
    components.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将创建 `dev` 和 `main` 两个代码分支，修改一些代码，将其推送到 GitLab，并在分支之间切换，以查看更改是否会触发构建过程。一旦准备好构建发布镜像，我们将用发布名称标记提交，推送到
    GitLab，并验证自动化管道如何在 GitLab 中的镜像项目内创建相应的发布镜像。这些任务的步骤已包含在 `Chapter13/Readme.md` 文件中，请仔细遵循，并在不同的
    GitLab 项目（`Code` 和 `Images`）中查看管道结果和生成的文件。在继续下一步之前，请熟悉这些流程，接下来我们将推送并构建 Helm charts，以便部署不同应用组件。
- en: 'We will now manage the Helm charts’ code files and their associated projects’
    repositories. We set up for you three Helm charts, one for each component (`simplestlab-db`,
    `simplestlab-app`, and `simplestlab-lb`), and one umbrella chart that will include
    the others as dependencies. Therefore, four project repositories must be created:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将管理 Helm charts 的代码文件及其相关项目的仓库。我们为你设置了三个 Helm charts，每个组件一个（`simplestlab-db`、`simplestlab-app`
    和 `simplestlab-lb`），以及一个包含其他 charts 作为依赖项的 umbrella chart。因此，必须创建四个项目仓库：
- en: '`simplestlab`: This chart defines the umbrella Helm chart used to deploy all
    components at once and its Ingress resource. We didn’t add any Ingress resource
    on any other component.'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab`：此 chart 定义了用于一次性部署所有组件的 umbrella Helm chart 以及其 Ingress 资源。我们没有在任何其他组件上添加
    Ingress 资源。'
- en: '`simplestlab-app`: Describes the application backend component Deployment resource
    deployment.'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-app`：描述了应用程序后端组件的 Deployment 资源部署。'
- en: '`simplestlab-db`: Describes the database component StatefulSet deployment.'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-db`：描述了数据库组件 StatefulSet 部署。'
- en: '`simplestlab-lb`: This describes the load balancer DaemonSet deployment.'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-lb`：描述了负载均衡器 DaemonSet 部署。'
- en: This project should be `Public` in this demo because we will not declare any
    credentials in Argo CD. You will use credentials and `Private` repositories in
    your production and development platforms, but this will definitely require more
    configurations for this demo environment.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本项目应设置为 `Public`，因为我们不会在 Argo CD 中声明任何凭证。你将在生产和开发平台上使用凭证和 `Private` 仓库，但这在演示环境中肯定需要更多的配置。
- en: Important note
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The `simplestlab` umbrella chart depends on `simplestlab-app`, `simplestlab-db`,
    and `simplestlab-lb` charts. Whatever change you make to any of these projects
    requires a Helm chart dependencies update on the `simplestlab` umbrella chart.
    While you use the prepared CI/CD environment, you will need to run the `simplestlab`
    umbrella chart project pipeline again to rebuild these dependencies. If you want
    to manually update them, you will use a Helm dependencies update in the `HelmCharts/simplestlab`
    directory. We prepared various scenarios in the `Chart.yaml` file in case you
    want to test it locally (review the `Chapter13/Simplestlab/Values/simplestlab/values.yaml`
    file comments).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '`simplestlab` umbrella chart 依赖于 `simplestlab-app`、`simplestlab-db` 和 `simplestlab-lb`
    charts。对这些项目的任何更改都需要在 `simplestlab` umbrella chart 上更新 Helm chart 依赖项。在使用已准备好的
    CI/CD 环境时，你需要再次运行 `simplestlab` umbrella chart 项目管道，以重新构建这些依赖项。如果你想手动更新它们，可以在
    `HelmCharts/simplestlab` 目录下执行 Helm 依赖项更新。我们在 `Chart.yaml` 文件中准备了各种场景，以防你想在本地测试（请查看
    `Chapter13/Simplestlab/Values/simplestlab/values.yaml` 文件中的注释）。'
- en: Once the Helm charts’ project repositories are created, we can push the Helm
    charts’ code into their GitLab-associated repositories. The code for the charts
    is located in `Chapter13/Simplestlab/HelmCharts`. Push each component’s code to
    the appropriate repository.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Helm charts 项目仓库创建完成，我们就可以将 Helm charts 的代码推送到它们对应的 GitLab 仓库。Charts 的代码位于`Chapter13/Simplestlab/HelmCharts`。将每个组件的代码推送到相应的仓库。
- en: 'We have included in the charts’ code the `.gitlab-ci.yaml` file for GitLab
    automation. This file describes three stages:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在 charts 代码中包含了 `.gitlab-ci.yaml` 文件，用于 GitLab 自动化。该文件描述了三个阶段：
- en: '`test` (which validates the Helm chart using its own linter)'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test`（使用自己的 linter 验证 Helm chart）'
- en: '`dependencies` (which validates the chart dependencies if any are declared)'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dependencies`（用于验证是否声明了chart依赖项）'
- en: '`build` (which packages the code into a Helm chart `.``tgz` file)'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`build`（将代码打包成Helm chart `.tgz` 文件）'
- en: Important note
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We need to include two new variables, `DOCKERHUB_USERNAME` (with your Docker
    Hub username) and `DOCKERHUB_PASSWORD` (with your Docker Hub password). These
    variables should be defined in the `HelmChart/SimplestLab` umbrella chart only.
    This repository is `Public`, and anyone will be able to read your password, but
    you are using your own demo environment. You can secure this password by making
    it `Private`, but you will need to prepare some username authentication (new user
    or even coder user here) and include it in the Argo CD OCI repository.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要包括两个新变量，`DOCKERHUB_USERNAME`（你的Docker Hub用户名）和`DOCKERHUB_PASSWORD`（你的Docker
    Hub密码）。这些变量应仅在`HelmChart/SimplestLab`主chart中定义。此仓库是`公开`的，任何人都可以读取你的密码，但你正在使用自己的演示环境。你可以将此密码设置为`私有`，但你需要准备一些用户名身份验证（新用户或甚至是此处的开发人员用户），并将其包含在Argo
    CD OCI仓库中。
- en: 'The GitLab automation file will trigger two types of package construction processes:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GitLab自动化文件将触发两种类型的包构建过程：
- en: '`HelmChart` project repository.'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HelmChart`项目仓库。'
- en: '`simplestlab` chart.'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab` chart。'
- en: We will create `dev` and `main` code branches and verify the build process when
    we push code to GitLab. Steps for making some changes and pushing them to GitLab
    are described in the `Chapter13/Readme.md` file. The `simplestlab` umbrella chart
    will be pushed to Docker Hub, and we will be ready to use it, but first, we will
    need to add the `values.yaml` file to the `Values` project repository.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将创建`dev`和`main`代码分支，并在将代码推送到GitLab时验证构建过程。修改并推送代码的步骤可以在`Chapter13/Readme.md`文件中找到。`simplestlab`主chart将被推送到Docker
    Hub，我们准备好使用它，但首先我们需要将`values.yaml`文件添加到`Values`项目仓库中。
- en: 'We will create a `Simplestlab/values/simplestlab` repository to manage a simple
    values file that will be used to deploy the `simplestlab` application using the
    `simplestlab` umbrella Helm chart. The file contains different sections:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个`Simplestlab/values/simplestlab`仓库，用于管理一个简单的值文件，该文件将用于通过`简易实验室`的主Helm
    chart部署`simplestlab`应用。该文件包含不同的部分：
- en: '`simplestlab-lb`: Defines the values to overwrite when deploying the `simplestlab-lb`
    Helm chart, added as a dependency in the umbrella chart.'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-lb`：定义了在部署`simplestlab-lb` Helm chart时要覆盖的值，该chart作为依赖项添加到主chart中。'
- en: '`simplestlab-app`: Defines the values to overwrite when deploying the `simplestlab-app`
    Helm chart, added as a dependency in the umbrella chart.'
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-app`：定义了在部署`simplestlab-app` Helm chart时要覆盖的值，该chart作为依赖项添加到主chart中。'
- en: '`simplestlab-db`: Defines the values to overwrite when deploying the `simplestlab-db`
    Helm chart, added as a dependency in the umbrella chart.'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-db`：定义了在部署`simplestlab-db` Helm chart时要覆盖的值，该chart作为依赖项添加到主chart中。'
- en: '`App` component (`__dbhost: db__`). The correct data is commented: `__dbhost:
    simplestlab-simplestlab-db__`. Thus, when you create the Argo CD application for
    the first time, the application component and the load balancer components will
    fail. Until you change the correct mentioned value in the `values` YAML file,
    this will not fix the problem in the load balancer component.'
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`App`组件（`__dbhost: db__`）。正确的数据已被注释：`__dbhost: simplestlab-simplestlab-db__`。因此，当首次创建Argo
    CD应用时，应用组件和负载均衡器组件将失败。直到你在`values` YAML文件中更改正确的值，此问题才会在负载均衡器组件中修复。'
- en: The second test will deploy a new configuration that will fix the load balancer
    component by deploying a completely new `nginx.conf` ConfigMap. To make this happen,
    uncomment the `nginxConfig` key in `simplestlab-lb`. Indentation is key; uncomment
    all the lines (you can leave the `###################################` line).
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个测试将部署一个新配置，通过部署全新的`nginx.conf` ConfigMap来修复负载均衡器组件。要实现此目标，请取消注释`nginxConfig`键，在`simplestlab-lb`中进行修改。缩进非常关键；取消注释所有行（可以保留`###################################`这一行）。
- en: When an Application resource is created in Argo CD, the synchronization with
    the different reports starts, and every time you change either the Helm chart
    package or the values file, the misconfigurations will be reflected in the Argo
    CD environment.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当在Argo CD中创建应用资源时，开始与不同报告的同步，每次更改Helm chart包或值文件时，配置错误将会反映在Argo CD环境中。
- en: Create a `simplestlab` values repository (`Project`) inside the `Values` project,
    and push the file from `Chapter13/Simplestlab/values/simplestlab` into this new
    repository.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Values` 项目中创建一个 `simplestlab` 值仓库（`Project`），并将 `Chapter13/Simplestlab/values/simplestlab`
    文件推送到这个新仓库中。
- en: 'We will now integrate our application into Argo CD. We will use the Argo CD
    CLI to manage the integration of our Kubernetes cluster with Argo CD. To connect
    Kubernetes with Argo CD, create a ServiceAccount resource with cluster privileges
    to manage applications cluster-wide. Detailed instructions for integrating our
    Minikube Kubernetes cluster are included in the `Chapter13` repository. Follow
    these instructions, and then log in to Argo CD to create the following repositories:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将把应用集成到 Argo CD 中。我们将使用 Argo CD CLI 来管理我们 Kubernetes 集群与 Argo CD 的集成。为了将
    Kubernetes 与 Argo CD 连接，创建一个具有集群权限的 ServiceAccount 资源，以便在整个集群范围内管理应用。关于集成 Minikube
    Kubernetes 集群的详细说明已包含在 `Chapter13` 仓库中。按照这些说明进行操作，然后登录到 Argo CD，创建以下仓库：
- en: '`coder` as the username and `c0der000` as the password.'
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`coder` 作为用户名，`c0der000` 作为密码。'
- en: '`simplestlab-chart` package.'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-chart` 包。'
- en: '`simplestlab-chart` package uploaded at Docker Hub as a workaround for an issue
    in Argo CD with self-signed certificates ([https://github.com/argoproj/argo-cd/issues/12371](https://github.com/argoproj/argo-cd/issues/12371)).'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simplestlab-chart` 包已上传至 Docker Hub，作为 Argo CD 在自签名证书问题上的一种解决方法 ([https://github.com/argoproj/argo-cd/issues/12371](https://github.com/argoproj/argo-cd/issues/12371))。'
- en: Screenshots are provided in the instructions to guide you through the setup
    process.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指令中提供了截图，帮助你完成设置过程。
- en: Once the repositories are created in Argo CD, we can create an Argo CD Application
    resource. The Argo CD GUI does not allow us to use multiple repositories, hence
    we will not be able to use a code repository for the values file and another one
    for the Helm chart package artifact. In these circumstances, we need to prepare
    the Application resource using a YAML file. We included a YAML file for you in
    `Chapter13/ArgoCD/Applications`. The `minikube-simplestlab.yaml` file includes
    both the values file repository ([https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git](https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git))
    and the Helm chart repository ([docker.io/frjaraur](http://docker.io/frjaraur)).
    If you have followed all the steps, you can use your own Helm chart repository.
    Mine is public, and you will be able to use it at any time. The `Applications`
    manifest includes the sources for deploying an application and the destination
    environment – the Minikube lab environment in our case.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦在 Argo CD 中创建了仓库，我们可以创建一个 Argo CD 应用资源。由于 Argo CD GUI 不允许我们使用多个仓库，因此我们无法同时使用一个代码仓库来存储值文件，另一个仓库来存储
    Helm chart 包的制品。在这种情况下，我们需要通过 YAML 文件来准备应用资源。我们在 `Chapter13/ArgoCD/Applications`
    中为你提供了一个 YAML 文件。`minikube-simplestlab.yaml` 文件包括了值文件仓库（[https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git](https://gitlab.172.31.255.254.nip.io/simplestlab/values/simplestlab.git)）和
    Helm chart 仓库（[docker.io/frjaraur](http://docker.io/frjaraur)）。如果你已经按照所有步骤操作，你也可以使用自己的
    Helm chart 仓库。我的仓库是公开的，你可以随时使用它。`Applications` 清单包括了应用部署的源和目标环境——在我们的例子中是 Minikube
    实验环境。
- en: 'We will create this new resource using `kubectl`:'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将使用 `kubectl` 创建这个新资源：
- en: '[PRE3]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Important note
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: We have included in the Argo CD Application resource the `simplestlab` namespace.
    This namespace should be created before the application is actually deployed.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Argo CD 应用资源中包含了 `simplestlab` 命名空间。该命名空间应在应用实际部署之前创建。
- en: Next, we change the database host lab. The first thing you will notice is that
    the application’s `App` component does not work. This is due to the fact that
    the connection string is wrong (check the comments included in the `Chapter13/Simplestlab/Values/simplestlab/values.yaml`
    file). Change the `dbhost` key to `simplestlab-simplestlab-db` and verify the
    changes in Argo CD.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们更改数据库主机实验室。你首先会注意到应用的 `App` 组件无法正常工作。这是因为连接字符串错误（请查看 `Chapter13/Simplestlab/Values/simplestlab/values.yaml`
    文件中的注释）。将 `dbhost` 键更改为 `simplestlab-simplestlab-db` 并在 Argo CD 中验证更改。
- en: 'Verify the new name, automatically created by the Helm chart template (these
    names could have been fixed, but this is a common error and we can see how to
    solve it in this example):'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证由 Helm chart 模板自动创建的新名称（这些名称本可以被修复，但这是一个常见的错误，我们可以通过这个例子来看到如何解决它）：
- en: '[PRE4]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'envVariables:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'envVariables:'
- en: 'dbhost: simplestlab-simplestlab-db'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'dbhost: simplestlab-simplestlab-db'
- en: '[PRE5]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Commit the new changes and push the file to our repository in GitLab using Git.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交新的更改并通过 Git 将文件推送到 GitLab 仓库。
- en: The changes will be shown on Argo CD in a few seconds. We haven’t configured
    auto-sync, hence we will see a misconfiguration of the values (out of sync). Current
    values in the cluster are different from those expected by the configuration.
    We will just proceed to sync the application (screenshots are included in the
    repository). This will create a new Secret resource. We will delete the `App`
    component Pods, and the new changes will be applied to this component.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些更改会在几秒钟内在 Argo CD 上显示。我们没有配置自动同步，因此我们将看到值的配置错误（不同步）。集群中的当前值与配置文件中期望的值不同。我们只需继续同步应用程序（屏幕截图已包含在仓库中）。这将创建一个新的
    Secret 资源。我们将删除 `App` 组件的 Pods，新的更改将应用于此组件。
- en: Once the first problem is solved, you will find a new error because the `Loadbalancer`
    component isn’t able to reach the `App` component. So, next, we need to fix the
    `Loadbalancer` component. In this case, we will change the `__nginx.conf__` file
    required by `Nginx ___Lb___`. It is included as a ConfigMap resource and managed
    by the `___nginxConfig___` key in the values file. We need to change the name
    of the application backend service (`___App___` component). By default, it uses
    `___app___`, as you can see in the default values file included in the `___simplest-lb___`
    Helm chart (`SimplestLab/HelmCharts/simplestlab/values.yaml`).
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦第一个问题解决，你会发现一个新的错误，因为 `Loadbalancer` 组件无法访问 `App` 组件。因此，接下来我们需要修复 `Loadbalancer`
    组件。在这种情况下，我们将修改 `Nginx ___Lb___` 所需的 `__nginx.conf__` 文件。它作为 ConfigMap 资源包含，并由
    values 文件中的 `___nginxConfig___` 键管理。我们需要更改应用程序后端服务的名称（`___App___` 组件）。默认情况下，它使用
    `___app___`，如你在 `___simplest-lb___` Helm 图表中的默认值文件（`SimplestLab/HelmCharts/simplestlab/values.yaml`）中所见。
- en: 'We first verify the name of the `App` component service:'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先验证 `App` 组件服务的名称：
- en: '[PRE6]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '# Second Test Update -- Uncomment this section'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 第二次测试更新 -- 取消注释此部分'
- en: 'nginxConfig: |'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'nginxConfig: |'
- en: user  nginx;
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: user  nginx;
- en: worker_processes  auto;
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: worker_processes  auto;
- en: error_log  /tmp/nginx/error.log warn;
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: error_log  /tmp/nginx/error.log warn;
- en: pid        /tmp/nginx/nginx.pid;
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pid        /tmp/nginx/nginx.pid;
- en: events {
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: events {
- en: worker_connections  1024;
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: worker_connections  1024;
- en: '}'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: http {
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: http {
- en: server {
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: server {
- en: listen 8080;
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: listen 8080;
- en: location /healthz {
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: location /healthz {
- en: add_header Content-Type text/plain;
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: add_header Content-Type text/plain;
- en: return 200 'OK';
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return 200 'OK';
- en: '}'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: location / {
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: location / {
- en: proxy_pass http://simplestlab-simplestlab-app:3000;
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: proxy_pass http://simplestlab-simplestlab-app:3000;
- en: '}'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: '}'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: '}'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: '[PRE7]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We commit and push the new changes. Argo CD will show the changes in a few seconds,
    and we will sync the resources and delete the `Lb` Pod, associated with the DaemonSet,
    to fix the NGINX configuration issue. After the synchronization and removal of
    the Pod, the new Pod works fine, and Argo CD will show the application as healthy
    and synced.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们提交并推送新的更改。Argo CD 会在几秒钟内显示这些更改，我们将同步资源并删除与 DaemonSet 关联的 `Lb` Pod，以修复 NGINX
    配置问题。同步和删除 Pod 后，新的 Pod 会正常工作，Argo CD 会显示应用程序为健康且已同步。
- en: We’ve now reached the end of this long and complex lab, but we divided it into
    different stages to make it easier to follow. You can make changes to either your
    configurations, code, or Helm charts and trigger pipelines or GitOps integration
    to manage your application status and behavior. We can’t explain in a single lab
    all the configurations we have done to make all the workflow work; we gave you
    some tips that will help, and you can deep dive by yourself, exploring the already
    prepared configuration and script steps.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经到达了这个漫长而复杂实验的结尾，但我们将其分成了不同的阶段，以便更容易跟随。你可以更改你的配置、代码或 Helm 图表，并触发管道或 GitOps
    集成来管理你的应用程序状态和行为。我们无法在一个实验中解释所有我们所做的配置，这些配置使得整个工作流程能够顺利运作；我们给了你一些有用的提示，你可以深入研究，探索已经准备好的配置和脚本步骤。
- en: It would be useful to follow the lab by including the NetworkPolicy resources
    created in [*Chapter 11*](B19845_11.xhtml#_idTextAnchor244) and the NGINX and
    Postgres Prometheus exporters prepared in [*Chapter 12*](B19845_12.xhtml#_idTextAnchor267).
    After the completion of this lab, you will understand how the different automations
    work and will be ready to create your own using any other popular DevOps tool
    because the basic concepts are the same, no matter whether you use a cloud solution
    or deploy your DevOps tools in your own data center.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随实验时，最好包含在[*第11章*](B19845_11.xhtml#_idTextAnchor244)中创建的 NetworkPolicy 资源，以及在[*第12章*](B19845_12.xhtml#_idTextAnchor267)中准备的
    NGINX 和 Postgres Prometheus 导出器。完成本实验后，你将理解不同的自动化是如何工作的，并且能够使用任何其他流行的 DevOps 工具创建自己的自动化，因为基本概念是相同的，无论你是使用云解决方案还是在自己的数据中心部署
    DevOps 工具。
- en: Summary
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we described the life cycle of an application using software
    containers. We used most of the content learned in this book so far to prepare
    a CI/CD workflow, while we quickly reviewed the different stages involved in the
    creation of an application based on containers. We also presented some of the
    most popular applications used by DevOps teams to implement and automate the complete
    supply chain of an application and learned how to use them in the *Labs* section.
    This final lab showed you the different stages involved in the life cycle of an
    application. We coded our application, prepared our container images to use as
    our application’s artifacts, and prepared Helm charts, which we used to deploy
    the application in Kubernetes. Finally, we triggered the execution of the application
    in the Kubernetes cluster using Argo CD to deliver the application after its configuration
    was done. All changes will be tracked, and the automation and orchestration functionalities
    help us to deliver changes quickly and reliably. You are now ready to employ the
    content of this book to create your own supply chain or use one already created
    using other common DevOps tools. Best of luck preparing and delivering your applications
    using software containers!
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们描述了使用软件容器的应用程序生命周期。我们使用了本书至今学习的大部分内容来准备一个CI/CD工作流，同时快速回顾了基于容器创建应用程序的不同阶段。我们还介绍了一些由DevOps团队用来实现和自动化应用程序完整供应链的最受欢迎的应用程序，并在*实验室*部分学习了如何使用它们。这个最终实验展示了应用程序生命周期中涉及的不同阶段。我们编写了应用程序代码，准备了容器镜像作为应用程序的工件，并准备了Helm图表，用于在Kubernetes中部署应用程序。最后，我们通过Argo
    CD触发了应用程序在Kubernetes集群中的执行，以在配置完成后交付应用程序。所有的变更都会被追踪，自动化和编排功能帮助我们快速且可靠地交付变更。现在，你已经准备好运用本书的内容创建你自己的供应链，或使用其他常见的DevOps工具创建的供应链。祝你好运，在使用软件容器准备和交付应用程序的过程中取得成功！
