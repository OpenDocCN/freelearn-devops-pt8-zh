- en: Chapter 4. Automating Complete Infrastructures with Terraform
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '第四章 使用 Terraform 自动化完整基础设施  '
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将介绍以下配方：  '
- en: Provisioning a complete CoreOS infrastructure on Digital Ocean with Terraform
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 Digital Ocean 上使用 Terraform 部署完整的 CoreOS 基础设施  '
- en: Provisioning a three-tier infrastructure on Google Compute Engine
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 Google Compute Engine 上部署三层基础设施  '
- en: Provisioning a GitLab CE + CI runners on OpenStack
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 OpenStack 上部署 GitLab CE + CI 运行器  '
- en: Managing Heroku Apps and Add-ons using Terraform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用 Terraform 管理 Heroku 应用和插件  '
- en: Creating a scalable Docker Swarm cluster on bare metal with Packet
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在裸金属上使用 Packet 创建可扩展的 Docker Swarm 集群  '
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '介绍  '
- en: In this chapter, we'll describe complete infrastructures using Terraform, how
    it looks when everything is tied together, with a real project in mind. Most examples
    from previous chapters on Terraform were on Amazon Web Services, so to try to
    be more diverse and complete, this chapter is dedicated to other infrastructure
    services, namely Digital Ocean, Google Cloud, Heroku, and Packet. On Digital Ocean,
    we'll build a fully working and monitored CoreOS cluster with DNS dynamically
    updated. On Google Cloud, we'll build a three-tier infrastructure with two HTTP
    nodes behind a load balancer and an isolated MySQL managed database. Using OpenStack,
    we'll deploy a GitLab CE and two GitLab CI runners, using different storage solutions.
    We'll see how we can integrate and automate a Heroku environment. We'll end this
    chapter with a powerful and scalable Docker Swarm cluster on bare metal using
    Packet, capable of scaling hundreds of containers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将描述使用 Terraform 的完整基础设施，展示当一切都结合在一起时的样子，并以实际项目为例。前几章中大多数 Terraform 示例都使用了亚马逊
    Web 服务（AWS），因此为了更加多样化和完整，本章将专注于其他基础设施服务，即 Digital Ocean、Google Cloud、Heroku 和
    Packet。在 Digital Ocean 上，我们将构建一个完全可用并且实时监控的 CoreOS 集群，DNS 动态更新。在 Google Cloud
    上，我们将构建一个三层基础设施，包含两个 HTTP 节点在负载均衡器后面以及一个独立的 MySQL 管理数据库。使用 OpenStack，我们将部署 GitLab
    CE 和两个 GitLab CI 运行器，使用不同的存储解决方案。我们将看到如何整合和自动化 Heroku 环境。最后，我们将使用 Packet 在裸金属上构建一个强大且可扩展的
    Docker Swarm 集群，能够扩展至数百个容器。  '
- en: Note
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '注意  '
- en: The Terraform version in use for this book is 0.7.4.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '本书使用的 Terraform 版本是 0.7.4。  '
- en: Provisioning a complete CoreOS infrastructure on Digital Ocean with Terraform
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '在 Digital Ocean 上使用 Terraform 部署完整的 CoreOS 基础设施  '
- en: In this recipe, we'll build from scratch a fully working CoreOS cluster on Digital
    Ocean in their New York region, using Terraform and cloud-init. We'll add some
    latency monitoring as well with StatusCake, so we have a good foundation of using
    Terraform on Digital Ocean.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '在此配方中，我们将从零开始构建一个完全可用的 CoreOS 集群，部署在 Digital Ocean 的纽约数据中心，使用 Terraform 和 cloud-init。我们还将使用
    StatusCake 添加一些延迟监控，因此我们为在 Digital Ocean 上使用 Terraform 打下了一个良好的基础。  '
- en: Getting ready
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '准备工作  '
- en: 'To step through this recipe, you will need the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '要执行此配方，你将需要以下内容：  '
- en: A working Terraform installation
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个可用的 Terraform 安装  '
- en: A Digital Ocean account
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个 Digital Ocean 账户  '
- en: A StatusCake account
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个 StatusCake 账户  '
- en: An Internet connection
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '一个互联网连接  '
- en: How to do it…
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '如何执行此操作…  '
- en: 'Let''s start by creating the `digitalocean` provider (it only requires an API
    token) in a file named `providers.tf`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从在名为 `providers.tf` 的文件中创建 `digitalocean` 提供者（它只需要一个 API 密钥）开始：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Declare the `do_token` variable in a file named `variables.tf`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '在名为 `variables.tf` 的文件中声明 `do_token` 变量：  '
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Also, don''t forget to set it in a private `terraform.tfvars` file:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '同时，别忘了在私有的 `terraform.tfvars` 文件中设置它：  '
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Handling the SSH key
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '处理 SSH 密钥  '
- en: 'We know that we''ll need an SSH key to log into the cluster members. With Digital
    Ocean, the resource is named `digitalocean_ssh_key`. I propose that we name the
    SSH key file `iac_admin_sshkey` in the `keys` directory, but as you might prefer
    something else, let''s use a variable for that as well. Let''s write this in a
    `keys.tf` file:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '我们知道，我们将需要一个 SSH 密钥来登录集群成员。对于 Digital Ocean，该资源名为 `digitalocean_ssh_key`。我建议我们将
    SSH 密钥文件命名为 `iac_admin_sshkey`，并将其放置在 `keys` 目录中，但由于你可能喜欢其他名称，我们也可以为此使用一个变量。让我们在
    `keys.tf` 文件中编写此内容：  '
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the related variable in `variables.tf`, with our suggested default:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '在 `variables.tf` 中创建相关变量，并使用我们建议的默认值：  '
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It''s now time to effectively override the value in the `terraform.tfvars`
    file if you feel like it:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你愿意，现在是有效覆盖 `terraform.tfvars` 文件中的值的时候了：  '
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Creating the CoreOS cluster members
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '创建 CoreOS 集群成员  '
- en: 'Here''s the core of our infrastructure: three nodes running in the New York
    City data center NYC1, with private networking enabled, no backups activated (set
    it to `true` if you feel like it!), the SSH key we previously created, and a cloud-init
    file to initiate configuration. A virtual machine at Digital Ocean is named a
    *droplet*, so the resource to launch a droplet is `digitalocean_droplet`. All
    variables'' names relate to what we just enumerated:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们基础设施的核心：三个节点运行在纽约市数据中心 NYC1，启用了私有网络，未激活备份（如果需要，可以设置为 `true`！），我们之前创建的 SSH
    密钥，以及一个用于初始化配置的 cloud-init 文件。在 Digital Ocean 中，虚拟机被称为 *droplet*，所以启动 droplet
    的资源是 `digitalocean_droplet`。所有变量名都与我们刚才列举的内容相关：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Declare all the variables in the `variables.tf` file, with some good defaults
    (the smallest 512 MB droplet, a three-node cluster), and some defaults we''ll
    want to override (AMS3 data center or the stable CoreOS channel):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `variables.tf` 文件中声明所有变量，并设置一些良好的默认值（最小 512 MB droplet，三节点集群），以及我们想要覆盖的一些默认值（AMS3
    数据中心或稳定版 CoreOS 渠道）：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here are our overridden values in `terraform.tfvars` (but feel free to put
    your own values, such as using another data center or CoreOS release):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在 `terraform.tfvars` 中的覆盖值（但你可以随意使用自己的值，比如使用不同的数据中心或 CoreOS 版本）：
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Adding useful output
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加有用的输出
- en: 'It would be awesome to automatically have a few auto-documented lines on how
    to connect to our CoreOS cluster. As we can do that with the Terraform outputs,
    let''s use this example for a start, in `outputs.tf`. This is constructing an
    SSH command line with dynamic information from Terraform that we''ll be able to
    use easily (it''s simply iterating over every `digitalocean_droplet.coreos.*`
    available):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果能自动生成一些关于如何连接到我们的 CoreOS 集群的文档行，那就太棒了。由于我们可以通过 Terraform 输出做到这一点，让我们从 `outputs.tf`
    中这个例子开始。它构造了一个带有动态信息的 SSH 命令行，我们可以轻松使用（它只是遍历每个可用的 `digitalocean_droplet.coreos.*`）：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will look like this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Dynamic DNS Integration
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 动态 DNS 集成
- en: 'One of the attractive features of Digital Ocean is the easy DNS integration.
    For example, if our domain is `infrastructure-as-code.org` and we launch a *blog*
    droplet, we''ll end up registering it automatically under the public DNS name
    `blog.infrastructure-as-code.org`. Pretty easy and dynamic! To give Digital Ocean
    power on our domain, we need to go to our registrar (where we bought our domain),
    and configure our domain to be managed by Digital Ocean, using their own nameservers,
    which are as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Digital Ocean 的一个吸引人的特点是简单的 DNS 集成。例如，如果我们的域名是 `infrastructure-as-code.org`，而我们启动了一个
    *blog* droplet，我们将自动将其注册为公有 DNS 名称 `blog.infrastructure-as-code.org`。非常简单和动态！为了让
    Digital Ocean 管理我们的域名，我们需要访问我们的域名注册商（即购买域名的地方），并配置我们的域名由 Digital Ocean 管理，使用他们的自有
    DNS 服务器，具体如下：
- en: '`ns1.digitalocean.com`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ns1.digitalocean.com`'
- en: '`ns2.digitalocean.com`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ns2.digitalocean.com`'
- en: '`ns3.digitalocean.com`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ns3.digitalocean.com`'
- en: 'This prerequisite being done, let''s declare our domain in the `dns.tf` file
    using the `digitalocean_domain` resource, automatically using a `cluster_domainname`
    variable for the domain name, and an initial IP address matching, that we can
    either set to a value you already know or to an arbitrary droplet:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此先决条件后，我们在 `dns.tf` 文件中声明我们的域名，使用 `digitalocean_domain` 资源，自动使用 `cluster_domainname`
    变量作为域名，并进行初始 IP 地址匹配，这个 IP 地址我们可以设置为已知值或任意一个 droplet：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Add the new variable in `variables.tf`:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `variables.tf` 中添加新变量：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Don't forget to override it as necessary in `terraform.tfvars`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了在 `terraform.tfvars` 中根据需要覆盖它。
- en: 'The next step is to register automatically every droplet in the DNS. By iterating
    over each droplet, and extracting their `name` and `ipv4_address` attributes,
    we''ll add this `digitalocean_record` resource into the mix:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是自动将每个 droplet 注册到 DNS。通过遍历每个 droplet，提取它们的 `name` 和 `ipv4_address` 属性，我们将把这个
    `digitalocean_record` 资源加入到配置中：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will automatically register every droplet under the name core-[1,2,3].mydomain.com,
    for easier access and reference.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这将自动将每个 droplet 注册为名称为 core-[1,2,3].mydomain.com，以便更方便地访问和引用。
- en: 'If you like, you can access the `fqdn` attribute of this resource right from
    the outputs (`outputs.tf`):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，你可以直接在输出文件（`outputs.tf`）中访问该资源的 `fqdn` 属性：
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Integrating cloud-init
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成 cloud-init
- en: We need to build a fully working `cloud-config.yml` file for our CoreOS cluster.
    Refer to the cloud-init part of this book in [Chapter 5](ch05.html "Chapter 5. Provisioning
    the Last Mile with Cloud-Init"), *Provisioning the Last Mile with Cloud-Init*
    for more information on the `cloud-config.yml` file, and especially on configuring
    CoreOS with it.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为 CoreOS 集群构建一个完全可用的 `cloud-config.yml` 文件。有关 `cloud-config.yml` 文件的更多信息，特别是如何配置
    CoreOS，参考本书的 [第5章](ch05.html "第5章. 使用 Cloud-Init 配置最后一公里")，*使用 Cloud-Init 配置最后一公里*。
- en: 'What we need for a fully usable CoreOS cluster are the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的完全可用的 CoreOS 集群包括以下内容：
- en: A working etcd cluster on the local network interface (`$private_ipv4`)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地网络接口（`$private_ipv4`）上的工作 etcd 集群
- en: A working fleet cluster on the local network interface (`$private_ipv4`)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地网络接口（`$private_ipv4`）上的工作 fleet 集群
- en: Fleet is a distributed init system. You can think of it as systemd for a whole
    cluster
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Fleet 是一个分布式初始化系统。你可以把它看作是整个集群的 systemd。
- en: To configure etcd, we first need to obtain a new token. This token is unique
    and can be distributed through different channels. It can be easily obtained through
    the [https://coreos.com/os/docs/latest/cluster-discovery.html](https://coreos.com/os/docs/latest/cluster-discovery.html)
    etcd service. Then we'll start 2 units—etcd and fleet.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置 etcd，首先需要获取一个新的令牌。这个令牌是唯一的，可以通过不同的渠道分发。可以通过 [https://coreos.com/os/docs/latest/cluster-discovery.html](https://coreos.com/os/docs/latest/cluster-discovery.html)
    等等服务轻松获取。然后我们将启动两个单元——etcd 和 fleet。
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Note this URL carefully and copy paste it in the following `cloud-config.yml`
    file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细注意这个 URL，并将其复制粘贴到以下 `cloud-config.yml` 文件中：
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This will be enough to start an etcd + fleet cluster on CoreOS. [Chapter 5](ch05.html
    "Chapter 5. Provisioning the Last Mile with Cloud-Init"), *Provisioning the Last*
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这就足够在 CoreOS 上启动一个 etcd + fleet 集群。[第5章](ch05.html "第5章. 使用 Cloud-Init 配置最后一公里")，*配置最后一公里*
- en: '*Mile with Cloud-Init*, for in-depth details on cloud-init.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*与 Cloud-Init 配置最后一公里*，深入了解 cloud-init。'
- en: Integrating dynamic StatusCake monitoring
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成动态 StatusCake 监控
- en: We can reuse our knowledge from previous chapters to easily integrate full latency
    monitoring to the hosts of our CoreOS cluster, using a free StatusCake account
    ([https://statuscake.com](https://statuscake.com)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以复用之前章节中的知识，通过使用免费的 StatusCake 账户 ([https://statuscake.com](https://statuscake.com))，轻松地为
    CoreOS 集群的主机集成完整的延迟监控。
- en: 'Start by configuring the provider in `providers.tf`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在 `providers.tf` 中配置提供商：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Declare the required variables in `variables.tf`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `variables.tf` 中声明所需的变量：
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Also, override with your own values in `terraform.tfvars`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在 `terraform.tfvars` 中用你自己的值进行覆盖。
- en: 'Now we can use the `statuscake_test` resource to activate immediate latency
    (ping) monitoring on every droplet by iterating over each `digitalocean_droplet.coreos.*`
    resource value:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `statuscake_test` 资源通过遍历每个 `digitalocean_droplet.coreos.*` 资源值，在每个
    Droplet 上启用即时延迟（ping）监控：
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'It''s time to `terraform apply` this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候运行 `terraform apply` 了：
- en: '[PRE20]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Confirm that we can connect to a member using the command line from the output:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 确认我们可以通过命令行连接到一个成员，查看输出：
- en: '[PRE21]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Verify the etcd cluster health:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 验证 etcd 集群的健康状况：
- en: '[PRE22]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Check that all fleet members are all right:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 检查所有 fleet 成员是否正常：
- en: '[PRE23]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Enjoy, in less than a minute, you're ready to use a CoreOS cluster with basic
    monitoring, using only fully automated Terraform code!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 享受吧，在不到一分钟的时间里，你就可以通过完全自动化的 Terraform 代码，使用带有基本监控的 CoreOS 集群！
- en: Provisioning a three-tier infrastructure on Google Compute Engine
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Google Compute Engine 上配置三层基础设施
- en: 'We''ll provision a ready to use, three-tier, load-balanced web infrastructure
    on Google Compute Engine, using two CentOS 7.2 servers for the web and one master
    Google MySQL instance. The MySQL instance will allow connections only from the
    two web servers (with valid credentials), and all three instances (SQL and HTTP)
    will be accessible from a single *corporate* network (our company''s network).
    The topology looks like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Google Compute Engine 上配置一个三层负载均衡的 web 基础设施，使用两个 CentOS 7.2 服务器作为 web 服务器，以及一个主
    Google MySQL 实例。MySQL 实例只允许来自这两个 web 服务器的连接（并且需要有效的凭证），所有三个实例（SQL 和 HTTP）都将通过一个单一的
    *公司* 网络（我们公司的网络）进行访问。拓扑结构如下：
- en: '![Provisioning a three-tier infrastructure on Google Compute Engine](img/B05671_04_01.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![在 Google Compute Engine 上配置三层基础设施](img/B05671_04_01.jpg)'
- en: Getting ready
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To step through this recipe, you will need the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要按步骤执行这个配方，你需要以下内容：
- en: A working Terraform installation
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可用的 Terraform 安装
- en: A Google Compute Engine account with a project
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Google Compute Engine 项目账号
- en: An Internet connection
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一条互联网连接
- en: How to do it…
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何执行...
- en: The first thing we need to do is to get our credentials from the console.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要首先从控制台获取我们的凭据。
- en: Generating API credentials for a Google project
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为 Google 项目生成 API 凭据。
- en: Navigate to your Google Cloud project, and in the *API Manager*, select **Credentials**
    | **Create credentials** | **Service Account Key**. Now choose **Compute Engine
    default service account** from the dropdown list, in the JSON format. Save this
    file as `account.json` at the root of the infrastructure repository.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 转到您的 Google Cloud 项目，在 *API 管理器* 中选择 **凭据** | **创建凭据** | **服务帐号密钥**。现在从下拉列表中选择
    **Compute Engine 默认服务帐号**，格式选择 JSON。将此文件保存为 `account.json`，放在基础设施存储库的根目录。
- en: 'Create the variables to define our credentials file in `variables.tf`, store
    the region we''re running in, and the Google Compute project name:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `variables.tf` 文件中创建变量来定义我们的凭据文件，存储我们正在运行的区域和 Google Compute 项目名称：
- en: '[PRE24]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Don''t forget to override those values in `terraform.tfvars` if you want to:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记在 `terraform.tfvars` 中覆盖这些值（如果需要）：
- en: '[PRE25]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, in a `providers.tf` file, add the `google` provider:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在 `providers.tf` 文件中，添加 `google` 供应商：
- en: '[PRE26]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Our `google` provider is now configured!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `google` 供应商现在已配置完成！
- en: Creating Google Compute HTTP instances
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 Google Compute HTTP 实例。
- en: 'Here''s the checklist of our requirements for these HTTP hosts:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们为这些 HTTP 主机的需求清单：
- en: We want two of them
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要两个实例。
- en: Their type is `n1-standard-1` (3.75 GB of RAM, one vCPU)
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们的类型是 `n1-standard-1`（3.75 GB RAM，1 vCPU）。
- en: 'Their region and zone is: us-east1-d'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们的区域和区域是：us-east1-d。
- en: 'They are running CentOS 7.2 (official image is: centos-cloud/centos 7)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们正在运行 CentOS 7.2（官方镜像为：centos-cloud/centos 7）。
- en: The default SSH username is `centos`
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认的 SSH 用户名是 `centos`。
- en: The SSH key known to us is (`keys/admin_key`)
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已知的 SSH 密钥是 (`keys/admin_key`)。
- en: We want a fully updated system with Docker installed and running
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要一个完全更新的系统，并安装并运行 Docker。
- en: 'Let''s define generic variables for all these requirements in a `variables.tf`
    file:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 `variables.tf` 文件中为所有这些要求定义通用变量：
- en: '[PRE27]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now let''s override in `terraform.tfvars` the generic values we just set:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在 `terraform.tfvars` 中覆盖刚设置的通用值：
- en: '[PRE28]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Google Cloud instances are called from Terraform using the resource `google_compute_instance`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 实例通过 `google_compute_instance` 资源从 Terraform 调用：
- en: 'Let''s add what we already know in this resource:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在此资源中添加我们已知的内容：
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This could be enough, but we want to go much farther.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能已经足够了，但我们希望走得更远。
- en: 'For example, we''ll later add a firewall, whose rule will apply to a target
    defined by its tags. Let''s add a tag right now, so we can use it later:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，稍后我们将添加一个防火墙，其规则将应用于由其标签定义的目标。现在让我们立即添加一个标签，以便稍后使用它：
- en: '[PRE30]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We have to configure networking. It''s necessary in our case to have a public
    IPv4, because we need to access the servers by SSH from outside. We might have
    chosen to not have publicly exposed servers and use a bastion host instead. To
    create a network interface in our default network, mapped behind a public IPv4,
    add the following to the `google_compute_instance` resource:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须配置网络。在我们的情况下需要一个公共 IPv4 地址，因为我们需要从外部通过 SSH 访问服务器。我们也可以选择不公开暴露服务器而使用堡垒主机。要在默认网络中创建一个网络接口，映射到公共
    IPv4 后面，请将以下内容添加到 `google_compute_instance` 资源中：
- en: '[PRE31]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s finish by connecting automatically to each instance and fully update
    it, then install, enable, and start Docker. We do this using the `remote-exec`
    provisioner, correctly configured with the right SSH username and private key:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们最后通过 `remote-exec` 配置项自动连接到每个实例并完全更新它，然后安装、启用和启动 Docker。我们将正确配置 `remote-exec`
    与正确的 SSH 用户名和私钥：
- en: '[PRE32]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We're finally done, with our two instances automatically provisioned!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于完成了，我们的两个实例已自动配置完成！
- en: Creating a Google Compute Firewall rule
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个 Google Compute 防火墙规则。
- en: 'Our goal is simple: we want to allow anyone (0.0.0.0/0) to access using HTTP
    (TCP port `80`) any instance with the tag `www` in the default network. To do
    this, let''s use the `google_compute_firewall` resource:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标很简单：我们希望允许任何人（0.0.0.0/0）通过 HTTP（TCP 端口 `80`）访问任何标记为 `www` 的默认网络中的实例。为此，让我们使用
    `google_compute_firewall` 资源：
- en: '[PRE33]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Load balancing Google Compute instances
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负载均衡 Google Compute 实例。
- en: 'To load balance requests across our two instances, we''ll need to create a
    *pool* of hosts, where membership will be handled by a simple health check: an
    HTTP `GET` on / every second, with an immediate timeout (`1` second), and removal
    after `3` errors. We can do this in a file named `pool.tf` with the `google_compute_http_health_check`
    resource:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们的两个实例之间负载均衡请求，我们需要创建一个*主机池*，其成员资格将通过简单的健康检查来管理：每秒对 / 进行一次 HTTP `GET` 请求，立即超时（`1`
    秒），并在发生 `3` 次错误后移除。我们可以在名为 `pool.tf` 的文件中使用 `google_compute_http_health_check`
    资源来实现：
- en: '[PRE34]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Feel free to transform those values into variables for better tuning on your
    end!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 随意将这些值转换为变量，以便在你的环境中进行更好的调优！
- en: 'Now, let''s define the pool, which is defined by the results of the health
    checks and instances inclusion. This is done using the `google_compute_target_pool`
    resource:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义池，池是由健康检查的结果和实例的包含情况定义的。这可以通过 `google_compute_target_pool` 资源来实现：
- en: '[PRE35]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `self_link` attribute returns the URI of the resource.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`self_link` 属性返回资源的 URI。'
- en: 'Now we have our pool of hosts with health checks, let''s create the load balancer
    itself. It''s done using the `google_compute_forwarding_rule` resource, simply
    pointing to the pool of hosts we created earlier. Add the following in a `loadbalancer.tf`
    file:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了带健康检查的主机池，接下来创建负载均衡器本身。我们可以使用 `google_compute_forwarding_rule` 资源来实现，只需指向我们之前创建的主机池即可。将以下内容添加到
    `loadbalancer.tf` 文件中：
- en: '[PRE36]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Creating a Google MySQL database instance
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个 Google MySQL 数据库实例
- en: Our typical target application needs a database to store and access data. We
    won't get into database replication here, but it can also be done quite simply
    with Terraform on Google Cloud.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的典型目标应用需要一个数据库来存储和访问数据。这里我们不深入讨论数据库复制，但它也可以通过 Terraform 在 Google Cloud 上轻松实现。
- en: Note
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Double-check you have the SQL API activated in the Google Cloud Console: [https://console.cloud.google.com/apis/library](https://console.cloud.google.com/apis/library).
    By default, it isn''t.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细检查你是否在 Google Cloud 控制台中激活了 SQL API：[https://console.cloud.google.com/apis/library](https://console.cloud.google.com/apis/library)。默认情况下，它是没有激活的。
- en: 'Here''s a checklist of what we know about our MySQL database:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们关于 MySQL 数据库的检查清单：
- en: It's running on us-east1 region
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它运行在 us-east1 区域
- en: It's running MySQL 5.6
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它运行 MySQL 5.6
- en: It's type is *D2* (1 GB of RAM)
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的类型是*D2*（1 GB 内存）
- en: Our own network and both HTTP servers can access it
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们自己的网络和两个 HTTP 服务器都可以访问它
- en: We want a database named `app_db`
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望创建一个名为 `app_db` 的数据库
- en: We want a user with a password to be allowed to connect from the HTTP servers
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望一个具有密码的用户能够从 HTTP 服务器连接
- en: 'Let''s put all these variables in the `variables.tf` file:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把所有这些变量放在 `variables.tf` 文件中：
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Don''t forget to override each generic value in the `terraform.tfvars`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了在 `terraform.tfvars` 中覆盖每个通用值：
- en: '[PRE38]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now we can build our database using the `google_sql_database_instance` resource
    in a `db.tf` file:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `google_sql_database_instance` 资源在 `db.tf` 文件中构建数据库：
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `pricing_plan` `"PACKAGE"` is more interesting for a long-lasting database.
    Also, the `authorized_network` block doesn't currently support a `count` value,
    so we can't iterate dynamically over every HTTP host. For now, we have to duplicate
    the block, but that may very well change in a newer Terraform version.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`pricing_plan` `"PACKAGE"` 更适合长期使用的数据库。同时，`authorized_network` 块当前不支持 `count`
    值，因此我们无法动态迭代每个 HTTP 主机。目前，我们必须复制该块，但在未来的 Terraform 版本中，这种情况可能会改变。'
- en: 'Let''s now create a database, using a `google_sql_database` resource:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `google_sql_database` 资源创建一个数据库：
- en: '[PRE40]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finish by creating the SQL user with host restriction. Like the `authorized_network`
    block, the `google_sql_user` resource doesn''t support a count value yet, so we
    have to duplicate the code for each HTTP server for now:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过创建具有主机限制的 SQL 用户来完成。与 `authorized_network` 块类似，`google_sql_user` 资源当前还不支持
    `count` 值，因此我们暂时需要为每个 HTTP 服务器复制代码：
- en: '[PRE41]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Adding some useful outputs
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加一些有用的输出
- en: 'It would be awesome to have some useful information such as IPs for all our
    instances and services and usernames and passwords. Let''s add some outputs in
    `outputs.tf`:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一些有用的信息，如所有实例和服务的 IP、用户名和密码，会非常棒。让我们在 `outputs.tf` 中添加一些输出：
- en: '[PRE42]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here we are!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 到这里了！
- en: '[PRE43]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Simply deploy our application on the HTTP servers and we''re done! To test
    drive the load balancer and the HTTP instances, you can simply deploy the NGINX
    container on each server and see the traffic flow:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 只需在 HTTP 服务器上部署我们的应用程序，任务就完成了！为了测试负载均衡器和 HTTP 实例，您可以简单地在每个服务器上部署 NGINX 容器并查看流量：
- en: '[PRE44]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Provisioning a GitLab CE + CI runners on OpenStack
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 OpenStack 上部署 GitLab CE 和 CI 运行器
- en: OpenStack is a very popular open source cloud computing solution. Many providers
    are based on it, and you can roll your own in your data center. In this example,
    we'll use the public OpenStack by OVH, located in Montreal, QC (Canada), but we
    can use any other OpenStack. There're differences in implementation for every
    custom deployment, but we'll stick with very stable features.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 是一个非常流行的开源云计算解决方案。许多提供商都基于它，你也可以在自己的数据中心中构建它。在这个示例中，我们将使用 OVH 提供的公共
    OpenStack，位于加拿大蒙特利尔，但你也可以使用任何其他 OpenStack。每个自定义部署在实现上有所不同，但我们将坚持使用非常稳定的功能。
- en: We'll launch one compute instance running Ubuntu LTS 16.04 for GitLab, with
    a dedicated block device for Docker, and two other compute instances for GitLab
    CI runners. Security will allow HTTP for everyone, but SSH only for a known IP
    from our corporate network. To store our builds or releases, we'll create a *container*,
    which is in OpenStack terminology—an object storage. The equivalent with AWS S3
    is a *bucket*.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将启动一个运行 Ubuntu LTS 16.04 的计算实例来托管 GitLab，使用一个专用的块设备来存储 Docker，并且还会启动两个计算实例来作为
    GitLab CI 运行器。安全组将允许所有人访问 HTTP，但仅允许来自公司网络已知 IP 的 SSH 访问。为了存储我们的构建或发布，我们将创建一个 *容器*，在
    OpenStack 术语中，这就是对象存储。AWS S3 的等效物是 *存储桶*。
- en: Getting ready
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To step through this recipe, you will need the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行这个操作步骤，你将需要以下资源：
- en: A working Terraform installation.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个有效的 Terraform 安装。
- en: An OpenStack account on any OpenStack provider (public or private). This recipe
    uses an account on OVH's public OpenStack ([https://www.ovh.com/us/](https://www.ovh.com/us/)).
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 OpenStack 账户，使用任何 OpenStack 提供商（公有或私有）。这个配方使用的是 OVH 公共 OpenStack 的账户（[https://www.ovh.com/us/](https://www.ovh.com/us/)）。
- en: An Internet connection.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个互联网连接。
- en: How to do it…
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We''ll create:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建：
- en: Three compute instances (virtual machines)
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个计算实例（虚拟机）
- en: One keypair
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个密钥对
- en: One block storage device
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个块存储设备
- en: One security group
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个安全组
- en: One object storage bucket
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个对象存储桶
- en: Configuring the OpenStack provider
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 OpenStack 提供商
- en: 'Let''s start by configuring the OpenStack provider. We need four pieces of
    information: a username, a password, an OpenStack tenant name, and an OpenStack
    authentication endpoint URL. To make the code very dynamic, let''s create variables
    for those in `variables.tf`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先配置 OpenStack 提供商。我们需要四个信息：用户名、密码、OpenStack 租户名称和 OpenStack 认证端点 URL。为了使代码更加动态，我们将在
    `variables.tf` 文件中为这些信息创建变量：
- en: '[PRE45]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Don't forget to override the default values with your own in the `terraform.tfvars`
    file!
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了在 `terraform.tfvars` 文件中用你自己的值覆盖默认值！
- en: '[PRE46]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Now we're good to go.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好开始了。
- en: Creating a key pair on OpenStack
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 OpenStack 上创建一个密钥对
- en: 'To authenticate ourselves on the instances, we need to provide the public part
    of the key pair to OpenStack. This is done using the `openstack_compute_keypair_v2`
    resource, specifying in which region we want the key, and where the key is. Let''s
    add both variables in `variables.tf`:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在实例上进行身份验证，我们需要将密钥对的公钥部分提供给 OpenStack。可以使用 `openstack_compute_keypair_v2`
    资源来完成此操作，指定我们希望在哪个区域生成密钥，以及密钥存放的位置。让我们在 `variables.tf` 中添加这两个变量：
- en: '[PRE47]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Next, override them in the `terraform.tfvars` file:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在 `terraform.tfvars` 文件中覆盖它们：
- en: '[PRE48]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now we can build our resource in the `keys.tf` file:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在 `keys.tf` 文件中构建我们的资源：
- en: '[PRE49]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Creating a security group on OpenStack
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 OpenStack 上创建安全组
- en: 'We know our requirements are to allow HTTP (TCP/80) from anywhere, but SSH
    (TCP/22) only from one corporate network. Add it right now in `variables.tf` so
    we can use it:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们的要求是允许来自任何地方的 HTTP（TCP/80）访问，但仅允许来自一个公司网络的 SSH（TCP/22）访问。现在就将其添加到 `variables.tf`
    中，以便我们可以使用：
- en: '[PRE50]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Don't forget to override with your own network in `terraform.tfvars`.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了在 `terraform.tfvars` 中覆盖为你自己的网络配置。
- en: 'Let''s create a first security group allowing HTTP for everyone in our region,
    using the `openstack_compute_secgroup_v2` resource in a `security.tf` file:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个安全组，允许我们区域中的所有人访问 HTTP，使用 `openstack_compute_secgroup_v2` 资源，并将其放在 `security.tf`
    文件中：
- en: '[PRE51]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Following the same pattern, create another security group to allow SSH only
    from our corporate network:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 按照相同的模式，再创建一个安全组，仅允许来自我们公司网络的 SSH 访问：
- en: '[PRE52]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Creating block storage volumes on OpenStack
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 OpenStack 上创建块存储卷
- en: 'In our requirements, we want a dedicated volume to be available to our GitLab
    instance, for Docker. We decide this one will be `10` GB in size. This volume
    will be mounted by the compute instance under a dedicated device (likely `/dev/vdb`).
    The whole thing is done using the `openstack_blockstorage_volume_v2` resource:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的需求，我们希望为 GitLab 实例提供一个专用的卷，用于 Docker。我们决定这个卷的大小为 `10` GB。该卷将由计算实例挂载为一个专用设备（可能是
    `/dev/vdb`）。整个过程将使用 `openstack_blockstorage_volume_v2` 资源完成：
- en: '[PRE53]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Add a simple output in `outputs.tf` so we know the volume description, name,
    and size:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `outputs.tf` 中添加一个简单的输出，以便我们知道存储卷的描述、名称和大小：
- en: '[PRE54]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: We now have every requirement to launch our compute instances.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经具备启动计算实例的所有要求。
- en: Creating compute instances on OpenStack
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 OpenStack 上创建计算实例
- en: 'It''s now time to create the instances. We know they have to be Ubuntu 16.04,
    and we decide on a flavor name: a flavor is the type of the machine. It varies
    from every other OpenStack installation. In our case, it''s named `vps-ssd-1`.
    Let''s define some defaults in the `variables.tf` file:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是创建实例的时候了。我们知道它们必须是 Ubuntu 16.04，并且我们决定了一个 flavor 名称：flavor 是机器的类型，每个 OpenStack
    安装的类型可能不同。在我们的情况下，它被命名为 `vps-ssd-1`。我们来在 `variables.tf` 文件中定义一些默认值：
- en: '[PRE55]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Also, override them with good values in `terraform.tfvars`:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，在 `terraform.tfvars` 中使用合适的值覆盖它们：
- en: '[PRE56]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'To create a compute instance, we use a resource named `openstack_compute_instance_v2`.
    This resource takes all the parameters we previously declared (name, image, flavor,
    SSH key, and security groups). Let''s try this in `instances.tf`:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个计算实例，我们使用名为 `openstack_compute_instance_v2` 的资源。此资源需要我们之前声明的所有参数（名称、镜像、flavor、SSH
    密钥和安全组）。让我们在 `instances.tf` 中尝试一下：
- en: '[PRE57]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'To attach the block storage volume we created, we need to add a `volume {}`
    block inside the resource:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 要附加我们创建的块存储卷，我们需要在资源中添加一个 `volume {}` 块：
- en: '[PRE58]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now, an optional but fun part is that the commands needed to format the volume,
    mount it at the right place, fully update the system, install Docker, and run
    the GitLab CE container. This is done using the `remote-exec` provisioner and
    requires a SSH username. Let''s set it as `variables.tf`:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，稍显有趣但可选的部分是需要的命令，用于格式化卷、将其挂载到正确的位置、全面更新系统、安装 Docker，并运行 GitLab CE 容器。这是通过
    `remote-exec` 提供器完成的，并且需要 SSH 用户名。我们将其设置为 `variables.tf`：
- en: '[PRE59]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now we can just type in all the commands to be executed when the instance is
    ready:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以输入所有命令，当实例准备好时它们将被执行：
- en: '[PRE60]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Add a simple output in the `outputs.tf` file, so we easily know the GitLab
    instance public IP:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `outputs.tf` 文件中添加一个简单的输出，以便我们可以轻松查看 GitLab 实例的公网 IP：
- en: '[PRE61]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The runner instances are the same, but a little simpler, as they don''t need
    a local volume. However, we need to set the amount of runners we want in `variables.tf`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 runner 实例是相同的，但稍微简单一些，因为它们不需要本地存储卷。不过，我们需要在 `variables.tf` 中设置所需的 runner
    数量：
- en: '[PRE62]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Override the value to have more runners in `terraform.tfvars`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `terraform.tfvars` 中覆盖值，以便有更多的 runners：
- en: '[PRE63]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Now we can create our runner instances using the `openstack_compute_instance_v2`
    resource:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `openstack_compute_instance_v2` 资源来创建我们的 runner 实例：
- en: '[PRE64]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This will launch a GitLab CI runner, so builds can be triggered by GitLab! (there's
    one last step of configuration, though. It's out of the scope of this book, but
    we need to register each runner to the main GitLab instance by executing `docker
    exec -it gitlab-runner gitlab-runner register` and answering the questions).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动一个 GitLab CI runner，因此可以通过 GitLab 触发构建！(不过还有最后一步配置，这超出了本书的范围，但我们需要通过执行 `docker
    exec -it gitlab-runner gitlab-runner register` 来将每个 runner 注册到主 GitLab 实例，并回答相应问题)。
- en: 'Add the following output to `outputs.tf` so we know all the IP addresses of
    our runners:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `outputs.tf` 中添加以下输出，以便我们知道所有 runner 的 IP 地址：
- en: '[PRE65]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Creating an object storage container on OpenStack
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 OpenStack 上创建对象存储容器
- en: 'This one is very simple: it only requires a name and a region. As it''s to
    store releases, let''s call it `releases`, using the `openstack_objectstorage_container_v1`
    resource, in an `objectstorage.tf` file:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这个非常简单：它只需要一个名称和一个区域。由于它是用来存储发布的，我们将其命名为 `releases`，使用 `openstack_objectstorage_container_v1`
    资源，在 `objectstorage.tf` 文件中：
- en: '[PRE66]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Add a simple output in `outputs.tf` so we remember the `Object Storage` container
    name:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `outputs.tf` 中添加一个简单的输出，以便我们记住 `Object Storage` 容器的名称：
- en: '[PRE67]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Applying
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用
- en: 'In the end, do a `terraform apply`:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，执行 `terraform apply`：
- en: '[PRE68]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Connect to the GitLab instance and enjoy the runners (after GitLab token registration)!
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 连接到 GitLab 实例，享受运行的过程（在 GitLab token 注册之后）！
- en: Managing Heroku apps and add-ons using Terraform
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Terraform 管理 Heroku 应用和附加组件
- en: 'Heroku is a popular **Platform-as-a-Service** (**PaaS**), where you have absolutely
    no control over the infrastructure. But even for such platforms, Terraform can
    automate and manage things for you, so Heroku can do the rest. We''ll create an
    app (a simple GitHub Hubot: [http://hubot.github.com/](http://hubot.github.com/)),
    but feel free to use your own. On top of this app, we''ll automatically plug a
    Heroku add-on (redis) and deploy everything.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Heroku 是一个流行的 **平台即服务** (**PaaS**)，在这里你对基础设施没有任何控制权。但即便是这样的平台，Terraform 也能为你自动化和管理许多工作，剩下的交给
    Heroku 来处理。我们将创建一个应用程序（一个简单的 GitHub Hubot：[http://hubot.github.com/](http://hubot.github.com/)），但你也可以使用自己的应用程序。在这个应用程序的基础上，我们将自动添加一个
    Heroku 插件（redis）并部署所有内容。
- en: Getting ready
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To step through this recipe, you will need the following:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成此教程，你需要以下资源：
- en: A working Terraform installation
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个工作正常的 Terraform 安装
- en: A Heroku account ([https://www.heroku.com/](https://www.heroku.com/))
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Heroku 账户 ([https://www.heroku.com/](https://www.heroku.com/))
- en: An optional Slack Token
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可选的 Slack 令牌
- en: An Internet connection
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要互联网连接
- en: How to do it…
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'First things first: we need to define the Heroku provider. It consists of an
    e-mail address and an API key. Let''s create generic variables for that in `variables.tf`:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 首先：我们需要定义 Heroku 提供者。它由一个电子邮件地址和 API 密钥组成。让我们在 `variables.tf` 中为此创建通用变量：
- en: '[PRE69]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Don''t forget to override them in `terraform.tfvars`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了在 `terraform.tfvars` 中重写这些变量：
- en: '[PRE70]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Now we can create the Heroku provider with the information we have:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以用已有的信息创建 Heroku 提供者：
- en: '[PRE71]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Creating a Heroku application with Terraform
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Terraform 创建 Heroku 应用程序
- en: 'Instead of clicking through Heroku to create an application, let''s do it right
    from Terraform. We want to run our app in Europe and we want Hubot to connect
    to Slack, so we need to provide a Slack token as well. Let''s start by creating
    default values in `variables.tf`:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不通过点击 Heroku 来创建应用程序，而是直接从 Terraform 中完成。我们希望在欧洲运行我们的应用程序，并且希望 Hubot 连接到 Slack，因此我们还需要提供一个
    Slack 令牌。让我们从在 `variables.tf` 中创建默认值开始：
- en: '[PRE72]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now we can create our first Heroku app with its variables using the `heroku_app`
    resource, in `heroku.tf`:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `heroku_app` 资源，在 `heroku.tf` 中创建我们的第一个 Heroku 应用程序及其变量：
- en: '[PRE73]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: That's it! As simple as it seems.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！看起来很简单。
- en: 'Add some output in `outputs.tf` so we have better information about our app,
    like the Heroku app URL and environment variables:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `outputs.tf` 中添加一些输出，以便我们能获取更多关于应用程序的信息，比如 Heroku 应用程序 URL 和环境变量：
- en: '[PRE74]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Adding Heroku add-ons using Terraform
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Terraform 添加 Heroku 插件
- en: 'Some add-ons need Redis to store data. Instead of going through the web application
    and enabling add-ons, let''s instead use the `heroku_addon` resource. It takes
    a reference to the app to link the add-on to, and a plan (`hobby-dev` is free,
    so let''s use that):'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 一些插件需要 Redis 来存储数据。我们不通过 Web 应用程序启用插件，而是使用 `heroku_addon` 资源。它需要一个应用程序的引用来链接插件，并且还需要一个计划（`hobby-dev`
    是免费的，所以我们使用这个计划）：
- en: '[PRE75]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Using Heroku with Terraform
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Heroku 和 Terraform
- en: 'It''s out of the scope of this book to show Heroku usage, but let''s apply
    this terraform code:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不涉及 Heroku 的使用，但让我们应用这段 terraform 代码：
- en: '[PRE76]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'If you don''t have an application ready to ship on Heroku, let''s try to deploy
    GitHub''s chat robot *Hubot*. It''s an easy application ready to use on Heroku.
    Quickly reading through the Hubot documentation, let''s install the Hubot generator:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有准备好要在 Heroku 上部署的应用程序，那就尝试部署 GitHub 的聊天机器人 *Hubot* 吧。它是一个可以在 Heroku 上直接使用的简单应用程序。快速浏览
    Hubot 文档后，让我们安装 Hubot 生成器：
- en: '[PRE77]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Create a new `hubot`:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的 `hubot`：
- en: '[PRE78]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Answer the questions and when you''re done, using the usual `heroku` command,
    add the Heroku git remote for our Heroku app:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 回答问题，完成后，使用常规的 `heroku` 命令，为我们的 Heroku 应用程序添加 Heroku git 远程连接：
- en: '[PRE79]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Now you can `git push heroku` and see your application being deployed, all using
    Terraform.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用 `git push heroku` 来看到应用程序被部署，整个过程都在 Terraform 的控制下。
- en: Creating a scalable Docker Swarm cluster on bare metal with Packet
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在裸金属服务器上通过 Packet 创建可扩展的 Docker Swarm 集群
- en: IaaS clouds have been popularized through heavy usage of virtual machines. Recent
    initiatives are targeting bare metal servers with an API, so we get the best of
    both worlds—on-demand servers through an API and incredible performance through
    direct access to the hardware. [https://www.packet.net/](https://www.packet.net/)
    is a bare metal IaaS provider ([https://www.scaleway.com/](https://www.scaleway.com/)
    is another) very well supported by Terraform with an awesome global network. Within
    minutes we have new hardware ready and connected to the network.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: IaaS云服务通过广泛使用虚拟机已经变得非常流行。最近的举措针对裸金属服务器提供API服务，使得我们可以同时享受两者的优势——通过API按需获取服务器，并通过直接访问硬件获得卓越的性能。[https://www.packet.net/](https://www.packet.net/)是一个裸金属IaaS提供商（[https://www.scaleway.com/](https://www.scaleway.com/)是另一个），并且Terraform对此提供了极好的支持，拥有强大的全球网络。几分钟内，我们就能获得新的硬件并将其连接到网络中。
- en: 'We''ll build a fully automated and scalable Docker Swarm cluster, so we can
    operate highly scalable and performant workloads on bare metal: this setup can
    scale thousands of containers in just a few minutes. This cluster is composed
    of *Type 0* machines (4 cores and 8 GB RAM), for one manager and 2 nodes, totaling
    12 cores and 24 GB of RAM, but we can use more performant machines if we want:
    the same cluster with *Type 2* machines will have 72 cores and 768 GB of RAM (though
    the price will adapt accordingly).'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个完全自动化且可扩展的Docker Swarm集群，以便在裸金属上运行高度可扩展和高性能的工作负载：这个设置可以在几分钟内扩展数千个容器。该集群由*类型0*机器组成（4核和8GB
    RAM），包括1个管理节点和2个工作节点，总共12核和24GB RAM，但如果需要，我们可以使用更高性能的机器：同样的集群如果使用*类型2*机器，将拥有72核和768GB
    RAM（不过价格会相应调整）。
- en: Getting ready
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To step through this recipe, you will need the following:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 要逐步完成这个步骤，你将需要以下内容：
- en: A working Terraform installation
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可用的Terraform安装环境
- en: A Packet.net account with an API key
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Packet.net账户和API密钥
- en: An Internet connection
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个互联网连接
- en: How to do it…
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Let''s start by creating the `packet` provider, using the API key (an authentication
    token). Create the variable in `variables.tf`:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们通过API密钥（身份验证token）创建`packet`提供者。在`variables.tf`文件中创建变量：
- en: '[PRE80]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Also, be sure to override the value in `terraform.tfvars` with the real token:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，确保在`terraform.tfvars`中覆盖真实的token值：
- en: '[PRE81]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Creating a Packet project using Terraform
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Terraform创建Packet项目
- en: 'Packet, like some other IaaS providers, uses the notion of *project* to group
    machines. Let''s create a project named `Docker Swarm Bare Metal Infrastructure`,
    since that''s what we want to do, in a `projects.tf` file:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Packet和一些其他IaaS提供商一样，使用*项目*的概念来组织机器。让我们在`projects.tf`文件中创建一个名为`Docker Swarm
    Bare Metal Infrastructure`的项目，因为这正是我们想做的：
- en: '[PRE82]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: This way, if you happen to manage multiple projects or customers, you can split
    them all into their own projects.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，如果你需要管理多个项目或客户，你可以将它们分配到各自的项目中。
- en: Handling Packet SSH keys using Terraform
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Terraform管理Packet SSH密钥
- en: 'To connect to the machines using SSH, we need at least one public key uploaded
    to our Packet account. Let''s create a variable to store it in `variables.tf`:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过SSH连接到机器，我们需要至少上传一个公钥到Packet账户。我们在`variables.tf`文件中创建一个变量来存储它：
- en: '[PRE83]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Don't forget to override the value in `terraform.tfvars` if you use another
    name for the key.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用了不同的密钥名称，别忘了在`terraform.tfvars`中覆盖其值。
- en: 'Let''s use the `packet_ssh_key` resource to create the SSH key on our Packet
    account:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`packet_ssh_key`资源在Packet账户中创建SSH密钥：
- en: '[PRE84]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Bootstraping a Docker Swarm manager on Packet using Terraform
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Terraform在Packet上启动Docker Swarm管理节点
- en: 'We''ll create two types of servers for this Docker Swarm cluster: managers
    and nodes. Managers are controlling what''s executed on the nodes. We''ll start
    by bootstrapping the Docker Swarm manager server, using the Packet service (more
    alternatives are available from Packet API):'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为这个Docker Swarm集群创建两种类型的服务器：管理节点和工作节点。管理节点控制在工作节点上执行的任务。我们将从引导Docker Swarm管理节点服务器开始，使用Packet服务（Packet
    API提供了更多的选择）：
- en: We want the cheapest server (`baremetal_0`)
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望选择最便宜的服务器（`baremetal_0`）
- en: We want the servers in Amsterdam (`ams1`)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望服务器位于阿姆斯特丹（`ams1`）
- en: We want the servers to run Ubuntu 16.04 (`ubuntu_16_04_image`)
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望服务器运行Ubuntu 16.04（`ubuntu_16_04_image`）
- en: Default SSH user is `root`
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认SSH用户是`root`
- en: Billing will be `hourly`, but that can be `monthly` as well
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计费将按`小时`计算，但也可以选择`月度`计费
- en: 'Let''s put generic information in `variables.tf` so we can manipulate them:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把一些通用信息放入`variables.tf`，以便之后进行操作：
- en: '[PRE85]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Also, override them in `terraform.tfvars` to match our values:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在`terraform.tfvars`中覆盖它们，以确保与我们的值匹配：
- en: '[PRE86]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'To create a server with Packet, let''s use the `packet_device` resource, specifying
    the chosen plan, facility, operating system, billing, and the project in which
    it will run:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Packet 创建服务器，我们可以使用`packet_device`资源，指定所选计划、设施、操作系统、计费方式以及运行项目：
- en: '[PRE87]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Now, let's create two scripts that will execute when the server is ready. The
    first one will update Ubuntu (`update_os.sh`) while the second will install Docker
    (`install_docker.sh`).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建两个脚本，当服务器准备好后执行。第一个脚本将更新 Ubuntu（`update_os.sh`），而第二个脚本将安装 Docker（`install_docker.sh`）。
- en: '[PRE88]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'This script will install and start Docker:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本将安装并启动 Docker：
- en: '[PRE89]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'We can now call those scripts as a `remote-exec` provisioner inside the `packet_device`
    resource:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将这些脚本作为`remote-exec`配置器，在`packet_device`资源内调用：
- en: '[PRE90]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: At this point, the system is fully provisioned and functional, with Docker running.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，系统已完全配置并正常运行，Docker 也正在运行。
- en: 'To initialize a Docker Swarm cluster, starting with Docker 1.12, we can just
    issue the following command:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 要初始化 Docker Swarm 集群，从 Docker 1.12 开始，我们只需要执行以下命令：
- en: '[PRE91]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'A server at Packet has one interface sharing both public and private IP addresses.
    The private IP is the second one, and is available through the following exported
    attribute: `${packet_device.swarm_master.network.2.address}`. Let''s create another
    `remote-exec` provisioner, so the Swarm manager is initialized automatically,
    right after bootstrap:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: Packet 上的服务器有一个接口，既共享公共 IP 地址，也共享私有 IP 地址。私有 IP 是第二个，且可以通过以下导出的属性访问：`${packet_device.swarm_master.network.2.address}`。我们来创建另一个`remote-exec`配置器，这样
    Swarm 管理器将在启动后自动初始化：
- en: '[PRE92]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: At this point, we have a Docker cluster running, with only one node—the manager
    itself.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们已经有一个正在运行的 Docker 集群，只有一个节点——即管理节点本身。
- en: 'The last step is to store the Swarm token, so the nodes can join. The token
    can be obtained with the following command:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是存储 Swarm 令牌，以便节点能够加入。可以使用以下命令获取令牌：
- en: '[PRE93]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'We''ll store this token in a simple file in our infrastructure repository (`worker.token`),
    so we can access it and version it. Let''s create a variable to store our token
    in a file in `variables.tf`:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把此令牌存储在基础设施存储库中的一个简单文件（`worker.token`）中，这样我们可以访问并版本化它。我们来创建一个变量，将令牌存储在`variables.tf`中的文件中：
- en: '[PRE94]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'We will execute the previous `docker swarm` command through SSH when everything
    else is done, using a `local-exec` provisioner. As we can''t interact with the
    process, let''s skip the host key checking and other initial SSH checks:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 当其他操作完成后，我们将通过 SSH 执行先前的`docker swarm`命令，使用`local-exec`配置器。由于我们无法与进程进行交互，所以跳过主机密钥检查和其他初始的
    SSH 检查：
- en: '[PRE95]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: We're now done with the Docker Swarm manager!
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在完成了 Docker Swarm 管理器的配置！
- en: Bootstraping Docker Swarm nodes on Packet using Terraform
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Terraform 在 Packet 上启动 Docker Swarm 节点
- en: 'We need nodes to join the swarm, so the workload can be spread. For convenience,
    the machine specs for the nodes will be the same as that of the master. Here''s
    what will happen:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要节点加入 Swarm 集群，以便工作负载能够分散。为了方便起见，节点的机器规格将与主节点相同。以下是将要发生的情况：
- en: Two nodes are created
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了两个节点
- en: The token file is sent to each node
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令牌文件已发送到每个节点
- en: The operating system is updated, and Docker is installed
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统已更新，Docker 已安装
- en: The node joins the swarm
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点加入 Swarm 集群
- en: 'Let''s start by creating a variable for the number of nodes we want, in `variables.tf`:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从在`variables.tf`中创建一个用于指定节点数量的变量开始：
- en: '[PRE96]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Override that value as the cluster grows in `terraform.tfvars`:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 随着集群的增长，在`terraform.tfvars`中重写该值：
- en: '[PRE97]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Create the nodes using the same `packet_device` resource we used for the master:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与主节点相同的`packet_device`资源来创建节点：
- en: '[PRE98]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Add a `file` provisioner to copy the token file:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个`file`配置器来复制令牌文件：
- en: '[PRE99]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Using the same update and Docker installation scripts as the master, create
    the same `remote-exec` provisioner:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与主节点相同的更新和 Docker 安装脚本，创建相同的`remote-exec`配置器：
- en: '[PRE100]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: The operating system is now fully updated and Docker is running.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统现已完全更新，Docker 正在运行。
- en: 'Now we want to join the Docker Swarm cluster. To do this, we need two pieces
    of information: the token and the local IP of the master. We already have the
    token in a file locally, and Terraform knows the local IP of the swarm manager.
    So a trick is to create a simple script (I suggest you write a more robust one!),
    that reads the local token, and takes the local manager IP address as an argument.
    In a file named `scripts/join_swarm.sh`, enter the following lines:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想加入 Docker Swarm 集群。为此，我们需要两项信息：token 和主节点的本地 IP 地址。我们已经在本地文件中有了 token，Terraform
    也知道 Swarm 管理节点的本地 IP 地址。所以一个技巧是创建一个简单的脚本（建议你写一个更健壮的脚本！），它读取本地的 token，并将本地管理节点的
    IP 地址作为参数传递。在名为 `scripts/join_swarm.sh` 的文件中，输入以下内容：
- en: '[PRE101]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Now we just have to send this file to the nodes using the `file` provisioner:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要使用 `file` 提供者将这个文件发送到各个节点：
- en: '[PRE102]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Use it as a last step through a `remote-exec` provisioner, sending the local
    Docker master IP (`${packet_device.swarm_master.network.2.address}"`) as an argument
    to the script:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，通过 `remote-exec` 提供者使用它，将本地 Docker 主节点 IP (`${packet_device.swarm_master.network.2.address}"`)
    作为参数传递给脚本：
- en: '[PRE103]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Launch the whole infrastructure:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 启动整个基础设施：
- en: '[PRE104]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Our cluster is running.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的集群正在运行。
- en: Using the Docker Swarm cluster
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Docker Swarm 集群
- en: Using our Docker Swarm cluster is out of the scope of this book, but now we
    have it, let's take a quick look to scale a container to the thousands!
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的 Docker Swarm 集群超出了本书的范围，但现在我们已经有了它，让我们快速看看如何将容器扩展到数千个！
- en: 'Verify we have our 3 nodes:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 验证我们是否有 3 个节点：
- en: '[PRE105]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: We want a common network for our containers, and we want to scale to the thousands.
    So a typical /24 network won't be enough (that's the `docker network` default).
    Let's create a /16 overlay network, so we have room for scale!
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为我们的容器创建一个共享网络，并且希望能够扩展到数千个容器。所以一个典型的 /24 网络是不够的（那是 `docker network` 的默认设置）。我们来创建一个
    /16 的覆盖网络，这样就有足够的扩展空间了！
- en: '[PRE106]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Create a Docker service that will simply launch an nginx container on this
    new overlay network, with 3 replicas (3 instances of the container running at
    the same time):'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 Docker 服务，它将在这个新的覆盖网络上启动一个 nginx 容器，并且有 3 个副本（容器的 3 个实例同时运行）：
- en: '[PRE107]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Verify if it''s working:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 验证它是否正常工作：
- en: '[PRE108]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Now, accessing by HTTP any of the public IPs of the cluster, any container
    of any node can answer: we can make an HTTP request to node-1, and it can be a
    container on node-2 responding. Nice!'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过 HTTP 访问集群的任何公共 IP 地址，任何节点上的容器都可以响应：我们可以向节点-1 发起 HTTP 请求，而响应可能来自节点-2 上的一个容器。很棒！
- en: 'Let''s scale our service now, from 3 replicas to 100:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来扩展我们的服务，从 3 个副本扩展到 100 个：
- en: '[PRE109]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: We just scaled to a hundred containers in a few seconds and split them on all
    3 bare metal machines.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在几秒钟内将容器扩展到一百个，并将它们分布到所有 3 台裸金属机器上。
- en: Now, you know you can scale, and with such a configuration you can push the
    `nginx` service to 500, 1000, or maybe more!
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你知道可以进行扩展，并且通过这样的配置，你可以将 `nginx` 服务扩展到 500 个、1000 个，甚至更多！
