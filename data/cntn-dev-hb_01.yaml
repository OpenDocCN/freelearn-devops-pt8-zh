- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Modern Infrastructure and Applications with Docker
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker的现代基础设施与应用程序
- en: Software engineering and development is always evolving and introducing new
    technologies in its architectures and workflows. Software containers appeared
    more than a decade ago, becoming particularly popular over the last five years
    thanks to Docker, which made the concept mainstream. Currently, every enterprise
    manages its container-based application infrastructure in production in both the
    cloud and on-premises distributed infrastructures. This book will teach you how
    to increase your development productivity using software containers so that you
    can create, test, share, and run your applications. You will use a container-based
    workflow and your final application artifact will be a Docker image-based deployment,
    ready to run in production environments.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程与开发一直在不断发展，引入新技术到架构和工作流中。软件容器在十多年前就已出现，并在过去五年中特别流行，得益于Docker的普及，使得这一概念成为主流。目前，每个企业都在云端和本地分布式基础设施上管理其基于容器的应用程序基础设施。本书将教你如何通过使用软件容器来提高开发生产力，从而创建、测试、共享和运行你的应用程序。你将使用基于容器的工作流，最终的应用程序构件将是基于Docker镜像的部署，准备在生产环境中运行。
- en: This chapter will introduce software containers in the context of the current
    software development culture, which needs faster software supply chains made of
    moving, distributed pieces. We will review how containers work and how they fit
    into modern application architectures based on distributed components with very
    specific functionalities (microservices). This allows developers to choose the
    best language for each application component and distribute the total application
    load. We will learn about the kernel features that make software containers possible
    and learn how to create, share, and run application components as software containers.
    At the end of this chapter, we will learn about the different tools that can help
    us work with software containers and provide specific use cases for your laptop,
    desktop computer, and servers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍软件容器，尤其是在当前软件开发文化中的应用。现代开发文化需要更快速的软件供应链，由可移动、分布式的组件组成。我们将回顾容器的工作原理以及它们如何适应基于分布式组件（具有非常特定功能的微服务）的现代应用程序架构。这使得开发人员可以为每个应用组件选择最合适的语言，并分散整个应用程序的负载。我们将学习使软件容器成为可能的内核特性，并学习如何创建、共享和运行作为软件容器的应用程序组件。在本章的最后，我们将了解不同的工具，帮助我们使用软件容器，并为你的笔记本电脑、台式机和服务器提供具体的应用场景。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Evolution of application architecture, from monoliths to distributed microservice
    architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序架构的演变，从单体架构到分布式微服务架构
- en: Developing microservice-based applications
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发基于微服务的应用程序
- en: How containers fit in the microservices model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器如何适应微服务模型
- en: Understanding the main concepts, features, and components of software containers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解软件容器的主要概念、特性和组成部分
- en: Comparing virtualization and containers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较虚拟化和容器
- en: Building, sharing, and running containers
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建、共享和运行容器
- en: Explaining Windows containers
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释Windows容器
- en: Improving security using software containers
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用软件容器提升安全性
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This book will teach you how to use software containers to improve your application
    development. We will use open source tools for building, sharing, and running
    containers, along with a few commercial ones that don’t require licensing for
    non-professional use. Also included in this book are some labs to help you practically
    understand the content that we’ll work through. These labs can be found at [https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter1](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter1).
    The *Code In Action* video for this chapter can be found at [https://packt.link/JdOIY](https://packt.link/JdOIY).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将教你如何使用软件容器来提高应用程序开发效率。我们将使用开源工具来构建、共享和运行容器，并结合一些不需要专业授权的商业工具。此外，本书还包含一些实验，帮助你实践理解我们所讨论的内容。这些实验可以在[https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter1](https://github.com/PacktPublishing/Containers-for-Developers-Handbook/tree/main/Chapter1)找到。本章的*Code
    In Action*视频可以在[https://packt.link/JdOIY](https://packt.link/JdOIY)找到。
- en: From monoliths to distributed microservice architectures
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从单体架构到分布式微服务架构
- en: Application architectures are continuously evolving due to technological improvements.
    Throughout the history of computation, every time a technical gap is resolved
    in hardware and software engineering, software architects rethink how applications
    can be improved to take advantage of the new developments. For example, network
    speed increases made distributing application components across different servers
    possible, and nowadays, it’s not even a problem to distribute these components
    across data centers in multiple countries.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随着技术的进步，应用架构不断演变。在计算历史上，每当硬件和软件工程中的技术差距得到解决时，软件架构师就会重新思考如何改进应用，以利用这些新的技术进展。例如，网络速度的提升使得将应用组件分布到不同服务器成为可能，如今，甚至将这些组件分布到多个国家的数据中心也不成问题。
- en: To take a quick look at how computers were adopted by enterprises, we must go
    back in time to the old mainframe days (before the 1990s). This can be considered
    the base for what we call **unitary architecture** – one big computer with all
    the processing functionality, accessed by users through terminals. Following this,
    the **client-server** model became very popular as technology also advanced on
    the user side. Server technologies improved while clients gained more and more
    functionality, freeing up the server load for publishing applications. We consider
    both models as **monoliths** as all application components run on one server;
    even if the databases are decoupled from the rest of the components, running all
    important components in a dedicated server is still considered monolithic. Both
    of these models were very difficult to upgrade when performance started to drop.
    In these cases, newer hardware with higher specifications was always required.
    These models also suffer from availability issues, meaning that any maintenance
    tasks required on either the server or application layer will probably lead to
    service outages, which affects the normal system uptime.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要快速了解计算机是如何被企业采纳的，我们必须回到早期的主机时代（1990年代之前）。这可以被视为我们今天所称的**单体架构**的基础——一台拥有所有处理功能的大型计算机，用户通过终端进行访问。在此之后，随着用户端技术的进步，**客户端-服务器**模型变得非常流行。服务器技术不断改进，而客户端则获得了越来越多的功能，减轻了服务器的负载，从而支持应用发布。我们认为这两种模型都是**单体**的，因为所有应用组件都运行在同一台服务器上；即使数据库与其他组件解耦，将所有重要组件运行在专用服务器上，仍然被视为单体架构。这两种模型在性能下降时都很难升级。在这种情况下，通常需要更高规格的硬件。这些模型也存在可用性问题，即任何对服务器或应用层的维护任务都可能导致服务中断，进而影响系统的正常运行时间。
- en: Exploring monolithic applications
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索单体应用
- en: '**Monolithic applications** are those in which all functionalities are provided
    by just one component, or a set of them so tightly integrated that they cannot
    be decoupled from one another. This makes them hard to maintain. They weren’t
    designed with reusability or modularity in mind, meaning that every time developers
    need to fix an issue, add some new functionality, or change an application’s behavior,
    the entire application is affected due to, for example, having to recompile the
    whole application’s code.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**单体应用**是指所有功能由一个组件或一组紧密集成的组件提供，这些组件彼此之间无法解耦，从而使得它们的维护变得困难。它们的设计并未考虑重用性或模块化，意味着每当开发人员需要修复一个问题、添加新功能或改变应用的行为时，整个应用都会受到影响，例如，可能需要重新编译整个应用程序的代码。'
- en: Providing high availability to monolithic applications required duplicated hardware,
    quorum resources, and continuous visibility between application nodes. This may
    not have changed too much today but we have many other resources for providing
    high availability. As applications grew in complexity and gained responsibility
    for many tasks and functionalities, we started to decouple them into a few smaller
    components (with specific functions such as the web server, database, and more),
    although core components were kept immutable. Running all application components
    together on the same server was better than distributing them into smaller pieces
    because network communication speeds weren’t high enough. Local filesystems were
    usually used for sharing information between application processes. These applications
    were difficult to scale (more hardware resources were required, usually leading
    to acquiring newer servers) and difficult to upgrade (testing, staging, and certification
    environments before production require the same hardware or at least compatible
    ones). In fact, some applications could run only on specific hardware and operating
    system versions, and developers needed workstations or servers with the same hardware
    or operating system to be able to develop fixes or new functionality for these
    applications.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为单体应用程序提供高可用性需要重复的硬件、仲裁资源和应用程序节点之间的持续可见性。虽然今天这一点可能没有太大变化，但我们现在拥有许多其他资源来提供高可用性。随着应用程序复杂性的增加，它们开始承担更多任务和功能，我们开始将其解耦成几个较小的组件（例如，Web
    服务器、数据库等具有特定功能的组件），尽管核心组件保持不变。将所有应用程序组件运行在同一台服务器上比将它们分散到更小的部分更为合适，因为当时的网络通信速度并不够快。通常，使用本地文件系统在应用程序进程之间共享信息。这些应用程序的扩展性差（需要更多的硬件资源，通常导致需要购买更先进的服务器），并且升级困难（生产前需要相同或至少兼容的硬件来进行测试、预发布和认证环境的构建）。事实上，一些应用程序只能在特定的硬件和操作系统版本上运行，开发人员需要具备相同硬件或操作系统的工作站或服务器才能开发修复程序或新功能。
- en: Now that we know how applications were designed in the early days, let’s introduce
    virtualization in data centers.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了早期应用程序的设计方式，现在让我们介绍一下数据中心中的虚拟化技术。
- en: Virtual machines
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟机
- en: The concept of **virtualization** – providing a set of physical hardware resources
    for specific purposes – was already present in the mainframe days before the 1990s,
    but in those days, it was closer to the definition of **time-sharing** at the
    compute level. The concept we commonly associate with virtualization comes from
    the introduction of the **hypervisor** and the new technology introduced in the
    late 1990s that allowed for the creation of complete virtual servers running their
    own virtualized operating systems. This hypervisor software component was able
    to virtualize and share host resources in virtualized guest operating systems.
    In the 1990s, the adoption of Microsoft Windows and the emergence of Linux as
    a server operating system in the enterprise world established x86 servers as the
    industry standard, and virtualization helped the growth of both of these in our
    data centers, improving hardware usage and server upgrades. The virtualization
    layer simplified virtual hardware upgrades when applications required more memory
    or CPU and also improved the process of providing services with high availability.
    Data centers became smaller as newer servers could run dozens of virtual servers,
    and as physical servers’ hardware capabilities increased, the number of virtualized
    servers per node increased.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**虚拟化**的概念——为特定目的提供一组物理硬件资源——早在1990年代前就已经出现在大型机时代，但在那个时期，它更接近于计算级别的**时间共享**定义。我们通常所说的虚拟化概念源于1990年代末期引入的**虚拟机监控器**（hypervisor）及新技术，它使得能够创建运行自己虚拟操作系统的完整虚拟服务器。这个虚拟机监控器软件组件能够在虚拟化的客户操作系统中虚拟化并共享主机资源。在1990年代，微软Windows的普及和Linux作为企业级服务器操作系统的崛起，使得x86服务器成为行业标准，虚拟化技术推动了这两者在数据中心的增长，提高了硬件的利用率并促进了服务器的升级。当应用程序需要更多内存或CPU时，虚拟化层简化了虚拟硬件的升级过程，也提高了高可用性服务的提供过程。随着新的服务器能够运行数十个虚拟服务器，数据中心变得更加紧凑，而随着物理服务器硬件能力的提升，每个节点上虚拟化的服务器数量也在增加。'
- en: 'In the late 1990s, the servers became services. This means that companies started
    to think about the services they provided instead of the way they did it. Cloud
    providers arrived to provide services to small businesses that didn’t want to
    acquire and maintain their own data centers. Thus, a new architecture model was
    created, which became pretty popular: the **cloud computing infrastructure** model.
    Amazon launched **Amazon Web Services** (**AWS**), providing storage, computation,
    databases, and other infrastructure resources. And pretty soon after that, Elastic
    Compute Cloud entered the arena of virtualization, allowing you to run your own
    servers with a few clicks. Cloud providers also allowed users to use their well-documented
    **application programming interfaces** (**APIs**) for automation, and the concept
    of **Infrastructure as Code** (**IaC**) was introduced. We were able to create
    our virtualization instances using programmatic and reusable code. This model
    also changed the service/hardware relationship and what started as a good idea
    at first – using cloud platforms for every enterprise service – became a problem
    for big enterprises, which saw increased costs pretty quickly based on network
    bandwidth usage and as a result of not sufficiently controlling their use of cloud
    resources. Controlling cloud service costs soon became a priority for many enterprises,
    and many open source projects started with the premise of providing cloud-like
    infrastructures. **Infrastructure elasticity** and **easy provisioning** are the
    keys to these projects. OpenStack was the first one, distributed in smaller projects,
    each one focused on different functionalities (storage, networking, compute, provisioning,
    and so on). The idea of having on-premises cloud infrastructure led software and
    infrastructure vendors into new alliances with each other, in the end providing
    new technologies for data centers with the required flexibility and resource distribution.
    They also provided APIs for quickly deploying and managing provisioned infrastructure,
    and nowadays, we can provision either cloud infrastructure resources or resources
    on our data centers using the same code with few changes.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在1990年代末期，服务器变成了服务。这意味着公司开始考虑他们提供的服务，而不是如何提供服务。云服务提供商应运而生，向那些不想拥有和维护自己数据中心的小型企业提供服务。因此，创建了一种新的架构模型，并变得相当流行：**云计算基础设施**模型。亚马逊推出了**亚马逊网络服务**（**AWS**），提供存储、计算、数据库以及其他基础设施资源。很快，弹性计算云（Elastic
    Compute Cloud）进入了虚拟化领域，允许用户通过几次点击就能运行自己的服务器。云服务提供商还允许用户使用他们的文档完备的**应用程序编程接口**（**API**）进行自动化，并引入了**基础设施即代码**（**IaC**）的概念。我们可以通过编程和可重用的代码创建虚拟化实例。这个模型还改变了服务/硬件的关系，最初作为一个好主意——将云平台用于每个企业服务——最终变成了大企业的问题，这些企业很快就看到了基于网络带宽使用的成本增加，且由于没有充分控制其云资源的使用，成本进一步上升。控制云服务成本很快成为许多企业的优先事项，许多开源项目也基于提供云类基础设施的前提开始了。**基础设施弹性**和**简易配置**是这些项目的关键。OpenStack是第一个，它被分发成多个小项目，每个项目专注于不同的功能（存储、网络、计算、配置等）。拥有本地云基础设施的想法促使软件和基础设施供应商建立新的合作伙伴关系，最终为数据中心提供了具有所需灵活性和资源分配的新技术。他们还提供了用于快速部署和管理配置基础设施的API，现在，我们可以使用相同的代码，仅需少量更改，就能配置云基础设施资源或我们数据中心的资源。
- en: Now that we have a good idea of how server infrastructures work today, let’s
    go back to applications.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经对今天的服务器基础设施有了清晰的了解，接下来让我们回到应用程序。
- en: Three-tier architecture
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 三层架构
- en: Even with these decoupled infrastructures, applications can still be monoliths
    if we don’t prepare them for separation into different components. Elastic infrastructures
    allow us to distribute resources and it would be nice to have distributed components.
    Network communications are essential and technological evolution has increased
    speeds, allowing us to consume network-provided services as if they were local
    and facilitating the use of distributed components.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有了这些解耦的基础设施，如果我们没有将应用程序准备好分离成不同的组件，它们仍然可能是单体应用。弹性基础设施允许我们分配资源，最好能够拥有分布式组件。网络通信至关重要，技术的进步提高了速度，使我们能够像使用本地服务一样使用网络提供的服务，并促进了分布式组件的使用。
- en: '**Three-tier architecture** is a software application architecture where the
    application is decoupled into three to five logical and physical computing layers.
    We have the **presentation tier**, or user interface; the **application tier**,
    or backend, where data is processed; and the **data tier**, where the data for
    use in the application is stored and managed, such as in a database. This model
    was used even before virtualization arrived on the scene, but you can imagine
    the improvement of being able to distribute application components across different
    virtual servers instead of increasing the number of servers in your data center.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**三层架构**是一种软件应用架构，其中应用被解耦成三到五个逻辑和物理计算层。我们有**表示层**，即用户界面；**应用层**，即后台，数据在此被处理；以及**数据层**，应用所需的数据在此存储和管理，比如在数据库中。即使在虚拟化技术出现之前，这种模型也已经被使用，但你可以想象，能够将应用组件分布到不同的虚拟服务器上，而不是增加数据中心中服务器的数量，这样的改进。'
- en: 'Just to recap before continuing our journey: the evolution of infrastructure
    and network communications has allowed us to run component-distributed applications,
    but we just have a few components per application in the three-tier model. Note
    that in this model, different roles are involved in application maintenance as
    different software technologies are usually employed. For example, we need database
    administrators, middleware administrators, and infrastructure administrators for
    systems and network communications. In this model, although we are still forced
    to use servers (virtual or physical), application component maintenance, scalability,
    and availability are significantly improved. We can manage each component in isolation,
    executing different maintenance tasks and fixes and adding new functionalities
    decoupled from the application core. In this model, developers can focus on either
    frontend or backend components. Some coding languages are specialized for each
    layer – for example, JavaScript was the language of choice for frontend developers
    (although it evolved for backend services too).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续我们的旅程之前，先回顾一下：基础设施和网络通信的发展使我们能够运行组件分布式的应用，但在三层模型中，每个应用只有少量组件。请注意，在这个模型中，由于通常采用不同的软件技术，不同的角色参与到应用的维护中。例如，我们需要数据库管理员、中间件管理员以及系统和网络通信的基础设施管理员。在这个模型中，尽管我们仍然不得不使用服务器（虚拟或物理），但应用组件的维护、可扩展性和可用性得到了显著提高。我们可以独立管理每个组件，执行不同的维护任务和修复，并在不依赖于应用核心的情况下增加新功能。在这个模型中，开发人员可以专注于前端或后端组件。一些编程语言专门为每一层设计——例如，JavaScript是前端开发人员的首选语言（尽管它也发展成为后端服务的语言）。
- en: As Linux systems grew in popularity in the late 1990s, applications were distributed
    into different components, and eventually different applications working together
    and running in different operating systems became a new requirement. Shared files,
    provided by network filesystems using either **network-attached storage** (**NAS**)
    or more complex **storage area network** (**SAN**) storage backends were used
    at first, but **Simple Object Access Protocol** (**SOAP**) and other queueing
    message technologies helped applications to distribute data between components
    and manage their information without filesystem interactions. This helped decouple
    applications into more and more distributed components running on top of different
    operating systems.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Linux系统在1990年代末期的普及，应用被分布成不同的组件，最终，不同的应用在不同操作系统上协同工作，成为一种新的需求。最初通过网络文件系统提供的共享文件（使用**网络附加存储**（**NAS**）或更复杂的**存储区域网络**（**SAN**）存储后端）被使用，但**简单对象访问协议**（**SOAP**）和其他队列消息技术帮助应用在组件之间分发数据并管理其信息，而无需与文件系统交互。这有助于将应用解耦成更多分布式组件，运行在不同的操作系统之上。
- en: Microservices architecture
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务架构
- en: The **microservices architecture** model goes a step further, decoupling applications
    into smaller pieces with enough functionality to be considered components. This
    model allows us to manage a completely independent component life cycle, freeing
    us to choose whatever coding language fits best with the functionality in question.
    Application components are kept light in terms of functionality and content, which
    should lead to them using fewer host resources and responding faster to start
    and stop commands. Faster restarts are key to resilience and help us maintain
    our applications while up, with fewer outages. Application health should not depend
    on component-external infrastructure; we should improve components’ logic and
    resilience so that they can start and stop as fast as possible. This means that
    we can ensure that changes to an application are applied quickly, and in the case
    of failure, the required processes will be up and running in seconds. This also
    helps in managing the application components’ life cycle as we can upgrade components
    very fast and prepare circuit breakers to manage stopped dependencies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**微服务架构**模型更进一步，将应用程序解耦为足够小的组件，每个组件都有足够的功能，可以视为独立的模块。该模型使我们能够管理完全独立的组件生命周期，允许我们选择最适合该功能的编程语言。应用程序组件在功能和内容方面保持轻量，这应该使它们占用更少的主机资源，并能够更快地响应启动和停止命令。更快的重启对于系统的弹性至关重要，并帮助我们在应用程序运行时减少故障停机。应用程序的健康状况不应依赖于组件外部的基础设施；我们应改进组件的逻辑和弹性，使其能够尽可能快速地启动和停止。这意味着我们可以确保应用程序的变更能够迅速应用，并且在发生故障时，所需的进程能在几秒钟内启动。这还帮助我们管理应用程序组件的生命周期，因为我们可以非常快速地升级组件，并准备断路器来管理停止的依赖。'
- en: Microservices use the **stateless** paradigm; therefore, application components
    should be stateless. This means that a microservice’s state must be abstracted
    from its logic or execution. This is key to being able to run multiple replicas
    of an application component, allowing us to run them distributed on different
    nodes from a pool.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务采用**无状态**范式；因此，应用组件应该是无状态的。这意味着微服务的状态必须与其逻辑或执行过程相分离。这对于能够运行多个副本的应用组件至关重要，使我们能够在不同节点上分布运行它们。
- en: This model also introduced the concept of *run everywhere*, where an application
    should be able to run its components on either cloud or on-premise infrastructures,
    or even a mix of both (for example, the presentation layer for components could
    run on cloud infrastructure while the data resides in our data center).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型还引入了*随处运行*的概念，即应用程序应该能够在云端或本地基础设施上运行其组件，甚至是两者的混合（例如，组件的展示层可以运行在云基础设施上，而数据则存储在我们的数据中心）。
- en: 'Microservices architecture provides the following helpful features:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构提供以下有用特性：
- en: Applications are decoupled into different smaller pieces that provide different
    features or functionalities; thus, we can change any of them at any time without
    impacting the whole application.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序被解耦为多个较小的部分，提供不同的特性或功能；因此，我们可以随时更改其中任何一部分，而不会影响整个应用程序。
- en: Decoupling applications into smaller pieces lets developers focus on specific
    functionalities and allows them to use the most appropriate programming language
    for each component.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用程序解耦为更小的部分，使开发人员可以专注于特定的功能，并允许他们为每个组件使用最合适的编程语言。
- en: Interaction between application components is usually provided via **Representational
    State Transfer** (**REST**) API calls using HTTP. RESTful systems aim for fast
    performance and reliability and can scale without any problem.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用组件之间的交互通常通过**表现性状态转移**（**REST**）API调用使用HTTP来提供。RESTful系统旨在实现快速的性能和可靠性，并能够无障碍地扩展。
- en: Developers describe which methods, actions, and data they provide in their microservice,
    which are then consumed by other developers or users. Software architects must
    standardize how application components talk with each other and how microservices
    are consumed.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发人员描述他们的微服务提供哪些方法、操作和数据，这些方法、操作和数据会被其他开发人员或用户使用。软件架构师必须标准化应用组件之间的交互方式以及微服务的使用方式。
- en: Distributing application components across different nodes allows us to group
    microservices into nodes for the best performance, closer to data sources and
    with better security. We can create nodes with different features to provide the
    best fit for our application components.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用组件分布在不同的节点上，能够将微服务分组到节点中，以获得最佳的性能，更接近数据源并具备更好的安全性。我们可以创建具有不同特性的节点，以便为我们的应用组件提供最合适的环境。
- en: Now that we’ve learned what microservices architecture is, let’s take a look
    at its impact on the development process.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了什么是微服务架构，让我们来看看它对开发过程的影响。
- en: Developing distributed applications
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发分布式应用程序
- en: Monolith applications, as we saw in the previous section, are applications in
    which all functionalities run together. Most of these applications were created
    for specific hardware, operating systems, libraries, binary versions, and so on.
    To run these applications in production, you need a least one dedicated server
    with the right hardware, operating system, libraries, and so on, and developers
    require a similar node architecture and resources even just for fixing possible
    application issues. Adding to this, the pre-production environments for tasks
    such as certification and testing will multiply the number of servers significantly.
    Even if your enterprise had the budget for all these servers, any maintenance
    task as a result of any upgrade in any operating system-related component in production
    should always be replicated on all other environments. Automation helps in replicating
    changes between environments, but this is not easy. You have to replicate environments
    and maintain them. On the other hand, new node provisioning could have taken months
    in the old days (preparing the specifications for a new node, drawing up the budget,
    submitting it to your company’s approvals workflow, looking for a hardware provider,
    and so on). Virtualization helped system administrators provision new nodes for
    developers faster, and automation (provided by tools such as Chef, Puppet, and,
    my favorite, Ansible) allowed for the alignment of changes between all environments.
    Therefore, developers were able to obtain their development environments quickly
    and ensure they were using an aligned version of system resources, improving the
    process of application maintenance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 单体应用程序，正如我们在上一节中看到的，是所有功能共同运行的应用程序。这些应用程序大多数是为特定的硬件、操作系统、库、二进制版本等创建的。要在生产环境中运行这些应用程序，你至少需要一台配备正确硬件、操作系统、库等的专用服务器，而开发人员即便只是为了修复可能的应用问题，也需要类似的节点架构和资源。更不用说，像认证和测试等任务的预生产环境将显著增加服务器的数量。即使你的企业有足够的预算来购买这些服务器，任何由于操作系统相关组件升级导致的维护任务，都必须在所有其他环境中进行复制。这时，自动化有助于在环境之间复制更改，但这并不容易。你必须复制并维护这些环境。另一方面，过去（在虚拟化出现之前）新节点的配置可能需要数月时间（准备新节点的规格、制定预算、提交到公司审批流程、寻找硬件供应商等）。虚拟化帮助系统管理员为开发人员更快地配置新节点，自动化工具（如Chef、Puppet，以及我最喜欢的Ansible）帮助对所有环境之间的更改进行对齐。因此，开发人员能够迅速获取他们的开发环境，并确保他们使用的是对齐版本的系统资源，从而提高了应用程序维护的效率。
- en: Virtualization also worked very well with the three-tier application architecture.
    It was easy to run application components for developers in need of a database
    server to connect to while coding new changes. The problem with virtualization
    comes from the concept of replicating a complete operating system with server
    application components when we only need the software part. A lot of hardware
    resources are consumed for the operating system alone, and restarting these nodes
    takes some time as they are a complete operating system running on top of a hypervisor,
    itself running on a physical server with its own operating system.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟化与三层应用架构的兼容性也非常好。开发人员在需要连接数据库服务器来编写新更改时，能够轻松运行应用组件。虚拟化的问题出在复制一个完整操作系统及其服务器应用组件的概念上，而我们只需要软件部分。仅操作系统就消耗了大量硬件资源，且由于这些节点运行的是一个完整的操作系统，该系统又位于一个虚拟机监控器上，而虚拟机监控器又运行在一台具有自己操作系统的物理服务器上，因此重启这些节点需要一些时间。
- en: Anyhow, developers were hampered by outdated operating system releases and packages,
    making it difficult for them to enable the evolution of their applications. System
    administrators started to manage hundreds of virtual hosts and even with automation,
    they weren’t able to maintain operating systems and application life cycles in
    alignment. Provisioning virtual machines on cloud providers using their **Infrastructure-as-a-Service**
    (**IaaS**) platforms or using their **Platform-as-a-Service** (**PaaS**) environments
    and scripting the infrastructure using their APIs (IaC) helped but the problem
    wasn’t fully resolved due to the quickly growing number of applications and required
    changes. The application life cycle changed from one or two updates per year to
    dozens per day.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，开发者受限于过时的操作系统版本和软件包，这使得他们难以推动应用程序的发展。系统管理员开始管理数百个虚拟主机，即使使用自动化，也无法保持操作系统和应用生命周期的同步。通过使用云提供商的**基础设施即服务**（**IaaS**）平台，或者使用**平台即服务**（**PaaS**）环境，并通过其API（IaC）脚本化基础设施，虽然有所帮助，但由于应用程序数量的快速增长以及所需的更改，问题并未完全解决。应用生命周期从每年一两次更新变成了每天几十次更新。
- en: Developers started to use cloud-provided services and using scripts and applications
    quickly became more important than the infrastructure on which they were running,
    which today seems completely normal and logical. Faster network communications
    and distributed reliability made it easier to start deploying our applications
    anywhere, and data centers became smaller. We can say that developers started
    this movement and it became so popular that we finished decoupling application
    components from the underlying operating systems.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者开始使用云提供的服务，并且使用脚本和应用程序变得比运行它们的基础设施更为重要，这在今天看起来是完全正常和合乎逻辑的。更快的网络通信和分布式可靠性使得我们能够更容易地在任何地方部署应用程序，数据中心也变得越来越小。我们可以说，正是开发者推动了这个运动，并且它变得如此流行，以至于我们最终将应用组件从底层操作系统中解耦。
- en: Software containers are the evolution of process isolation features that were
    learned throughout the development of computer history. Mainframe computers allowed
    us to share CPU time and memory resources many years ago. Chroot and jail environments
    were common ways of sharing operating system resources with users, who were able
    to use all the binaries and libraries prepared for them by system administrators
    in BSD operating systems. On Solaris systems, we had **zones** as resource containers,
    which acted as completely isolated virtual servers within a single operating system
    instance.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 软件容器是计算机历史发展中学到的进程隔离特性的演进。多年前，大型机计算机使我们能够共享CPU时间和内存资源。Chroot和jail环境是共享操作系统资源的常见方式，用户可以使用系统管理员为他们在BSD操作系统中准备的所有二进制文件和库。在Solaris系统中，我们有**区域**作为资源容器，充当单一操作系统实例内完全隔离的虚拟服务器。
- en: So, why don’t we just isolate processes instead of full operating systems? This
    is the main idea behind containers. Containers use kernel features to provide
    process isolation at the operating system level, and all processes run on the
    same host but are isolated from each other. So, every process has its own set
    of resources sharing the same host kernel.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们不直接隔离进程，而不是完整的操作系统呢？这就是容器背后的主要思想。容器利用内核特性，在操作系统层面提供进程隔离，所有进程运行在同一主机上，但彼此隔离。因此，每个进程都有自己的一套资源，分享同一个主机内核。
- en: Linux kernels have featured this design of process grouping since the late 2000s
    in the form of **control groups** (**cgroups**). This feature allows the Linux
    kernel to manage, restrict, and audit groups of processes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 自2000年代末以来，Linux内核就以**控制组**（**cgroups**）的形式具备了这一进程分组的设计。这个特性允许Linux内核管理、限制和审计进程组。
- en: Another very important Linux kernel feature that’s used with containers is **kernel
    namespaces**, which allow Linux to run processes wrapped with their process hierarchy,
    along with their own network interfaces, users, filesystem mounts, and inter-process
    communication. Using kernel namespaces and control groups, we can completely isolate
    a process within an operating system. It will run as if it were on its own, using
    its own operating system and limited CPU and memory (we can even limit its disk
    I/O).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个与容器一起使用的非常重要的Linux内核特性是**内核命名空间**，它允许Linux运行与其进程层次结构绑定的进程，同时具备自己的网络接口、用户、文件系统挂载和进程间通信。通过使用内核命名空间和控制组，我们可以完全隔离操作系统中的进程。它将像在自己的操作系统中运行一样，使用自己有限的CPU和内存（我们甚至可以限制它的磁盘I/O）。
- en: The **Linux Containers** (**LXC**) project took this idea further and created
    the first working implementation of it. This project is still available, is still
    in progress, and was the key to what we now know as **Docker containers**. LXC
    introduced terms such as **templates** to describe the creation of encapsulated
    processes using kernel namespaces.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**Linux 容器**（**LXC**）项目进一步发展了这一理念，创造了第一个可行的实现。这个项目仍然存在，并且还在持续进展，它是我们现在所知的**Docker
    容器**的关键。LXC 引入了诸如**模板**等术语，用来描述使用内核命名空间创建封装进程。'
- en: Docker containers took all these concepts and created Docker Inc., an open source
    project that made it easy to run software containers on our systems. Containers
    ushered in a great revolution, just as virtualization did more than 20 years ago.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 容器将所有这些概念结合起来，创建了 Docker Inc.，一个开源项目，使得在我们的系统上运行软件容器变得简单。容器带来了一场伟大的革命，就像虚拟化在
    20 多年前所做的那样。
- en: Going back to microservices architecture, the ideal application decoupling would
    mean running defined and specific application functionalities as completely standalone
    and isolated processes. This led to the idea of running microservice applications’
    components within containers, with minimum operating system overhead.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 回到微服务架构，理想的应用解耦意味着将定义和特定的应用功能作为完全独立且隔离的进程运行。这促生了将微服务应用组件运行在容器内的理念，且操作系统开销最小。
- en: What are containers?
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是容器？
- en: We can define a container as a process with all its requirements isolated using
    cgroups and namespace kernel features. A **process** is the way we execute a task
    within the operating system. If we define a **program** as the set of instructions
    developed using a programming language, included in an executable format on disk,
    we can say that a process is a program in action.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将容器定义为一个进程，所有的需求都通过 cgroups 和命名空间内核功能被隔离。**进程**是我们在操作系统内执行任务的方式。如果我们将**程序**定义为使用编程语言开发的指令集，并以可执行格式存储在磁盘上，那么我们可以说，进程就是程序在运行。
- en: The execution of a process involves the use of some system resources, such as
    CPU and memory, and although it runs on its own environment, it can use the same
    information as other processes sharing the same host system.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 进程的执行涉及使用一些系统资源，如 CPU 和内存，尽管它在自己的环境中运行，但它可以使用与其他共享同一主机系统的进程相同的信息。
- en: Operating systems provide tools for manipulating the behavior of processes during
    execution, allowing system administrators to prioritize the critical ones. Each
    process running on a system is uniquely identified by a **Process Identifier**
    (**PID**). A parent-child relationship between processes is developed when one
    process executes a new process (or creates a new thread) during its execution.
    The new process (or sub-process) that’s created will have as its parent the previous
    one, and so on. The operating system stores information about process relations
    using PIDs and parent PIDs. Processes may inherit a parent hierarchy from the
    user who runs them, so users own and manage their own processes. Only administrators
    and privileged users can interact with other users’ processes. This behavior also
    applies to child processes created by our executions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统提供了在执行过程中操控进程行为的工具，允许系统管理员优先处理关键进程。每个在系统上运行的进程都有一个唯一的**进程标识符**（**PID**）。当一个进程在执行过程中执行一个新进程（或创建一个新线程）时，会产生进程之间的父子关系。新创建的进程（或子进程）将以之前的进程为父进程，依此类推。操作系统使用
    PID 和父 PID 存储进程关系的信息。进程可能会继承从运行它们的用户那里来的父级层级，因此用户拥有并管理自己的进程。只有管理员和特权用户能够与其他用户的进程交互。这种行为同样适用于我们执行时创建的子进程。
- en: Each process runs on its own environment and we can manipulate its behavior
    using operating system features. Processes can access files as needed and use
    pointers to descriptors during execution to manage these filesystem resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 每个进程都在自己的环境中运行，我们可以使用操作系统的功能来操控它的行为。进程可以根据需要访问文件，并在执行过程中使用指针来描述符来管理这些文件系统资源。
- en: The operating system kernel manages all processes, scheduling them on its physical
    or virtualized CPUs, giving them appropriate CPU time, and providing them with
    memory or network resources (among others).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统内核管理所有进程，将它们调度到物理或虚拟化的 CPU 上，分配适当的 CPU 时间，并为它们提供内存或网络资源（等等）。
- en: These definitions are common to all modern operating systems and are key for
    understanding software containers, which we will discuss in detail in the next
    section.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这些定义适用于所有现代操作系统，并且是理解软件容器的关键，我们将在下一节详细讨论。
- en: Understanding the main concepts of containers
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解容器的主要概念
- en: We have learned that as opposed to virtualization, containers are processes
    running in isolation and sharing the host operating system kernel. In this section,
    we will review the components that make containers possible.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，与虚拟化不同，容器是运行在隔离环境中的进程，并共享主机操作系统的内核。在本节中，我们将回顾使容器成为可能的各个组件。
- en: Kernel process isolation
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内核进程隔离
- en: We already introduced kernel process namespace isolation as a key feature for
    running software containers. Operating system kernels provide namespace-based
    **isolation**. This feature has been present in Linux kernels since 2006 and provides
    different layers of isolation associated with the properties or attributes a process
    has when it runs on a host. When we apply these namespaces to processes, they
    will run their own set of properties and will not see the other processes running
    alongside them. Hence, kernel resources are partitioned such that each set of
    processes sees different sets of resources. Resources may exist in multiple spaces
    and processes may share them.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了内核进程命名空间隔离作为运行软件容器的关键特性。操作系统内核提供基于命名空间的**隔离**。自2006年以来，这一特性就存在于Linux内核中，并提供与进程在主机上运行时的属性或特征相关的不同隔离层级。当我们将这些命名空间应用于进程时，它们会运行自己的属性集，并且看不到与它们并行运行的其他进程。因此，内核资源被分割，使每组进程看到不同的资源集。资源可以存在于多个空间中，进程可能会共享这些资源。
- en: 'Containers, as they are host processes, run with their own associated set of
    kernel namespaces, such as the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 容器作为主机进程运行，具有自己的内核命名空间集，如下所示：
- en: '**Processes**: The container’s main process is the parent of others within
    the container. All these processes share the same process namespace.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进程**：容器的主进程是容器内其他进程的父进程。所有这些进程共享同一进程命名空间。'
- en: '**Network**: Each container receives a network stack with unique interfaces
    and IP addresses. Processes (or containers) sharing the same network namespace
    will get the same IP address. Communications between containers pass through host
    bridge interfaces.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络**：每个容器都分配一个独特的网络栈，包含唯一的接口和IP地址。共享同一网络命名空间的进程（或容器）将获得相同的IP地址。容器之间的通信通过主机桥接接口进行。'
- en: '**Users**: Users within containers are unique; therefore, each container gets
    its own set of users, but these users are mapped to real host user identifiers.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户**：容器内的用户是独立的；因此，每个容器都有自己的用户集，但这些用户会映射到主机的实际用户标识符。'
- en: '**Inter-process communication** (**IPC**): Each container receives its own
    set of shared memory, semaphores, and message queues so that it doesn’t conflict
    with other processes on the host.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进程间通信**（**IPC**）：每个容器都会获得一组独立的共享内存、信号量和消息队列，从而避免与主机上其他进程发生冲突。'
- en: '**Mounts**: Each container mounts a root filesystem; we can also attach remote
    and host local mounts.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**挂载**：每个容器挂载一个根文件系统；我们还可以附加远程和主机本地挂载。'
- en: '**Unix time-sharing** (**UTS**): Each container is assigned a hostname and
    the time is synced with the underlying host.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Unix时间共享**（**UTS**）：每个容器都会被分配一个主机名，并且时间会与底层主机同步。'
- en: Processes running inside a container sharing the same process kernel namespace
    will receive PIDs as if they were running alone inside their own kernel. The container’s
    main process is assigned PID 1 and other sub-processes or threads will get subsequent
    IDs, inheriting the main process hierarchy. The container will die if the main
    process dies (or is stopped).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器内运行的进程共享同一内核命名空间时，将获得类似于单独在自己内核内运行的PID。容器的主进程被分配PID 1，其他子进程或线程将获得后续ID，继承主进程的层次结构。如果主进程死亡（或被停止），容器也会死掉。
- en: 'The following diagram shows how our system manages container PIDs inside the
    container’s PID namespace (represented by the gray box) and outside, at the host
    level:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了我们的系统如何管理容器PID在容器的PID命名空间（由灰色框表示）内外的分配：
- en: '![Figure 1.1 – Schema showing a hierarchy of PIDs when you execute an NGINX
    web server with four worker processes](img/B19845_01_01.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1 – 展示执行一个带有四个工作进程的NGINX web服务器时PID层次结构的示意图](img/B19845_01_01.jpg)'
- en: Figure 1.1 – Schema showing a hierarchy of PIDs when you execute an NGINX web
    server with four worker processes
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 展示执行一个带有四个工作进程的NGINX web服务器时PID层次结构的示意图
- en: In the preceding figure, the main process running inside a container is assigned
    PID 1, while the other processes are its children. The host runs its own PID 1
    process and all other processes run in association with this initial process.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，容器内运行的主进程被分配为 PID 1，而其他进程是其子进程。主机运行自己的 PID 1 进程，所有其他进程与这个初始进程关联运行。
- en: Control groups
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 控制组
- en: 'A **cgroup** is a feature provided by the Linux kernel that enables us to limit
    and isolate the host resources associated with processes (such as CPU, memory,
    and disk I/O). This provides the following features:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**cgroup** 是 Linux 内核提供的一项功能，允许我们限制和隔离与进程相关的主机资源（例如 CPU、内存和磁盘 I/O）。它提供了以下功能：'
- en: '**Resource limits**: Host resources are limited by using a cgroup and thus,
    the number of resources that a process can use, including CPU or memory'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源限制**：通过使用 cgroup 限制主机资源，因此进程可以使用的资源数量（包括 CPU 或内存）是有限的'
- en: '**Prioritization**: If resource contention is observed, the amount of host
    resources (CPU, disk, or network) that a process can use compared to processes
    in another cgroup can be controlled'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优先级**：如果观察到资源争用，可以控制与另一个 cgroup 中的进程相比，进程可以使用的主机资源（CPU、磁盘或网络）数量'
- en: '**Accounting**: Cgroups monitor and report resource limits usage at the cgroup
    level'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计账**：Cgroups 在 cgroup 层级监控并报告资源限制的使用情况'
- en: '**Control**: We can manage the status of all processes in a cgroup'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制**：我们可以管理 cgroup 中所有进程的状态'
- en: The isolation of cgroups will not allow containers to bring down a host by exhausting
    its resources. An interesting fact is that you can use cgroups without software
    containers just by mounting a cgroup (cgroup type system), adjusting the CPU limits
    of this group, and finally adding a set of PIDs to this group. This procedure
    will apply to either cgroups-V1 or the newer cgroups-V2.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: cgroup 的隔离机制不会允许容器通过耗尽主机资源来使主机崩溃。有趣的是，你可以在没有软件容器的情况下使用 cgroup，只需挂载一个 cgroup（cgroup
    类型系统），调整该组的 CPU 限制，最后将一组 PID 添加到该组中。这个过程适用于 cgroups-V1 或更新的 cgroups-V2。
- en: Container runtime
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器运行时
- en: A **container runtime**, or **container engine**, is a piece of software that
    runs containers on a host. It is responsible for downloading container images
    from a registry to create containers, monitoring the resources available in the
    host to run the images, and managing the isolation layers provided by the operating
    system. The container runtime also reviews the current status of containers and
    manages their life cycle, starting again when their main process dies (if we declare
    them to be available whenever this happens).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器运行时**，或称为 **容器引擎**，是一种在主机上运行容器的软件。它负责从注册表下载容器镜像以创建容器，监控主机上可用的资源以运行这些镜像，并管理操作系统提供的隔离层。容器运行时还会检查容器的当前状态并管理其生命周期，在主进程死亡时重新启动（如果我们声明容器在这种情况下可以随时恢复）。'
- en: We generally group container runtimes into **low-level runtimes** and **high-level
    runtimes**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将容器运行时分为 **低级容器运行时** 和 **高级容器运行时**。
- en: Low-level runtimes are those simple runtimes focused only on software container
    execution. We can consider `ldd` command on our binaries and libraries and iterate
    this process with all its dependencies, and so on. We will get a complete list
    of all the files strictly required for the process and this would become the smallest
    image for the application.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 低级容器运行时是那些仅专注于软件容器执行的简单运行时。我们可以考虑对二进制文件和库执行 `ldd` 命令，并迭代所有依赖项的过程。这样我们就能得到一个完整的文件列表，列出所有进程严格需要的文件，这将成为应用程序的最小镜像。
- en: High-level container runtimes usually implement the **Container Runtime Interface**
    (**CRI**) specification of the OCI. This was created to make container orchestration
    more runtime-agnostic. In this group, we have Docker, CRI-O, and Windows/Hyper-V
    containers.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 高级容器运行时通常实现 OCI 的 **容器运行时接口** (**CRI**) 规范。这是为了使容器编排更具运行时无关性。在这一组中，我们有 Docker、CRI-O
    和 Windows/Hyper-V 容器。
- en: 'The CRI interface defines the rules so that we can integrate our container
    runtimes into container orchestrators, such as Kubernetes. Container runtimes
    should have the following characteristics:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: CRI 接口定义了规则，使我们能够将容器运行时集成到容器编排器中，例如 Kubernetes。容器运行时应具备以下特点：
- en: Be capable of starting/stopping pods
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够启动/停止 pod
- en: Deal with all containers (start, pause, stop, and delete them)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理所有容器（启动、暂停、停止和删除它们）
- en: Manage container images
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理容器镜像
- en: Provide metrics collection and access to container logs
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供度量收集和容器日志访问
- en: The Docker container runtime became mainstream in 2016, making the execution
    of containers very easy for users. CRI-O was created explicitly for the Kubernetes
    orchestrator by Red Hat to allow the execution of containers using any OCI-compliant
    low-level runtime. High-level runtimes provide tools for interacting with them,
    and that’s why most people choose them.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Docker容器运行时在2016年成为主流，使得用户可以轻松执行容器。CRI-O是由Red Hat专门为Kubernetes调度器创建的，旨在使用任何符合OCI标准的低级运行时执行容器。高级运行时提供与它们交互的工具，这也是大多数人选择它们的原因。
- en: A middle ground between low-level and high-level container runtimes is provided
    by Containerd, which is an industry-standard container runtime. It runs on Linux
    and Windows and can manage the complete container life cycle.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Containerd作为一种行业标准的容器运行时，提供了低级和高级容器运行时之间的中间地带。它可以在Linux和Windows上运行，并且可以管理整个容器生命周期。
- en: The technology behind runtimes is evolving very fast; we can even improve the
    interaction between containers and hosts using sandboxes (**gVisor** from Google)
    and virtualized runtimes (**Kata Containers**). The former increases containers’
    isolation by not sharing the host’s kernel with them. A specific kernel (the small
    **unikernel** with restricted capabilities) is provided to containers as a proxy
    to the real kernel. Virtualized runtimes, on the other hand, use virtualization
    technology to isolate a container within a very small virtual machine. Although
    both cases add some load to the underlying operating system, security is increased
    as containers don’t interact directly with the host’s kernel.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时背后的技术发展非常迅速；我们甚至可以通过沙箱技术（Google的**gVisor**）和虚拟化运行时（**Kata Containers**）来改善容器和宿主机之间的交互。前者通过不与宿主机共享内核来增加容器的隔离性。容器提供一个特定的内核（具有限制能力的小**unikernel**）作为代理，来替代真实的内核。而虚拟化运行时则使用虚拟化技术将容器隔离在一个非常小的虚拟机中。虽然这两种情况都会给底层操作系统增加一些负担，但通过容器不直接与宿主机内核交互，安全性得到了提升。
- en: Container runtimes only review the main process execution. If any other process
    running inside a container dies and the main process isn’t affected, the container
    will continue running.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时仅审查主进程的执行。如果容器内的其他进程死亡且不影响主进程，容器将继续运行。
- en: Kernel capabilities
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内核能力
- en: Starting with Linux kernel release 2.2, the operating system divides process
    privileges into distinct units, known as **capabilities**. These capabilities
    can be enabled or disabled by operating system and system administrators.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 从Linux内核2.2版本开始，操作系统将进程权限划分为不同的单元，称为**能力**。这些能力可以由操作系统和系统管理员启用或禁用。
- en: Previously, we learned that containers run processes in isolation using the
    host’s kernel. However, it is important to know that only a restricted set of
    these kernel capabilities are allowed inside containers unless they are explicitly
    declared. Therefore, containers improve their processes’ security at the host
    level because those processes can’t do anything they want. The capabilities that
    are currently available inside a container running on top of the Docker container
    runtime are `SETPCAP`, `MKNOD`, `AUDIT_WRITE`, `CHOWN`, `NET_RAW`, `DAC_OVERRIDE`,
    `FOWNER`, `FSETID`, `KILL`, `SETGID`, `SETUID`, `NET_BIND_SERVICE`, `SYS_CHROOT`,
    and `SETFCAP`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前了解到，容器通过使用宿主机的内核来运行进程。但重要的是要知道，除非显式声明，否则只有一小部分内核能力允许在容器内使用。因此，容器提高了进程在宿主机级别的安全性，因为这些进程不能做任何它们想做的事情。当前在基于Docker容器运行时运行的容器内可用的能力包括`SETPCAP`、`MKNOD`、`AUDIT_WRITE`、`CHOWN`、`NET_RAW`、`DAC_OVERRIDE`、`FOWNER`、`FSETID`、`KILL`、`SETGID`、`SETUID`、`NET_BIND_SERVICE`、`SYS_CHROOT`和`SETFCAP`。
- en: This set of capabilities allows, for example, processes inside a container to
    attach and listen on ports below `1024` (the `NET_BIND_SERVICE` capability) or
    use ICMP (the `NET_RAW` capability).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这一套功能允许，例如，容器内的进程附加并监听低于`1024`端口（`NET_BIND_SERVICE`能力）或使用ICMP（`NET_RAW`能力）。
- en: If our process inside a container requires us to, for example, create a new
    network interface (perhaps to run a containerized OpenVPN server), the `NET_ADMIN`
    capability should be included.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在容器内的进程需要，例如，创建一个新的网络接口（可能是为了运行一个容器化的OpenVPN服务器），应该包含`NET_ADMIN`能力。
- en: Important note
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Container runtimes allow containers to run with full privileges using special
    parameters. The processes within these containers will run with all kernel capabilities
    and it could be very dangerous. You should avoid using privileged containers –
    it is best to take some time to verify which capabilities are needed by an application
    to work correctly.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时允许容器以完全权限运行，使用特殊的参数。这些容器中的进程将使用所有内核功能，这可能非常危险。您应该避免使用特权容器——最好花些时间验证应用程序正确运行所需的功能。
- en: Container orchestrators
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器编排工具
- en: Now that we know that we need a runtime to execute containers, we must also
    understand that this will work in a standalone environment, without hardware high
    availability. This means that server maintenance, operating system upgrades, and
    any other problem at the software, operating system, or hardware levels may affect
    your application.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们需要一个运行时来执行容器，我们还必须理解，这将在一个独立的环境中工作，且没有硬件高可用性。这意味着服务器维护、操作系统升级以及在软件、操作系统或硬件层面上的任何问题都可能影响您的应用程序。
- en: High availability requires resource duplicity and thus more servers and/or hardware.
    These resources will allow containers to run on multiple hosts, each one with
    a container runtime. However, maintaining application availability in this situation
    isn’t easy. We need to ensure that containers will be able to run on any of these
    nodes; in the *Overlay filesystems* section, we’ll learn that synchronizing container-related
    resources within nodes involves more than just copying a few files. **Container
    orchestrators** manage node resources and provide them to containers. They schedule
    containers as needed, take care of their status, provide resources for persistence,
    and manage internal and external communications (in [*Chapter 6*](B19845_06.xhtml#_idTextAnchor134),
    *Fundamentals of Orchestration*, we will learn how some orchestrators delegate
    some of these features to different modules to optimize their work).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性需要资源的冗余，因此需要更多的服务器和/或硬件。这些资源将允许容器在多个主机上运行，每个主机都有一个容器运行时。然而，在这种情况下维持应用程序的可用性并不容易。我们需要确保容器能够在这些节点中的任何一个上运行；在*覆盖文件系统*一节中，我们将了解到，同步节点内与容器相关的资源不仅仅是复制几个文件。**容器编排工具**管理节点资源并将其提供给容器。它们根据需要调度容器，处理容器状态，为持久性提供资源，并管理内部和外部通信（在[*第6章*](B19845_06.xhtml#_idTextAnchor134)《编排基础》中，我们将学习一些编排工具如何将其中的一些功能委派给不同的模块，以优化它们的工作）。
- en: The most famous and widely used container orchestrator today is **Kubernetes**.
    It has a lot of great features to help manage clustered containers, although the
    learning curve can be tough. Also, **Docker Swarm** is quite simple and allows
    you to quickly execute your applications with high availability (or resilience).
    We will cover both in detail in [*Chapter 7*](B19845_07.xhtml#_idTextAnchor147),
    *Orchestrating with Swarm*, and [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170),
    *Deploying Applications with the Kubernetes Orchestrator*. There were other opponents
    in this race but they stayed by the wayside while Kubernetes took the lead.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当今最著名且广泛使用的容器编排工具是**Kubernetes**。它有很多很棒的功能，帮助管理集群容器，尽管学习曲线可能较为陡峭。此外，**Docker
    Swarm**非常简单，并且允许您快速执行具有高可用性（或弹性）的应用程序。我们将在[*第7章*](B19845_07.xhtml#_idTextAnchor147)《使用Swarm进行编排》和[*第8章*](B19845_08.xhtml#_idTextAnchor170)《使用Kubernetes编排器部署应用程序》中详细讲解这两者。在这场竞争中还有其他对手，但它们都被抛在了后头，而Kubernetes则占据了主导地位。
- en: HashiCorp’s **Nomad** and Apache’s **Mesos** are still being used for very special
    projects but are out of scope for most enterprises and users. Kubernetes and Docker
    Swarm are community projects and some vendors even include them within their enterprise-ready
    solutions. Red Hat’s **OpenShift**, SUSE’s **Rancher**, Mirantis’ **Kubernetes
    Engine** (old Docker Enterprise platform), and VMware’s **Tanzu**, among others,
    all provide on-premises and some cloud-prepared custom Kubernetes platforms. But
    those who made Kubernetes the most-used platform were the well-known cloud providers
    – Google, Amazon, Azure, and Alibaba, among others, serve their own container
    orchestration tools, such as Amazon’s **Elastic Container Service** or **Fargate**,
    Google’s **Cloud Run**, and Microsoft’s **Azure Container Instances**, and they
    also package and manage their own Kubernetes infrastructures for us to use (Google’s
    GKE, Amazon’s EKS, Microsoft’s AKS, and so on). They provide **Kubernetes-as-a-Service**
    platforms where you only need an account to start deploying your applications.
    They also serve you storage, advanced networking tools, resources for publishing
    your applications, and even *follow-the-sun* or worldwide distributed architectures.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: HashiCorp 的 **Nomad** 和 Apache 的 **Mesos** 仍然用于一些非常特殊的项目，但对于大多数企业和用户来说超出了范围。Kubernetes
    和 Docker Swarm 是社区项目，一些厂商甚至将它们包含在企业级解决方案中。Red Hat 的 **OpenShift**、SUSE 的 **Rancher**、Mirantis
    的 **Kubernetes Engine**（旧版 Docker 企业平台）和 VMware 的 **Tanzu** 等，提供了本地部署的以及部分云准备的定制
    Kubernetes 平台。但使 Kubernetes 成为最常用平台的是那些著名的云提供商——Google、Amazon、Azure 和 Alibaba
    等，他们提供自己的容器编排工具，如 Amazon 的 **弹性容器服务** 或 **Fargate**，Google 的 **Cloud Run**，以及
    Microsoft 的 **Azure 容器实例**，他们还为我们打包并管理自己的 Kubernetes 基础设施（Google 的 GKE，Amazon
    的 EKS，Microsoft 的 AKS 等）。他们提供 **Kubernetes 即服务** 平台，你只需要一个账户就可以开始部署应用程序。他们还为你提供存储、先进的网络工具、发布应用程序的资源，甚至是
    *跟随太阳* 或全球分布式架构。
- en: There are many Kubernetes implementations. The most popular is probably OpenShift
    or its open source project, OKD. There are others based on a binary that launches
    and creates all of the Kubernetes components using automated procedures, such
    as Rancher RKE (or its government-prepared release, RKE2), and those featuring
    only the strictly necessary Kubernetes components, such as K3S or K0S, to provide
    the lightest platform for IoT and more modest hardware. And finally, we have some
    Kubernetes distributions for desktop computers, offering all the features of Kubernetes
    ready to develop and test applications with. In this group, we have Docker Desktop,
    Rancher Desktop, Minikube, and **Kubernetes in Docker** (**KinD**). We will learn
    how to use them in this book to develop, package, and prepare applications for
    production.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有很多实现。最流行的可能是 OpenShift 或其开源项目 OKD。还有一些基于二进制文件的项目，通过自动化程序启动并创建所有
    Kubernetes 组件，如 Rancher RKE（或其政府版本 RKE2），以及仅包含严格必要的 Kubernetes 组件的项目，如 K3S 或 K0S，以提供最轻量的平台，适用于物联网和更谦逊的硬件。最后，我们还有一些
    Kubernetes 发行版，专为桌面计算机提供，具备 Kubernetes 所有功能，准备好用于开发和测试应用程序。在这个组中，我们有 Docker Desktop、Rancher
    Desktop、Minikube 和 **Kubernetes in Docker**（**KinD**）。我们将在本书中学习如何使用它们来开发、打包和准备生产环境的应用程序。
- en: We shouldn’t forget solutions for running orchestrated applications based on
    multiple containers on standalone servers or desktop computers, such as **Docker
    Compose**. Docker has prepared a simple Python-based orchestrator for quick application
    development, managing the container dependencies for us. It is very convenient
    for testing all of our components together on a laptop with minimum overhead,
    instead of running a full Kubernetes or Swarm cluster. We will cover this tool,
    seeing as it has evolved a lot and is now part of the common Docker client command
    line, in [*Chapter 5*](B19845_05.xhtml#_idTextAnchor118), *Creating* *Multi-Container
    Applications*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应忽视基于多个容器在独立服务器或桌面计算机上运行编排应用程序的解决方案，例如**Docker Compose**。Docker 为我们准备了一个简单的基于
    Python 的编排工具，用于快速应用程序开发，管理容器依赖关系。这对于在笔记本电脑上以最小开销测试我们所有组件非常方便，而不是运行完整的 Kubernetes
    或 Swarm 集群。我们将在[*第 5 章*](B19845_05.xhtml#_idTextAnchor118)中介绍这个工具，*创建* *多容器应用程序*，因为它已经发展了很多，并且现在是常见的
    Docker 客户端命令行的一部分。
- en: Container images
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器镜像
- en: Earlier in this chapter, we mentioned that containers run thanks to **container
    images**, which are used as templates for executing processes in isolation and
    attached to a filesystem; therefore, a container image contains all the files
    (binaries, libraries, configurations, and so on) required by its processes. These
    files can be a subset of some operating system or just a few binaries with configurations
    built by yourself.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本章前面提到，容器能够运行是因为有了**容器镜像**，这些镜像作为模板用于在隔离环境中执行进程并附加到文件系统上；因此，容器镜像包含了其进程所需的所有文件（如二进制文件、库、配置文件等）。这些文件可以是某些操作系统的子集，或者只是由你自己构建的少量二进制文件和配置。
- en: Virtual machine templates are immutable, as are container templates. This immutability
    means that they don’t change between executions. This feature is key because it
    ensures that we get the same results every time we use an image for creating a
    container. Container behavior can be changed using configurations or command-line
    arguments through the container runtime. This ensures that images created by developers
    will work in production as expected, and moving applications to production (or
    even creating upgrades between different releases) will be smooth and fast, reducing
    the time to market.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机模板是不可变的，容器模板也是如此。这个不可变性意味着它们在执行之间不会发生变化。这个特性非常关键，因为它确保每次使用镜像创建容器时，我们都会得到相同的结果。容器的行为可以通过容器运行时的配置或命令行参数进行更改。这确保了开发人员创建的镜像在生产环境中能够按预期工作，并且将应用程序迁移到生产环境（甚至在不同版本之间创建升级）将变得平滑且快速，从而缩短上市时间。
- en: Container images are a collection of files distributed in layers. We shouldn’t
    add anything more than the files required by the application. As images are immutable,
    all these layers will be presented to containerized processes as read-only sets
    of files. But we don’t duplicate files between layers. Only files modified on
    one layer will be stored in the next layer above – this way, each layer retains
    the changes from the original base layer (referenced as the base image).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 容器镜像是分层分发的文件集合。我们不应添加除应用程序所需文件以外的任何内容。由于镜像是不可变的，这些层会作为只读文件集呈现给容器化进程。但我们不会在层之间重复文件。只有在某一层上修改的文件会存储在上面一层中——这样，每一层都会保留来自原始基础层（称为基础镜像）的更改。
- en: 'The following diagram shows how we create a container image using multiple
    layers:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了如何使用多个层创建容器镜像：
- en: '![Figure 1.2 – Schema of stacked layers representing a container image](img/B19845_01_02.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2 – 表示容器镜像的堆叠层次结构示意图](img/B19845_01_02.jpg)'
- en: Figure 1.2 – Schema of stacked layers representing a container image
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – 表示容器镜像的堆叠层次结构示意图
- en: A base layer is always included, although it could be empty. The layers above
    this base layer may include new binaries or just include new meta-information
    (which does not create a layer but a meta-information modification).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 基础层始终会包含，即使它是空的。位于基础层之上的层可能包含新的二进制文件，或者仅包含新的元信息（这不会创建一个层，而只是修改元信息）。
- en: To easily share these templates between computers or even environments, these
    file layers are packaged into `.tar` files, which are finally what we call images.
    These packages contain all layered files, along with meta-information that describes
    the content, specifies the process to be executed, identifies the ports that will
    be exposed to communicate with other containerized processes, specifies the user
    who will own it, indicates the directories that will be kept out of container
    life cycle, and so on.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便在计算机之间或不同环境之间共享这些模板，这些文件层会被打包成 `.tar` 文件，这些文件最终就被称为镜像。这些包包含了所有的层文件，以及描述内容的元信息，指定要执行的进程，标识将暴露出来以与其他容器化进程进行通信的端口，指定将拥有该镜像的用户，指示将在容器生命周期中保持不变的目录等信息。
- en: We use different methods to create these images, but we aim to make the process
    reproducible, and thus we use Dockerfiles as recipes. In [*Chapter 2*](B19845_02.xhtml#_idTextAnchor036),
    *Building Container Images*, we will learn about the image creation workflow while
    utilizing best practices and diving deep into command-line options.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用不同的方法来创建这些镜像，但我们的目标是使这个过程可重复，因此我们使用 Dockerfile 作为配方。在[*第 2 章*](B19845_02.xhtml#_idTextAnchor036)《构建容器镜像》中，我们将学习镜像创建的工作流程，同时使用最佳实践并深入探讨命令行选项。
- en: These container images are stored on registries. This application software is
    intended to store file layers and meta-information in a centralized location,
    making it easy to share common layers between different images. This means that
    two images using a common Debian base image (a subset of files from the complete
    operating system) will share these base files, thus optimizing disk space usage.
    This can also be employed on containers’ underlying host local filesystems, saving
    a lot of space.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些容器镜像存储在注册表中。该应用软件旨在将文件层和元信息存储在一个集中位置，使得在不同镜像之间共享公共层变得容易。这意味着，两个使用相同 Debian
    基础镜像（来自完整操作系统的文件子集）的镜像将共享这些基础文件，从而优化磁盘空间的使用。这也可以在容器的底层主机本地文件系统上使用，节省大量空间。
- en: Another result of the use of these layers is that containers using the same
    template image to execute their processes will use the same set of files, and
    only those files that get modified will be stored.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些镜像层的另一个结果是，使用相同模板镜像执行其进程的容器将使用相同的文件集，只有被修改的文件会被存储。
- en: All these behaviors related to the optimized use of files shared between different
    images and containers are provided by operating systems thanks to overlay filesystems.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些与优化不同镜像和容器之间共享文件的行为都得到了操作系统的支持，这要归功于 overlay 文件系统。
- en: Overlay filesystems
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Overlay 文件系统
- en: An **overlay filesystem** is a union mount filesystem (a way of combining multiple
    directories into one that appears to contain their whole combined content) that
    combines multiple underlying mount points. This results in a structure with a
    single directory that contains all underlying files and sub-directories from all
    sources.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**Overlay 文件系统**是一种联合挂载文件系统（将多个目录合并成一个，看起来包含其所有合并内容的方式），它结合了多个底层挂载点。这导致了一个结构，其中包含一个单一的目录，包含来自所有源的所有底层文件和子目录。'
- en: Overlay filesystems merge content from directories, combining the file objects
    (if any) yielded by different processes, with the *upper* filesystem taking precedence.
    This is the magic behind container-image layers’ reusability and disk space saving.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Overlay 文件系统将来自不同目录的内容合并，结合由不同进程生成的文件对象（如果有的话），其中 *上层* 文件系统具有优先权。这是容器镜像层可重用性和节省磁盘空间背后的魔法。
- en: Now that we understand how images are packaged and how they share content, let’s
    go back to learning a bit more about containers. As you may have learned in this
    section, containers are processes that run in isolation on top of a host operating
    system thanks to a container runtime. Although the kernel host is shared by multiple
    containers, features such as kernel namespaces and cgroups provide special containment
    layers that allow us to isolate them. Container processes need some files to work,
    which are included in the container space as immutable templates. As you may think,
    these processes will probably need to modify or create some new files found on
    container image layers, and a new read-write layer will be used to store these
    changes. The container runtime presents this new layer to the container to enable
    changes – we usually refer to this as the **container layer**.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了镜像是如何打包以及它们如何共享内容的，接下来我们回到学习更多关于容器的内容。正如你在本节中可能学到的，容器是依赖于容器运行时在主机操作系统上孤立运行的进程。尽管多个容器共享内核主机，但像内核命名空间和
    cgroups 这样的特性提供了特殊的隔离层，使我们能够将其隔离开来。容器进程需要一些文件来工作，这些文件作为不可变模板包含在容器空间中。正如你所想，这些进程可能需要修改或创建一些新的文件，这些文件位于容器镜像层中，新的读写层将用于存储这些更改。容器运行时将这个新层呈现给容器，以便进行更改——我们通常称之为
    **容器层**。
- en: 'The following schema outlines the read-write layers coming from the container
    image template with the newly added container layer, where the container’s running
    processes store their file modifications:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下架构概述了来自容器镜像模板的读写层与新添加的容器层，其中容器运行进程存储其文件修改：
- en: '![Figure 1.3 – Container image layers will always be read-only; the container
    adds a new layer with read-write capabilities](img/B19845_01_03.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – 容器镜像层将始终为只读；容器会添加一个具有读写权限的新层](img/B19845_01_03.jpg)'
- en: Figure 1.3 – Container image layers will always be read-only; the container
    adds a new layer with read-write capabilities
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 容器镜像层将始终为只读；容器会添加一个具有读写权限的新层
- en: The changes made by container processes are always *ephemeral* as the container
    layer will be lost whenever we remove the container, while image layers are immutable
    and will remain unchanged. With this behavior in mind, it is easy to understand
    that we can run multiple containers using the same container image.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 容器进程所做的更改始终是*短暂的*，因为每当我们删除容器时，容器层将被丢失，而镜像层是不可变的，将保持不变。了解这种行为后，我们可以轻松理解为什么可以使用相同的容器镜像运行多个容器。
- en: 'The following figure represents this situation where three different running
    containers were created from the same image:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下图表示了这一情况，三个不同的运行容器是从相同的镜像创建的：
- en: '![Figure 1.4 – Three different containers run using the same container image](img/B19845_01_04.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4 – 使用相同容器镜像运行的三个不同容器](img/B19845_01_04.jpg)'
- en: Figure 1.4 – Three different containers run using the same container image
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 使用相同容器镜像运行的三个不同容器
- en: As you may have noticed, this behavior leaves a very small footprint on our
    operating systems in terms of disk space. Container layers are very small (or
    at least they should be, and you as a developer will learn which files shouldn’t
    be left inside the container life cycle).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所注意到的，这种行为在操作系统中留下的磁盘空间占用非常小。容器层非常小（或者至少它应该是小的，作为开发者，你会学到哪些文件不应该留在容器生命周期内）。
- en: Container runtimes manage how these overlay folders will be included inside
    containers and the magic behind that. The mechanism for this is based on specific
    operating system drivers that implement **copy-on-write** filesystems. Layers
    are arranged one on top of the other and only files modified within them are merged
    on the upper layer. This process is managed at speed by operating system drivers,
    but some small overhead is always expected, so keep in mind that all files that
    are modified continuously by your application (logs, for example) should never
    be part of the container.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时管理这些叠加文件夹如何包含在容器内及其背后的机制。这个机制基于特定的操作系统驱动程序，这些驱动程序实现了**写时复制（copy-on-write）**文件系统。各层依次排列，只有在其中修改的文件才会合并到上层。这个过程由操作系统驱动程序高速管理，但总会有一些小的开销，因此请记住，所有由应用程序持续修改的文件（例如日志文件）不应包含在容器内。
- en: Important note
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: '*Copy-on-write* uses small layered filesystems or folders. Files from any layer
    are accessible to read access, but *write* requires searching for the file within
    the underlying layers and copying this file to the upper layer to store the changes.
    Therefore, the I/O overhead from reading files is very small and we can keep multiple
    layers for better file distribution between containers. In contrast, writing requires
    more resources and it would be better to leave big files and those subject to
    many or continuous modifications out of the container layer.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*写时复制（Copy-on-write）*使用小型分层文件系统或文件夹。任何层中的文件都可以进行读取访问，但*写入*则需要在底层查找文件，并将该文件复制到上层以存储更改。因此，从文件读取产生的I/O开销非常小，我们可以保持多个层以便更好地分配文件到容器之间。相比之下，写入需要更多资源，最好将大文件和那些需要频繁或持续修改的文件排除在容器层之外。'
- en: It is also important to notice that containers are not ephemeral at all. As
    mentioned previously, changes in the container layer are retained until the container
    is removed from the operating system; so, if you create a 10 GB file in the container
    layer, it will reside on your host’s disk. Container orchestrators manage this
    behavior, but be careful where you store your persistent files. Administrators
    should do container housekeeping and disk maintenance to avoid disk-pressure problems.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是要注意，容器并非完全短暂。如前所述，容器层中的更改会一直保留，直到容器从操作系统中被移除；因此，如果你在容器层创建了一个10 GB的文件，它将会保存在主机的磁盘中。容器编排器管理这种行为，但要小心你存储持久文件的位置。管理员应当进行容器清理和磁盘维护，以避免磁盘压力问题。
- en: Developers should keep this in mind and prepare their applications using containers
    to be logically ephemeral and store persistent data outside the container’s layers.
    We will learn about options for persistence in [*Chapter 10*](B19845_10.xhtml#_idTextAnchor231),
    *Leveraging Application Data Management* *in Kubernetes*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者应该牢记这一点，并使用容器准备应用程序，使其在逻辑上是短暂的，并将持久数据存储在容器层之外。我们将在[*第10章*](B19845_10.xhtml#_idTextAnchor231)中学习关于持久化的选项，*在Kubernetes中利用应用数据管理*。
- en: This thinking leads us to the next section, where we will discuss the intrinsic
    dynamism of container environments.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这种思维方式引导我们进入下一部分，在这一部分我们将讨论容器环境的内在动态性。
- en: Understanding dynamism in container-based applications
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解基于容器的应用程序中的动态性
- en: We have seen how containers run using immutable storage (container images) and
    how the container runtime adds a new layer for managing changed files. Although
    we mentioned in the previous section that containers are not ephemeral in terms
    of disk usage, we have to include this feature in our application’s design. Containers
    will start and stop whenever you upgrade your application’s components. Whenever
    you change the base image, a completely new container will be created (remember
    the layers ecosystem described in the previous section). This will become even
    worse if you want to distribute these application components across a cluster
    – even using the same image will result in different containers being created
    on different hosts. Thus, this **dynamism** is inherited in these platforms.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到容器如何使用不可变存储（容器镜像）运行，以及容器运行时如何为管理已更改的文件添加新层。尽管我们在上一节中提到容器在磁盘使用方面并非短暂存在，但我们仍然必须在应用程序设计中考虑这一特性。每当你升级应用程序的组件时，容器将会启动和停止。每当你更改基础镜像时，将创建一个全新的容器（记得前面提到的层次结构生态系统）。如果你想将这些应用程序组件分发到一个集群中，这种情况会变得更加复杂——即使使用相同的镜像，也会在不同的主机上创建不同的容器。因此，这种**动态性**在这些平台中是继承而来的。
- en: In the context of networking communications inside containers, we know that
    processes running inside a container share its network namespace, and thus they
    all get the same network stack and IP address. But every time a new container
    is created, the container runtime will provide a new IP address. Thanks to container
    orchestration and the **Domain Name System** (**DNS**) included, we can communicate
    with our containers. As IP addresses are dynamically managed by the container
    runtime’s internal **IP Address Management** (**IPAM**) using defined pools, every
    time a container dies (whether the main process is stopped, killed manually, or
    ended by an error), it will free its IP address and IPAM will assign it to a new
    container that might be part of a completely different application. Hence, we
    can trust the IP address assignment although we shouldn’t use container IP addresses
    in our application configurations (or even worse, write them in our code, which
    is a bad practice in every scenario). IP addresses will be dynamically managed
    by the IPAM container runtime component by default. We will learn about better
    mechanisms we can use to reference our application’s containers, such as service
    names, in [*Chapter 4*](B19845_04.xhtml#_idTextAnchor096), *Running* *Docker Containers*.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器内的网络通信上下文中，我们知道容器内运行的进程共享其网络命名空间，因此它们都会获得相同的网络栈和 IP 地址。但每当创建一个新容器时，容器运行时会提供一个新的
    IP 地址。得益于容器编排和所包含的**域名系统**（**DNS**），我们可以与我们的容器进行通信。由于 IP 地址由容器运行时的内部**IP 地址管理**（**IPAM**）使用定义的池进行动态管理，每当一个容器死亡时（无论是主进程被停止、手动杀死，还是因错误结束），它将释放其
    IP 地址，IPAM 会将其分配给一个新的容器，这个容器可能属于一个完全不同的应用程序。因此，我们可以信任 IP 地址分配，尽管我们不应该在应用程序配置中使用容器
    IP 地址（更糟的是，在代码中写入它们，这是任何场景下的坏实践）。IP 地址将由 IPAM 容器运行时组件默认动态管理。我们将在[*第4章*](B19845_04.xhtml#_idTextAnchor096)中学习更多可以用来引用应用程序容器的更好机制，比如服务名称，*运行*
    *Docker 容器*。
- en: Applications use fully qualified domain names (or short names if we are using
    internal domain communications, as we will learn when we use Docker Compose to
    run multi-container applications, and also when applications run in more complicated
    container orchestrations).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序使用完全限定的域名（或者在使用内部域名通信时使用简短的名称，正如我们在使用 Docker Compose 运行多容器应用程序时会学到的那样，此外，当应用程序运行在更复杂的容器编排中时也是如此）。
- en: Because IP addresses are dynamic, special resources should be used to assign
    sets of IP addresses (or unique IP addresses, if we have just one process replica)
    to service names. In the same way, publishing application components requires
    some resource mappings, using **network address translation** (**NAT**) for communicating
    between users and external services and those running inside containers, distributed
    across a cluster in different servers or even different infrastructures (such
    as cloud-provided container orchestrators, for example).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 IP 地址是动态的，因此应该使用专门的资源来为服务名称分配一组 IP 地址（或者如果我们只有一个进程副本，则分配唯一的 IP 地址）。同样，发布应用程序组件也需要一些资源映射，使用**网络地址转换**（**NAT**）来实现用户与外部服务以及运行在容器中的服务之间的通信，这些容器可能分布在不同的服务器上的集群中，甚至是在不同的基础设施中（例如，云提供的容器编排器）。
- en: Since we’re reviewing the main concepts related to containers in this chapter,
    we can’t miss out on the tools that are used for creating, executing, and sharing
    containers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在本章回顾与容器相关的主要概念，因此不能忽视用于创建、执行和共享容器的工具。
- en: Tools for managing containers
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理容器的工具
- en: As we learned previously, the container runtime will manage most of the actions
    we can achieve with containers. Most of these runtimes run as **daemons** and
    provide an interface for interacting with them. Among these tools, Docker stands
    out as it provides *all the tools in a box*. Docker acts as a client-server application
    and in newer releases, both the client and server components are packaged separately,
    but in any case, both are needed by users. At first, when Docker Engine was the
    most popular and reliable container engine, Kubernetes adopted it as its runtime.
    But this marriage did not last long, and Docker Engine was deprecated in Kubernetes
    release 1.22\. This happened because Docker manages its own integration of Containerd,
    which is not standardized nor directly usable by the Kubernetes CRI. Despite this
    fact, Docker is still the most widely used option for developing container-based
    applications and the de facto standard for building images.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所学，容器运行时将管理我们可以通过容器实现的大多数操作。大多数这些运行时以**守护进程**的形式运行，并提供与之交互的接口。在这些工具中，Docker脱颖而出，因为它提供了*一盒子中的所有工具*。Docker作为一个客户端-服务器应用程序，且在较新的版本中，客户端和服务器组件是分别打包的，但无论如何，用户都需要这两者。最初，当Docker
    Engine是最流行和可靠的容器引擎时，Kubernetes选择了它作为其运行时。但是这种结合并没有持续太久，Docker Engine在Kubernetes
    1.22版本中被弃用。这是因为Docker管理它自己的Containerd集成，而这并非标准化，也不能直接由Kubernetes的CRI使用。尽管如此，Docker仍然是开发基于容器的应用程序最广泛使用的选项，也是构建镜像的事实标准。
- en: We mentioned Docker Desktop and Rancher Desktop earlier in this section. Both
    act as container runtime clients that use either the `docker` or `nerdctl` command
    lines. We can use such clients because in both cases, `dockerd` or `containerd`
    act as container runtimes.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中之前提到了Docker Desktop和Rancher Desktop。两者都充当容器运行时客户端，使用`docker`或`nerdctl`命令行。我们可以使用这些客户端，因为在这两种情况下，`dockerd`或`containerd`充当容器运行时。
- en: Developers and the wider community pushed Docker to provide a solution for users
    who prefer to run containers without having to run a privileged system daemon,
    which is dockerd’s default behavior. It took some time but finally, a few years
    ago, Docker published its rootless runtime with user privileges. During this development
    phase, another container executor arrived, called Podman, created by Red Hat to
    solve the same problem. This solution can run without root privileges and aims
    to avoid the use of a daemonized container runtime. The host user can run containers
    without any system privilege by default; only a few tweaks are required by administrators
    if the containers are to be run in a security-hardened environment. This made
    Podman a very secure option for running containers in production (without orchestration).
    Docker also included rootless containers by the end of 2019, making both options
    secure by default.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者和广泛的社区推动Docker为那些希望运行容器而不需要运行特权系统守护进程的用户提供解决方案，而这正是`dockerd`的默认行为。这花了一些时间，但最终，在几年前，Docker发布了其无根（rootless）运行时，并赋予用户权限。在此开发阶段，另一个名为Podman的容器执行器应运而生，由Red
    Hat创建，旨在解决相同的问题。此解决方案可以在没有root权限的情况下运行，并且避免使用守护进程化的容器运行时。默认情况下，主机用户可以无需任何系统权限运行容器；如果容器要在安全加固环境中运行，管理员只需要做一些小的调整。这使得Podman成为在生产环境中运行容器（没有编排）的一个非常安全的选项。Docker也在2019年底加入了无根容器，使得这两种选择默认都是安全的。
- en: As you learned at the beginning of this section, containers are processes that
    run on top of an operating system, isolated using its kernel features. It is quite
    evident why containers are so popular in microservice environments (one container
    runs a process, which is ultimately a microservice), although we can still build
    microservice-based applications without containers. It is also possible to use
    containers to run whole application components together, although this isn’t an
    ideal situation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本节开始时学到的，容器是运行在操作系统上的进程，通过操作系统的内核特性进行隔离。容器在微服务环境中如此流行是显而易见的（一个容器运行一个进程，最终它是一个微服务），尽管我们仍然可以在没有容器的情况下构建基于微服务的应用程序。也可以使用容器将整个应用组件一起运行，尽管这并不是理想的情况。
- en: Important note
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In this chapter, we’ll largely focus on software containers in the context of
    Linux operating systems. This is because they were only introduced in Windows
    systems much later. However, we will also briefly discuss them in the context
    of Windows.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将主要关注在Linux操作系统环境中的软件容器。这是因为容器在Windows系统中直到后期才被引入。然而，我们也会简要讨论它们在Windows环境中的应用。
- en: We shouldn’t compare containers with virtual nodes. As discussed earlier in
    this section, containers are mainly based on cgroups and kernel namespaces while
    virtual nodes are based on hypervisor software. This software provides sandboxing
    capabilities and specific virtualized hardware resources to guest hosts. We still
    need to prepare operating systems to run these virtual guest hosts. Each guest
    node will receive a piece of virtualized hardware and we must manage servers’
    interactions as if they were physical.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应该将容器与虚拟节点进行比较。正如本节前面所讨论的，容器主要基于cgroups和内核命名空间，而虚拟节点则基于虚拟化管理程序软件。这些软件提供了沙箱功能以及特定的虚拟化硬件资源给来宾主机。我们仍然需要为这些虚拟来宾主机准备操作系统。每个来宾节点将获得一块虚拟化的硬件，我们必须像管理物理服务器一样管理这些虚拟主机之间的交互。
- en: We’ll compare these models side by side in the following section.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将并排比较这些模型。
- en: Comparing virtualization and containers
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟化与容器比较
- en: 'The following schema represents a couple of virtual guest nodes running on
    top of a physical host:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 下图表示几个虚拟来宾节点在物理主机之上的运行情况：
- en: '![Figure 1.5 – Applications running on top of virtual guest nodes, running
    on top of a physical server](img/B19845_01_05.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5 – 运行在物理服务器之上的虚拟来宾节点上运行的应用程序](img/B19845_01_05.jpg)'
- en: Figure 1.5 – Applications running on top of virtual guest nodes, running on
    top of a physical server
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 运行在物理服务器之上的虚拟来宾节点上运行的应用程序
- en: A physical server running its own operating system executes a hypervisor software
    layer to provide virtualization capabilities. A specific amount of hardware resources
    is virtualized and provisioned to these new virtual guest nodes. We should install
    new operating systems for these new hosts and after that, we will be able to run
    applications. Physical host resources are partitioned for guest hosts and both
    nodes are completely isolated from each other. Each virtual machine executes its
    own kernel and its operating system runs on top of the host. There is complete
    isolation between guests’ operating systems because the underlying host’s hypervisor
    software keeps them separated.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一台物理服务器运行其自身的操作系统，并执行一个虚拟化管理程序（hypervisor）软件层，以提供虚拟化功能。一定数量的硬件资源被虚拟化并分配给这些新的虚拟来宾节点。我们需要为这些新主机安装操作系统，之后我们就可以运行应用程序。物理主机资源被划分给来宾主机，且两个节点完全隔离。每个虚拟机执行自己的内核，操作系统运行在主机之上。由于底层主机的虚拟化管理程序软件将它们隔离开来，因此来宾操作系统之间是完全隔离的。
- en: In this model, we require a lot of resources, even if we just need to run a
    couple of processes per virtual host. Starting and stopping virtual hosts will
    take time. Lots of non-required software and processes will probably run on our
    guest host and it will require some tuning to remove them.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种模型中，我们需要大量资源，即使我们只需为每个虚拟主机运行几个进程。启动和停止虚拟主机将需要时间。很多不必要的软件和进程可能会在我们的来宾主机上运行，我们需要做一些调整以去除它们。
- en: As we have learned, the microservices model is based on the idea of applications
    running decoupled in different processes with complete functionality. Thus, running
    a complete operating system within just a couple of processes doesn’t seem like
    a good idea.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所学到的，微服务模型基于应用程序在不同进程中解耦运行，并具备完整功能的理念。因此，在仅仅几个进程中运行完整的操作系统似乎并不是一个好主意。
- en: Although automation will help us, we need to maintain and configure those guest
    operating systems in terms of running the required processes and managing users,
    access rights, and network communications, among other things. System administrators
    maintain these hosts as if they were physical. Developers require their own copies
    to develop, test, and certify application components. Scaling up these virtual
    servers can be a problem because in most cases, increasing resources require a
    complete reboot to apply the changes.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管自动化会帮助我们，但我们仍然需要维护和配置这些来宾操作系统，以便运行所需的进程并管理用户、访问权限、网络通信等内容。系统管理员像管理物理主机一样管理这些主机。开发人员需要自己的副本来开发、测试和认证应用组件。扩展这些虚拟服务器可能会成为问题，因为在大多数情况下，增加资源需要重新启动才能应用更改。
- en: Modern virtualization software provides API-based management, which enhances
    their usage and virtual node maintenance, but it is not enough for microservice
    environments. Elastic environments, where components should be able to scale up
    or down on demand, will not fit well in virtual machines.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现代虚拟化软件提供基于 API 的管理，增强了它们的使用和虚拟节点的维护，但这对于微服务环境来说还不够。在弹性环境中，组件应该能够根据需求进行扩展或收缩，而虚拟机并不适合这种需求。
- en: 'Now, let’s review the following schema, which represents a set of containers
    running on physical and virtual hosts:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾以下架构图，表示一组运行在物理和虚拟主机上的容器：
- en: '![Figure 1.6 – A set of containers running on top of physical and virtual hosts](img/B19845_01_06.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.6 – 一组运行在物理和虚拟主机上的容器](img/B19845_01_06.jpg)'
- en: Figure 1.6 – A set of containers running on top of physical and virtual hosts
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 一组运行在物理和虚拟主机上的容器
- en: All containers in this schema share the same host kernel as they are just processes
    running on top of an operating system. In this case, we don’t care whether they
    run on a virtual or a physical host; we expect the same behavior. Instead of hypervisor
    software, we have a `/etc/hosts` and `/etc/nsswitch.conf` files would probably
    be required (along with some network libraries and their dependencies). The **attack
    surface** will be completely different than having a whole operating system full
    of binaries, libraries, and running services, regardless of whether the application
    uses them or not.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中，所有容器共享相同的主机内核，因为它们只是运行在操作系统之上的进程。在这种情况下，我们不关心它们是运行在虚拟主机还是物理主机上；我们期望它们表现相同。我们不再需要虚拟机管理程序软件，而是可能需要`/etc/hosts`和`/etc/nsswitch.conf`文件（以及一些网络库及其依赖项）。**攻击面**将与拥有满是二进制文件、库和运行服务的完整操作系统完全不同，无论应用程序是否使用它们。
- en: Containers are designed to run just one main process (and its threads or sub-processes)
    and this makes them lightweight. They can start and stop as fast as their main
    process does.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 容器被设计为只运行一个主要进程（及其线程或子进程），这使得它们非常轻量。它们可以像其主进程一样快速启动和停止。
- en: All the resources consumed by a container are related to the given process,
    which is great in terms of the allocation of hardware resources. We can calculate
    our application’s resource consumption by observing the load of all its microservices.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 容器消耗的所有资源都与给定的进程相关，这在硬件资源分配方面非常有利。我们可以通过观察所有微服务的负载来计算应用程序的资源消耗。
- en: We define **images** as templates for running containers. These images contain
    all the files required by the container to work plus some meta-information providing
    its features, capabilities, and which commands or binaries will be used to start
    the process. Using images, we can ensure that all the containers created with
    one template will run the same. This eliminates infrastructure friction and helps
    developers prepare their applications to run in production. The configuration
    (and of course security information such as credentials) is the only thing that
    differs between the development, testing, certification, and production environments.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将**镜像**定义为运行容器的模板。这些镜像包含容器工作所需的所有文件，并附带一些元信息，提供其特性、能力以及将用于启动进程的命令或二进制文件。通过使用镜像，我们可以确保使用相同模板创建的所有容器运行方式相同。这消除了基础设施摩擦，并帮助开发人员准备应用程序在生产环境中运行。配置（当然，还有诸如凭证之类的安全信息）是开发、测试、认证和生产环境之间唯一的差异。
- en: Software containers also improve application security because they run by default
    with limited privileges and allow only a set of system calls. They run anywhere;
    all we need is a container runtime to be able to create, share, and run containers.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 软件容器还提高了应用程序的安全性，因为它们默认以有限的权限运行，并且仅允许一组系统调用。它们可以在任何地方运行；我们所需要的只是一个容器运行时，以便能够创建、共享和运行容器。
- en: Now that we know what containers are and the most important concepts involved,
    let’s try to understand how they fit into development processes.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了容器是什么以及涉及的最重要概念，让我们尝试理解它们如何融入开发流程中。
- en: Building, sharing, and running containers
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建、共享和运行容器
- en: '*Build, ship, and run*: you might have heard or read this quote years ago.
    Docker Inc. used it to promote the ease of using containers. When creating container-based
    applications, we can use Docker to build container images, share these images
    within environments, move the content from our development workstations to testing
    and staging environments, execute them as containers, and finally use these packages
    in production. Only a few changes are required throughout, mainly at the application’s
    configuration level. This workflow ensures application usage and immutability
    between the development, testing, and staging stages. Depending on the container
    runtime and container orchestrator chosen for each stage, Docker could be present
    throughout (Docker Engine and Docker Swarm). Either way, most people still use
    the Docker command line to create container images due to its great, always-evolving
    features that allow us, for example, to build images for different processor architectures
    using our desktop computers.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*构建、发布和运行*：你可能几年前听过或读到过这句话。Docker公司使用它来推广容器的使用简便性。在创建基于容器的应用程序时，我们可以使用Docker来构建容器镜像，在环境中共享这些镜像，将内容从开发工作站移动到测试和预发布环境，作为容器执行它们，最终在生产环境中使用这些包。整个过程只需要进行少量更改，主要是在应用程序的配置层面。这个工作流程确保了开发、测试和预发布阶段之间应用的使用性和不可变性。根据每个阶段所选择的容器运行时和容器编排器，Docker可能会贯穿始终（Docker
    Engine和Docker Swarm）。无论如何，大多数人仍然使用Docker命令行来创建容器镜像，因为它具有出色且不断发展的功能，使我们能够例如在桌面计算机上为不同处理器架构构建镜像。'
- en: Adding **continuous integration** (**CI**) and **continuous deployment** (**CD**)
    (or **continuous delivery**, depending on the source) to the equation simplifies
    developers’ lives so they can focus on their application’s architecture and code.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 添加**持续集成**（**CI**）和**持续部署**（**CD**）（或**持续交付**，具体取决于来源）简化了开发人员的工作，使他们能够专注于应用程序的架构和代码。
- en: They can code on their workstations and push their code to a source code repository,
    and this event will trigger a CI/CD automation to build applications artifacts,
    compiling their code and providing the artifacts in the form of binaries or libraries.
    This automation can also include these artifacts inside container images. These
    become the new application artifacts and are stored in image registries (the backends
    that store container images). Different executions can be chained to test this
    newly compiled component together with other components in the integration phase,
    achieve verification via some tests in the testing phase, and so on, passing through
    different stages until it gets to production. All these chained workflows are
    based on containers, configuration, and the images used for execution. In this
    workflow, developers never explicitly create a release image; they only build
    and test development ones, but the same Dockerfile recipe is used on their workstations
    and in the CI/CD phases executed on servers. Reproducibility is key.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 他们可以在工作站上编写代码并将其推送到源代码库，这一事件将触发CI/CD自动化，构建应用程序工件，编译代码并将工件以二进制或库的形式提供。这种自动化还可以将这些工件包含在容器镜像中。这些工件成为新的应用程序工件并存储在镜像仓库中（存储容器镜像的后端）。不同的执行可以通过链接来测试这个新编译的组件与其他组件在集成阶段的表现，通过一些测试验证它在测试阶段的效果，依此类推，经过不同阶段直到进入生产环境。所有这些链式工作流都基于容器、配置和用于执行的镜像。在这个工作流中，开发人员从未显式创建发布镜像；他们只构建和测试开发镜像，但相同的Dockerfile配方既用于他们的工作站，也用于在服务器上执行的CI/CD阶段。可复现性是关键。
- en: Developers can run multiple containers on their developer workstations as if
    they were using the real environment. They can test their code along with other
    components in their environment, allowing them to evaluate and discover problems
    faster and fix them even before moving their components to the CI/CD pipelines.
    When their code is ready, they can push it to their code repository and trigger
    the automation. Developers can build their development images, test them locally
    (be it a standalone component, multiple components, or even a full application),
    prepare their release code, then push it, and the CI/CD orchestrator will build
    the release image for them.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员可以在开发工作站上运行多个容器，就像使用真实环境一样。他们可以在环境中测试自己的代码和其他组件，这使得他们能够更快地评估和发现问题，甚至在将组件移到CI/CD管道之前就修复这些问题。当代码准备好后，开发人员可以将其推送到代码库并触发自动化流程。开发人员可以构建他们的开发镜像，在本地进行测试（无论是独立组件、多个组件，还是一个完整的应用程序），准备发布代码，然后将其推送，CI/CD协调器会为他们构建发布镜像。
- en: In these contexts, images are shared between environments via the use of image
    registries. *Shipping* images from server to server is easy as the host’s container
    runtime will download the images from the given registries – but only those layers
    not already present on the servers will be downloaded, hence the layer distribution
    within container images is key.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些环境中，图像通过使用镜像注册表在不同环境之间共享。*从服务器到服务器传输*镜像非常简单，因为主机的容器运行时将从指定的注册表下载镜像——但只有那些在服务器上尚不存在的层会被下载，因此容器镜像中的层分布至关重要。
- en: 'The following schema outlines this simplified workflow:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下架构概述了这个简化的工作流：
- en: '![Figure 1.7 – Simplified schema representing a CI/CD workflow example using
    software containers to deliver applications to production](img/B19845_01_07.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.7 – 使用软件容器将应用程序交付到生产环境中的 CI/CD 工作流示例的简化架构](img/B19845_01_07.jpg)'
- en: Figure 1.7 – Simplified schema representing a CI/CD workflow example using software
    containers to deliver applications to production
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 – 使用软件容器将应用程序交付到生产环境中的 CI/CD 工作流示例的简化架构
- en: Servers running these different stages can be either standalone servers, pools
    of nodes from orchestrated clusters, or even more complex dedicated infrastructures,
    including in some cases cloud-provided hosts or whole clusters. Using container
    images ensures the artifact’s content and infrastructure-specific configurations
    will run in the custom application environment in each case.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这些不同阶段的服务器可以是独立服务器、编排集群中的节点池，或者更复杂的专用基础设施，包括某些情况下由云提供的主机或整个集群。使用容器镜像可以确保制品的内容和特定基础设施的配置能够在每个案例中以定制应用环境的方式运行。
- en: With this in mind, we can imagine how we could build a full development chain
    using containers. We talked about Linux kernel namespaces already, so let’s continue
    by understanding how these isolation mechanisms work on Microsoft Windows.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这一点，我们可以设想如何使用容器构建完整的开发链条。我们已经讨论过 Linux 内核命名空间，那么接下来我们将继续了解这些隔离机制如何在微软 Windows
    上工作。
- en: Explaining Windows containers
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释 Windows 容器
- en: During this chapter, we have focused on software containers within Linux operating
    systems. Software containers started on Linux systems, but due to their importance
    and advances in technology in terms of host resource usage, Microsoft introduced
    them in the Microsoft Windows Server 2016 operating system. Before this, Windows
    users and administrators were only capable of using software containers for Linux
    through virtualization. Thus, there was the Docker Toolbox solution, of which
    Docker Desktop formed a part, and installing this software on our Windows-based
    computer allowed us to have a terminal with the Docker command line, a fancy GUI,
    and a Hyper-V Linux virtual machine where containers would run. This made it easy
    for entry-level users to use software containers on their Windows desktops, but
    Microsoft eventually brought in a game-changer here, creating a new encapsulation
    model.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们重点讨论了 Linux 操作系统中的软件容器。软件容器起源于 Linux 系统，但由于其重要性以及在主机资源使用方面的技术进步，微软在 Microsoft
    Windows Server 2016 操作系统中引入了容器。在此之前，Windows 用户和管理员只能通过虚拟化使用 Linux 软件容器。因此，出现了
    Docker Toolbox 解决方案，其中 Docker Desktop 是其一部分，安装此软件可以让我们在基于 Windows 的计算机上拥有一个终端，其中包括
    Docker 命令行、精美的 GUI 和一个 Hyper-V Linux 虚拟机，容器将在其中运行。这使得初学者可以轻松地在 Windows 桌面上使用软件容器，但微软最终带来了一个改变游戏规则的创新，创造了一种新的封装模型。
- en: Important note
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Container runtimes are client-server applications, so we can serve the runtime
    to local (by default) and remote clients. When we use a remote runtime, we can
    use our clients to execute commands on this runtime using different clients, such
    as `docker` or `nerdctl`, depending on the server side. Earlier in this chapter,
    we mentioned that desktop solutions such as Docker Desktop or Rancher Desktop
    use this model, running a container runtime server where the common clients, executed
    from common Linux terminals or Microsoft PowerShell, can manage software containers
    running on the server side.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时是客户端-服务器应用程序，因此我们可以将运行时服务提供给本地（默认）和远程客户端。当我们使用远程运行时时，我们可以使用不同的客户端（如 `docker`
    或 `nerdctl`，具体取决于服务器端）在此运行时上执行命令。我们在本章前面提到，诸如 Docker Desktop 或 Rancher Desktop
    这样的桌面解决方案使用这种模型，运行一个容器运行时服务器，常见客户端可以从常规的 Linux 终端或 Microsoft PowerShell 中执行，用来管理运行在服务器端的容器。
- en: 'Microsoft provided two different software container models:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 微软提供了两种不同的软件容器模型：
- en: '**Hyper-V Linux Containers**: The old model, which uses a Linux virtual machine'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hyper-V Linux 容器**：旧模型，使用 Linux 虚拟机。'
- en: '**Windows Server Containers**, also known as **Windows Process Containers**:
    This is the new model, allowing the execution of Windows operating-system-based
    applications'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Windows Server 容器**，也称为**Windows 进程容器**：这是新模型，允许运行基于 Windows 操作系统的应用程序。'
- en: From the user’s perspective, the management and execution of containers running
    on Windows are the same, no matter which of the preceding models is in use, but
    only one model can be used per server, thus applying to all containers on that
    server. The differences here come from the isolation used in each model.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户的角度来看，运行在 Windows 上的容器的管理和执行是相同的，无论使用的是哪种模型，但每台服务器只能使用一种模型，因此适用于该服务器上的所有容器。这里的差异来源于每种模型所使用的隔离方式。
- en: '**Process isolation** on Windows works in the same way it does on Linux. Multiple
    processes run on a host, accessing the host’s kernel, and the host provides isolation
    using namespaces and resources control (along with other specific methods, depending
    on the underlying operating system). As we already know, processes get their own
    filesystem, network, processes identifiers, and so on, but in this case, they
    also get their own Windows registry and object namespace.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**进程隔离**在 Windows 上的工作方式与 Linux 上相同。多个进程在主机上运行，访问主机的内核，主机通过命名空间和资源控制（以及根据底层操作系统的其他特定方法）提供隔离。如我们所知，进程有自己的文件系统、网络、进程标识符等，但在这种情况下，它们还会拥有自己的
    Windows 注册表和对象命名空间。'
- en: Due to the very nature of the Microsoft Windows operating system, some system
    services and **dynamic linked libraries** (**DLLs**) are required within the containers
    and cannot be shared from the host. Thus, process containers need to contain a
    copy of these resources, which makes Windows images quite a lot bigger than Linux-based
    container images. You may also encounter some compatibility issues within image
    releases, depending on which base operating system (files tree) was used to generate
    it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 由于微软 Windows 操作系统的本质，一些系统服务和**动态链接库**（**DLLs**）在容器中是必需的，并且无法从宿主机共享。因此，进程容器需要包含这些资源的副本，这使得
    Windows 镜像比基于 Linux 的容器镜像要大得多。根据用于生成镜像的基础操作系统（文件树），您还可能会遇到一些兼容性问题。
- en: 'The following schema represents both models side by side so that we can observe
    the main stack differences:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示意图并排展示了这两种模型，方便我们观察主要的堆栈差异：
- en: '![Figure 1.8 – A comparison of Microsoft Windows software container models](img/B19845_01_08.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8 – 微软 Windows 软件容器模型比较](img/B19845_01_08.jpg)'
- en: Figure 1.8 – A comparison of Microsoft Windows software container models
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – 微软 Windows 软件容器模型比较
- en: We will use Windows Server containers when our application requires strong integration
    with the Microsoft operating system, for example, for integrating **Group Managed
    Service Accounts** (**gMSA**) or encapsulating applications that don’t run under
    Linux hosts.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的应用程序需要与微软操作系统紧密集成时，例如集成**组管理服务帐户**（**gMSA**）或封装无法在 Linux 主机上运行的应用程序时，我们将使用
    Windows Server 容器。
- en: From my experience, Windows Server containers became very popular when they
    initially arrived, but as Microsoft improved the support of their applications
    for Linux operating systems, the fact that developers could create their applications
    in .NET Core for either Microsoft Windows or Linux, and the lack of many cloud
    providers offering this technology, made them almost disappear from the scene.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，Windows Server 容器在最初推出时非常受欢迎，但随着微软改进了其应用程序对 Linux 操作系统的支持，以及开发者能够为微软
    Windows 或 Linux 创建 .NET Core 应用程序的事实，再加上许多云服务提供商未提供此技术，使得 Windows Server 容器几乎从市场上消失。
- en: It is also important to mention that orchestration technology evolution helped
    developers move to Linux-only containers. Windows Server containers were supported
    only on top of Docker Swarm until 2019 when Kubernetes announced their support.
    Due to the large increase of Kubernetes’ adoption in the developer community and
    even in enterprise environments, Windows Server container usage reduced to very
    specific and niche use cases.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要提到的是，编排技术的演变帮助开发者转向仅 Linux 的容器。Windows Server 容器在 2019 年之前仅在 Docker Swarm
    上受支持，直到 Kubernetes 宣布支持它。由于 Kubernetes 在开发者社区甚至企业环境中的广泛应用，Windows Server 容器的使用减少到非常特定和小众的用例。
- en: Nowadays, Kubernetes supports Microsoft Windows Server hosts running as worker
    roles, allowing process container execution. We will learn about Kubernetes and
    host roles in [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170), *Deploying Applications
    with the Kubernetes Orchestrator*. Despite this fact, you will probably not find
    many Kubernetes clusters running Windows Server container workloads.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，Kubernetes 支持运行 Microsoft Windows Server 主机作为工作角色，允许进程容器的执行。我们将在[*第8章*](B19845_08.xhtml#_idTextAnchor170)《使用
    Kubernetes 协调器部署应用程序》中了解 Kubernetes 和主机角色。尽管如此，你可能不会发现很多 Kubernetes 集群在运行 Windows
    Server 容器工作负载。
- en: We mentioned that containers improve application security. The next section
    will show you the improvements at the host and container levels that make containers
    *safer* *by default*.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到过容器可以提高应用程序的安全性。下一节将展示在主机和容器层面上使容器*默认*更*安全*的改进措施。
- en: Improving security using software containers
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用软件容器提高安全性
- en: In this section, we are going to introduce some of the features found on container
    platforms that help improve application security.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一些容器平台上的功能，这些功能有助于提高应用程序的安全性。
- en: If we keep in mind how containers run, we know that we first need a **host**
    with a container runtime. So, having a host with just the software required is
    the first security measure. We should use dedicated hosts in production for running
    container workloads. We do not need to concern ourselves with this while developing,
    but system administrators should prepare production nodes with minimal attack
    surfaces. We should never share these hosts for use in serving other technologies
    or services. This feature is so important that we can even find dedicated operating
    systems, such as Red Hat’s CoreOS, SuSE’s RancherOS, VMware’s PhotonOS, TalOS,
    or Flatcar Linux, just to mention the most popular ones. These are minimal operating
    systems that just include a container runtime. You can even create your own by
    using Moby’s LinuxKit project. Some vendors’ customized Kubernetes platforms,
    such as Red Hat’s OpenShift, create their clusters using CoreOS, improving the
    whole environment’s security.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们记住容器是如何运行的，我们知道首先需要一个带有容器运行时的**主机**。因此，拥有一个只包含必要软件的主机是第一道安全防线。我们应该在生产环境中使用专用主机来运行容器工作负载。开发过程中我们不需要过多担心这一点，但系统管理员应为生产节点准备最小化攻击面。我们绝不应该共享这些主机用于提供其他技术或服务。这个特性非常重要，以至于我们可以找到专门的操作系统，比如
    Red Hat 的 CoreOS、SuSE 的 RancherOS、VMware 的 PhotonOS、TalOS 或 Flatcar Linux，仅举几种流行的操作系统。这些是最小化的操作系统，仅包含一个容器运行时。你甚至可以通过使用
    Moby 的 LinuxKit 项目来创建自己的操作系统。一些厂商定制的 Kubernetes 平台，比如 Red Hat 的 OpenShift，使用 CoreOS
    创建集群，从而提高整个环境的安全性。
- en: We will never connect to any cluster host to execute containers. Container runtimes
    work in client-server mode. Rather, we expose this engine service and simply using
    a client on our laptop or desktop computers will be more than enough to execute
    containers on the host.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们永远不会连接到任何集群主机来执行容器。容器运行时采用客户端-服务器模式。相反，我们暴露这个引擎服务，简单地在我们的笔记本电脑或台式机上使用客户端就足以在主机上执行容器。
- en: Locally, clients connect to container runtimes using `/var/run/docker.sock`
    for `dockerd`, for example). Adding read-write access to this socket to specific
    users will allow them to use the daemon to build, pull, and push images or execute
    containers. Configuring the container runtime in this way may be worse if the
    host has a master role in an orchestrated environment. It is crucial to understand
    this feature and know which users will be able to run containers on each host.
    System administrators should keep their container runtimes’ sockets safe from
    untrusted users and only allow authorized access. These sockets are local and,
    depending on which runtime we are using, TCP or even SSH (in `dockerd`, for example)
    can be used to secure remote access. Always ensure **Transport Layer Security**
    (**TLS**) is used to secure socket access.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地，客户端通过使用 `/var/run/docker.sock` 连接到容器运行时，例如 `dockerd`。为特定用户添加对这个套接字的读写访问权限将允许他们使用守护进程来构建、拉取和推送镜像或执行容器。在这种方式下配置容器运行时，如果主机在编排环境中具有主控角色，可能会带来更大的安全风险。理解这一特性并了解哪些用户能够在每个主机上运行容器至关重要。系统管理员应确保容器运行时的套接字免受不信任用户的访问，仅允许授权访问。这些套接字是本地的，具体取决于我们使用的运行时，TCP
    或甚至 SSH（例如在 `dockerd` 中）可以用于确保远程访问的安全。始终确保使用**传输层安全性**（**TLS**）来保护套接字访问。
- en: It is important to note that container runtimes do not provide any **role-based
    access control** (**RBAC**). We will need to add this layer later with other tools.
    Docker Swarm does not provide RBAC, but Kubernetes does. RBAC is key for managing
    user privileges and multiple application isolation.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，容器运行时不提供任何**基于角色的访问控制**（**RBAC**）。我们需要使用其他工具后续添加这一层。Docker Swarm 不提供
    RBAC，但 Kubernetes 提供。RBAC 是管理用户权限和多个应用隔离的关键。
- en: We should say here that, currently, desktop environments (Docker Desktop and
    Rancher Desktop) also work with this model, in which you don’t connect to the
    host running the container runtime. A virtualized environment is deployed on your
    system (using Qemu if on Linux, or Hyper-V or the newer Windows Subsystem for
    Linux on Windows hosts) and our client, using a terminal, will connect to this
    virtual container runtime (or the Kubernetes API when deploying workloads on Kubernetes,
    as we will learn in [*Chapter 8*](B19845_08.xhtml#_idTextAnchor170), *Deploying
    Applications with the* *Kubernetes Orchestrator*).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该在此提到，目前，桌面环境（Docker Desktop 和 Rancher Desktop）也采用这一模型，在这种模型中，你并不直接连接到运行容器运行时的主机。一个虚拟化环境会部署在你的系统上（如果是
    Linux，使用 Qemu；如果是 Windows 主机，使用 Hyper-V 或更新的 Windows 子系统 Linux），我们的客户端将通过终端连接到该虚拟容器运行时（或者在
    Kubernetes 上部署工作负载时，连接到 Kubernetes API，正如我们将在[*第 8 章*](B19845_08.xhtml#_idTextAnchor170)，《使用
    Kubernetes 调度器部署应用程序》中学习到的）。
- en: Here, we have to reiterate that container runtimes add only a subset of kernel
    capabilities by default to container processes. But this may not be enough in
    some cases. To improve containers’ security behavior, container runtimes also
    include a default **Secure Computing Mode** (**Seccomp**) profile. Seccomp is
    a Linux security facility that filters the system calls allowed inside containers.
    Specific profiles can be included and used by runtimes to add some required system
    calls. You, as the developer, need to notice when your application requires extra
    capabilities or uncommon system calls. The special features described in this
    section are used on host monitoring tools, for example, or if we need to add a
    new kernel module using system administration containers.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们必须重申，容器运行时默认仅向容器进程添加了一部分内核能力。但在某些情况下，这可能不够。为了提升容器的安全行为，容器运行时还包括一个默认的**安全计算模式**（**Seccomp**）配置文件。Seccomp
    是一个 Linux 安全功能，用于过滤容器内允许的系统调用。特定的配置文件可以由运行时包含并使用，以添加一些所需的系统调用。作为开发者，你需要注意当应用程序需要额外的能力或非常规系统调用时。本节所描述的特性，例如，适用于主机监控工具，或者当我们需要通过系统管理容器添加新的内核模块时。
- en: Container runtimes usually run as daemons; thus, they will quite probably run
    as root users. This means that any container can contain the host’s files inside
    (we will learn how we can mount volumes and host paths within containers in [*Chapter
    4*](B19845_04.xhtml#_idTextAnchor096), *Running Docker Containers*) or include
    the host’s namespaces (container processes may access host’s PIDs, networks, IPCs,
    and so on). To avoid the undesired effects of running container runtime privileges,
    system administrators should apply special security measures using **Linux Security
    Modules** (**LSM**), such as SELinux or AppArmor, among others.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时通常作为守护进程运行；因此，它们很可能以 root 用户身份运行。这意味着任何容器都可以包含主机的文件（我们将在[*第 4 章*](B19845_04.xhtml#_idTextAnchor096)，《运行
    Docker 容器》中学习如何在容器内挂载卷和主机路径），或者包含主机的命名空间（容器进程可能访问主机的 PID、网络、IPC 等）。为了避免容器运行时权限带来的不良影响，系统管理员应该使用**Linux
    安全模块**（**LSM**），如 SELinux 或 AppArmor 等，采取特别的安全措施。
- en: SELinux should be integrated into container runtimes and container orchestration.
    These integrations can be used to ensure, for example, that only certain paths
    are allowed inside containers. If your application requires access to the host’s
    files, non-default SELinux labels should be included to modify the default runtime
    behavior. Container runtimes’ software installation packages include these settings,
    among others, to ensure that common applications will run without problems. However,
    those with special requirements, such as those that are prepared to read hosts’
    logs, will require further security configurations.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: SELinux 应该与容器运行时和容器编排进行集成。这些集成可以确保例如，仅允许某些路径进入容器。如果你的应用程序需要访问主机的文件，应包含非默认的 SELinux
    标签，以修改默认的运行时行为。容器运行时的软件安装包包括这些设置等，以确保常见应用能够正常运行。然而，那些有特殊需求的应用，例如需要读取主机日志的应用，将需要进一步的安全配置。
- en: So far in this chapter, we have provided a quick overview of the key concepts
    related to containers. In the following section, we’ll put this into practice.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们已经提供了与容器相关的关键概念的快速概述。在接下来的部分，我们将把这些内容付诸实践。
- en: Labs
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: In this first chapter, we covered a lot of content, learning what containers
    are and how they fit into the modern microservices architecture.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了大量内容，了解了什么是容器以及它们如何融入现代微服务架构。
- en: In this lab, we will install a fully functional development environment for
    container-based applications. We will use Docker Desktop because it includes a
    container runtime, its client, and a minimal but fully functional Kubernetes orchestration
    solution.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本实验中，我们将为基于容器的应用程序安装一个完整的开发环境。我们将使用 Docker Desktop，因为它包含了一个容器运行时、客户端，并且提供了一个最小但功能完整的
    Kubernetes 编排解决方案。
- en: We could use Docker Engine in Linux directly (the container runtime only, following
    the instructions at [https://docs.docker.com/](https://docs.docker.com/)) for
    most labs but we will need to install a new tool for the Kubernetes labs, which
    requires a minimal Kubernetes cluster installation. Thus, even for just using
    the command line, we will use the Docker Desktop environment.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们本可以直接在 Linux 上使用 Docker Engine（仅容器运行时，按照[https://docs.docker.com/](https://docs.docker.com/)中的说明），用于大多数实验，但对于
    Kubernetes 实验，我们需要安装一个新工具，要求进行最小的 Kubernetes 集群安装。因此，即使是仅使用命令行，我们也将使用 Docker Desktop
    环境。
- en: Important note
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: We will use a Kubernetes desktop environment to minimize CPU and memory requirements.
    There are even lighter Kubernetes cluster alternatives such as KinD or K3S, but
    these may require some customization. Of course, you can also use any cloud provider’s
    Kubernetes environment if you feel more comfortable doing so.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Kubernetes 桌面环境，以最小化 CPU 和内存要求。还有更轻量的 Kubernetes 集群替代方案，如 KinD 或 K3S，但这些可能需要一些自定义配置。当然，如果您觉得更舒服，您也可以使用任何云服务提供商的
    Kubernetes 环境。
- en: Installing Docker Desktop
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Docker Desktop
- en: This lab will guide you through the installation of **Docker Desktop** on your
    laptop or workstation and how to execute a test to verify that it works correctly.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验将引导您在笔记本电脑或工作站上安装**Docker Desktop**，并执行测试以验证其是否正确运行。
- en: Docker Desktop can be installed on Microsoft Windows 10, most of the common
    Linux flavors, and macOS (the arm64 and amd64 architectures are both supported).
    This lab will show you how to install this software on Windows 10, but I will
    use Windows and Linux interchangeably in other labs as they mostly work the same
    – we will review any differences between the platforms when required.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Desktop 可以安装在 Microsoft Windows 10、大多数常见的 Linux 版本和 macOS 上（arm64 和 amd64
    架构都受支持）。本实验将向您展示如何在 Windows 10 上安装此软件，但在其他实验中，我将交替使用 Windows 和 Linux，因为它们的操作方式大致相同——我们将在需要时回顾不同平台之间的差异。
- en: We will follow the simple steps documented at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).
    Docker Desktop can be deployed on Windows using **Hyper-V** or the newer **Windows
    Subsystem for Linux** 2 (**WSL 2**). This second option uses less compute and
    memory resources and is nicely integrated into Microsoft Windows, making it the
    preferred installation method, but note that WSL2 is required on your host before
    installing Docker Desktop. Please follow the instructions from Microsoft at [https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)
    before installing Docker Desktop. You can install any Linux distribution because
    the integration will be automatically included.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照[https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)中记录的简单步骤进行操作。Docker
    Desktop 可以在 Windows 上使用**Hyper-V**或较新的**Windows Subsystem for Linux** 2（**WSL
    2**）进行部署。第二种选项占用的计算和内存资源较少，并且与微软 Windows 紧密集成，是首选的安装方法。但请注意，在安装 Docker Desktop
    之前，您的主机必须安装 WSL2。请在安装 Docker Desktop 之前，按照微软提供的[https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)中的说明进行操作。您可以安装任何
    Linux 发行版，因为该集成会自动包含。
- en: 'We will use the **Ubuntu** WSL distribution. It is available from the **Microsoft
    Store** and is simple to install:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**Ubuntu** WSL 发行版。它可以从**微软商店**获取，安装起来非常简单：
- en: '![Figure 1.9 – Ubuntu in the Microsoft Store](img/B19845_01_09.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.9 – 微软商店中的 Ubuntu](img/B19845_01_09.jpg)'
- en: Figure 1.9 – Ubuntu in the Microsoft Store
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – 微软商店中的 Ubuntu
- en: 'During the installation, you will be prompted for **username** and **password**
    details for this Windows subsystem installation:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装过程中，您将被提示输入**用户名**和**密码**，以完成此 Windows 子系统的安装：
- en: '![Figure 1.10 – After installing Ubuntu, you will have a fully functional Linux
    Terminal](img/B19845_01_10.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.10 – 安装 Ubuntu 后，你将拥有一个完全功能的 Linux 终端](img/B19845_01_10.png)'
- en: Figure 1.10 – After installing Ubuntu, you will have a fully functional Linux
    Terminal
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – 安装 Ubuntu 后，你将拥有一个完全功能的 Linux 终端
- en: You can close this Ubuntu Terminal as the Docker Desktop integration will require
    you to open a new one once it has been configured.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以关闭此 Ubuntu 终端，因为 Docker Desktop 集成将要求你在配置完成后打开一个新的终端。
- en: Important note
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You may need to execute some additional steps at [https://docs.microsoft.com/windows/wsl/wsl2-kernel](https://docs.microsoft.com/windows/wsl/wsl2-kernel)
    to update WSL2 if your operating system hasn’t been updated.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的操作系统尚未更新，可能需要在 [https://docs.microsoft.com/windows/wsl/wsl2-kernel](https://docs.microsoft.com/windows/wsl/wsl2-kernel)
    执行一些额外步骤以更新 WSL2。
- en: 'Now, let’s continue with the Docker Desktop installation:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续进行 Docker Desktop 安装：
- en: 'Download the installer from [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/):'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)
    下载安装程序：
- en: '![Figure 1.11 – Docker Desktop download section](img/B19845_01_11.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.11 – Docker Desktop 下载部分](img/B19845_01_11.jpg)'
- en: Figure 1.11 – Docker Desktop download section
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11 – Docker Desktop 下载部分
- en: 'Once downloaded, execute the `Docker Desktop Installer.exe` binary. You will
    be asked to choose between Hyper-V or WSL2 backend virtualization; we will choose
    WSL2:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载后，执行 `Docker Desktop Installer.exe` 可执行文件。系统会要求你选择 Hyper-V 或 WSL2 后端虚拟化，我们将选择
    WSL2：
- en: '![Figure 1.12 – Choosing the WSL2 integration for better performance](img/B19845_01_12.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.12 – 选择 WSL2 集成以获得更好的性能](img/B19845_01_12.jpg)'
- en: Figure 1.12 – Choosing the WSL2 integration for better performance
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 – 选择 WSL2 集成以获得更好的性能
- en: 'After clicking **Ok**, the installation process will begin decompressing the
    required files (libraries, binaries, default configurations, and so on). This
    could take some time (1 to 3 minutes), depending on your host’s disk speed and
    compute resources:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**确定**后，安装过程将开始解压所需的文件（库、二进制文件、默认配置等）。这可能需要一些时间（1 到 3 分钟），具体取决于主机的磁盘速度和计算资源：
- en: '![Figure 1.13 – The installation process will take a while as the application
    files are decompressed and installed on your system](img/B19845_01_13.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.13 – 安装过程将花费一段时间，因为应用文件正在解压并安装到系统中](img/B19845_01_13.jpg)'
- en: Figure 1.13 – The installation process will take a while as the application
    files are decompressed and installed on your system
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13 – 安装过程将花费一段时间，因为应用文件正在解压并安装到系统中
- en: 'To finish the installation, we will be asked to log out and log in again because
    our user was added to new system groups (Docker) to enable access to the remote
    Docker daemon via operating system pipes (similar to Unix sockets):'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为完成安装，我们将被要求注销并重新登录，因为我们的用户已被添加到新的系统组（Docker）中，以便通过操作系统管道（类似 Unix 套接字）访问远程 Docker
    守护进程：
- en: '![Figure 1.14 – Docker Desktop has been successfully installed and we must
    log out](img/B19845_01_14.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.14 – Docker Desktop 已成功安装，且我们必须注销](img/B19845_01_14.jpg)'
- en: Figure 1.14 – Docker Desktop has been successfully installed and we must log
    out
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14 – Docker Desktop 已成功安装，且我们必须注销
- en: Once we log in, we can execute Docker Desktop using the newly added application
    icon. We can enable Docker Desktop execution on start, which could be very useful,
    but it may slow down your computer if you are short on resources. I recommend
    starting Docker Desktop only when you are going to use it.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，我们可以通过新添加的应用图标执行 Docker Desktop。我们可以启用 Docker Desktop 开机启动，这可能非常有用，但如果计算机资源不足，可能会导致计算机变慢。我建议仅在需要使用
    Docker Desktop 时启动它。
- en: 'Once we’ve accepted the Docker Subscription license terms, Docker Desktop will
    start. This may take a minute:'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们接受了 Docker 订阅许可协议，Docker Desktop 将启动。这可能需要一些时间：
- en: '![Figure 1.15 – Docker Desktop is starting](img/B19845_01_15.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.15 – Docker Desktop 正在启动](img/B19845_01_15.jpg)'
- en: Figure 1.15 – Docker Desktop is starting
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15 – Docker Desktop 正在启动
- en: You can skip the quick guide that will appear when Docker Desktop is running
    because we will learn more about this in the following chapters as we deep dive
    into building container images and container execution.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以跳过 Docker Desktop 运行时出现的快速指南，因为我们将在后续章节中深入学习如何构建容器镜像和容器执行。
- en: 'We will get the following screen, showing us that Docker Desktop is ready:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将看到以下屏幕，显示 Docker Desktop 已准备就绪：
- en: '![Figure 1.16 – Docker Desktop main screen](img/B19845_01_16.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.16 – Docker Desktop 主屏幕](img/B19845_01_16.jpg)'
- en: Figure 1.16 – Docker Desktop main screen
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.16 – Docker Desktop 主屏幕
- en: 'We need to enable WSL2 integration with our favorite Linux distribution:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要启用 WSL2 与我们最喜爱的 Linux 发行版的集成：
- en: '![Figure 1.17 – Enabling our previously installed Ubuntu using WSL2](img/B19845_01_17.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.17 – 启用我们先前安装的 Ubuntu 使用 WSL2](img/B19845_01_17.jpg)'
- en: Figure 1.17 – Enabling our previously installed Ubuntu using WSL2
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.17 – 启用我们先前安装的 Ubuntu 使用 WSL2
- en: 'After this step, we are finally ready to work with Docker Desktop. Let’s open
    a terminal using our Ubuntu distribution, execute `docker`, and, after that, `docker
    info`:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成此步骤后，我们终于准备好使用 Docker Desktop。让我们使用 Ubuntu 发行版打开终端，执行 `docker`，然后执行 `docker
    info`：
- en: '![Figure 1.18 – Executing some Docker commands just to verify container runtime
    integration](img/B19845_01_18.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.18 – 执行一些 Docker 命令以验证容器运行时集成](img/B19845_01_18.jpg)'
- en: Figure 1.18 – Executing some Docker commands just to verify container runtime
    integration
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.18 – 执行一些 Docker 命令以验证容器运行时集成
- en: As you can see, we have a fully functional Docker client command line associated
    with the Docker Desktop WSL2 server.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们拥有一个完全功能的 Docker 客户端命令行，它与 Docker Desktop WSL2 服务器关联。
- en: 'We will end this lab by executing an `docker run-ti alpine` to download the
    Alpine image and execute a container using it:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过执行`docker run-ti alpine`来下载 Alpine 镜像并使用它执行容器，结束本实验：
- en: '![Figure 1.19 – Creating a container and executing some commands inside before
    exiting](img/B19845_01_19.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.19 – 创建一个容器并在退出前执行一些命令](img/B19845_01_19.jpg)'
- en: Figure 1.19 – Creating a container and executing some commands inside before
    exiting
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.19 – 创建一个容器并在退出前执行一些命令
- en: 'This container execution left changes in Docker Desktop; we can review the
    current images present in our container runtime:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此容器执行已在 Docker Desktop 中留下更改；我们可以查看当前容器运行时中存在的镜像：
- en: '![Figure 1.20 – Docker Desktop – the Images view](img/B19845_01_20.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.20 – Docker Desktop – 镜像视图](img/B19845_01_20.jpg)'
- en: Figure 1.20 – Docker Desktop – the Images view
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.20 – Docker Desktop – 镜像视图
- en: 'We can also review the container, which is already dead because we exited by
    simply executing `exit` inside its shell:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以查看容器，它已经停止，因为我们通过在其 shell 内执行 `exit` 命令退出：
- en: '![Figure 1.21 – Docker Desktop – the Containers view](img/B19845_01_21.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.21 – Docker Desktop – 容器视图](img/B19845_01_21.jpg)'
- en: Figure 1.21 – Docker Desktop – the Containers view
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.21 – Docker Desktop – 容器视图
- en: Now, Docker Desktop works and we are ready to work through the following labs
    using our WSL2 Ubuntu Linux distribution.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Docker Desktop 已经启动，我们准备好使用 WSL2 Ubuntu Linux 发行版继续进行接下来的实验。
- en: Summary
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned the basics around containers and how they fit into
    modern microservices applications. The content presented in this chapter has helped
    you understand how to implement containers in distributed architectures, using
    already-present host operating system isolation features and container runtimes,
    which are the pieces of software required for building, sharing, and executing
    containers.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了有关容器的基础知识以及它们如何融入现代微服务应用程序。本章内容帮助你理解如何在分布式架构中实现容器，利用现有的主机操作系统隔离特性和容器运行时，后者是构建、共享和执行容器所需的软件组件。
- en: Software containers assist application development by providing resilience,
    high availability, scalability, and portability thanks to their very nature, and
    will help you create and manage the application life cycle.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 软件容器通过其天生的特性帮助应用程序开发，提供了弹性、高可用性、可扩展性和可移植性，并将帮助你创建和管理应用程序生命周期。
- en: In the next chapter, we will deep dive into the process of creating container
    images.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨创建容器镜像的过程。
