- en: Real-Time Data Analysis - Azure Stream Analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时数据分析 - Azure Stream Analytics
- en: While some Azure components enable us to deliver data to the cloud, in most
    cases we also need something that is designed for analyzing and querying streamed
    data. One such service is Azure Stream Analytics, a real-time data analysis tool,
    which is able to read all messages sent through, for example, Event Hub, and transform,
    and save them using one of the predefined outputs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些 Azure 组件使我们能够将数据传输到云中，但在大多数情况下，我们还需要某些专门用于分析和查询流数据的工具。其中一个服务是 Azure Stream
    Analytics，它是一个实时数据分析工具，能够读取所有通过 Event Hub 等传送的消息，并使用预定义的输出之一进行转换和保存。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Working with Azure Stream Analytics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 Azure Stream Analytics 的协作
- en: Available input and output types
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的输入和输出类型
- en: Querying data using the query language
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用查询语言查询数据
- en: Ensuring the correct order of incoming data and performing checkpoints or replays
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保传入数据的正确顺序，并执行检查点或重播操作
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To perform the exercises in this chapter, you will need:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行本章的练习，你将需要：
- en: Visual Studio 2017 instance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Visual Studio 2017 实例
- en: An Azure subscription
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Azure 订阅
- en: Azure Stream Analytics tools—[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Stream Analytics 工具—[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install)
- en: Azure Stream Analytics introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Stream Analytics 介绍
- en: In the previous chapter, we discussed Azure Event Hub, which is a solution for
    receiving and processing thousands of messages per second, by introducing the
    implementation of event processor hosts. While it is great for workloads such
    as big data pipelines or IoT scenarios, it is not a solution to everything, especially
    if you want to avoid hosting VMs. Scaling such architectures can be cumbersome
    and nonintuitive; this is why there is Azure Stream Analytics, which is an event-processing
    engine designed for high volumes of data. It fills a gap where other services
    such as Event Hub or IoT Hub do not perform well (or where to do so they require
    much more skill and/or more sophisticated architecture), particularly for real-time
    analytics, anomaly detection, and geospatial analytics. It is an advanced tool
    for advanced tasks, which will greatly improve your cloud and message-processing
    skills.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了 Azure Event Hub，这是一个用于接收和处理每秒数千条消息的解决方案，介绍了事件处理器主机的实现。尽管它非常适合大数据管道或物联网场景等工作负载，但它并不是所有问题的解决方案，尤其是当你想避免托管虚拟机时。扩展此类架构可能会繁琐且不直观；这就是为什么有
    Azure Stream Analytics，它是一个为大量数据设计的事件处理引擎。它弥补了其他服务（如 Event Hub 或 IoT Hub）表现不佳的空白（或者如果要做到这一点，它们需要更多的技能和/或更复杂的架构），特别是在实时分析、异常检测和地理空间分析方面。它是一个为高级任务设计的先进工具，将大大提高你的云技术和消息处理能力。
- en: Stream ingestions versus stream analysis
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流式数据摄取与流式分析
- en: 'To get started, we will compare two topics:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始，我们将比较两个主题：
- en: '**Stream ingestion**: This is a process where you introduce a service/API for
    receiving messages from your producers. Such a service is designed to ingest data
    only—it does nothing more (such as transforming or analyzing). To perform any
    kind of analysis of ingested data, you have to introduce your own processors.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流摄取**：这是一个引入服务/API用于接收来自生产者的消息的过程。这类服务只设计用于摄取数据—它不做其他事情（如转换或分析）。要对摄取的数据执行任何分析，你必须引入自己的处理器。'
- en: '**Stream analysis**: This is a process where you actually analyze the data.
    You search for anomalies, duplicates, or malformed data, process it, and push
    it further to other services for storing, presenting, and triggering other actions.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流分析**：这是一个实际分析数据的过程。你会搜索异常、重复或格式错误的数据，处理它，并将其推送到其他服务进行存储、展示和触发其他操作。'
- en: 'To make things even clearer, we can take a look at the following diagram:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地说明这一点，我们可以查看以下图示：
- en: '![](img/b15af9bc-e1b6-4bf3-9539-95324c45e3d0.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b15af9bc-e1b6-4bf3-9539-95324c45e3d0.png)'
- en: 'It shows the four steps of data processing:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 它展示了数据处理的四个步骤：
- en: '**Produce**: Where data is actually produced by different services, devices,
    and clients'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成**：数据实际上是由不同的服务、设备和客户端产生的地方'
- en: '**Ingest**: This is when the data is consumed from different sources'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摄取**：这是从不同的来源消费数据的过程'
- en: '**Analyze**: During this step data is analyzed, transformed, and routed to
    appropriate services and components'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Analyze**: 在此步骤中，数据被分析、转换并路由到适当的服务和组件。'
- en: '**Use**: Storing, displaying, and processing data further in other services,
    such as PowerBI, Azure Functions, and many others'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Use**: 在其他服务中进一步存储、显示和处理数据，例如PowerBI、Azure Functions等等。'
- en: While Azure Event Hub or Azure IoT Hub is a part of the ingest step, Azure Stream
    Analytics is responsible for **analyzing**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure Event Hub或Azure IoT Hub作为摄入步骤的一部分时，Azure Stream Analytics负责**分析**。
- en: Note that you are not limited to Azure services when it comes to ingesting data.
    In such a scenario, you can also use any kind of queue or API, as long as it is
    capable of processing thousands of events per second.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在摄入数据时，您并不限于Azure服务。在这种情况下，只要它能够处理每秒数千个事件，您也可以使用任何类型的队列或API。
- en: Azure Stream Analytics concepts
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Stream Analytics概念
- en: 'In Azure Stream Analytics, the most important concept is a **stream**. You
    can think about it as a flow of many events carrying data—they do not necessarily
    have to be the same or share schema. Analyzing such a stream is not a trivial
    task. If you have to decode hundreds of thousands of events, the process has to
    be quick, robust, and reliable. We will discuss the main concepts of this service
    to verify whether it is capable of acting as our analyzing solution and the main
    events processor:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure Stream Analytics中，最重要的概念是**流**。您可以将其视为携带数据的许多事件的流——它们不一定相同或共享架构。分析这样的流不是一件简单的任务。如果您需要解码数十万个事件，该过程必须快速、稳健且可靠。我们将讨论该服务的主要概念，以验证它是否能够作为我们的分析解决方案和主要事件处理器：
- en: '**Fully managed**: Azure Stream Analytics is a fully managed platform as a
    service(PaaS), so you do not have to worry about provisioning resources and scaling
    it—the runtime will take care of that, so you can focus on providing optimal queries
    for data analysis.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fully managed**: Azure Stream Analytics 是一个完全托管的平台即服务（PaaS），因此您无需担心资源配置和扩展问题——运行时会自行处理，这样您就可以专注于为数据分析提供最佳查询。'
- en: '**An SQL-based query language**: To analyze data, Azure Stream Analytics uses
    an SQL-based query language, which enables developers to build advanced procedures
    quickly, which extract from a stream exactly what they want. Additionally, you
    can bring your own extensions such as ML solutions or user-defined aggregates
    to perform extra calculations, using tools unavailable to the service.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**An SQL-based query language**: 为了分析数据，Azure Stream Analytics使用基于SQL的查询语言，使开发人员能够快速构建高级程序，从流中精确提取所需内容。此外，您可以引入自己的扩展，如ML解决方案或用户定义的聚合，以执行额外的计算，使用服务不可用的工具。'
- en: '**Performance**: Azure Stream Analytics is focused on **streaming units **(**SUs**) instead
    of some hardcoded values of CPUs or memory. This is because it is designed to
    provide stable performance and recurrent execution time. What is more, thanks
    to this concept, you can easily scale your solution to meet your demands.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Performance**: Azure Stream Analytics专注于**流单元（SUs）**而不是一些硬编码的CPU或内存值。这是因为它设计用于提供稳定的性能和反复执行时间。此概念使得您可以轻松扩展解决方案以满足需求。'
- en: '**Low cost of ownership**: In Azure Stream Analytics you pay only for what
    you choose. As pricing depends on the number of SUs per hour, there is no additional
    cost to be incorporated in the overall payment.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Low cost of ownership**: 在Azure Stream Analytics中，您只需支付您选择的内容。由于定价取决于每小时的SUs数量，因此在总体付款中不会增加额外费用。'
- en: 'There are also some extra technical concepts (such as input/output types, checkpoints,
    or replays), which we will cover in the next parts of this chapter. To see the
    big picture of the whole pipeline using Azure Stream Analytics, please check the
    following image:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后续部分，我们将涵盖一些额外的技术概念（例如输入/输出类型、检查点或重播）。要了解使用Azure Stream Analytics的整个管道的全貌，请查看以下图片：
- en: '![](img/1e589130-614e-4d10-a8d3-2198eb66b992.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e589130-614e-4d10-a8d3-2198eb66b992.png)'
- en: Of course, there could be other references on this picture (additional services,
    user functions, and analyzers), but for the sake of simplicity, I did not include
    them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在这张图片上可能还有其他参考信息（附加服务、用户功能和分析器），但为了简单起见，我没有包括它们。
- en: Input and output types
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输入和输出类型
- en: Azure Stream Analytics offers a seamless integration with some native Azure
    services, such as Azure Event Hub, Azure IoT Hub, or Azure Blob Storage. Additionally,
    it can be easily configured to output data to an SQL database, Blob, or Event Azure
    Data Lake Store. To leverage those possibilities, you will have to define both
    input and output types, which you are interested in. This allows for data to be
    easily ingested (in the form of a stream), so a job, which you will write, can
    work on thousands of events, analyzing and processing them. In this section, you
    will learn how to get started with Azure Stream Analytics and to define both the
    inputsand outputs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Stream Analytics提供与一些本地Azure服务的无缝集成，例如Azure Event Hub、Azure IoT Hub或Azure
    Blob Storage。此外，它还可以轻松配置，将数据输出到SQL数据库、Blob或Azure Data Lake Store。为了利用这些功能，你需要定义你感兴趣的输入和输出类型。这使得数据可以轻松地以流的形式被接收，从而你的作业可以在数千个事件上进行工作，进行分析和处理。在本节中，你将学习如何开始使用Azure
    Stream Analytics，并定义输入和输出。
- en: Create Azure Stream Analytics in Azure portal
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Azure门户中创建Azure Stream Analytics
- en: 'To get started, you will need to create an instance of Azure Stream Analytics.
    To do so, you have to click on + Create a resourceand search for `Stream Analytics
    job`. This will display a form, where you can enter all the necessary data to
    create a service:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，你需要创建一个Azure Stream Analytics实例。为此，你需要点击+ 创建资源并搜索`Stream Analytics job`。这将显示一个表单，你可以在其中输入所有必要的数据来创建一个服务：
- en: '![](img/5e62ebf9-4ae7-4a9e-9fd8-6cd399f8efa2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e62ebf9-4ae7-4a9e-9fd8-6cd399f8efa2.png)'
- en: 'There are two fields, which at first you might overlook:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个字段，初看之下你可能会忽视它们：
- en: 'Hosting environment: Azure Stream Analytics can be hosted in two ways: as a
    native Azure service or deployed to an on-premise IoT Edge gateway device. IoT
    Edge is a topic beyond the scope of this book, so the natural choice will be Cloud.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 托管环境：Azure Stream Analytics可以通过两种方式托管：作为本地Azure服务或部署到本地IoT Edge网关设备。IoT Edge是本书超出范围的主题，因此自然的选择将是云。
- en: 'Streaming units (1 to 120): You have to select how many SUs you would like
    to provision for a job to process your events. The number of required SUs depends
    on the characteristics of your job, and additionally may vary depending on the
    input type of your choice. There is a link in the *Further reading*section, which
    describes in detail how many SUs you may need for your job.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流处理单元（1到120）：你需要选择为一个作业分配多少个SUs来处理事件。所需的SUs数量取决于你作业的特性，并且可能会根据你选择的输入类型有所变化。在*进一步阅读*部分有一个链接，详细描述了你可能需要多少SUs来处理你的作业。
- en: Remember that you will pay €0.093/hour for each SU you choose, even when it
    is not working on a job.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，你将为每个选择的SU支付€0.093/小时，即使它没有在作业上工作。
- en: 'Once you click Create and open the Overview blade, you will see an empty dashboard:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你点击创建并打开概览面板，你将看到一个空的仪表盘：
- en: '![](img/989b4ee6-dfd4-4c1a-883a-91dcb9a90482.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/989b4ee6-dfd4-4c1a-883a-91dcb9a90482.png)'
- en: 'As you can see, both Inputs and Outputsare empty for now—we have to change
    this, so we can use them in our query. Both of the features are available on the
    left, in the JOB TOPOLOGYsection:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Inputs和Outputs目前都是空的——我们需要更改这些设置，这样我们才能在查询中使用它们。两项功能可以在左侧的JOB TOPOLOGY部分找到：
- en: '![](img/eb0061d0-855e-43dc-89ac-b6deb2a3dc9d.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb0061d0-855e-43dc-89ac-b6deb2a3dc9d.png)'
- en: Adding an input
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加输入
- en: 'To add an input, click on the Inputs blade. It will display an empty screen,
    where you have two possibilities:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加输入，点击Inputs面板。它将显示一个空白的屏幕，你有两种选择：
- en: + Add stream input: Here you can add a link to services that enable you to ingest
    a stream. Currently available Azure components are Azure Event Hub, Azure IoT
    Hub, and Azure Blob Storage. The inputs can live (or not) in the same subscription,
    and such a connection supports compression (so you can pass a compressed stream using,
    for example, GZip or deflate).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: + 添加流输入：在这里，你可以添加一个链接，连接到支持流数据接收的服务。目前可用的Azure组件包括Azure Event Hub、Azure IoT
    Hub和Azure Blob Storage。输入可以是实时的（也可以不是），并且这种连接支持压缩（例如，你可以传输使用GZip或deflate压缩的流）。
- en: + Add reference input: Instead of ingesting data from a real-time stream, you
    can also use Azure Blob Storage and add a reference to it, so you can ingest so-called reference
    data. In that scenario, Azure Stream Analytics will load the whole data into memory,
    so it can perform lookups on it. It is an ideal solution for static or slowly
    changing data, and supports data up to the maximum size of 300 MB
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: + 添加引用输入：您不仅可以从实时流中获取数据，还可以使用 Azure Blob Storage 并添加对其的引用，从而获取所谓的引用数据。在这种情况下，Azure
    Stream Analytics 会将整个数据加载到内存中，以便进行查找。这是处理静态或变化缓慢的数据的理想解决方案，并且支持最大为 300 MB 的数据。
- en: 'Here you can find an example of configuring Event Hub as an input:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以找到将 Event Hub 配置为输入的示例：
- en: '![](img/79d74fab-61f3-495c-8db9-9616807fe09d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79d74fab-61f3-495c-8db9-9616807fe09d.png)'
- en: 'Depending on your choices (whether you have an Event Hub in your subscription
    or not, whether it exists or not), there will be different options available.
    In the previous example, I configured a new hub (which was nonexistent) to be
    the source of my data. There are some fields, however, which I would like to cover
    now:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的选择（是否在您的订阅中有 Event Hub，是否存在 Event Hub），会有不同的选项可用。在之前的示例中，我配置了一个新的 Hub（它是不存在的）作为我的数据来源。下面有一些字段，我现在想解释一下：
- en: 'Event Hub consumer group: If you would like to make Azure Stream Analytics read
    data from the very beginning, enter a consumer group here. By default, it will
    use `$Default`, which is the default consumer group in Azure Event Hub.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Event Hub 消费者组：如果您希望 Azure Stream Analytics 从头开始读取数据，请在此输入消费者组。默认情况下，它将使用 `$Default`，这是
    Azure Event Hub 中的默认消费者组。
- en: 'Event serialization format: You can choose from JSON, Avro, and CSV. This allows
    you to deserialize events automatically, based on the used serialization format.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件序列化格式：您可以选择 JSON、Avro 和 CSV。这可以根据使用的序列化格式自动反序列化事件。
- en: 'Event compression type: If you are using GZip or Deflate, here you can choose
    the right option, so the input will be automatically deserialized.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件压缩类型：如果您使用的是 GZip 或 Deflate，在这里您可以选择正确的选项，这样输入将会自动反序列化。
- en: Note that you need an actual Azure Event Hub namespace to be able to  create
    a hub from Azure Stream Analytics automatically.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要一个实际的 Azure Event Hub 命名空间，才能通过 Azure Stream Analytics 自动创建一个 Hub。
- en: After filling all the required fields, you will be able to click on the Create button
    to initialize the creation of a new input. Of course, you can add more than just
    one input as they will all be available in the input stream, so you will be able
    to work with the incoming events. Before you start your job, you will need at
    least one output, which we are about to add now.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 填写所有必填字段后，您将能够点击“创建”按钮，初始化创建一个新的输入。当然，您可以添加多个输入，因为它们都会出现在输入流中，您将能够处理传入的事件。在开始作业之前，您至少需要一个输出，接下来我们将添加输出。
- en: Adding an output
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加输出
- en: 'To add an output, you have to click on the Outputs blade. It is similar to
    the Inputs one, but there are different kinds of output available:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加输出，您必须点击“输出”页面。它类似于“输入”页面，但有不同种类的输出可用：
- en: '![](img/6df0fb16-6d94-4ad7-9180-e9f97ea21ce8.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6df0fb16-6d94-4ad7-9180-e9f97ea21ce8.png)'
- en: 'As you can see, there are many different types of output available, which makes Azure
    Stream Analytics so flexible when it comes to pushing ingested data to different
    services. We can divide them into different categories:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有许多不同类型的输出可用，这使得 Azure Stream Analytics 在将获取的数据推送到不同服务时非常灵活。我们可以将它们分为不同类别：
- en: Storage: SQL database, Blob storage, Table storage, Cosmos DB, and Data Lake
    Store
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储：SQL 数据库、Blob 存储、Table 存储、Cosmos DB 和 Data Lake Store
- en: Reporting: Power BI
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 报告：Power BI
- en: Compute: Azure Functions
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算：Azure Functions
- en: Messaging: Event Hub, Service Bus
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息传递：Event Hub、Service Bus
- en: 'Depending on the category, you will have different options for what you can
    do with the processed events:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 根据类别，您将有不同的选项可以对处理过的事件进行操作：
- en: 'Storage: Storing data for further operations, archiving, and event log'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储：用于进一步操作、归档和事件日志的数据存储
- en: Reporting: Near real-time reports
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 报告：近实时报告
- en: Compute: An easy solution for achieving unlimited integration capabilities
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算：实现无限集成能力的简单解决方案
- en: Messaging: Pushing events further for different pipelines and systems
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息传递：将事件推送到不同的管道和系统
- en: 'Here you can find a configuration for integrating Azure Table storage as an
    output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以找到将 Azure Table 存储配置为输出的示例：
- en: '![](img/05d434e1-3b7e-4cdf-8b23-5bc4a81c4c3d.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05d434e1-3b7e-4cdf-8b23-5bc4a81c4c3d.png)'
- en: Available fields depend heavily on the selected output type, so I will not focus
    on them in this chapter. You can find a reference to them in the *Further reading*section.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可用字段很大程度上取决于所选的输出类型，因此我在本章中不会重点讨论这些内容。你可以在*进一步阅读*部分找到相关参考。
- en: Azure Stream Analytics query language
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Stream Analytics 查询语言
- en: The strength of Azure Stream Analytics, besides the rich selection of Azure
    services that seamlessly integrate with it, lies in its query language, which
    allows you to analyze an input stream easily and output it to a required service.
    As it is an SQL-like language, it should be intuitive and easy to learn for most
    developers using this service. Even if you are not familiar with SQL, the many
    examples available and its simple syntax should make it easy for you.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Azure Stream Analytics 丰富的 Azure 服务选择，可以无缝集成外，其强大之处还在于查询语言，它允许你轻松地分析输入流并将其输出到所需的服务。由于它是类似
    SQL 的语言，它应该对大多数使用该服务的开发者来说直观且容易学习。即使你不熟悉 SQL，提供的许多示例和简单的语法也应该使你容易掌握。
- en: Writing a query
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写查询
- en: 'In the Azure portal, the query window for Azure Stream Analytics can be found
    either in the Overview or Query blade:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure 门户中，Azure Stream Analytics 的查询窗口可以在概览或查询面板中找到：
- en: '![](img/ccdb9cfe-a9f2-4d77-9823-e423acf8c87c.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ccdb9cfe-a9f2-4d77-9823-e423acf8c87c.png)'
- en: 'In the preceding example, you can see a simple SQL-like query, which performs
    the following three things:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，你可以看到一个简单的类似 SQL 的查询，它执行以下三项操作：
- en: Selects data from the input using the given alias
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用给定的别名从输入中选择数据
- en: Chooses the particular columns
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择特定的列
- en: Pushes them into a specific output
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们推送到特定的输出中
- en: 'You can also click on the Edit querylink, so you will be routed to the Query screen:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以点击“编辑查询”链接，这样你将被引导到查询页面：
- en: '![](img/7414db1b-be82-4085-9504-6cd0af031699.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7414db1b-be82-4085-9504-6cd0af031699.png)'
- en: 'As you can see, to be able to actually work with a query, you will need both
    an input and an output, as without them you will not be able to save it. In general,
    a query consists of three elements:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，要实际使用查询，你需要同时拥有输入和输出，否则你将无法保存它。一般来说，查询由三个元素组成：
- en: '`SELECT`: Where you are selecting columns from the input you are interested
    in'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SELECT`：你从输入中选择你感兴趣的列'
- en: '`INTO`: Where you are telling the engine which output you are interested in'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`INTO`：你告诉引擎你感兴趣的输出'
- en: '`FROM`: Where you are selecting an input from which data should be fetched'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FROM`：你选择要从中提取数据的输入'
- en: 'Of course, the preceding statements are not the only ones, which are available—you
    can use plenty of different options, such as GROUP BY, LIKE, or HAVING. It all
    depends on the input stream and the schema of incoming data. For some jobs, you
    may only need to perform a quick transformation and extract the necessary columns;
    for others, you might require more sophisticated syntax for getting exactly what
    you want. You will find common query patterns in the link in the *Further reading*section.
    In the preceding example, in the `SELECT` part of the query, I have selected three
    columns, which are available when analyzing Azure Event Hub events. What is more,
    I used the `AS ` construct to tell the engine to actually rename fields to match
    those defined in the Outputs section. When I run my job, I can see that it actually
    passes events to my table:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，上述语句并不是唯一可用的—你可以使用许多不同的选项，如 GROUP BY、LIKE 或 HAVING。一切取决于输入流和传入数据的模式。对于某些任务，你可能只需要进行简单的转换并提取必要的列；而对于其他任务，你可能需要更复杂的语法来精确获取所需内容。你可以在*进一步阅读*部分的链接中找到常见的查询模式。在上面的示例中，在查询的
    `SELECT` 部分，我选择了三个在分析 Azure Event Hub 事件时可用的列。而且，我使用了 `AS` 构造，告诉引擎实际重命名字段以匹配 Outputs
    部分中定义的字段。当我运行作业时，我可以看到它确实将事件传递给了我的表：
- en: '![](img/79802b23-11fa-4186-8a01-2d5182fb8ea7.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79802b23-11fa-4186-8a01-2d5182fb8ea7.png)'
- en: 'However, there are some problems with the current setup:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当前配置存在一些问题：
- en: We rely on the Event Hub fields, which might change in the future.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们依赖于 Event Hub 字段，这些字段未来可能会发生变化。
- en: We are missing the actual data of an event.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们缺少事件的实际数据。
- en: There are duplicated columns.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在重复的列。
- en: 'Let''s assume each event has the following structure:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个事件具有以下结构：
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Of course, particular data changes over time. We can quickly change the query:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，特定数据会随时间变化。我们可以快速修改查询：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And adapt the configuration to change the output a little bit:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 并调整配置，稍微改变输出：
- en: '![](img/9668fd25-804b-4ef7-8cfa-e45792b367cf.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9668fd25-804b-4ef7-8cfa-e45792b367cf.png)'
- en: 'However, the basic constructs are only a few percent of the overall capability
    of the service. There are also inbuilt functions, which can be easily used in
    each query to enhance it, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，基本构造只占该服务整体能力的一小部分。还有一些内置函数，可以在每个查询中轻松使用以增强查询，具体如下：
- en: 'Mathematical functions:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数学函数：
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Aggregate functions:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚合函数：
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Analytic functions:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析函数：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Geospatial functions:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 地理空间函数：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'String functions:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 字符串函数：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In addition to these, there are some more such as record functions, date/time
    functions, conversion, or array functions. The preceding examples are of course
    not all the available functions. You can find them all in the *Further reading*section.
    The important thing here is that some functions are deterministic (this means
    that they always return the same result if the same input values are used), and
    some are not—this is especially important when handling high loads and trying
    to avoid possible anomalies.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些，还有一些其他函数，如记录函数、日期/时间函数、转换函数或数组函数。上述示例当然并不是所有可用的函数。你可以在*进一步阅读*部分找到所有的函数。这里需要记住的重要一点是，某些函数是确定性的（这意味着，如果使用相同的输入值，它们总是返回相同的结果），而有些则不是——这在处理高负载并试图避免可能的异常时尤其重要。
- en: Remember, you can merge different streams of data and push them to a single
    output (or vice versa—have a single input and distribute it to multiple outputs).
    This is a very powerful feature of this service, which makes ingesting and processing
    data much easier.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，你可以合并不同的数据流并将它们推送到单个输出（或者反过来——有一个输入并将其分发到多个输出）。这是此服务的一个非常强大的功能，使得数据的摄取和处理变得更加容易。
- en: Event ordering, checkpoints, and replays
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件排序、检查点和重放
- en: 'In the previous sections, we covered some basic topics of Azure Stream Analytics:
    how to configure inputs and outputs, querying data, and using the service. In
    the last part of this chapter, I will show you its more advanced features such
    as event ordering, checkpoints, and replays, which ensure that events are processed
    exactly in a way you would expect. These topics are in fact common subjects in
    many different messaging solutions, so you will be able to use knowledge from
    this chapter in your other projects.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们介绍了 Azure Stream Analytics 的一些基础主题：如何配置输入和输出、查询数据以及使用该服务。在本章的最后部分，我将向你展示它的一些更高级的功能，如事件排序、检查点和重放，这些功能确保事件以你预期的方式被精确处理。这些话题实际上是许多不同消息传递解决方案中的常见内容，因此你可以将本章中的知识应用到其他项目中。
- en: Event ordering
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件排序
- en: 'There are two concepts of events when it comes to their ordering:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件排序时有两个概念：
- en: Application (or event) time
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用时间（或事件时间）
- en: Arrival time
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到达时间
- en: 'There is a clear distinction between them:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 它们之间有明显的区别：
- en: '**Application time**: This is a timestamp when an event was generated on the
    client (or application) side. It tells you exactly when it occurred.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用时间**：这是事件在客户端（或应用程序）端生成的时间戳。它告诉你事件发生的确切时间。'
- en: '**Arrival time**: This is a system timestamp, which is not present in the original
    payload. It tells you when an event was received by a service and picked up for
    processing.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**到达时间**：这是一个系统时间戳，在原始负载中不存在。它告诉你事件何时被服务接收并开始处理。'
- en: 'Depending on the input type, arrival time and application time will be different
    properties (`EventEnqueuedUtcTime `or `EnqueuedTime `for arrival time, whereas
    application time, in general, will be a generic property). What you have to remember
    is, depending on the selected scenario, you can process events as they come but
    out of order, or in order but delayed. This can be easily described using the
    following event sequence:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输入类型， 到达时间和 应用时间将是不同的属性（`EventEnqueuedUtcTime`或`EnqueuedTime`表示到达时间，而应用时间通常将是一个通用属性）。你需要记住的是，根据所选择的场景，你可以按顺序处理事件但有延迟，或者按乱序处理事件。这个可以通过以下事件序列轻松描述：
- en: '**Arrival**: `2018-09-02T12:17:49` **Application**: `2018-09-02T12:17:48`'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**到达时间**：`2018-09-02T12:17:49` **应用时间**：`2018-09-02T12:17:48`'
- en: '**Arrival**: `2018-09-02T12:17:50` **Application**:` 2018-09-02T12:17:44`'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**到达时间**：`2018-09-02T12:17:50` **应用时间**：`2018-09-02T12:17:44`'
- en: '**Arrival**: `2018-09-02T12:17:51` **Application**:`2018-09-02T12:17:46`'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**到达时间**：`2018-09-02T12:17:51` **应用时间**：`2018-09-02T12:17:46`'
- en: If you process events as they come into the stream, they will be processed **out
    of order**—in fact, they occurred in a different order, so there is a possibility
    that some data will be outdated. The other option is to sort events by application
    time; in such a scenario, the process will be delayed, but the order will be preserved.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果按事件流到来的顺序处理，它们将被**无序处理**——实际上，它们发生的顺序不同，因此有可能某些数据会变得过时。另一种选择是按应用时间对事件进行排序；在这种情况下，处理会延迟，但顺序将得以保留。
- en: Whether you need to or not, processing events in order depends on the data schema
    and characteristics of the processed events. Processing them in order is more
    time-consuming, but sometimes you just cannot do it the other way.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 是否需要按顺序处理事件，取决于数据模式和已处理事件的特征。按顺序处理事件更耗时，但有时你根本无法采用其他方式。
- en: 'Azure Stream Analytics has a feature named Event ordering, which allows you
    to make a decision about what to do with events, which are either out of order
    or outdated:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**Azure Stream Analytics** 具有一个名为事件排序的功能，允许你决定如何处理无序或过时的事件：'
- en: '![](img/053f17d5-6cee-4585-a4ce-77f90fc5ddf0.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/053f17d5-6cee-4585-a4ce-77f90fc5ddf0.png)'
- en: 'There are two options available:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种可用选项：
- en: 'Events that arrive late: This one allows you to process outdated events (for
    which the application time does not match the one processed as the last one) within
    a defined time window.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟到达的事件：这一选项允许你在定义的时间窗口内处理过时的事件（即应用时间与最后处理的事件时间不匹配的事件）。
- en: 'Out of order events: It is possible that Azure Stream Analytics consider some
    of your events to be  out of order (this situation could happen, for instance,
    if your senders'' clocks are skewed). Here you can set a time window, during which
    this situation is acceptable).'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无序事件：可能会发生**Azure Stream Analytics** 将一些事件视为无序事件的情况（例如，如果发送方的时钟不一致）。在这种情况下，你可以设置一个时间窗口，在该时间窗口内可以接受此情况。
- en: Additionally, you can define an action, which will be performed if an event
    either arrived late or was out of order—for Drop, it will simply be removed, and
    if you select Adjust, processing will be suspended for some time when such situations
    occur.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以定义一个操作，如果事件迟到或无序，则会执行该操作——对于丢弃（Drop）操作，它将被简单移除，如果选择调整（Adjust），当这种情况发生时，处理将暂停一段时间。
- en: Checkpoints and replays
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查点和重放
- en: 'In fact, Azure Stream Analytics is a stateful service, which is able to track
    the event-processing progress. This makes it suitable for the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，**Azure Stream Analytics** 是一个有状态服务，能够跟踪事件处理进度。这使得它适用于以下场景：
- en: Job recovery
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业恢复
- en: Stateful query logic
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有状态查询逻辑
- en: Different job start modes (now, custom, and when last stopped)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的作业启动模式（现在、自定义和上次停止时）
- en: 'Of course, there is a difference between what is possible after the checkpoint
    and when a replay is necessary. There are situations when the data stored within
    a checkpoint is not enough, and the whole replay is required; however, this may
    differ depending on your query. In fact, it depends on the query parallelization
    factor and can be described using the following formula:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在检查点之后和重放时，情况是有所不同的。当检查点中存储的数据不足时，可能需要进行完整的重放；然而，这取决于你的查询。实际上，它依赖于查询的并行化因素，可以通过以下公式描述：
- en: '*[The input event rate] x [The gap length] / [Number of processing partitions]*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*[输入事件速率] x [间隔长度] / [处理分区数]*'
- en: The more processors you have, the faster you can recover when something goes
    wrong. A good rule of thumb is to introduce more SUs in case your job fails and
    you have to close the gap quickly.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器越多，出现问题时恢复得越快。一个好的经验法则是，当作业失败并且你需要快速填补间隙时，增加更多的 SUs。
- en: The important thing to consider when replaying data is the use of window functions in
    your queries (tumbling, hopping, sliding, or session)—they allow you to process
    data in different kinds of windows, but complicate the replay mechanism.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 重放数据时需要考虑的重要因素是查询中使用的窗口函数（滚动窗口、跳跃窗口、滑动窗口或会话窗口）——它们允许你在不同类型的窗口中处理数据，但也使得重放机制变得复杂。
- en: Summary
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered Azure Stream Analytics, a service for processing
    streams of data in near real time. You have learned what the available inputs
    and outputs are and how to configure them. What is more, you were able to write
    your first query, and check how the query language works for analyzing and processing
    incoming events. If you need a PaaS  that can quickly read and transform events
    and push them to many different Azure services, Azure Stream Analytics is for
    you.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 Azure Stream Analytics，这是一个用于近实时处理数据流的服务。你已经了解了可用的输入和输出，并学习了如何配置它们。而且，你也能够编写你的第一个查询，并查看查询语言如何用于分析和处理传入事件。如果你需要一个能够快速读取和转换事件，并将其推送到多个不同
    Azure 服务的 PaaS，Azure Stream Analytics 就是你需要的服务。
- en: In the next chapter, we will go through Azure Service Bus, an enterprise-class
    messaging solution that is in fact the foundation of Azure Event Hub, which we
    discussed previously.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讲解 Azure Service Bus，这是一种企业级的消息传递解决方案，实际上是我们之前讨论的 Azure Event Hub 的基础。
- en: Questions
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the payment model for Azure Stream Analytics?
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Azure Stream Analytics 的付费模型是什么？
- en: What is the difference between a stream and the reference output?
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流和引用输出有什么区别？
- en: What is the difference between application and arrival time?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用时间和到达时间有什么区别？
- en: Which query construct do you need to select an ID from an input and push it
    to an output?
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要使用哪个查询构造来选择输入中的 ID 并将其推送到输出？
- en: Can you process different inputs in the same query?
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能在同一个查询中处理不同的输入吗？
- en: When is an event considered out of order?
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时认为事件是无序的？
- en: Is it possible to get a substring from a property in a query? If so, which function
    can be used for that?
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否可以从查询中的某个属性提取子字符串？如果可以，应该使用哪个函数？
- en: Further reading
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Scaling and SUs: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption)
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展和 SUs：[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption)
- en: Different output types: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的输出类型： [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-define-outputs)
- en: Common query patterns: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见查询模式：[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-stream-analytics-query-patterns)
- en: Window functions: [https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 窗口函数：[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)
